[
    {
        "Projects": [],
        "keywords": [
            "Hypertext",
            "browsing",
            "information retrieval",
            "information seeking",
            "evaluation",
            "hcir"
        ],
        "AcceptDate": "08/21/2001",
        "palwebID": "PR-01-005",
        "Venue": "Information Processing and Management 37 (3) pp. 507-520",
        "palwebURL": [],
        "PublicationDate": "08/21/2001",
        "ID": "5",
        "Authors": [
            "Richard Bodner",
            "Mark Chignell",
            "Nipon Charoenkitkarn",
            "Gene Golovchinsky",
            "Richard Kopak"
        ],
        "Title": "The impact of text browsing on text retrieval performance.",
        "Abstract": "The results from a series of three experiments that used Text Retrieval Conference (TREC) data and TREC search topics are compared. These experiments each involved three novel user interfaces (one per experiment). User interfaces that made it easier for users to view text were found to improve recall in all three experiments. A distinction was found between a cluster of subjects (a majority of whom were search experts) who tended to read fewer documents more carefully (readers, or exclusives) and subjects who skimmed through more documents without reading them as carefully (skimmers, or inclusives). Skimmers were found to have significantly better recall overall. A major outcome from our experiments at TREC and with the TREC data, is that hypertext interfaces to information retrieval (IR) tasks tend to increase recall. Our interpretation of this pattern of results across the three experiments is that increased interaction with the text (more pages viewed) generally improves recall. Findings from one of the experiments indicated that viewing a greater diversity of text on a single screen (i.e., not just more text per se, but more articles available at once) may also improve recall. In an experiment where a traditional (type-in) query interface was contrasted with a condition where queries were marked up on the text, the improvement in recall due to viewing more text was more pronounced with search novices. Our results demonstrate that markup and hypertext interfaces to text retrieval systems can benefit recall and can also benefit novices. The challenge now will be to find modified versions of hypertext interfaces that can improve precision, as well as recall and that can work with users who prefer to use different types of search strategy or have different types of training and experience."
    },
    {
        "Projects": [
            "Manga",
            "MBase",
            "VideoKeyframes"
        ],
        "keywords": [
            "manga",
            "mbase",
            "media",
            "video",
            "keyframes"
        ],
        "AcceptDate": "08/21/2001",
        "palwebID": "PR-01-006",
        "Venue": "IEEE Computer, 34(9), pp. 61-67",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-006/FXPAL-PR-01-006.pdf"
        ],
        "PublicationDate": "09/01/2001",
        "ID": "6",
        "Authors": [
            "Andreas Girgensohn",
            "John Boreczky",
            "Lynn Wilcox"
        ],
        "Title": "Keyframe-Based User Interfaces for Digital Video\r\n\r\n\r\n\r\n\r\n\r\n",
        "Abstract": "To meet the diverse needs of business, education, and personal video users, the authors developed three visual interfaces that help identify potentially useful or relevant video segments. In such interfaces, keyframes-still images automatically extracted from video footage-can distinguish videos, summarize them, and provide access points. Well-chosen keyframes enhance a listing's visual appeal and help users select videos. Keyframe selection can vary depending on the application's requirements: A visual summary of a video-captured meeting may require only a few highlight keyframes, a video editing system might need a keyframe for every clip, while a browsing interface requires an even distribution of keyframes over the video's full length. The authors conducted user studies for each of their three interfaces, gathering input for subsequent interface improvements. The studies revealed that finding a similarity measure for collecting video clips into groups that more closely match human perception poses a challenge. Another challenge is to further improve the video-segmentation algorithm used for selecting keyframes. A new version will provide users with more information and control without sacrificing the interface's ease of use. \r\n"
    },
    {
        "Projects": [
            "FlySPEC",
            "FlyCam"
        ],
        "keywords": [
            "immersive",
            "flyspec",
            "spec",
            "flycam"
        ],
        "AcceptDate": "08/21/2001",
        "palwebID": "PR-01-007",
        "Venue": "In Proceedings of Conference on Modeling and Design of Wireless Networks (ITCOM2001), Denver, Colorado, August 23-24 August 2001.",
        "palwebURL": [],
        "PublicationDate": "08/23/2001",
        "ID": "7",
        "Authors": [
            "Qiong Liu"
        ],
        "Title": "On Building Automatic Camera-Management System for Online Lecture Broadcast",
        "Abstract": ""
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-016",
        "Venue": "In Proceedings of UBICOMP 2001, Atlanta, Georgia. September 30-October 2, 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-016/PR-01-016.pdf"
        ],
        "PublicationDate": "09/30/2001",
        "ID": "16",
        "Authors": [
            "Paul Castro",
            "Patrick Chiu",
            "Ted  Kremenek",
            "Richard Muntz"
        ],
        "Title": "A probabilistic room location service for wireless networked environments",
        "Abstract": "The popularity of wireless networks has increased in recent years and is becoming a common addition to LANs. In this paper we investigate a novel use for a wireless network based on the IEEE 802.11 standard: inferring the location of a wireless client from signal quality measures. Similar work has been limited to prototype systems that rely on nearest-neighbor techniques to\r\ninfer location. In this paper, we describe Nibble, a Wi-Fi location service that\r\nuses Bayesian networks to infer the location of a device. We explain the general\r\ntheory behind the system and how to use the system, along with describing our\r\nexperiences at a university campus building and at a research lab. We also\r\ndiscuss how probabilistic modeling can be applied to a diverse range of\r\napplications that use sensor data."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [
            "media"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-017",
        "Venue": "In Proceedings of Tenth World Wide Web Conference (2001), Hong Kong, May 1-5, 2001, pp. 140-149.<BR>\r\n\r\nAvailable at <A HREF=\"http://www10.org\">www10.org</A>\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-017/PR-01-017.pdf"
        ],
        "PublicationDate": "05/01/2001",
        "ID": "17",
        "Authors": [
            "Patrick Chiu",
            "John Boreczky",
            "Andreas Girgensohn",
            "Don Kimber"
        ],
        "Title": "LiteMinutes: An Internet-Based System for Multimedia Meeting Minutes",
        "Abstract": "The Internet provides a highly suitable infrastructure for sharing multimedia meeting records, especially as multimedia technologies become more lightweight and workers more mobile. LiteMinutes is a system that uses both the Web and email for creating, revising, distributing, and accessing multimedia information captured in a meeting. Supported media include text notes taken on wireless laptops, slide images captured from presentations, and video recorded by cameras in the room. At the end of a meeting, text notes are sent by the note taking applet to the server, which formats them in HTML with links from each note item to the captured slide images and video recording. Smart link generation is achieved by capturing contextual metadata such as the on/off state of the media equipment and the room location of the laptop, and inferring whether it makes sense to supply media links to a particular note item. Note takers can easily revise meeting minutes after a meeting by modifying the email message sent to them and mailing it back to the server\u2019s email address. We explore design issues concerning preferences for email and Web access of meeting minutes, as well as the different timeframes for access. We also describe the integration with a comic book style video summary and visualization system with text captions for browsing the video recording of a meeting."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-018",
        "Venue": "316 pages 1st edition (March 15, 2001); Springer Verlag; ISBN: 1852332441",
        "palwebURL": [],
        "PublicationDate": "03/15/2001",
        "ID": "18",
        "Authors": [
            "Elizabeth Churchill",
            "David Snowdon"
        ],
        "Title": "Collaborative Virtual Environments. Digital Places and Spaces for Interaction. ",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-019",
        "Venue": "In B. Brown, N. Green, R. Harper (Eds.) Wireless World: Social and Interactional Aspects of Wireless Technology,\r\n\r\nLondon, UK: Springer-Verlag. To appear.\r\n\r\n",
        "palwebURL": [],
        "PublicationDate": "12/01/2001",
        "ID": "19",
        "Authors": [
            "Elizabeth Churchill",
            "Nina Wakeford"
        ],
        "Title": "Framing Mobile Collaborations and Mobile Technologies.",
        "Abstract": "Recent years have seen a marked increase in the production and promotion of portable,\r\nwireless communication devices: mobile phones with internet access, wireless PDAs\r\nsuch as the Palm VII and smart pagers such as RIM's 850 and 950. Some claim the\r\npresence of such devices in the hands, bags and pockets of so many people heralds a new\r\nworld of work in which people can be reached and information accessed \"anywhere,\r\nanytime\". Whether or not access to information in itself can promote new working\r\npractices, individuals whose lives revolve around movement between work sites have\r\nbeen singled out as an obvious market for such portable wireless communication devices.\r\nUsing these devices such \u00e2\u20ac\u0153mobile workers\u00e2\u20ac\u009d can be in touch with colleagues, collaborators\r\nand clients \"24/7\", and still sustain non-work social relationships due, apparently, to their\r\nconstant connectedness whilst mobile.\r\nIn this chapter we have two goals. The first is to address the design of mobile\r\ntechnologies. This second is to illustrate our design approach, wherein we consider local\r\npractices of technology use, but also the broader cultural context in which technologies\r\nare designed, produced, bought, sold, used and redesigned. Our ultimate design aim is to\r\nbuild upon existing practices, but also to consider possibilities for the development of\r\ninnovative technologies that enable new, complementary, practices."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "media",
            "similarity",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-020",
        "Venue": "In Proceedings of the International Conference on Image Processing, Thessaloniki, Greece. October 7-10, 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-020/FXPAL-PR-01-020.pdf"
        ],
        "PublicationDate": "10/07/2001",
        "ID": "20",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote"
        ],
        "Title": "Scene Boundary Detection Via Video Self-Similarity Analysis.\r\n\r\n",
        "Abstract": "In this paper, we present a novel framework for analyzing video using self-similarity. Video scenes are located by analyzing inter-frame similarity matrices. The approach is flexible to the choice of similarity measure and is robust and data-independent because the data is used to model itself. We present the approach and its application to scene boundary detection. This is shown to dramatically outperform a conventional scene-boundary detector that uses a histogram-based measure of frame difference."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-01-021",
        "Venue": "In Collaborative Virtual Environments. Digital Places and Spaces for Interaction. Springer Verlag, 2001, pages 265-281.  \r\n",
        "palwebURL": [],
        "PublicationDate": "03/15/2001",
        "ID": "21",
        "Authors": [
            "R\u00e9my Evard",
            "Elizabeth Churchill",
            "Sara Bly"
        ],
        "Title": "Waterfall Glen: Social Virtual Reality at Work. ",
        "Abstract": "social computing"
    },
    {
        "Projects": [],
        "keywords": [
            "similarity",
            "music",
            "media",
            "audio"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-022",
        "Venue": "In Proceedings of the International Conference on Multimedia and Expo 2001 (ICME), Tokyo, Japan. August 22-25, 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-022/FXPAL-PR-01-022.pdf"
        ],
        "PublicationDate": "08/25/2001",
        "ID": "22",
        "Authors": [
            "Jonathan Foote",
            "Shingo Uchihashi"
        ],
        "Title": "The Beat Spectrum: A New Approach to Rhythm Analysis\r\n\r\n\r\n\r\n",
        "Abstract": "We introduce the beat spectrum, a new method of automatically characterizing the rhythm and tempo of music and audio. The beat spectrum is a measure of acoustic self-similarity as a function of time lag. Highly structured or repetitive music will have strong beat spectrum peaks at the repetition times. This reveals both tempo and the relative strength of particular beats, and therefore can distinguish between different kinds of rhythms at the same tempo. We also introduce the beat spectrogram which graphically illustrates rhythm variation over time. Unlike previous approaches to tempo analysis, the beat spectrum does not depend on particular attributes such as energy or frequency, and thus will work for any music or audio in any genre. We present tempo estimation results for a variety of musical genres, which are accurate to within 1%. This approach has a variety of applications, including music retrieval by similarity and automatically  generating music videos."
    },
    {
        "Projects": [
            "FlyCam"
        ],
        "keywords": [
            "immersive",
            "video",
            "flycam"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-023",
        "Venue": "In Proceedings of the Thirty-fourth Annual Hawaii International Conference on System Sciences (HICSS), Big Island, Hawaii. January 7-12, 2001.\r\n\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-023/FXPAL-PR-01-023.pdf"
        ],
        "PublicationDate": "02/07/2001",
        "ID": "23",
        "Authors": [
            "Jonathan Foote",
            "Don Kimber"
        ],
        "Title": "Enhancing Distance Learning with Panoramic Video\r\n\r\n",
        "Abstract": "This paper describes a new system for panoramic two-way video communication. Digitally combining images from an array of inexpensive video cameras results in a wide-field panoramic camera, from inexpensive off-the-shelf hardware. This system can aid distance learning in several ways, by both presenting a better view of the instructor and teaching materials to the students, and by enabling better audience feedback to the instructor. Because the camera is fixed with respect to the background, simple motion analysis can be used to track objects and people of interest. Electronically selecting a region of this results in a rapidly steerable \"virtual camera.\" We present system details and a prototype distance-learning scenario using multiple panoramic cameras."
    },
    {
        "Projects": [
            "Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-024",
        "Venue": "In Proceedings of Human-Computer Interaction (INTERACT '01), IOS Press, Tokyo, Japan, pp. 464-471",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-024/FXPAL-PR-01-024.pdf"
        ],
        "PublicationDate": "07/09/2001",
        "ID": "24",
        "Authors": [
            "Andreas Girgensohn",
            "Sara Bly",
            "Frank Shipman",
            "John Boreczky",
            "Lynn Wilcox"
        ],
        "Title": "Home Video Editing Made Easy - Balancing Automation and User Control\r\n\r\n",
        "Abstract": "Hitchcock is a system to simplify the process of editing video. Its key features are the use of automatic analysis to find the best quality video clips, an algorithm to cluster those clips into meaningful piles, and an intuitive user interface for combining the desired clips into a final video. We conducted a user study to determine how the automatic clip creation and pile navigation support users in the editing process. The study showed that users liked the ease-of-use afforded by automation, but occasionally had problems navigating and overriding the automated editing decisions. These findings demonstrate the need for a proper balance between automation and user control. Thus, we built a new version of Hitchcock that retains the automatic editing features, but provides additional controls for navigation and for allowing users to modify the system decisions."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "digital libraries",
            "mobility"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-025",
        "Venue": "Communications of the ACM. 44(5), May 2001, ACM Press. pp. 55-56.",
        "palwebURL": [],
        "PublicationDate": "05/01/2001",
        "ID": "25",
        "Authors": [
            "Catherine Marshall",
            "Gene Golovchinsky",
            "Morgan Price"
        ],
        "Title": "Digital libraries and mobility.\r\n",
        "Abstract": "Available at the ACM Digital Library <a href=\"http://doi.acm.org/10.1145/374308.374340\" target=\"_blank\" >here</a>"
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "field work",
            "e-books",
            "digital libraries"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-026",
        "Venue": "In Proceedings of JCDL 2001 (Roanoke, VA, June 23-27). ACM Press. pp. 41-48. ",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-026/FXPAL-PR-01-026.pdf"
        ],
        "PublicationDate": "06/23/2001",
        "ID": "26",
        "Authors": [
            "Catherine Marshall",
            "Morgan Price",
            "Gene Golovchinsky",
            "Bill Schilit"
        ],
        "Title": "<img src=\"/images/honorable.png\" title=\"Honorable mention for Vannevar Bush Best Paper Award\" border=\"0\"/> Designing e-Books for Legal Research.",
        "Abstract": "In this paper we report the findings from a field study of legal research in a first-tier law school and on the resulting redesign of XLibris, a next-generation e-book. We first characterize a work setting in which we expected an e-book to be a useful interface for reading and otherwise using a mix of physical and digital library materials, and explore what kinds of reading-related functionality would bring value to this setting. We do this by describing important aspects of legal research in a heterogeneous information environment, including mobility, reading, annotation, link following and writing practices, and their general implications for design. We then discuss how our work with a user community and an evolving e-book prototype allowed us to examine tandem issues of usability and utility, and to redesign an existing e-book user interface to suit the needs of law students. The study caused us to move away from the notion of a stand-alone reading device and toward the concept of a document laptop, a platform that would provide wireless access to information resources, as well as support a fuller spectrum of reading-related activities."
    },
    {
        "Projects": [],
        "keywords": [
            "quiet calls",
            "SocComp"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-027",
        "Venue": "In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 174-181, ACM Press, March 31-April 5, 2001, Seattle, WA.",
        "palwebURL": [],
        "PublicationDate": "03/31/2001",
        "ID": "27",
        "Authors": [
            "Les Nelson",
            "Sara Bly",
            "Tomas Sokoler"
        ],
        "Title": "Quiet Calls: Talking Silently on Mobile Phones, ",
        "Abstract": ""
    },
    {
        "Projects": [
            "M-Links"
        ],
        "keywords": [
            "ubiquitous",
            "m-links"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-028",
        "Venue": "The 7th Annual International Conference on Mobile Computing and Networking (MOBICOM 2001), Rome, Italy, July 16-21 2001, ACM Press, 2001, pp. 122-131.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-028/FXPAL-PR-01-028.pdf"
        ],
        "PublicationDate": "07/16/2001",
        "ID": "28",
        "Authors": [
            "Bill Schilit",
            "Jonathan Trevor",
            "David Hilbert",
            "T.K. Koh"
        ],
        "Title": "m-Links: An Infrastructure for Very Small Internet Devices. \r\n\r\n",
        "Abstract": "In this paper we describe the Mobile Link (m-Links) infrastructure for utilizing existing World Wide Web content and services on wireless phones and other very small Internet terminals. Very small devices, typically with 3-20 lines of text, provide portability and other functionality while sacrificing usability as Internet terminals. In order to provide access on such limited hardware we propose a small device web navigation model that is more appropriate than the desktop computers web browsing model. We introduce a middleware proxy, the Navigation Engine, to facilitate the navigation model by concisely displaying the Webs link (i.e., URL) structure. Because not all Web information is appropriately \"linked,\" the Navigation Engine incorporates data-detectors to extract bits of useful information such as phone numbers and addresses. In order to maximize program-data composibility, multiple network-based services (similar to browser plug-ins) are keyed to a links attributes such as its MIME type. We have built this system with an emphasis on user extensibility and we describe the design and implementation as well as a basic set of middleware services that we have found to be particularly important."
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-030",
        "Venue": "ACM Symposium on Applied Computing,  SAC 2002. To Appear. \r\n\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-030/FXPAL-PR-02-030.pdf"
        ],
        "PublicationDate": "03/11/2002",
        "ID": "30",
        "Authors": [
            "Brad Dolin",
            "Forrest Bennett",
            "Eleanor Rieffel"
        ],
        "Title": "Co-evolving an Effective Fitness Sample: Experiments in Symbolic Regression and Distributed Robot Control. \r\n\r\n",
        "Abstract": ""
    },
    {
        "Projects": [
            "FlyCam"
        ],
        "keywords": [
            "flycam"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-031",
        "Venue": "Proc. International Conference on Image Processing, Thessaloniki, Greece, September 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-031/FXPAL-PR-01-031.pdf"
        ],
        "PublicationDate": "09/01/2001",
        "ID": "31",
        "Authors": [
            "Xinding Sun",
            "Jonathan Foote",
            "Don Kimber",
            "B. Manjunath"
        ],
        "Title": "Recording the Region of Interest from FlyCam Panoramic Video\r\n",
        "Abstract": "A novel method for region of interest tracking and recording\r\nvideo is presented. The proposed method is based on the FlyCam system, which produces high resolution and wide-angle\r\nvideo sequences by stitching the video frames from multiple\r\nstationary cameras. The method integrates tracking and\r\nrecording processes, and targets applications such as classroom lectures and video conferencing. First, the region of interest (which typically covers the speaker) is tracked using a Kalman filter. Then, the Kalman filter estimation results are used for virtual camera control and to record the video. The system has no physical camera motion and the virtual camera parameters are readily available for video indexing. The proposed system has been implemented for real time recording of lectures and presentations."
    },
    {
        "Projects": [
            "FlyCam"
        ],
        "keywords": [
            "flycam",
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-032",
        "Venue": "Proc. ACM Multimedia 2001, Ottawa, CA, Oct. 2001. \r\n",
        "palwebURL": [],
        "PublicationDate": "10/01/2001",
        "ID": "32",
        "Authors": [
            "Xinding Sun",
            "Jonathan Foote",
            "Don Kimber",
            "B. Manjunath"
        ],
        "Title": "Panoramic Video Capturing and Compressed Domain Virtual Camera Control.\r\n",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "quantum"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-038",
        "Venue": "ACM Computing Surveys, Vol. 32(3), pp. 300 - 335",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-038/FXPAL-PR-00-038.pdf"
        ],
        "PublicationDate": "09/01/2000",
        "ID": "38",
        "Authors": [
            "Eleanor Rieffel",
            "Wolfgang Polak"
        ],
        "Title": "An Introduction to Quantum Computing for Non-Physicists.",
        "Abstract": "Richard Feynman's observation that quantum mechanical effects could not be simulated efficiently on a computer led to speculation that computation in general could be done more efficiently if it used quantum effects. This speculation appeared justified when Peter Shor described a polynomial time quantum algorithm for factoring integers. In quantum systems, the computational space increases exponentially with the size of the system which enables exponential parallelism. This parallelism could lead to exponentially faster quantum algorithms than possible classically. The catch is that accessing the results, which requires measurement, proves tricky and requires new non-traditional programming techniques. The aim of this paper is to guide computer scientists and other non-physicists through the conceptual and notational barriers that separate quantum computing from conventional computing. We introduce basic principles of quantum mechanics to explain where the power of quantum computers comes from and why it is difficult to harness. We describe quantum cryptography, teleportation, and dense coding. Various approaches to harnessing the power of quantum parallelism are explained, including Shor's algorithm, Grover's algorithm, and Hogg's algorithms. We conclude with a discussion of quantum error correction. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-039",
        "Venue": "CHI 98 Summary, ACM Press, 1998, pp. 141-142.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-039/FXPAL-PR-98-039.pdf"
        ],
        "PublicationDate": "04/18/1998",
        "ID": "39",
        "Authors": [
            "Andreas Girgensohn",
            "Alison Lee"
        ],
        "Title": "Developing Collaborative Applications On the World Wide Web. ",
        "Abstract": "The World Wide Web is often viewed as the latest and most user friendly way of providing information over the Internet (i.e., server of documents). It is not customarily viewed as a platform for developing and deploying applications. In this tutorial, we introduce, demonstrate, and discuss how Web technologies like CGI scripts, Javascript, and Java can be used in combination with Web browsers to design, create, distribute and execute collaborative applications. We discuss constraints with the Web approach as well as recent extensions that support application development. "
    },
    {
        "Projects": [
            "MBase"
        ],
        "keywords": [
            "video",
            "media",
            "mbase"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-041",
        "Venue": "In IEEE Multimedia Systems '99, IEEE Computer Society, vol. 1, pp. 756-761, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-041/FXPAL-PR-99-041.pdf"
        ],
        "PublicationDate": "02/01/1999",
        "ID": "41",
        "Authors": [
            "Andreas Girgensohn",
            "John Boreczky"
        ],
        "Title": "Time-Constrained Keyframe Selection Technique.",
        "Abstract": "In accessing large collections of digitized videos, it is often difficult to find both the appropriate video file and the portion of the video that is of interest. This paper describes a novel technique for determining keyframes that are different from each other and provide a good representation of the whole video. We use keyframes to distinguish videos from each other, to summarize videos, and to provide access points into them. The technique can determine any number of keyframes by clustering the frames in a video and by selecting a representative frame from each cluster. Temporal constraints are used to filter out some clusters and to determine the representative frame for a cluster. Desirable visual features can be emphasized in the set of keyframes. An application for browsing a collection of videos makes use of the keyframes to support skimming and to provide visual summaries. \r\n\r\n"
    },
    {
        "Projects": [
            "MBase",
            "VideoKeyframes"
        ],
        "keywords": [
            "mbase",
            "media",
            "video",
            "keyframes"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-042",
        "Venue": "In Multimedia Tools and Applications, 11(3), pp. 347-358, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-042/FXPAL-PR-00-042.pdf"
        ],
        "PublicationDate": "08/01/2000",
        "ID": "42",
        "Authors": [
            "Andreas Girgensohn",
            "John Boreczky"
        ],
        "Title": "Time-Constrained Keyframe Selection Technique.",
        "Abstract": "In accessing large collections of digitized videos, it is often difficult to find both the appropriate video file and the portion of the video that is of interest. This paper describes a novel technique for determining keyframes that are different from each other and provide a good representation of the whole video. We use keyframes to distinguish videos from each other, to summarize videos, and to provide access points into them. The technique can determine any number of keyframes by clustering the frames in a video and by selecting a representative frame from each cluster. Temporal constraints are used to filter out some clusters and to determine the representative frame for a cluster. Desirable visual features can be emphasized in the set of keyframes. An application for browsing a collection of videos makes use of the keyframes to support skimming and to provide visual summaries."
    },
    {
        "Projects": [],
        "keywords": [
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-043",
        "Venue": "In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (Phoenix, AZ), vol. 6, pp. 3045-3048, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-043/FXPAL-PR-99-043.pdf"
        ],
        "PublicationDate": "03/15/1999",
        "ID": "43",
        "Authors": [
            "Andreas Girgensohn",
            "Jonathan Foote"
        ],
        "Title": "Video Classification Using Transform Coefficients.",
        "Abstract": "This paper describes techniques for classifying video frames using statistical models of reduced DCT or Hadamard transform coefficients. When decimated in time and reduced using truncation or principal component analysis, transform coefficients taken across an entire frame image allow rapid modeling, segmentation, and similarity calculation. Unlike color-histogram metrics, this approach models image composition and works on grayscale images. Modeling the statistics of the transformed video frame images gives a likelihood measure that allows video to be segmented, classified, and ranked by similarity for retrieval. Experiments are presented that show an 87% correct classification rate for different classes. Applications are presented including a content-aware video browser. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-044",
        "Venue": "In Human-Computer Interaction INTERACT '99, IOS Press, pp. 458-465, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-044/FXPAL-PR-99-044.pdf"
        ],
        "PublicationDate": "08/30/1999",
        "ID": "44",
        "Authors": [
            "Andreas Girgensohn",
            "Alison Lee",
            "Thea Turner"
        ],
        "Title": "Being in Public and Reciprocity: Design for Portholes and User Preference.",
        "Abstract": "In our Portholes research, we found that users needed to have a sense of being in public and to know who can see them (audience) and who is looking currently at them (lookback). Two redesigns of the Portholes display present a 3D theater view of the audience. Different sections display core team members, non-core team members and lookback. An experiment determined that people have strong preferences about audience information and how it should be displayed. Layout preferences are varied, but unfolding techniques and cluster analysis reveal that these preference perspectives fall into four groups of similar preferences.\r\n"
    },
    {
        "Projects": [
            "Manga",
            "MBase"
        ],
        "keywords": [
            "manga",
            "media",
            "mbase",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-045",
        "Venue": "In Human-Computer Interaction INTERACT '99, IOS Press, pp. 205-212, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-045/FXPAL-PR-99-045.pdf"
        ],
        "PublicationDate": "08/30/1999",
        "ID": "45",
        "Authors": [
            "Andreas Girgensohn",
            "John Boreczky",
            "Lynn Wilcox",
            "Jonathan Foote"
        ],
        "Title": "Facilitating Video Access by Visualizing Automatic Analysis.",
        "Abstract": "When reviewing collections of video such as recorded meetings or presentations, users are often interested only in an overview or short segments of these documents. We present techniques that use automatic feature analysis, such as slide detection and applause detection, to help locate the desired video and to navigate to regions of interest within it. We built a web-based interface that graphically presents information about the contents of each video in a collection such as its keyframes and the distribution of a particular feature over time. A media player is tightly integrated with the web interface. It supports navigation within a selected file by visualiz-ing confidence scores for the presence of features and by using them as index points. We conducted a user study to refine the usability of these tools."
    },
    {
        "Projects": [
            "Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-046",
        "Venue": "In Proceedings of UIST '00, ACM Press, pp. 81-89, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-046/FXPAL-PR-00-046.pdf"
        ],
        "PublicationDate": "11/05/2000",
        "ID": "46",
        "Authors": [
            "Andreas Girgensohn",
            "John Boreczky",
            "Patrick Chiu",
            "John Doherty",
            "Jonathan Foote",
            "Gene Golovchinsky",
            "Shingo Uchihashi",
            "Lynn Wilcox"
        ],
        "Title": "A Semi-Automatic Approach to Home Video Editing.",
        "Abstract": "Hitchcock is a system that allows users to easily create custom videos from raw video shot with a standard video camera. In contrast to other video editing systems, Hitchcock uses automatic analysis to determine the suitability of portions of the raw video. Unsuitable video typically has fast or erratic camera motion. Hitchcock first analyzes video to identify the type and amount of camera motion: fast pan, slow zoom, etc. Based on this analysis, a numerical \"unsuitability\" score is computed for each frame of the video. Combined with standard editing rules, this score is used to identify clips for inclusion in the final video and to select their start and end points. To create a custom video, the user drags keyframes corresponding to the desired clips into a storyboard. Users can lengthen or shorten the clip without specifying the start and end frames explicitly. Clip lengths are balanced automatically using a spring-based algorithm."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-047",
        "Venue": "In Proceedings of the International Joint Conference on Work Activities Coordination and Collaboration, pp. 147-156, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-047/FXPAL-PR-99-047.pdf"
        ],
        "PublicationDate": "02/22/1999",
        "ID": "47",
        "Authors": [
            "Andreas Girgensohn"
        ],
        "Title": "Supporting the Writing of Reports in a Hierarchical Organization.",
        "Abstract": "In many hierarchical companies, reports from several independent groups must be merged to form a single, company-wide report. This paper describes a process and system for creating and structuring such reports and for propagating contributions up the organization. The system has been in regular use, in-house, by about 30 users for over a year to create monthly status reports. Our experiences indicate that it is possible to change a monthly reporting practice so that the system is easy to use, improves the quality of the written report, fosters collaboration across projects and creates a corporate memory for the company. These results were achieved as a consequence of our design effort to directly support the hierarchical and collaborative process of creating and assembling the report within the organization. User feedback has led to many improvements in the usability and functionality of the system. Further enhancements using information retrieval and text summarization techniques are in progress. \r\n"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-048",
        "Venue": "In GROUP'97, Proceedings of the International ACM SIGGROUP Conference on Supporting Group Work, ACM Press, 1997, pp. 385-394.",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-048/FXPAL-PR-97-048.pdf"
        ],
        "PublicationDate": "11/16/1997",
        "ID": "48",
        "Authors": [
            "Alison Lee",
            "Andreas Girgensohn",
            "Kevin Schlueter"
        ],
        "Title": "NYNEX Portholes: Initial User Reactions and Redesign Implications. ",
        "Abstract": "The prevalence of audio and video options on computers, coupled with the promise of bandwidth, have many prognosticators predicting a revolution in human communications. But what if the revolution materializes and no users show up? We were confronted with this question when we began deploying and studying the use of a video-based, background awareness application within our organization. Repeatedly, new users raised strong concerns about self-presentation, surveillance, privacy, video snapshots, and lack of audience cues. We describe how we addressed these concerns by evolving the application. As a consequence, we are also redesigning the user interface to the application. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-049",
        "Venue": "In CHI 97 Extended Abstracts, ACM Press, 1997, pp. 319-320.",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-049/FXPAL-PR-97-049.pdf"
        ],
        "PublicationDate": "03/22/1997",
        "ID": "49",
        "Authors": [
            "Alison Lee",
            "Kevin Schlueter",
            "Andreas Girgensohn"
        ],
        "Title": "Sensing Activity in Video Images. ",
        "Abstract": "Video-based awareness tools increase familiarity among remote group members and provide pre-communication information. Low-cost iconic indicators provide less but more succinct information than video images while preserving privacy. Observations of and feedback from users of our video awareness tool suggest that an activity sensing feature along with a variety of privacy options combines advantages of both the video images and iconic indicator approaches. We introduced the activity sensing feature in response to user requests. It derives activity information from video images and provides options to control privacy and improves the usability of video-based awareness tools."
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "quantum"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-050",
        "Venue": "IEEE Computer, pp. 38-45, January 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-050/FXPAL-PR-00-050.pdf"
        ],
        "PublicationDate": "02/01/2000",
        "ID": "50",
        "Authors": [
            "Andrew Steane",
            "Eleanor Rieffel"
        ],
        "Title": "Beyond Bits: The Future of Quantum Information Processing.",
        "Abstract": "Recently, physicists and computer scientists have\r\nrealized that not only do our ideas about computing\r\nrest on only partly accurate principles, but they miss\r\nout on a whole class of computation. Quantum physics\r\noffers powerful methods of encoding and manipulating\r\ninformation that are not possible within a classical\r\nframework. The potential applications of these quantum\r\ninformation processing methods include provably\r\nsecure key distribution for cryptography, rapid integer\r\nfactoring, and quantum simulation."
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-051",
        "Venue": "Proceedings of the 2nd NASA/DoD Workshop on Evolvable Hardware, pp. 21 - 27",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-051/FXPAL-PR-99-051.pdf"
        ],
        "PublicationDate": "07/19/1999",
        "ID": "51",
        "Authors": [
            "Brad Dolin",
            "Forrest Bennett",
            "Eleanor Rieffel"
        ],
        "Title": "Methods for Evolving Robust Distributed Robot Control Software: Coevolutionary and Single Population Techniques.",
        "Abstract": ""
    },
    {
        "Projects": [
            "Dynomite"
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-052",
        "Venue": "In CHI 97 Extended Abstracts, ACM Press, 1997, pp. 22-23. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-052/FXPAL-PR-97-052.pdf"
        ],
        "PublicationDate": "03/22/1997",
        "ID": "52",
        "Authors": [
            "Bill Schilit",
            "Lynn Wilcox",
            "Nitin Sawhney"
        ],
        "Title": "Merging the Benefits of Paper Notebooks with the Power of Computers in Dynomite ",
        "Abstract": "Dynomite is a portable electronic notebook that merges the benefits of paper note-taking with the organizational capabilities of computers. Dynomite incorporates four complementary features which combine to form an easy to use system for the capture and retrieval of handwritten and audio notes. First, Dynomite has a paper-like user interface. Second, Dynomite uses ink properties and keywords for content indexing of notes. Third, Dynomite's properties and keywords allows retrieval of specific ink and notes. The user is shown a view, or a subset of the notebook content, that dynamically changes as new information is added. Finally, Dynomite continuously records audio, but only permanently stores highlighted portions so that it is possible to augment handwritten notes with audio on devices with limited storage."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "information appliances",
            "annotation",
            "user interface"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-053",
        "Venue": "CHI 98 Conference Proceedings, ACM Press, 1998, pp. 249-256.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-053/FXPAL-PR-98-053.pdf"
        ],
        "PublicationDate": "04/18/1998",
        "ID": "53",
        "Authors": [
            "Bill Schilit",
            "Gene Golovchinsky",
            "Morgan Price"
        ],
        "Title": "Beyond Paper: Supporting Active Reading with Free Form Digital Ink Annotations. ",
        "Abstract": "Reading frequently involves not just looking at words on a page, but also underlining, highlighting and commenting, either on the text or in a separate notebook. This combination of reading with critical thinking and learning is called active reading [2]. To explore the premise that computation can enhance active reading we have built the XLibris\u00e2\u201e\u00a2 \"active reading machine.\" XLibris\u00e2\u201e\u00a2 uses a commercial high-resolution pen tablet display along with a paper-like user interface to support the key affordances of paper for active reading: the reader can hold a scanned image of a page in his lap and mark on it with digital ink. To go beyond paper, XXLibris\u00e2\u201e\u00a2 monitors the free-form ink annotations made while reading, and uses these to organize and to search for information. Readers can review, sort and filter clippings of their annotated text in a \"Reader's Notebook.\" XLibris\u00e2\u201e\u00a2 also searches for material related to the annotated text, and displays links to similar documents unobtrusively in the margin. XLibris\u00e2\u201e\u00a2 demonstrates that computers can help active readers organize and find information while retaining many of the advantages of reading on paper."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "information appliances",
            "annotation",
            "digital libraries",
            "user interface"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-054",
        "Venue": "In Proceedings of Digital Libraries 98 (Pittsburgh, PA June 23-26), ACM Press, 1998, pp. 217-226.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-054/FXPAL-PR-98-054.pdf"
        ],
        "PublicationDate": "06/23/1998",
        "ID": "54",
        "Authors": [
            "Bill Schilit",
            "Morgan Price",
            "Gene Golovchinsky"
        ],
        "Title": "Digital Library Information Appliances. ",
        "Abstract": "Although digital libraries are intended to support education and knowledge work, current digital library interfaces are narrowly focused on retrieval. Furthermore, they are designed for desktop computers with keyboards, mice, and high-speed network connections. Desktop computers fail to support many key aspects of knowledge work, including active reading, free form ink annotation, fluid movement among document activities, and physical mobility. This paper proposes portable computers specialized for knowledge work, or digital library information appliances, as a new platform for accessing digital libraries. We present a number of ways that knowledge work can be augmented and transformed by the use of such appliances. These insights are based on our implementation of two research prototype systems: XLibris,\u00e2\u201e\u00a2 an \"active reading machine,\" and TeleWeb, a mobile World Wide Web browser."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "annotation",
            "reading",
            "e-books",
            "information appliances"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-056",
        "Venue": "Computer, Vol. 32, No. 1, January 1999, pp. 65-73.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-056/FXPAL-PR-99-056.pdf"
        ],
        "PublicationDate": "02/01/1999",
        "ID": "56",
        "Authors": [
            "Bill Schilit",
            "Morgan Price",
            "Gene Golovchinsky",
            "Kei Tanaka",
            "Catherine Marshall"
        ],
        "Title": "As We May Read: The Reading Appliance Revolution.",
        "Abstract": "Reading appliances allow people to work on electronic documents much as they would on paper. They therefore provide an alternative to the standard \"browse or search and then print\" model of reading online. By integrating a wide variety of document activities, such as searching, organizing, and skimming, and by allowing fluid movement among them, reading appliances eliminate disruptive transitions between paper and digital media. \r\n"
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "reading",
            "annotation",
            "collaboration",
            "e-books",
            "information appliances",
            "abc"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-057",
        "Venue": "In Personal Technologies, Vol. 3, No. 1, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-057/FXPAL-PR-99-057.pdf"
        ],
        "PublicationDate": "02/01/1999",
        "ID": "57",
        "Authors": [
            "Catherine Marshall",
            "Morgan Price",
            "Gene Golovchinsky",
            "Bill Schilit"
        ],
        "Title": "Collaborating over Portable Reading Appliances.",
        "Abstract": "Reading appliances or e-books hold substantial promise to help us collaborate. In this paper, we use a study of a group activity - a reading group that meets to discuss articles of mutual interest - to explore four scenarios for collaborating with e-books: (1) meetings and face-to-face discussions; (2) serendipitous sharing of annotations, as when we borrow a document from a colleague or buy a used book; (3) community-wide use of anonymous annotations to guide future readers; and (4) e-books as a basis for initiating interaction between people. In so doing, we describe some methods for implementing these facilities, and introduce design guidelines."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "field work",
            "reading",
            "e-books",
            "user interface",
            "collaboration",
            "digital libraries"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-058",
        "Venue": "In Proceedings of ACM Digital Libraries 99, ACM Press, pp. 77-84, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-058/FXPAL-PR-99-058.pdf"
        ],
        "PublicationDate": "08/11/1999",
        "ID": "58",
        "Authors": [
            "Catherine Marshall",
            "Morgan Price",
            "Gene Golovchinsky",
            "Bill Schilit"
        ],
        "Title": "Introducing a Digital Library Reading Appliance into a Reading Group.",
        "Abstract": "How will we read digital library materials? This paper describes the reading practices of an on-going reading group, and how these practices changed when we introduced XLibris, a digital library reading appliance that uses a pen tablet computer to provide a paper-like interface. We interviewed group members about their reading practices, observed their meetings, and analyzed their annotations, both when they read a paper document and when they read using XLibris. We use these data to characterize their analytic reading, reference use, and annotation practices. We also describe the use of the Reader's Notebook, a list of clippings that XLibris computes from a reader's annotations. Implications for digital libraries stem from our findings on reading and mobility, the complexity of analytic reading, the social nature of reference following, and the unselfconscious nature of readers' annotations."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-00-059",
        "Venue": "In Successes and Failures of Digital Libraries (Harum and Twidale, eds). Urbana-Champaign: University of Illinois, 2000, pp. 97-117.",
        "palwebURL": [],
        "PublicationDate": "02/01/2000",
        "ID": "59",
        "Authors": [
            "Catherine Marshall"
        ],
        "Title": "The Future of Annotation in a Digital (Paper) World.",
        "Abstract": ""
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-96-060",
        "Venue": "Proceedings Interface Conference (Sydney, Australia, July 1996). ",
        "palwebURL": [
            "http://palweb/files/PR/1996/PR-96-060/FXPAL-PR-96-060.pdf"
        ],
        "PublicationDate": "07/01/1996",
        "ID": "60",
        "Authors": [
            "Don Kimber",
            "Lynn Wilcox"
        ],
        "Title": "Acoustic Segmentation for Audio Browsers",
        "Abstract": "Online digital audio is a rapidly growing resource, which can be accessed in rich new ways not previously possible. For example, it is possible to listen to just those portions of a long discussion which involve a given subset of people, or to instantly skip ahead to the next speaker. Providing this capability to users, however, requires generation of necessary indices, as well as an interface which utilizes these indices to aid navigation.\r\n\r\nWe describe algorithms which generate indices from automatic acoustic segmentation. These algorithms use hidden Markov models to segment audio into segments corresponding to different speakers or acoustics classes (e.g. music). Unsupervised model initialization using agglomerative clustering is described, and shown to work as well in most cases as supervised initialization.\r\n\r\nWe also describe a user interface which displays the segmentation in the form of a timeline, which tracks for the different acoustic classes. The interface can be used for direct navigation through the audio.\r\n\r\n"
    },
    {
        "Projects": [
            "FlyAbout",
            "FlyCam"
        ],
        "keywords": [
            "flycam",
            "flyabout"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-061",
        "Venue": "Proc. ACM Multimedia 2001, Ottawa,CA, Oct. 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-061/FXPAL-PR-01-061.html",
            "http://palweb/files/PR/2001/PR-01-061/FXPAL-PR-01-061.pdf"
        ],
        "PublicationDate": "09/30/2001",
        "ID": "61",
        "Authors": [
            "Don Kimber",
            "Jonathan Foote"
        ],
        "Title": "FlyAbout:Spatially Indexed Panoramic Video.",
        "Abstract": "We describe a system called FlyAbout which uses spatially indexed panoramic video for virtual reality applications. Panoramic video is captured by moving a 360\u00c2\u00b0 camera along continuous paths. Users can interactively replay the video with the ability to view any interesting object or choose a particular direction. Spatially indexed video gives the ability to travel along paths or roads with a map-like interface. At junctions, or intersection points, users can chose which path to follow as well as which direction to look, allowing interaction not available with conventional video. Combining the spatial index with a spatial database of maps or objects allows users to navigate to specific locations or interactively inspect particular objects.  "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-96-062",
        "Venue": "International Journal of Cooperative Information Systems 6(2), 1996. ",
        "palwebURL": [],
        "PublicationDate": "02/01/1996",
        "ID": "62",
        "Authors": [
            "Dan Kuokka",
            "L Harada"
        ],
        "Title": "Issues and Extensions for Information Matchmaking Protocols",
        "Abstract": "As agents see more use in dynamic, distributed information networks, information sharing facilitators, such as the SHADE matchmaker, and underlying knowledge-based agent communication protocols, such as the Knowledge Query and Manipulation Language, will see increased use. We have created several communities of agents collaborating via KQML and matchmaking within the domains of collaborative engineering and satellite image retrieval. Based on these experiences, matchmaking has proven to be very beneficial for multi-agent systems, but we have also identified a number of issues and extensions that are not only vital to KQML-based matchmaking, but to inter-agent protocols in general. These include representational approaches to advertising complex databases, approaches to error recovery and response timing, maintaining consistency among information providers, scalability, security, persistent requests in information brokering, and the dilemma between explicit vs. implicit brokering."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-96-063",
        "Venue": "Journal of Intelligent Information Systems, 1996. ",
        "palwebURL": [],
        "PublicationDate": "06/01/1996",
        "ID": "63",
        "Authors": [
            "Dan Kuokka",
            "L Harada"
        ],
        "Title": " Integrating Information via Matchmaking",
        "Abstract": "Trends such as the massive increase in information available via electronic networks, the use of on-line product data by distributed concurrent engineering teams, and dynamic supply chain integration for electronic commerce are placing severe burdens on traditional methods of information sharing and retrieval. Sources of information are far too numerous and dynamic to be found via traditional information retrieval methods, and potential consumers are seeing increased need for automatic notification services. Matchmaking is an approach based on emerging information integration technologies whereby potential producers and consumers of information send messages describing their information capabilities and needs. These descriptions, represented in rich, machine-interpretable description languages, are unified by the matchmaker to identify potential matches. Based on the matches, a variety of information brokering services are performed. We introduce matchmaking, and argue that it permits large numbers of dynamic consumers and providers, operating on rapidly-changing data, to share information more effectively than via traditional methods. Two matchmakers are described, the SHADE matchmaker, which operates over logical and structured text languages, and the COINS matchmaker, which operates over free text. These matchmakers have been used for a variety of applications, most significantly, in the domains of engineering and electronic commerce. We describe our experiences with the SHADE and COINS matchmaker, and we outline the major observed benefits and problems of matchmaking."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/01/1996",
        "palwebID": "PR-96-064",
        "Venue": "Journal of Intelligent Systems in Accounting, Finance, and Management 5(2), 1996.",
        "palwebURL": [],
        "PublicationDate": "02/01/1996",
        "ID": "64",
        "Authors": [
            "Dan Kuokka",
            "P Bonzon"
        ],
        "Title": "Reifying Behavior in Decision Support Systems",
        "Abstract": " "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-066",
        "Venue": "Communications of the ACM 40(1), 1997, pp. 52-59.",
        "palwebURL": [],
        "PublicationDate": "02/01/1997",
        "ID": "66",
        "Authors": [
            "D OLeary",
            "Dan Kuokka",
            "R Plant"
        ],
        "Title": "Artificial Intelligence and Virtual Organizations",
        "Abstract": "An abstract is not available. "
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "quantum"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-067",
        "Venue": "Quantum Computers and Quantum Computing, Vol. 1(1), pp. 4 - 57, R&C Dynamics. (Russian Translation.)",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-067/FXPAL-PR-00-067.pdf"
        ],
        "PublicationDate": "02/01/2000",
        "ID": "67",
        "Authors": [
            "Eleanor Rieffel",
            "Wolfgang Polak"
        ],
        "Title": "An Introduction to Quantum Computing for Non-Physicists.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-068",
        "Venue": "CHI 98 Summary, ACM Press, 1998, pp. 283-284.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-068/FXPAL-PR-98-068.pdf"
        ],
        "PublicationDate": "04/18/1998",
        "ID": "68",
        "Authors": [
            "Elin Pedersen"
        ],
        "Title": "People Presence or Room Activity Supporting Peripheral Awareness over Distance. ",
        "Abstract": "Peripheral awareness is a powerful human resource that has only recently been addressed in media space design. The challenge is to figure out what would be important to convey remotely and to strike a balance between too much and too little. Symbolic representation of remote activity is a powerful way to go, but as it turns out also easy to do wrong. This paper presents some early findings on problems and promises of using symbolic representation: it reports from informal studies of people using the AROMA prototype in regular office and home settings, and it conveys some lessons and designing appropriate and effective symbolic representations. "
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-069",
        "Venue": "September, San Francisco, USA. New York: ACM Press. 2000. ",
        "palwebURL": [],
        "PublicationDate": "09/01/2000",
        "ID": "69",
        "Authors": [
            "Elizabeth Churchill",
            "Martin Reddy"
        ],
        "Title": "CVE 2000. Proceedings of the ACM Conference on Collaborative Virtual Environments,",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-070",
        "Venue": "In Proceedings of GROUP '99 (Phoenix, AZ), ACM Press, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-070/FXPAL-PR-99-070.pdf"
        ],
        "PublicationDate": "11/14/1999",
        "ID": "70",
        "Authors": [
            "Elizabeth Churchill",
            "Sara Bly"
        ],
        "Title": "It's all in the words: Supporting work activities with lightweight tools.",
        "Abstract": "The development of tools to support synchronous communications between non-collocated colleagues has received considerable attention in recent years. Much of the work has focused on increasing a sense of co-presence between interlocutors by supporting aspects of face-to-face conversations that go beyond mere words (e.g. gaze, postural shifts). In this regard, a design goal for many environments is the provision of as much media-richness as possible to support non-collocated communication. In this paper we present results from our most recent interviews studying the use of a text-based virtual environment to support work collaborations. We describe how such an environment, though lacking almost all the visual and auditory cues known to be important in face-to-face conversation, has played an important role in day-to-day communication. We offer a set of characteristics we feel are important to the success of this text-only tool and discuss issues emerging from its long-term use. \r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-071",
        "Venue": "In Proceedings of the International Joint Conference on Work Activities Coordination and Collaboration, pp. 99-108, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-071/FXPAL-PR-99-071.pdf"
        ],
        "PublicationDate": "02/22/1999",
        "ID": "71",
        "Authors": [
            "Elizabeth Churchill",
            "Sara Bly"
        ],
        "Title": "Virtual Environments at Work: ongoing use of MUDs in the Workplace.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-072",
        "Venue": "In SIGGroup Bulletin, Volume 21, Number 1, April 2000. ACM Press, pp 6-11.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-072/FXPAL-PR-00-072.pdf"
        ],
        "PublicationDate": "04/01/2000",
        "ID": "72",
        "Authors": [
            "Elizabeth Churchill",
            "Sara Bly"
        ],
        "Title": "Culture Vultures: Considering Culture and Communication in Virtual Environments.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "stickychat",
            "SocComp"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-073",
        "Venue": "In CHI 2000 Conference Proceedings, ACM Press, pp. 454-461, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-073/FXPAL-PR-00-073.pdf"
        ],
        "PublicationDate": "04/01/2000",
        "ID": "73",
        "Authors": [
            "Elizabeth Churchill",
            "Jonathan Trevor",
            "Sara Bly",
            "Les Nelson",
            "Davor Cubranic"
        ],
        "Title": "Anchored Conversations. Chatting in the Context of a Document.",
        "Abstract": "This paper describes an application-independent tool called Anchored Conversations that brings together text-based conversations and documents. The design of Anchored Conversations is based on our observations of the use of documents and text chats in collaborative settings. We observed that chat spaces support work conversations, but they do not allow the close integration of conversations with work documents that can be seen when people are working together face-to-face. Anchored Conversations directly addresses this problem by allowing text chats to be anchored into documents. Anchored Conversations also facilitates document sharing; accepting an invitation to an anchored conversation results in the document being automatically uploaded. In addition, Anchored Conversations provides support for review, catch-up and asynchronous communications through a database. In this paper we describe motivating fieldwork, the design of Anchored Conversations, a scenario of use, and some preliminary results from a user study. "
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "conversational characters",
            "agents"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-074",
        "Venue": "In Embodied Conversational Agents, Cambridge, MA: MIT Press, pp. 64-94, 2000.",
        "palwebURL": [],
        "PublicationDate": "02/01/2000",
        "ID": "74",
        "Authors": [
            "Elizabeth Churchill",
            "Linda Cook",
            "Peter Hodgson",
            "Scott Prevost",
            "Joe Sullivan"
        ],
        "Title": "\"May I Help You?\": Designing Embodied Conversational Agent Allies.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-076",
        "Venue": "In Proceedings of the Thirty-Second Annual Hawaii International Conference on System Sciences (HICSS-32), R. Sprague, Jr., editor, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-076/FXPAL-PR-99-076.pdf"
        ],
        "PublicationDate": "02/05/1999",
        "ID": "76",
        "Authors": [
            "Eleanor Rieffel"
        ],
        "Title": "The Genre of Mathematics Documents and its Implications for Digital Documents.",
        "Abstract": "The genre of mathematics writing has several distinctive features that point to some of the weaknesses of current digital documents. Some of these weaknesses are surprising. While it might be expected that the importance of formatting and special symbols in mathematics writing would pose challenges for digital documents, the linked, chunked style of mathematics writing, with its Theorems, Lemmas, Corollaries and Remarks explicitly referring to each other, resembles standard hypertext so closely that one would expect that mathematics writing would take well to online hypertext form. It does not. This failure points to deficiencies in our understanding of the true strengths and weaknesses of digital documents. This paper describes mathematics writing, with particular emphasis on features of interest with respect to digital documents. The difficulties in producing effective digital mathematics documents are then examined and used as a basis for talking about general challenges for digital documents. The paper then discusses strengths of digital documents and some of the problems that need to be overcome before digital documents can live up to claims made for them. It also examines some of the misguided claims, such as superior support for non-linearity, that are commonly made for digital documents, explains why these claims are unwarranted, and speculates on why the claims have been made anyway. Suggestions are then given as to what the true benefits of digitization are, including performing computations on text, flexible control of time, and better support for hiding information. The paper concludes with a list of questions whose answers are critical to understanding the capabilities, and therefore the future, of digital documents.\r\n"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-00-077",
        "Venue": "In proceedings of DIS'2000, ACM Press, August 2000.",
        "palwebURL": [],
        "PublicationDate": "08/01/2000",
        "ID": "77",
        "Authors": [
            "Elin Pedersen",
            "Tomas Sokoler",
            "Les Nelson"
        ],
        "Title": "Expanding a Tangible User Interface",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-078",
        "Venue": "In Managing Multimedia Data: Using Metadata to Integrate and Apply Digital Data. A. Sheth and W. Klas (eds.), McGraw Hill, 1997. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-078/FXPAL-PR-97-078.pdf"
        ],
        "PublicationDate": "02/01/1997",
        "ID": "78",
        "Authors": [
            "F Chen",
            "Marti Hearst",
            "Don Kimber",
            "J Kupiec",
            "J Pedersen",
            "Lynn Wilcox"
        ],
        "Title": "Metadata for Mixed Media Access. ",
        "Abstract": "In this chapter, we discuss mixed-media access, an information access paradigm for multimedia data in which the media type of a query may differ from that of the data. This allows a single query to be used to retrieve information from data consisting of multiple types of media. In addition, multiple queries formulated in different media types can be used to more accurately specify the data to be retrieved. The types of media considered in this paper are speech, images of text, and full-length text. Some examples of metadata for mixed-media access are locations of keywords in speech and images, identification of speakers, locations of emphasized regions in speech, and locations of topic boundaries in text. Algorithms for automatically generating this metadata are described, including word spotting, speaker segmentation, emphatic speech detection, and subtopic boundary location. We illustrate the use of mixed-media access with an example of information access from multimedia data surrounding a formal presentation. \r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-079",
        "Venue": "Genetic Programming: Proceedings of EuroGP 2001, Springer LNCS 2038, pp. 234 - 245",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-079/FXPAL-PR-01-079.pdf"
        ],
        "PublicationDate": "04/18/2001",
        "ID": "79",
        "Authors": [
            "Forrest Bennett",
            "Brad Dolin",
            "Eleanor Rieffel"
        ],
        "Title": "Programmable Smart Membranes: Using Genetic Programming to Evolve Scalable Distributed Controllers for a Novel Self-Reconfigurable Modular Robotic Application.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-080",
        "Venue": "In Late Breaking Papers, GECCO 2000, pp. 35-42, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-080/FXPAL-PR-00-080.pdf"
        ],
        "PublicationDate": "07/08/2000",
        "ID": "80",
        "Authors": [
            "Forrest Bennett",
            "Eleanor Rieffel"
        ],
        "Title": "Using Genetic Programming to Design Decentralized Controllers for Self-Reconfigurable Modular Robots.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-081",
        "Venue": "In Proceedings of the 2nd NASA/DoD Workshop on Evolvable Hardware, pp. 43-52, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-081/FXPAL-PR-00-081.pdf"
        ],
        "PublicationDate": "07/13/2000",
        "ID": "81",
        "Authors": [
            "Forrest Bennett",
            "Eleanor Rieffel"
        ],
        "Title": "Design of Decentralized Controllers for Self-Reconfigurable Modular Robots Using Genetic Programming.",
        "Abstract": ""
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "Hypertext",
            "theory",
            "user interface",
            "e-books",
            "XLibris",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-082",
        "Venue": "In Proceedings of Hypertext '00, ACM Press, pp. 171-179, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-082/FXPAL-PR-00-082.pdf"
        ],
        "PublicationDate": "05/30/2000",
        "ID": "82",
        "Authors": [
            "Gene Golovchinsky",
            "Catherine Marshall"
        ],
        "Title": "Hypertext Interaction Revisited.",
        "Abstract": "Much of hypertext narrative relies on links to shape a reader's interaction with the text. But links may be too limited to express ambiguity, imprecision, and entropy, or to admit new modes of participation short of full collaboration. We use an e-book form to explore the implications of freeform annotation-based interaction with hypertext narrative. Readers' marks on the text can be used to guide navigation, create a persistent record of a reading, or to recombine textual elements as a means of creating a new narrative. In this paper, we describe how such an experimental capability was created on top of XLibris, a next generation e-book, using Forward Anywhere as the hypernarrative. We work through a scenario of interaction, and discuss the issues the work raises"
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "information retrieval",
            "evaluation",
            "annotation",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-083",
        "Venue": "In Proceedings of ACM SIGIR 99, ACM Press, pp. 19-25, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-083/FXPAL-PR-99-083.pdf"
        ],
        "PublicationDate": "08/15/1999",
        "ID": "83",
        "Authors": [
            "Gene Golovchinsky",
            "Morgan Price",
            "Bill Schilit"
        ],
        "Title": "From Reading to Retrieval: Freeform Ink Annotations as Queries.",
        "Abstract": "User interfaces for digital libraries tend to focus on retrieval: users retrieve documents online, but then print them out and work with them on paper. One reason for printing documents is to annotate them with freeform ink while reading. Annotation can help readers to understand documents and to make them their own. In addition, annotation can reveal readers' interests with respect to a particular document. In particular, it is possible to construct full-text queries based on annotated passages of documents. We describe an experiment that tested the effectiveness of such queries, as compared to relevance feedback query techniques. For a set of TREC topics and documents, queries derived from annotated passages produced significantly better results than queries derived from subjects' judgments of relevance. "
    },
    {
        "Projects": [],
        "keywords": [
            "Information seeking",
            "hypertext",
            "evaluation",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-97-084",
        "Venue": "In CHI 97 Conference Proceedings, ACM Press, 1997, pp. 407-414.",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-084/FXPAL-PR-97-084.pdf"
        ],
        "PublicationDate": "03/22/1997",
        "ID": "84",
        "Authors": [
            "Gene Golovchinsky"
        ],
        "Title": "Queries? Links? Is There a Difference?",
        "Abstract": "Hypertext interfaces are considered appropriate for information exploration tasks. The prohibitively expensive link creation effort, however, prevents traditional hypertext interfaces from being used with large coherent collections of text. Such collections typically require query-based interfaces. This paper examines a hybrid approach: the system described here creates anchors dynamically based on users' queries, and uses anchor selection as a query expansion mechanism. An experiment was conducted to compare browsing behavior in query- and link-based interfaces. Results suggest that query-mediated links are as effective as explicit queries, and that strategies adopted by users affect performance. This work has implications for the design of information exploration interfaces; the dynamic link algorithms described here are being incorporated into a Web server."
    },
    {
        "Projects": [],
        "keywords": [
            "Hypertext",
            "information seeking",
            "information retrieval",
            "user interface",
            "evaluation",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-97-085",
        "Venue": "In Proceedings of Hypertext 97, ACM Press, 1997, pp. 67-74.",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-085/FXPAL-PR-97-085.pdf"
        ],
        "PublicationDate": "04/06/1997",
        "ID": "85",
        "Authors": [
            "Gene Golovchinsky"
        ],
        "Title": "What the Query Told the Link: The Integration of Hypertext and Information Retrieval. ",
        "Abstract": "Traditionally hypertexts have been limited in size by the manual effort required to create hypertext links. In addition, large hyper-linked collections may overwhelm users with the range of possible links from any node, only a fraction of which may be appropriate for a given user at any time. This work explores automatic methods of link construction based on feedback from users collected during browsing. A full-text search engine mediates the linking process. Query terms that distinguish well among documents in the database become candidate anchors; links are mediated by passage-based relevance feedback queries. The newspaper metaphor is used to organize the retrieval results.\r\n\r\nVOIR, a software prototype that implements these algorithms has been used to browse a 74,500 node (250MB) database of newspaper articles. An experiment has been conducted to test the relative effectiveness of dynamic links and user-specified queries. Experimental results suggest that link-mediated queries are more effective than user-specified queries in retrieving relevant information. The paper concludes with a discussion of possible extensions to the linking algorithms.\r\n"
    },
    {
        "Projects": [
            "Manga"
        ],
        "keywords": [
            "manga",
            "media",
            "video",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-086",
        "Venue": "In CHI 2000 Conference Proceedings, ACM Press, pp. 185-192, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-086/FXPAL-PR-00-086.pdf"
        ],
        "PublicationDate": "04/01/2000",
        "ID": "86",
        "Authors": [
            "John Boreczky",
            "Andreas Girgensohn",
            "Gene Golovchinsky",
            "Shingo Uchihashi"
        ],
        "Title": "An Interactive Comic Book Presentation for Exploring Video.",
        "Abstract": "This paper presents a method for generating compact pictorial summarizations of video. We developed a novel approach for selecting still images from a video suitable for summarizing the video and for providing entry points into it. Images are laid out in a compact, visually pleasing display reminiscent of a comic book or Japanese manga. Users can explore the video by interacting with the presented summary. Links from each keyframe start video playback and/or present additional detail. Captions can be added to presentation frames to include commentary or descriptions such as the minutes of a recorded meeting. We conducted a study to compare variants of our summarization technique. The study participants judged the manga summary to be significantly better than the other two conditions with respect to their suitability for summaries and navigation, and their visual appeal. "
    },
    {
        "Projects": [],
        "keywords": [
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-087",
        "Venue": "In RIAO'2000 Conference Proceedings, Content-Based Multimedia Information Access, C.I.D., pp. 637-648, 2000.",
        "palwebURL": [],
        "PublicationDate": "04/12/2000",
        "ID": "87",
        "Authors": [
            "John Boreczky",
            "Jonathan Foote",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Interactive Similarity Search for Video Browsing and Retrieval.",
        "Abstract": "We present and interactive system that allows a user to locate regions of video that are similar to a video query. Thus segments of video can be found by simply providing an example of the video of interest. The user selects a video segment for the query from either a static frame-based interface or a video player. A statistical model of the query is calculated on-the-fly, and is used to find similar regions of video. The similarity measure is based on a Gaussian model of reduced frame image transform coefficients. Similarity in a single video is displayed in the Metadata Media Player. The player can be used to navigate through the video by jumping between regions of similarity. Similarity can be rapidly calculated for multiple video files as well. These results are displayed in MBase, a Web-based video browser that allows similarity in multiple video files to be visualized simultaneously. "
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "conversational characters",
            "agents"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-088",
        "Venue": "Cambridge, MA: MIT Press, 2000.",
        "palwebURL": [],
        "PublicationDate": "02/01/2000",
        "ID": "88",
        "Authors": [
            "Justine Cassell",
            "Joe Sullivan",
            "Scott Prevost",
            "Elizabeth Churchill"
        ],
        "Title": "Embodied Conversational Agents.",
        "Abstract": "J. Cassell, J. Sullivan, S. Prevost, and E. Churchill (Eds.)."
    },
    {
        "Projects": [
            "FlyCam"
        ],
        "keywords": [
            "flycam",
            "immersive",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-090",
        "Venue": "In Proceedings of IEEE International Conference on Multimedia and Expo, vol. III, pp. 1419-1422, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-090/FXPAL-PR-00-090.pdf"
        ],
        "PublicationDate": "07/30/2000",
        "ID": "90",
        "Authors": [
            "Jonathan Foote",
            "Don Kimber"
        ],
        "Title": "FlyCam: Practical Panoramic Video.",
        "Abstract": ""
    },
    {
        "Projects": [
            "MBase"
        ],
        "keywords": [
            "mbase",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-091",
        "Venue": "MULTIMEDIA '98, ACM Press, 1998, pp. 375-380.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-091/FXPAL-PR-98-091.pdf"
        ],
        "PublicationDate": "09/14/1998",
        "ID": "91",
        "Authors": [
            "Jonathan Foote",
            "John Boreczky",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "An Intelligent Media Browser using Automatic Multimodal Analysis. ",
        "Abstract": "Many techniques can extract information from an multimedia stream, such as speaker identity or shot boundaries. We present a browser that uses this information to navigate through stored media. Because automatically-derived information is not wholly reliable, it is transformed into a time-dependent \"confidence score.\" When presented graphically, confidence scores enable users to make informed decisions about regions of interest in the media, so that non-interesting areas may be skipped. Additionally, index points may be determined automatically for easy navigation, selection, editing, and annotation and will support analysis types other than the speaker identification and shot detection used here. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-092",
        "Venue": "In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (Phoenix, AZ), vol. 6, pp. 3029-3032, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-092/FXPAL-PR-99-092.pdf"
        ],
        "PublicationDate": "03/15/1999",
        "ID": "92",
        "Authors": [
            "Jonathan Foote",
            "John Boreczky",
            "Lynn Wilcox"
        ],
        "Title": "Finding Presentations in Recorded Meetings Using Audio and Video Features.",
        "Abstract": "This paper describes a method for finding segments in video-recorded meetings that correspond to presentations. These segments serve as indexes into the recorded meeting. The system automatically detects intervals of video that correspond to presentation slides. We assume that only one person speaks during an interval when slides are detected. Thus these intervals can be used as training data for a speaker spotting system. An HMM is automatically constructed and trained on the audio data from each slide interval. A Viterbi alignment then resegments the audio according to speaker. Since the same speaker may talk across multiple slide intervals, the acoustic data from these intervals is clustered to yield an estimate of the number of distinct speakers and their order. This allows the individual presentations in the video to be identified from the location of each presenter's speech. Results are presented for a corpus of six meeting videos. \r\n"
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "similarity",
            "media",
            "music",
            "audio"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-093",
        "Venue": "In Proceedings of ACM Multimedia '99, pp. 77-80, Orlando, Florida, November 1999",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-093/FXPAL-PR-99-093.pdf"
        ],
        "PublicationDate": "10/30/1999",
        "ID": "93",
        "Authors": [
            "Jonathan Foote"
        ],
        "Title": "Visualizing Music and Audio using Self-Similarity.",
        "Abstract": "This paper presents a novel approach to visualizing\r\nthe time structure of music and audio. The\r\nacoustic similarity between any two instants of\r\nan audio recording is calculated and displayed\r\nas a two-dimensional representation. Similar or\r\nrepeating elements are visually distinct, allowing\r\nidentification of structural and rhythmic\r\ncharacteristics. Visualization examples are presented\r\nfor orchestral, jazz, and popular music.\r\nApplications include content-based analysis\r\nand segmentation, as well as tempo and structure\r\nextraction."
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "similarity",
            "media",
            "audio"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-094",
        "Venue": "In Proceedings of IEEE International Conference on Multimedia and Expo, vol. I, pp. 452-455, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-094/FXPAL-PR-00-094.pdf"
        ],
        "PublicationDate": "07/30/2000",
        "ID": "94",
        "Authors": [
            "Jonathan Foote"
        ],
        "Title": "Automatic Audio Segmentation using a Measure of Audio Novelty.",
        "Abstract": ""
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "media",
            "music",
            "audio"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-095",
        "Venue": "In Proceedings of the International Symposium on Music Information Retrieval, in press.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-095/FXPAL-PR-00-095.pdf"
        ],
        "PublicationDate": "10/23/2000",
        "ID": "95",
        "Authors": [
            "Jonathan Foote"
        ],
        "Title": "ARTHUR: Retrieving Orchestral Music by Long-Term Structure",
        "Abstract": "We introduce an audio retrieval-by-example system for orchestral music. Unlike many other approaches, this system is based on analysis of the audio waveform and does not rely on symbolic or MIDI representations. ARTHUR retrieves audio on the basis of long-term structure, specifically the variation of soft and louder passages. The long-term structure is determined from envelope of audio energy versus time in one or more frequency bands. Similarity between energy profiles is calculated using dynamic programming. Given an example audio document, other documents in a collection can be ranked by similarity of their energy profiles. Experiments are presented for a modest corpus that demonstrate excellent results in retrieving different performances of the same orchestral work, given an example performance or short excerpt as a query.  "
    },
    {
        "Projects": [],
        "keywords": [
            "Printing",
            "user interface"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-096",
        "Venue": "In CHI 99 Extended Abstracts, ACM Press, pp. 240-241, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-096/FXPAL-PR-99-096.pdf"
        ],
        "PublicationDate": "05/18/1999",
        "ID": "96",
        "Authors": [
            "Jason Hong",
            "Morgan Price",
            "Bill Schilit",
            "Gene Golovchinsky"
        ],
        "Title": "Printertainment: Printing With Interactive Cover Sheets.",
        "Abstract": "We explored a new type of user interface, interactive cover sheets: computer forms laid out on the banner pages of print jobs that people can mark on, scan back into a multifunction printer/scanner, and use as input to applications. Cover sheets are commonly strewn around printer rooms; with interactivity, they can let people see what others have to say, add their own comments, or play games, all while waiting for their print jobs. We designed three prototype applications and deployed them briefly in our research lab. We found that interactive cover sheets can be very appealing, that the sheets must be designed so that people can still identify these pages as cover sheets, and that the slow interaction cycle favors asynchronous applications. "
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-097",
        "Venue": "GECCO 2002: Proceedings of the Genetic and Evolutionary Computation Conference, pp. 804 - 811, 2002.",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-097/FXPAL-PR-02-097.pdf"
        ],
        "PublicationDate": "07/09/2002",
        "ID": "97",
        "Authors": [
            "J Kubica",
            "Eleanor Rieffel"
        ],
        "Title": "Collaborating with a Genetic Programming System to Generate Modular Robotic Code.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-098",
        "Venue": "IEEE International Conference on Robotics and Automation, pp. 793 - 800, 2002.",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-098/FXPAL-PR-02-098.pdf"
        ],
        "PublicationDate": "05/11/2002",
        "ID": "98",
        "Authors": [
            "J Kubica",
            "Eleanor Rieffel"
        ],
        "Title": "Creating a Smarter Membrane: Automatic Code Generation for Modular Self-Reconfigurable Robots.",
        "Abstract": ""
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [
            "ubiquitous",
            "palplates"
        ],
        "AcceptDate": "",
        "palwebID": "PR-97-099",
        "Venue": "In CHI 97 Conference Proceedings, ACM Press, 1997, pp. 550-551. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-099/FXPAL-PR-97-099.pdf"
        ],
        "PublicationDate": "03/22/1997",
        "ID": "99",
        "Authors": [
            "Jennifer Mankoff",
            "Bill Schilit"
        ],
        "Title": "Supporting Knowledge Workers Beyond the Desktop with Palplates",
        "Abstract": "Palplates are a collection of touch-screen terminals placed around the office enabling human-computer interactions at the point of need. Supporting a community of mobile authenticated workers with a small number of stationary devices is an alternative to providing each person with a portable wireless computer. In contrast to the PC's desktop metaphor, Palplates use a place metaphor that reflect the actual rooms, corridors, and buildings that are part of the office place. Users interact graphically with applications supported by a geographic database. The user interface is generated dynamically based on the user\u00c3\u00a2\u00e2\u0082\u00ac\u00e2\u0084\u00a2s identity, the point-of-access, and the changing collection of physical office equipment, electronic documents and applications present at any given location."
    },
    {
        "Projects": [
            "M-Links"
        ],
        "keywords": [
            "ubiquitous",
            "m-links"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-100",
        "Venue": "The 14th Annual ACM Symposium on User Interfaces Software and Technology (UIST 2001), ACM Press, 2001.",
        "palwebURL": [],
        "PublicationDate": "11/11/2001",
        "ID": "100",
        "Authors": [
            "Jonathan Trevor",
            "David Hilbert",
            "Bill Schilit",
            "T.K. Koh"
        ],
        "Title": "From Desktop to Phonetop: A UI for Web Interaction on Very Small Devices.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-00-101",
        "Venue": "In Japan Hardcopy 2000, The Annual Conference of the Imaging Society of Japan. 6/12 6/14 2000.",
        "palwebURL": [],
        "PublicationDate": "06/12/2000",
        "ID": "101",
        "Authors": [
            "Jim Baker"
        ],
        "Title": "Knowledge and the New Economy",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-102",
        "Venue": "Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (Seattle, WA), Vol. 6, 1998, pp. 3741-3744.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-102/FXPAL-PR-98-102.pdf"
        ],
        "PublicationDate": "05/12/1998",
        "ID": "102",
        "Authors": [
            "John Boreczky",
            "Lynn Wilcox"
        ],
        "Title": "A Hidden Markov Model Framework for Video Segmentation Using Audio and Image Features.",
        "Abstract": "This paper describes a technique for segmenting video using hidden Markov models (HMM). Video is segmented into regions defined by shots, shot boundaries, and camera movement within shots. Features for segmentation include an image-based distance between adjacent video frames, an audio distance based on the acoustic difference in intervals just before and after the frames, and an estimate of motion between the two frames. Typical video segmentation algorithms classify shot boundaries by computing an image-based distance between adjacent frames and comparing this distance to fixed, manually determined thresholds. Motion and audio information is used separately. In contrast, our segmentation technique allows features to be combined within the HMM framework. Further, thresholds are not required since automatically trained HMMs take their place. This algorithm has been tested on a video data base, and has been shown to improve the accuracy of video segmentation over standard threshold-based systems. "
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-103",
        "Venue": "In Proceedings of the Thirty-second Annual Hawaii International Conference on System Sciences (Wailea, Hawaii, January 1999). ",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-103/FXPAL-PR-99-103.pdf"
        ],
        "PublicationDate": "02/01/1999",
        "ID": "103",
        "Authors": [
            "Lia Adams",
            "Lori Toomey",
            "Elizabeth Churchill"
        ],
        "Title": "Distributed Research Teams: Meeting Asynchronously in Virtual Space.",
        "Abstract": "As computer networks improve, more social and work interactions are carried out \"virtually\" by geographically separated group members. In this paper we discuss the design of a tool, PAVE, to support remote work interactions among colleagues in different time zones. PAVE extends a 2D graphical MOO and supports synchronous and asynchronous interactions. PAVE logs and indexes activities in the space. This capture facility enables playback and augmentation of meeting interactions by non-collocated group members. Thus, members can participate asynchronously in meetings they could not attend in real time, not just review them. \r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "conversational characters",
            "agents"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-104",
        "Venue": "In Human Cognition and Social Agent Technology, Kerstin Dautenhahn (Guest-editor), Advances in Consciousness Research Series. John Benjamins Publishing Company.",
        "palwebURL": [],
        "PublicationDate": "02/01/1999",
        "ID": "104",
        "Authors": [
            "Linda Cook",
            "Timothy Bickmore",
            "Sara Bly",
            "Elizabeth Churchill",
            "Scott Prevost",
            "Joe Sullivan"
        ],
        "Title": "Autonomous Synthetic Computer Characters as Personal Representatives.",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-105",
        "Venue": "In Proceeding of the CHI 99 Conference on Human Factors in Computing Systems, ACM Press, pp. 354-361, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-105/FXPAL-PR-99-105.pdf"
        ],
        "PublicationDate": "05/18/1999",
        "ID": "105",
        "Authors": [
            "Les Nelson",
            "Satoshi Ichimura",
            "Elin Pedersen",
            "Lia Adams"
        ],
        "Title": "Palette: A Paper Interface for Giving Presentations.",
        "Abstract": "The Palette is a digital appliance designed for intuitive control of electronic slide shows. Current interfaces demand too much of our attention to permit effective computer use in situations where we can not give the technology our fullest concentration. The Palette uses index cards that are printed with slide content that is easily identified by both humans and computers. The presenter controls the presentation by directly manipulating the cards. The Palette design is based on our observation of presentations given in a real work setting. Our experiences using the system are described, including new practices (e.g., collaborative presentation, enhanced notetaking) that arise from the affordances of this new approach. This system is an example of a new interaction paradigm called tacit interaction that supports users who can spare very little attention to a computer interface. "
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-106",
        "Venue": "In Proceedings of the Thirty-first Annual Hawaii International Conference on System Sciences (Wailea, Hawaii, January 1998). ",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-106/FXPAL-PR-98-106.pdf"
        ],
        "PublicationDate": "02/06/1998",
        "ID": "106",
        "Authors": [
            "Lori Toomey",
            "Lia Adams",
            "Elizabeth Churchill"
        ],
        "Title": "Meetings in a Virtual Space: Creating a Digital Document.",
        "Abstract": "Improvements in computer network infrastructures and information utilities have led to an increase in the number of social and work interactions carried out 'virtually' by geographically separated group members [1, 5, 6, 7]. In this paper we describe the design and evaluation of a prototype system that supports synchronous and asynchronous collaboration between researchers separated by space and time. The system provides non-collocated team members with a digital, virtual space for information sharing and discussion. For synchronous interactions, our design prioritizes provision of shared context, real-time discourse, and real-time problem solving and negotiation between the team members. In the case of asynchronous interactions, we have prioritized the capture of team decision making and negotiation processes and the representation of these processes in a context-rich, hypertextual document of team problem solving and negotiation. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-107",
        "Venue": "In Proceedings of the Thirty-first Annual Hawaii International Conference on System Sciences (Wailea, Hawaii, January 1998), Volume II, pp. 259-267. ",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-107/FXPAL-PR-98-107.pdf"
        ],
        "PublicationDate": "02/06/1998",
        "ID": "107",
        "Authors": [
            "Lynn Wilcox",
            "John Boreczky"
        ],
        "Title": "Annotation and Segmentation for Multimedia Indexing and Retrieval. ",
        "Abstract": "In this paper we describe a method for indexing and retrieval of multimedia data based on annotation and segmentation. Our goal is the retrieval of segments of audio and video suitable for inclusion in multimedia documents. Annotation refers to the association of text data with particular time locations of the media. Segmentation is the partitioning of continuous media into homogenous regions. Retrieval is performed over segments of the media using the annotations associated with the segments. We present two scenarios that describe how these techniques might be applied. In the first, we describe how excerpts from a video-taped usage study of a new device are located for inclusion in a report on the utility of the device. In the second, we show how sound bites from a recorded meeting are obtained for use in authoring a summary of the meeting.\r\n"
    },
    {
        "Projects": [
            "MBase"
        ],
        "keywords": [
            "mbase",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-108",
        "Venue": "In Proceedings ACM Multimedia (Part 2), ACM Press, p. 205, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-108/FXPAL-PR-99-108.pdf"
        ],
        "PublicationDate": "10/30/1999",
        "ID": "108",
        "Authors": [
            "Lynn Wilcox",
            "Andreas Girgensohn",
            "Jonathan Foote",
            "John Boreczky"
        ],
        "Title": "MBase: Indexing, Browsing and Playback of Media at FXPAL",
        "Abstract": "   "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-109",
        "Venue": "In Readings in Computational Auditory Scene Analysis, D. F. Rosenthal and H. G. Okuno, Lawrence Erlbaum, 1998.",
        "palwebURL": [],
        "PublicationDate": "02/01/1998",
        "ID": "109",
        "Authors": [
            "L Wyse",
            "Steve Smoliar"
        ],
        "Title": "Toward Content-Based Audio Indexing and Retrieval and a New Speaker Discrimination Technique.",
        "Abstract": ""
    },
    {
        "Projects": [
            "Dynomite"
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-110",
        "Venue": "In CHI 97 Conference Proceedings, ACM Press, 1997, pp. 186-193. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-110/FXPAL-PR-97-110.pdf"
        ],
        "PublicationDate": "03/22/1997",
        "ID": "110",
        "Authors": [
            "Lynn Wilcox",
            "Bill Schilit",
            "Nitin Sawhney"
        ],
        "Title": "Dynomite: A Dynamically Organized Ink and Audio Notebook. ",
        "Abstract": "Dynomite is a portable electronic notebook for the capture and retrieval of handwritten and audio notes. The goal of Dynomite is to merge the organization, search, and data acquisition capabilities of a computer with the benefits of a paper-based notebook. Dynomite provides novel solutions in four key problem areas. First, Dynomite uses a casual, low cognitive overhead interface. Second, for content indexing of notes, Dynomite uses ink properties and keywords. Third, to assist organization, Dynomite's properties and keywords define views, presenting a subset of the notebook content that dynamically changes as users add new information. Finally, to augment handwritten notes with audio on devices with limited storage, Dynomite continuously records audio, but only permanently stores those parts highlighted by the user."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "information appliances",
            "annotation",
            "user interface"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-111",
        "Venue": "CHI 98 Summary, ACM Press, 1998, pp. 22-23.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-111/FXPAL-PR-98-111.pdf"
        ],
        "PublicationDate": "04/18/1998",
        "ID": "111",
        "Authors": [
            "Morgan Price",
            "Bill Schilit",
            "Gene Golovchinsky"
        ],
        "Title": "XLibris: The Active Reading Machine. ",
        "Abstract": "Active reading is the combination of reading with critical thinking and learning, and involves not just reading per se, but also underlining, highlighting and commenting. We have built the XLibris\u00e2\u201e\u00a2 \"Active Reading Machine\" to explore the premise that computation can enhance the active reading process. XLibris\u00e2\u201e\u00a2 uses a high-resolution pen tablet display along with a paper-like user interface to emulate the physical experience of reading a document on paper: the reader can hold a scanned image of a page in his lap and mark on it with digital ink. XLibris\u00e2\u201e\u00a2 monitors free-form ink annotations made while reading, and uses these to organize and to search for information. Readers can review, sort and filter clippings of their annotated text in a \"Reader's Notebook.\" Finally, XLibris\u00e2\u201e\u00a2 searches for material related to the annotated text, and displays links unobtrusively in the margin. XLibris\u00e2\u201e\u00a2 demonstrates that computers can help active readers organize and find information while retaining many of the advantages of reading on paper."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "hypertext",
            "information appliances",
            "annotation",
            "user interface",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-112",
        "Venue": "In Proceedings of Hypertext '98 (Pittsburgh, PA), ACM Press, 1998, pp. 30-39.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-112/FXPAL-PR-98-112.pdf"
        ],
        "PublicationDate": "06/20/1998",
        "ID": "112",
        "Authors": [
            "Morgan Price",
            "Gene Golovchinsky",
            "Bill Schilit"
        ],
        "Title": "Linking By Inking: Trailblazing in a Paper-like Hypertext.",
        "Abstract": "\"Linking by inking\" is a new interface for reader-directed link construction that bridges reading and browsing activities. We are developing linking by inking in XLibris,\u00e2\u201e\u00a2 a hypertext system based on the paper document metaphor. Readers use a pen computer to annotate page images with free-form ink, much as they would on paper, and the computer constructs hypertext links based on the ink marks. This paper proposes two kinds of reader-directed links: automatic and manual. Automatic links are created in response to readers' annotations. The system extracts the text near free-form ink marks, uses these terms to construct queries, executes queries against a collection of documents, and unobtrusively displays links to related documents in the margin or as \"further reading lists.\" We also present a design for manual (ad hoc) linking: circling an ink symbol generates a multi-way link to other instances of the same symbol. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-113",
        "Venue": "UIST '98, ACM Press, 1998, pp. 195-202.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-113/FXPAL-PR-98-113.pdf"
        ],
        "PublicationDate": "11/01/1998",
        "ID": "113",
        "Authors": [
            "Patrick Chiu",
            "Lynn Wilcox"
        ],
        "Title": "A Dynamic Grouping Technique for Ink and Audio Notes. ",
        "Abstract": "In this paper, we describe a technique for dynamically grouping digital ink and audio to support user interaction in freeform note-taking systems. For ink, groups of strokes might correspond to words, lines, or paragraphs of handwritten text. For audio, groups might be a complete spoken phrase or a speaker turn in a conversation. Ink and audio grouping is important for editing operations such as deleting or moving chunks of ink and audio notes. The grouping technique is based on hierarchical agglomerative clustering. This clustering algorithm yields groups of ink or audio in a range of sizes, depending on the level in the hierarchy, and thus provides structure for simple interactive selection and rapid non-linear expansion of a selection. Ink and audio grouping is also important for marking portions of notes for subsequent browsing and retrieval. Integration of the ink and audio clusters provides a flexible way to browse the notes by selecting the ink cluster and playing the corresponding audio cluster. "
    },
    {
        "Projects": [
            "VideoKeyframes"
        ],
        "keywords": [
            "media",
            "video",
            "21stCenturyComputing",
            "keyframes"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-114",
        "Venue": "In Proceedings of IEEE International Conference on Multimedia and Expo, vol. III, pp. 1329-1332, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-114/FXPAL-PR-00-114.pdf"
        ],
        "PublicationDate": "07/30/2000",
        "ID": "114",
        "Authors": [
            "Patrick Chiu",
            "Andreas Girgensohn",
            "Wolfgang Polak",
            "Eleanor Rieffel",
            "Lynn Wilcox"
        ],
        "Title": "A Genetic Algorithm for Video Segmentation and Summarization.",
        "Abstract": "We describe a genetic segmentation algorithm for video. This\r\nalgorithm operates on segments of a string representation. It is\r\nsimilar to both classical genetic algorithms that operate on bits of\r\na string and genetic grouping algorithms that operate on subsets\r\nof a set. For evaluating segmentations, we define similarity\r\nadjacency functions, which are extremely expensive to optimize\r\nwith traditional methods. The evolutionary nature of genetic\r\nalgorithms offers a further advantage by enabling incremental\r\nsegmentation. Applications include video summarization and\r\nindexing for browsing, plus adapting to user access patterns."
    },
    {
        "Projects": [],
        "keywords": [
            "media",
            "video",
            "21stCenturyComputing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-115",
        "Venue": "In Proceedings of the Genetic and Evolutionary Computation Conference, Morgan Kaufmann Publishers, pp. 666-673, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-115/FXPAL-PR-00-115.pdf"
        ],
        "PublicationDate": "07/08/2000",
        "ID": "115",
        "Authors": [
            "Patrick Chiu",
            "Andreas Girgensohn",
            "Wolfgang Polak",
            "Eleanor Rieffel",
            "Lynn Wilcox",
            "Forrest Bennett"
        ],
        "Title": "A Genetic Segmentation Algorithm for Image Data Streams and Video.",
        "Abstract": "We describe a genetic segmentation algorithm for image data streams and video. This algorithm operates on segments of a string representation. It is similar to both classical genetic algorithms that operate on bits of a string and genetic grouping algorithms that operate on subsets of a set. It employs a segment fair crossover operation. For evaluating segmentations, we define similarity adjacency functions, which are extremely expensive to optimize with traditional methods. The evolutionary nature of genetic algorithms offers a further advantage by enabling incremental segmentation. Applications include browsing and summarizing video and collections of visually rich documents, plus a way of adapting to user access patterns. "
    },
    {
        "Projects": [
            "NoteLook"
        ],
        "keywords": [
            "immersive",
            "video",
            "annotation",
            "kumo",
            "NoteLook"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-116",
        "Venue": "In IEEE Multimedia Magazine, vol. 7, no. 4, Oct-Dec 2000, pp. 48-54.",
        "palwebURL": [],
        "PublicationDate": "10/01/2000",
        "ID": "116",
        "Authors": [
            "Patrick Chiu",
            "Ashutosh Kapuskar",
            "Sarah Reitmeier",
            "Lynn Wilcox"
        ],
        "Title": "Room with a Rear View: Meeting Capture in a Multimedia Conference Room.",
        "Abstract": ""
    },
    {
        "Projects": [
            "NoteLook"
        ],
        "keywords": [
            "notelook",
            "annotation",
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-117",
        "Venue": "In Proceedings of ACM Multimedia '99, Orlando, Florida, November 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-117/FXPAL-PR-99-117.pdf"
        ],
        "PublicationDate": "10/30/1999",
        "ID": "117",
        "Authors": [
            "Patrick Chiu",
            "Ashutosh Kapuskar",
            "Sarah Reitmeier",
            "Lynn Wilcox"
        ],
        "Title": "NoteLook: Taking Notes in Meetings with Digital Video and Ink.",
        "Abstract": "NoteLook is a client-server system designed and built to\r\nsupport multimedia note taking in meetings with digital\r\nvideo and ink. It is integrated into a conference room\r\nequipped with computer controllable video cameras, video\r\nconference camera, and a large display rear video projector.\r\nThe NoteLook client application runs on wireless pen-based\r\nnotebook computers. Video channels containing images of\r\nthe room activity and presentation material are transmitted\r\nby the NoteLook servers to the clients, and the images can\r\nbe interactively and automatically incorporated into the\r\nnote pages. Users can select channels, snap in large\r\nbackground images and sequences of thumbnails, and write\r\nfreeform ink notes. A smart video source management\r\ncomponent enables the capture of high quality images of the\r\npresentation material from a variety of sources. For\r\naccessing and browsing the notes and recorded video,\r\nNoteLook generates Web pages with links from the images\r\nand ink strokes correlated to the video."
    },
    {
        "Projects": [
            "NoteLook"
        ],
        "keywords": [
            "immersive",
            "notelook",
            "annotation"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-118",
        "Venue": "In Proceedings of the Second International Workshop on Cooperative Buildings (CoBuild'99). Lecture Notes in Computer Science, Vol. 1670 Springer-Verlag, pp. 79-88, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-118/FXPAL-PR-99-118.pdf"
        ],
        "PublicationDate": "10/01/1999",
        "ID": "118",
        "Authors": [
            "Patrick Chiu",
            "Ashutosh Kapuskar",
            "Sarah Reitmeier",
            "Lynn Wilcox"
        ],
        "Title": "Meeting Capture in a Media Enriched Conference Room.",
        "Abstract": "We describe a media enriched conference room designed for capturing\r\nmeetings. Our goal is to do this in a flexible, seamless, and unobtrusive\r\nmanner in a public conference room that is used for everyday work. Room activity\r\nis captured by computer controllable video cameras, video conference\r\ncameras, and ceiling microphones. Presentation material displayed on a large\r\nscreen rear video projector is captured by a smart video source management\r\ncomponent that automatically locates the highest fidelity image source. Wireless\r\npen-based notebook computers are used to take notes, which provide indexes\r\nto the captured meeting. Images can be interactively and automatically\r\nincorporated into the notes. Captured meetings may be browsed on the Web\r\nwith links to recorded video."
    },
    {
        "Projects": [],
        "keywords": [
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-119",
        "Venue": "In Proceedings of Hypertext '00, ACM Press, pp. 244-245, 2000.",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-119/FXPAL-PR-00-119.pdf"
        ],
        "PublicationDate": "05/30/2000",
        "ID": "119",
        "Authors": [
            "Patrick Chiu",
            "Jonathan Foote",
            "Andreas Girgensohn",
            "John Boreczky"
        ],
        "Title": "Automatically Linking Multimedia Meeting Documents by Image Matching.",
        "Abstract": "We describe a way to make a hypermedia meeting record from multimedia meeting documents by automatically generating links through image matching. In particular, we look at video recordings and scanned paper handouts of presentation slides with ink annotations. The algorithm that we employ is the Discrete Cosine Transform (DCT). Interactions with multipath links and paper interfaces are discussed. "
    },
    {
        "Projects": [],
        "keywords": [
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-120",
        "Venue": "Proceedings of the 5th world multi-conference on Systemics, Cybernetics and Informatics, vol. III, pp. 34 - 39, Orlando, Florida, USA, July 22 - 25, 2001.",
        "palwebURL": [],
        "PublicationDate": "07/22/2001",
        "ID": "120",
        "Authors": [
            "Qiong Liu",
            "S Levinson",
            "Y Wu",
            "T Huang"
        ],
        "Title": "How to Teach Speech to an Autonomous Robot through Human-Robot Interaction",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-121",
        "Venue": "Proceedings of the INNS-IEEE International Joint Conference on Neural Networks, vol. 3, pp. 2176 - 2181, Washington DC., July 14-19, 2001.",
        "palwebURL": [],
        "PublicationDate": "07/14/2001",
        "ID": "121",
        "Authors": [
            "Qiong Liu",
            "S Levinson",
            "Y Wu",
            "T Huang"
        ],
        "Title": "Robot Speech Learning via Entropy Guided LVQ and Memory Association",
        "Abstract": ""
    },
    {
        "Projects": [
            "immersive"
        ],
        "keywords": [
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-122",
        "Venue": "Proceedings of the 2001 IEEE International Conference on Multimedia and Expo (ICME2001), Tokyo, Japan, August 22-25, 2001.",
        "palwebURL": [],
        "PublicationDate": "08/22/2001",
        "ID": "122",
        "Authors": [
            "Qiong Liu",
            "T Huang",
            "Y Wu",
            "S Levinson"
        ],
        "Title": "SPOKEN LANGUAGE ACQUISITION VIA HUMAN-ROBOT INTERACTION",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-123",
        "Venue": "Proceedings of ACM CHI2001, vol. 3, pp. 442 - 449, Seattle, Washington, USA, March 31 - April 5, 2001.",
        "palwebURL": [],
        "PublicationDate": "04/05/2001",
        "ID": "123",
        "Authors": [
            "Qiong Liu",
            "Y Rui",
            "A Gupta",
            "J Cadiz"
        ],
        "Title": "Automating Camera Management for Lecture Room Environments",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-01-124",
        "Venue": "Proc. International Computer Music Conference, Habana, Cuba, September 2001.",
        "palwebURL": [],
        "PublicationDate": "09/17/2001",
        "ID": "124",
        "Authors": [
            "Roger Dannenberg",
            "Jonathan Foote",
            "George Tzanetakis",
            "Christopher Weare"
        ],
        "Title": "Panel: New Directions in Music Information Retrieval",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "ubiquitous"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-125",
        "Venue": "Computer, Vol. 34, No. 8, August 2001, pp. 31-34.",
        "palwebURL": [],
        "PublicationDate": "08/01/2001",
        "ID": "125",
        "Authors": [
            "Roy Want",
            "Bill Schilit"
        ],
        "Title": "Expanding the Horizons of Location-Aware Computing (Guest Editor's Introduction)",
        "Abstract": "R. Want and B. N. Schilit"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-126",
        "Venue": "UIST '98, ACM Press, 1998, pp. 119-120.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-126/FXPAL-PR-98-126.pdf"
        ],
        "PublicationDate": "11/01/1998",
        "ID": "126",
        "Authors": [
            "Richard Davis",
            "James Lin",
            "Jason Brotherton",
            "James Landay",
            "Morgan Price",
            "Bill Schilit"
        ],
        "Title": "A Framework for Sharing Handwritten Notes.",
        "Abstract": "NotePals is an ink-based, collaborative note taking application that runs on personal digital assistants (PDAs). Meeting participants write notes in their own handwriting on a PDA. These notes are shared with other participants by synchronizing later with a shared note repository that can be viewed using a desktop-based web browser. NotePals is distinguished by its lightweight process, interface, and hardware. This demonstration illustrates the design of two different NotePals clients and our web-based note browser. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-127",
        "Venue": "In Proceeding of the CHI 99 Conference on Human Factors in Computing Systems, ACM Press, pp. 338-345, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-127/FXPAL-PR-99-127.pdf"
        ],
        "PublicationDate": "05/18/1999",
        "ID": "127",
        "Authors": [
            "Richard Davis",
            "James Landay",
            "Victor Chen",
            "Jonathan Huang",
            "Rebecca Lee",
            "Francis Li",
            "James Lin",
            "C Morrey III",
            "Ben Schleimer",
            "Morgan Price",
            "Bill Schilit"
        ],
        "Title": "NotePals: Lightweight Note Sharing by the Group, for the Group.",
        "Abstract": "NotePals is a lightweight note sharing system that gives group members easy access to each other's experiences through their personal notes. The system allows notes taken by group members in any context to be uploaded to a shared repository. Group members view these notes with browsers that allow them to retrieve all notes taken in a given context or to access notes from other related notes or documents. This is possible because NotePals records the context in which each note is created (e.g., its author, subject, and creation time). The system is \"lightweight\" because it fits easily into group members' regular note-taking practices, and uses informal, ink-based user interfaces that run on portable, inexpensive hardware. In this paper we describe NotePals, show how we have used it to share our notes, and present our evaluations of the system. \r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "ubiquitous",
            "roomotes"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-128",
        "Venue": "In Proceeding of the CHI 01 Conference on Human Factors in Computing Systems, ACM Press, Seattle, WA. pp. 239-240.",
        "palwebURL": [],
        "PublicationDate": "03/31/2001",
        "ID": "128",
        "Authors": [
            "Ryuji Wakikawa",
            "Jonathan Trevor",
            "Bill Schilit",
            "John Boreczky"
        ],
        "Title": "Roomotes: Ubiquitous room-based remote control from cell phones",
        "Abstract": "R. Wakikawa, J. Trevor, B. N. Schilit, J. Boreczky."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-129",
        "Venue": "In Interactions, pp. 23-31, March-April 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-129/FXPAL-PR-99-129.pdf"
        ],
        "PublicationDate": "03/01/1999",
        "ID": "129",
        "Authors": [
            "Sara Bly",
            "Elizabeth Churchill"
        ],
        "Title": "Design Through Matchmaking: Technology in Search of Users.",
        "Abstract": "S. Bly and E.F. Churchill."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-130",
        "Venue": "CHI 98 Summary, ACM Press, 1998, pp. 313-314.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-130/FXPAL-PR-98-130.pdf"
        ],
        "PublicationDate": "04/18/1998",
        "ID": "130",
        "Authors": [
            "Sara Bly",
            "Linda Cook",
            "Timothy Bickmore",
            "Elizabeth Churchill",
            "Joe Sullivan"
        ],
        "Title": "The Rise of Personal Web Pages at Work. ",
        "Abstract": "A series of 20 interviews in four organizations explores the ways in which employees take advantage of personal web pages to support their work and to reflect who they are. Both interviewee comments and web page examples suggest the importance of individual personalizations of information management and dissemination, presentation and perception of personality, and usage from the reader's perspective. These results can inform the development of future web technologies for use in organizations. Furthermore, this self representation on web pages is a way of making individual knowledge more available in the workplace. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-00-131",
        "Venue": "In Proc. of Interaction 2000 Symposium. Information Processing Society of Japan, pp. 17 - 24. (in Japanese)",
        "palwebURL": [],
        "PublicationDate": "02/01/2000",
        "ID": "131",
        "Authors": [
            "Satoshi Ichimura",
            "Les Nelson",
            "Elin Pedersen"
        ],
        "Title": "CardGear: A Presentation System Manipulated with Paper Cards.",
        "Abstract": "S. Ichimura, L. Nelson, E.R. Pedersen."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-96-132",
        "Venue": "Proceedings Knowledge Representation for Interactive Multimedia Systems: Research and Experience (Budapest, Hungary, August 1996), ECAI, pp. 57-65.",
        "palwebURL": [
            "http://palweb/files/PR/1996/PR-96-132/FXPAL-PR-96-132.pdf"
        ],
        "PublicationDate": "08/01/1996",
        "ID": "132",
        "Authors": [
            "Scott Minneman",
            "Steve Smoliar"
        ],
        "Title": "Representing the Content of Video: Artifact or Process? ",
        "Abstract": "An approach to semantics based on traditional paradigms of knowledge representation (e.g., developing reductionist models of video document genres), while not entirely of the mark, may be significantly misdirected. Understanding the semantics of video and multimedia must begin with understanding how video (and film) are \"read\" and \"written.\" The purpose of this paper is to set an agenda for coming to an understanding of reading and writing multimedia and to address the representationalist implications of achieving that end. Further, we illustrate this research agenda, showing how we have applied concepts and methods from film theory (to the reading process) and interaction analysis (to the work of multimedia production), and what our preliminary findings might mean for computational support and knowledge representation in multimedia."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "conversational characters",
            "agents"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-133",
        "Venue": "In CHI 99 Extended Abstracts, ACM Press, pp. 244-245, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-133/FXPAL-PR-99-133.pdf"
        ],
        "PublicationDate": "05/18/1999",
        "ID": "133",
        "Authors": [
            "Scott Prevost",
            "Peter Hodgson",
            "Linda Cook",
            "Elizabeth Churchill"
        ],
        "Title": "Face-to-Face Interfaces.",
        "Abstract": "Recent work on the social nature of human-computer interactions [3] has prompted research on animated, anthropomorphic characters in user interfaces. Such interfaces may simplify user interactions by allowing them to use and interpret natural face-to-face communication techniques such as speech, gestures and facial expressions. We describe our initial implementation, a character that controls the A/V facilities in a state-of-the-art conference room, and outline the goals of our ongoing project. "
    },
    {
        "Projects": [
            "Manga"
        ],
        "keywords": [
            "manga",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-134",
        "Venue": "In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (Phoenix, AZ), vol. 6, pp. 3041-3044, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-134/FXPAL-PR-99-134.pdf"
        ],
        "PublicationDate": "03/15/1999",
        "ID": "134",
        "Authors": [
            "Shingo Uchihashi",
            "Jonathan Foote"
        ],
        "Title": "Summarizing Video using a Shot Importance Measure and a Frame-Packing Algorithm.",
        "Abstract": "This paper presents methods of generating compact pictorial summarizations of video. By calculating a measure of shot importance video can be summarized by de-emphasizing or discarding less important information, such as repeated or common scenes. In contrast to other approaches that present keyframes for each shot, this measure allows summarization by presenting only the most important shots. Selected keyframes can also be resized depending on their relative importance. We present an efficient packing algorithm that constructs a pictorial representation from differently-sized keyframes. This results in a compact and visually pleasing summary reminiscent of a comic book. "
    },
    {
        "Projects": [],
        "keywords": [
            "media",
            "annotation"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-135",
        "Venue": "In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (Phoenix, AZ), vol. 6, pp. 3453-3456, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-135/FXPAL-PR-99-135.pdf"
        ],
        "PublicationDate": "03/15/1999",
        "ID": "135",
        "Authors": [
            "Shingo Uchihashi",
            "Lynn Wilcox"
        ],
        "Title": "Automatic Index Creation for Handwritten Notes.",
        "Abstract": "This paper describes a technique for automatically creating an index for handwritten notes captured as digital ink. No text recog-nition is performed. Rather, a dictionary of possible index terms is built by clustering groups of ink strokes corresponding roughly to words. Terms whose distribution varies significantly across note pages are selected for the index. An index page containing the index terms is created, and terms are hyper-linked back to their original location in the notes. Further, index terms occurring in a note page are highlighted to aid browsing. \r\n"
    },
    {
        "Projects": [
            "Manga",
            "MBase"
        ],
        "keywords": [
            "manga",
            "media",
            "video",
            "mbase"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-136",
        "Venue": "In Proceedings ACM Multimedia, (Orlando, FL) ACM Press, pp. 383-392, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-136/FXPAL-PR-99-136.pdf"
        ],
        "PublicationDate": "10/30/1999",
        "ID": "136",
        "Authors": [
            "Shingo Uchihashi",
            "Jonathan Foote",
            "Andreas Girgensohn",
            "John Boreczky"
        ],
        "Title": "Video Manga: Generating Semantically Meaningful Video Summaries.",
        "Abstract": "This paper presents methods for automatically\r\ncreating pictorial video summaries that resemble\r\ncomic books. The relative importance of\r\nvideo segments is computed from their length\r\nand novelty. Image and audio analysis is used\r\nto automatically detect and emphasize meaningful\r\nevents. Based on this importance measure,\r\nwe choose relevant keyframes. Selected\r\nkeyframes are sized by importance, and then\r\nefficiently packed into a pictorial summary.\r\nWe present a quantitative measure of how well\r\na summary captures the salient events in a\r\nvideo, and show how it can be used to improve\r\nour summaries. The result is a compact and\r\nvisually pleasing summary that captures\r\nsemantically important events, and is suitable\r\nfor printing or Web access. Such a summary\r\ncan be further enhanced by including text captions\r\nderived from OCR or other methods. We\r\ndescribe how the automatically generated summaries\r\nare used to simplify access to a large\r\ncollection of videos."
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "modularRobots"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-137",
        "Venue": "IEEE International Conference on Robotics and Automation, pp. 801 - 808, 2002.",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-137/FXPAL-PR-02-137.pdf"
        ],
        "PublicationDate": "05/11/2002",
        "ID": "137",
        "Authors": [
            "S Vassilvitskii",
            "J Kubica",
            "Eleanor Rieffel",
            "J Suh",
            "M Yim"
        ],
        "Title": "On the General Reconfiguration Problem for Expanding Cube Style Modular Robots.",
        "Abstract": "S. Vassilvitskii, J. Kubica, E. G. Rieffel, J. W. Suh, M. Yim"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-96-138",
        "Venue": "IEEE Computer Society Multimedia Newsletter, 4, 1 (August 1996), pp. 45-48.",
        "palwebURL": [
            "http://palweb/files/PR/1996/PR-96-138/FXPAL-PR-96-138.pdf"
        ],
        "PublicationDate": "08/01/1996",
        "ID": "138",
        "Authors": [
            "Steve Smoliar",
            "Jim Baker"
        ],
        "Title": "Extended Media Research at the FX Palo Alto Laboratory",
        "Abstract": "The fundamental objective of Extended Media research is the empowering of documents through technology. We see our goal as that of inventing documents which communicate more effectively. Furthermore, we need to make it easier for the writer to record what must be communicated and for the reader to access it. Thus, we anticipate that one cannot invent new documents without also inventing new processes for both writing and reading. Our primary research thrust is thus in the authoring of hypermedia documents, supplemented by a secondary thrust concerned with the problem of managing archives and libraries where more than text is involved."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-139",
        "Venue": "In Proceedings of the Thirty-Second Annual Hawaii International Conference on System Sciences (HICSS-32), R. Sprague, Jr., editor, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-139/FXPAL-PR-99-139.pdf"
        ],
        "PublicationDate": "02/05/1999",
        "ID": "139",
        "Authors": [
            "Steve Smoliar",
            "Jim Baker"
        ],
        "Title": "Storytelling, Jamming, and All That Jazz: Knowledge Creation in the World of New Media.",
        "Abstract": "This is a critical view of the hypothesis that better access to a broader repertoire of media resources will significantly enhance our ability to communicate more effectively. It begins by laying down a foundation of some basic principles concerning the nature of knowledge creation. This foundation is framed in a manner that involves the potential relevance of two particularly creative activities, storytelling and making jazz. This foundation provides the basis for a critical examination of several media-rich presentations that were delivered at the Institute for the Future Outlook Exchange in November of 1997, since these presentations actually pertained to the practices of digital storytelling and jamming. This critique is followed by a more detailed examination of what we may learn from jazz if we wish to invoke it as a metaphor for knowledge creation. The report then concludes by discussing the implications of these observations for a new world of work experiences in which knowledge creation is a critical element."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-140",
        "Venue": "In Proceedings of the Thirtieth Annual Hawaii International Conference on System Sciences (Wailea, Hawaii, January 1997), Volume VI, pp. 68-77. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-140/FXPAL-PR-97-140.pdf"
        ],
        "PublicationDate": "01/07/1997",
        "ID": "140",
        "Authors": [
            "Steve Smoliar",
            "Jim Baker"
        ],
        "Title": "Text Types in Hypermedia.",
        "Abstract": "The discipline of narratology has long recognized the need to classify documents as instances of different text types. We have discovered that classification is as applicable to hypermedia as it is to any other document presentation. Following the work of S. Chatman (1978; 1990), we consider three such text types: description, argument and narrative. The goal of a description document is to describe some object or concept; this is usually achieved by describing component parts and then describing how those parts combine to constitute the entirety. An argument document, on the other hand, is concerned with establishing some assertion or point of view, and it is based on supporting evidence, as well as possible refutations and justifications for defeating those regulations. Finally, a narrative document recounts some sequence of events in time, addressing relationships such as causality and contingency among those events. We analyze these types through case studies that give an example of each as a hypermedia document. We then argue that this classification provides an organizational framework that facilitates the construction of outlines that serve the writer in preparing the actual content of a document. Such outlines can also benefit the reader's understanding of the content that the writer intended to convey; if the writer does not make those outlines available explicitly to the reader, the reader can use knowledge of the document type to construct his own version of those outlines. Finally, we review some early work in content based indexing and search of multimedia documents"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-141",
        "Venue": "In Proceedings: VISual'97; Second International Conference on Visual Information Systems (San Diego, CA), 1997, pp. 53-60. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-141/FXPAL-PR-97-141.pdf"
        ],
        "PublicationDate": "12/15/1997",
        "ID": "141",
        "Authors": [
            "Steve Smoliar",
            "Lynn Wilcox"
        ],
        "Title": "Indexing the Content of Multimedia Documents.",
        "Abstract": "As the concept of what constitutes a \"content-based\" search grows more mature, it becomes valuable for us to establish a clear sense of just what is meant by \"content.\" Recent multimedia document retrieval systems have dealt with this problem by indexing across multiple indexes; but it is important to identify how such multiple indexes are dealing with multiple dimensions of a description space, rather than simply providing the user with more descriptors. In this paper we consider a description space for multimedia documents based on three \"dimensions\" of a document, namely context, form, and content. We analyze the nature of this space with respect to three challenging examples of multimedia search tasks, and we address the nature of the index structures that would facilitate how these tasks may be achieved. These examples then lead us to some general conclusions on the nature of multimedia indexing and the intuitions we have inherited from the tradition of books and libraries. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-142",
        "Venue": "Proceedings: 1st International Workshop on Computational Semiotics (SEMIOTICS'97), 1997.",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-142/FXPAL-PR-97-142.pdf"
        ],
        "PublicationDate": "05/26/1997",
        "ID": "142",
        "Authors": [
            "Steve Smoliar",
            "Tina Schneider"
        ],
        "Title": "Signs, Links, and the Semiotics of Hypertext",
        "Abstract": "This paper examines the semiotic nature of the hypertext document from two points of view, both of which are based on Roland Barthes' ELEMENTS OF SEMIOLOGY. From the more conventional point of view, the hypertext document is discussed with respect to the four areas analyzed by Barthes: the distinction between language and speech, the relationship between the signifier and the signified, the syntagmatic and associative relationships among signs, and the hierarchical embedding of signs through connotation and metalanguage. The second examination is a hypertext document designed in such a way that the reader may EXPERIENCE Barthes' elements of semiology, rather than serve as a passive receiver of his exposition. The result is an interactive environment in its own right, entitled \"Signs and Links,\" that, through the experience of interaction, engages the reader in the definition of the conceptual space of Barthes' text."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-143",
        "Venue": "Image Databases and Multi-Media Search, A. W. M. Smeulders and R. Jain, editors, 1997, pp. 3-10.",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-143/FXPAL-PR-97-143.pdf"
        ],
        "PublicationDate": "01/01/1997",
        "ID": "143",
        "Authors": [
            "Steve Smoliar",
            "Jim Baker",
            "Takehiro Nakayama",
            "Lynn Wilcox"
        ],
        "Title": "Multimedia Search: An Authoring Perspective.",
        "Abstract": "S.W. Smoliar, J.D. Baker, T. Nakayama, and L. Wilcox,"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-99-144",
        "Venue": "In The Computer Journal, 42 (6), pp. 534-546, 1999.",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-144/FXPAL-PR-99-144.pdf"
        ],
        "PublicationDate": "02/01/1999",
        "ID": "144",
        "Authors": [
            "Timothy Bickmore",
            "Andreas Girgensohn",
            "Joe Sullivan"
        ],
        "Title": "Web Page Filtering and Re-Authoring for Mobile Users",
        "Abstract": "The Digestor system automatically converts web-based documents designed for desktop viewing into formats appropriate for handheld devices with small display screens, such as Palm-PCs, PDAs, and cellular phones. Digestor employs a heuristic planning algorithm and a set of structural page transformations to produce the \"best\" looking document for a given display size. Digestor can also be instructed, via a scripting language, to render portions of documents, thereby avoiding navigation through many screens of information. Two versions of Digestor have been deployed, one that re-authors HTML into HTML for conventional browsers, and one that converts HTML into HDML for Unwired Planet's micro-browsers. Digestor provides a crucial technology for rapidly accessing, scanning and processing information from arbitrary web-based documents from any location reachable by wired or unwired communication. "
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "conversational characters",
            "agents"
        ],
        "AcceptDate": "",
        "palwebID": "PR-98-145",
        "Venue": "In Proceedings of the Second International Conference on Autonomous Agents (Minneapolis, MN), 1998, pp 8-15.",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-145/FXPAL-PR-98-145.pdf"
        ],
        "PublicationDate": "05/09/1998",
        "ID": "145",
        "Authors": [
            "Timothy Bickmore",
            "Linda Cook",
            "Elizabeth Churchill",
            "Joe Sullivan"
        ],
        "Title": "Animated Autonomous Personal Representatives",
        "Abstract": "We describe the research goals and issues in constructing autonomous personal representatives, and the desirability of using synthetic characters as the user interface for such artifacts. An application of these autonomous representatives is then described in which characters can be attached to a document to express a user's point of view or give guided tours or presentations of the document's contents. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-96-146",
        "Venue": "Proceedings of the 16th International Conference on Computational Linguistics (Copenhagen, Denmark, August 1996).",
        "palwebURL": [],
        "PublicationDate": "08/01/1996",
        "ID": "146",
        "Authors": [
            "Takehiro Nakayama"
        ],
        "Title": "Content-Oriented Categorization of Document Images",
        "Abstract": "We have developed a technique that categorizes document images based on their content. Unlike conventional methods that use optical character recognition (OCR), we convert document images into word shape takens, a shape-based representation of words. Because we have only to recognize simple graphical features from image, this process is much faster than OCR. Although the mapping between word shape tokens and words is one-to-many, they are a rich source of information for content characterization. Using a vector space classifier with a scanned document image database, we show that the word shape token-based approach is quite adequate for content-oriented categorization in terms of accuracy compared with conventional OCR-based approaches."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-95-147",
        "Venue": "In Hypermedia Design, Montpellier 1995. S. FranssT, F. Garzotto, T. Isakowitz, J. Nardard, and M. Narard (eds.), Springer Verlag, 1996, pp. 39-58. ",
        "palwebURL": [],
        "PublicationDate": "11/01/1995",
        "ID": "147",
        "Authors": [
            "Takeshi Shimizu",
            "O Nakamura",
            "Y Kiyoki"
        ],
        "Title": "Multimedia Document System for Temporal and Spatial Structuring",
        "Abstract": "Structuring temporal relationships among multimedia information elements is one of the most important facilities for editing and creating multimedia documents. We have developed a multimedia system named MediaPreview which provides facilities for structuring and creating multimedia documents. In this paper, we present a document model which is adopted in MediaPreview. This model has been designed to realize spatial and temporal structuring for the documents. The main feature of this model is the concept of a \"Multimedia Paragraph\" (MMP) which is introduced to reduce the complexity of the temporal structuring, such as the asynchronous interactive operation among documents. The concept of \"MMP\" provides an explicit and basic unit which is used to create a document in a \"top-down\" manner. \r\n\r\nThis paper also presents the system architecture and implementation of MediaPreview in a distributed environment including database system facilities. This system realizes \"static\" and \"dynamic\" integration schemes for multimedia information elements. Our system includes a parallel database engine which manipulates multimedia information elements as streams. This database engine is effectively used for creating multimedia documents.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-98-148",
        "Venue": "In Proceedings of the Thirty-first Annual Hawaii International Conference on System Sciences (Wailea, Hawaii, January 1998), Volume II, pp. 207-215. ",
        "palwebURL": [
            "http://palweb/files/PR/1998/PR-98-148/FXPAL-PR-98-148.pdf"
        ],
        "PublicationDate": "02/06/1998",
        "ID": "148",
        "Authors": [
            "Takeshi Shimizu",
            "Steve Smoliar",
            "John Boreczky"
        ],
        "Title": "AESOP: An Outline-Oriented Authoring System",
        "Abstract": "Because a hypermedia document is more complex than conventional text, it requires preparation with respect to two key aspects. First, the author begins to develop a \"vision\" of the document-usually based on some outline-level description of his objectives. At the same time, as this outline is being developed, the author begins to extract useful segments from his resource materials and prepares his first version of the logic of a system of hyperlinks among those segments. In this paper we present a system named \"Authoring Environment for the deSktOP\" (AESOP) with two different types of \"outlining\" tools to handle these aspects. Planning the \"vision\" consists in defining a \"logical\" tree structure of the document. The plan for the link structure is based on a primitive unit called the view area, and AESOP provides a construct named Bento-Box for creating and manipulating view areas. Authors specify spatial and temporal layout within a single Bento-Box and define hyperlinks among the Bento-Boxes.\r\n"
    },
    {
        "Projects": [
            "M-Links"
        ],
        "keywords": [
            "ubiquitous",
            "m-links"
        ],
        "AcceptDate": "",
        "palwebID": "PR-97-149",
        "Venue": "In Proceedings for the Sixth International World Wide Web Conference, 1997, pp. 655-663. ",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-149/FXPAL-PR-97-149.html"
        ],
        "PublicationDate": "04/07/1997",
        "ID": "149",
        "Authors": [
            "Timothy Bickmore",
            "Bill Schilit"
        ],
        "Title": "Digestor: Device-Independent Access to the World Wide Web",
        "Abstract": "Digestor is a software system which automatically re-authors arbitrary documents from the world-wide web to display appropriately on small screen devices such as PDAs and cellular phones, providing device-independent access to the web. Digestor is implemented as an HTTP proxy which dynamically re-authors requested web pages using a heuristic planning algorithm and a set of structural page transformations to achieve the best looking document for a given display size.\r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-150",
        "Venue": "Proceedings of ACM Multimedia 2001, Ottawa, Canada, Oct. 5, 2001.",
        "palwebURL": [],
        "PublicationDate": "10/05/2001",
        "ID": "150",
        "Authors": [
            "Y Rui",
            "L He",
            "A Gupta",
            "Qiong Liu"
        ],
        "Title": "Building an Intelligent Camera Management System",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-01-151",
        "Venue": "In Workshop on Identifying Objects Across Variations in Lighting: Psychophysics & Computation, Proc. IEEE Intl. Conf. on Computer Vision & Pattern Recognition 2001. \r\n\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-151/FXPAL-PR-01-151.pdf"
        ],
        "PublicationDate": "12/12/2001",
        "ID": "151",
        "Authors": [
            "Matthew Cooper",
            "Keith Doolittle",
            "Michael Miller"
        ],
        "Title": "Signature Random Fields for Accommodating Illumination Variability",
        "Abstract": "In this paper, we document an extension to traditional\r\n\r\npattern-theoretic object templates to jointly accommodate\r\n\r\nvariations in object pose and in the radiant appearance of\r\n\r\nthe object surface. We first review classical object templates accommodating pose variation. We then develop an efficient subspace representation for the object radiance indexed on the surface of the three dimensional object tem-plate.  We integrate the low-dimensional representation for\r\n\r\nthe object radiance, or signature, into the pattern-theoretic template, and present the results of orientation estimation experiments. The experiments demonstrate both estimation performance fluctuations under varying illumination conditions and performance degradations associated with unknown scene illumination. We also present a Bayesian approach for estimation accommodating illumination variability."
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "similarity",
            "music",
            "audio",
            "media"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-152",
        "Venue": "Proc. International Conference on Computer Music (ICMC), Habana, Cuba, September 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-152/FXPAL-PR-01-152.pdf"
        ],
        "PublicationDate": "09/12/2001",
        "ID": "152",
        "Authors": [
            "Jonathan Foote",
            "Matthew Cooper"
        ],
        "Title": "Visualizing Musical Structure and Rhythm via Self-Similarity",
        "Abstract": "This paper presents a novel approach to visualizing the time structure of musical waveforms. The acoustic similarity between any two instants of an audio recording is displayed in a static 2D representation, which makes structural and rhythmic characteristics visible. Unlike practically all prior work, this method characterizes self-similarity rather than specific audio attributes such as pitch or spectral features. Examples are presented for classical and popular music. \r\n\r\n"
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "Hypertext",
            "theory",
            "user interface",
            "e-books",
            "XLibris",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-153",
        "Venue": "New Review of Hypermedia and Multimedia vol 6 (2000) pp 169-196",
        "palwebURL": [],
        "PublicationDate": "04/16/2000",
        "ID": "153",
        "Authors": [
            "Gene Golovchinsky",
            "Catherine Marshall"
        ],
        "Title": "Hypertext interactivity: From choice to participation",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "Information seeking",
            "information retrieval",
            "theory",
            "interaction",
            "evaluation",
            "methodology",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-97-154",
        "Venue": "New Review of Hypermedia and Multimedia . Vol 3. (1997), Taylor Graham. pp. 123-158. \r\n",
        "palwebURL": [],
        "PublicationDate": "06/01/1997",
        "ID": "154",
        "Authors": [
            "Gene Golovchinsky",
            "Mark Chignell",
            "Nipon Charoenkitkarn"
        ],
        "Title": "Formal experiments in causal attire: Case studies in information exploration",
        "Abstract": "This paper addresses the issue of how research methodology can be developed for the specific needs of research into information exploration behavior, based on a four year program of research on individual strategies in information exploration. We propose a meta-experimental framework where research is carried out through a dynamic interaction between what and why questions, and between confirmatory and exploratory analyses. This approach preserves many of the advantages of formal experimentation, while permitting a more holistic examination of phenomena that is characteristic of ethnography. The application of the meta-theoretical framework is illustrated in three case studies that examined new information exploration functionalities and interfaces and their relationship to expertise and exploration strategy.\r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "Information seeking",
            "user interface",
            "hypertext",
            "metaphor",
            "evaluation",
            "hcir"
        ],
        "AcceptDate": "",
        "palwebID": "PR-97-155",
        "Venue": "Journal of Information Processing & Management.33(5) pp. 663-683.\r\n\r\n\r\n\r\n",
        "palwebURL": [],
        "PublicationDate": "06/01/1997",
        "ID": "155",
        "Authors": [
            "Gene Golovchinsky",
            "Mark Chignell"
        ],
        "Title": "The Newspaper as an Information Exploration Metaphor",
        "Abstract": "The newspaper represents a mature information presentation medium that is well-suited to the presentation of relatively short, loosely related pieces of text. This work examines the implementation of the newspaper metaphor in an information exploration interface. Based on an analysis of differences between electronic books and electronic newspapers, we submit that the newspaper metaphor is an appropriate interface paradigm for large-scale full-text databases. Similarities between newspapers and hypertext databases lead us to suggest that this metaphor is appropriate for large automatically-generated hypertexts, independent of the nature of their content. We describe VOIR, a software prototype that we have used as an electronic newspaper workbench. The program constructs newspaper pages interactively, and allows users to specify their information-seeking intent in a variety of ways, including graphical Boolean queries, hypertext links, and typed-in queries. Finally, we discuss some implications that this work has for hypertext and information retrieval in general. \r\n\r\n\r\n\r\n"
    },
    {
        "Projects": [
            "SharedTextInput"
        ],
        "keywords": [
            "immersive",
            "annotation",
            "sti"
        ],
        "AcceptDate": "01/29/2002",
        "palwebID": "PR-02-158",
        "Venue": "CHI 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-158/FXPAL-PR-02-158.pdf"
        ],
        "PublicationDate": "04/22/2002",
        "ID": "158",
        "Authors": [
            "Laurent Denoue",
            "Patrick Chiu",
            "Tohru Fuse"
        ],
        "Title": "Shared Text Input for Note Taking on Handheld Devices",
        "Abstract": "Shared text input is a technique we implemented into a note taking system\r\nfor facilitating text entry on small devices. Instead of writing out words\r\non the tedious text entry interfaces found on handheld computers, users\r\ncan quickly reuse words and phrases already entered by others. Sharing\r\nnotes during a meeting also increases awareness among note takers. We\r\nfound that filtering the text to share was appropriate to deal with a\r\nvariety of design issues such as screen real estate, scalability, privacy,\r\nreciprocity, and predictability of text location"
    },
    {
        "Projects": [
            "Manga"
        ],
        "keywords": [
            "manga",
            "media",
            "video",
            "audio"
        ],
        "AcceptDate": "05/02/2002",
        "palwebID": "PR-02-159",
        "Venue": "Proceedings IEEE International Conference on Multimedia \r\nand Expo, Lausanne, Switzerland, August 2002 ",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-159/FXPAL-PR-02-159.pdf"
        ],
        "PublicationDate": "08/26/2002",
        "ID": "159",
        "Authors": [
            "Jonathan Foote",
            "Matthew Cooper",
            "Lynn Wilcox"
        ],
        "Title": "Enhanced Video Browsing Using Automatically Extracted Audio Excerpts ",
        "Abstract": "We present a method for rapidly and robustly extracting audio excerpts without the overhead of speech recognition or speaker segmentation. An immediate application is to automatically augment keyframe-based video summaries with informative audio excerpts associated with the video segments represented by the keyframes. Short audio clips combined with keyframes comprise an extremely lightweight and Web-browsable interface for auditioning video or similar media, without using bandwidth-intensive streaming video or audio."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "palette",
            "SocComp"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-160",
        "Venue": "CHI2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-160/FXPAL-PR-02-160.pdf"
        ],
        "PublicationDate": "04/22/2002",
        "ID": "160",
        "Authors": [
            "Elizabeth Churchill",
            "Les Nelson"
        ],
        "Title": "Tangibly Simple, Architecturally Complex: Evaluating a Tangible Presentation Aid",
        "Abstract": "In this paper, we describe an evaluation of the Palette, a presentation tool that was reported at CHI '99. The Palette allows presenters to quickly access digital presentations using physical cards that have unique barcodes printed on them. The Palette has been in use in our lab for over three years, and has been released as a product in Japan. Our evaluation consists of an analysis of usage logs, an expert walkthrough review, and observations and interviews with users, non-users and the system administrator. The findings reveal benefits and drawbacks of the technology, and offers design ideas for further work on tangible tools of this kind. "
    },
    {
        "Projects": [],
        "keywords": [
            "usage data"
        ],
        "AcceptDate": "",
        "palwebID": "PR-01-161",
        "Venue": "The Eighth IFIP TC.13 Conference On Human-Computer Interaction (INTERACT 2001). Tokyo, Japan, July 9-13, 2001.",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-161/FXPAL-PR-01-161.pdf"
        ],
        "PublicationDate": "07/09/2001",
        "ID": "161",
        "Authors": [
            "David Hilbert",
            "David Redmiles"
        ],
        "Title": "Large-Scale Collection of Usage Data to Inform Design",
        "Abstract": "The two most commonly used techniques for evaluating the fit between application design and use - namely, usability testing and beta testing with user feedback - suffer from a number of limitations that restrict evaluation scale (in the case of usability tests) and data quality (in the case of beta tests). They also fail to provide developers with an adequate basis for: (1) assessing the impact of suspected problems on users at large, and (2) deciding where to focus development and evaluation resources to maximize the benefit for users at large. This paper describes an agent-based approach for collecting usage data and user feedback over the Internet that addresses these limitations to provide developers with a complementary source of usage- and usability-related information.  Contributions include: a theory to motivate and guide data collection, an architecture capable of supporting very large scale data collection, and real-word experience suggesting the proposed approach is complementary to existing practice."
    },
    {
        "Projects": [],
        "keywords": [
            "usage data"
        ],
        "AcceptDate": "",
        "palwebID": "PR-00-162",
        "Venue": "ACM Computing Surveys, Vol. 32 No. 4, December 2000. \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-162/FXPAL-PR-00-162.pdf"
        ],
        "PublicationDate": "12/01/2000",
        "ID": "162",
        "Authors": [
            "David Hilbert",
            "David Redmiles"
        ],
        "Title": "Extracting usability information from user interface events",
        "Abstract": "Modern window-based user interface systems generate user interface events as natural products of their normal operation. Because such events can be automatically captured and because they indicate user behavior with respect to an application's user interface, they have long been regarded as a potentially fruitful source of information regarding application usage and usability. However, because user interface events are typically voluminos and rich in detail, automated support is generally required to extract information at a level of abstraction that is useful to investigators interested in analyzing application usage or evaluating usability. This survey examines computer-aided techniques used by HCI practitioners and researchers to extract usability-related information from user interface events. A framework is presented to help HCI practitioners and researchers categorize and compare the approaches that have been, or might fruitfully be, applied to this problem. Because many of the techniques in the research literature have not been evaluated in practice, this survey provides a conceptual evaluation to help identify some of the relative merits and drawbacks of the various classes of approaches. Ideas for future research in this area are also presented. This survey addresses the following questions: How might user interface events be used in evaluating usability? How are user interface events related to other forms of usability data? What are the key challenges faced by investigators wishing to exploit this data? What approaches have been brought to bear on this problem and how do they compare to one another? What are some of the important open research questions in this area? "
    },
    {
        "Projects": [
            "FlyCam",
            "FlySPEC"
        ],
        "keywords": [
            "immersive",
            "flyspec",
            "spec",
            "flycam"
        ],
        "AcceptDate": "04/05/2002",
        "palwebID": "PR-02-163",
        "Venue": "SPIE ITCOM 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-163/FXPAL-PR-02-163.doc",
            "http://palweb/files/PR/2002/PR-02-163/FXPAL-PR-02-163.pdf"
        ],
        "PublicationDate": "07/31/2002",
        "ID": "163",
        "Authors": [
            "Don Kimber",
            "Qiong Liu",
            "Jonathan Foote",
            "Lynn Wilcox"
        ],
        "Title": "Capturing and Presenting Shared Multi-Resolution Video",
        "Abstract": "We present a framework, motivated by rate-distortion theory and the human visual system, for optimally representing the real world given limited video resolution. To provide users with high fidelity views, we built a hybrid video camera system that combines a fixed wide-field panoramic camera with a controllable pan/tilt/zoom (PTZ) camera. In our framework, a video frame is viewed as a limited-frequency representation of some \"true\" image function.  Our system combines outputs from both cameras to construct the highest fidelity views possible, and controls the PTZ camera to maximize information gain available from higher spatial frequencies.  In operation, each remote viewer is presented with a small panoramic view of the entire scene, and a larger close-up view of a selected region. Users may select a region by marking the panoramic view.  The system operates the PTZ camera to best satisfy requests from multiple users. When no regions are selected, the system automatically operates the PTZ camera to minimize predicted video distortion. High-resolution images are cached and sent if a previously recorded region has not changed and the PTZ camera is pointed elsewhere. We present experiments demonstrating that the panoramic image can effectively predict where to gain the most information, and also that the system provides better images to multiple users than conventional camera systems."
    },
    {
        "Projects": [
            "FlySPEC"
        ],
        "keywords": [
            "SPEC",
            "flyspec",
            "immersive"
        ],
        "AcceptDate": "05/15/2002",
        "palwebID": "PR-02-164",
        "Venue": "IEEE International Conference on Multimedia and Expo 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-164/FXPAL-PR-02-164.pdf"
        ],
        "PublicationDate": "08/26/2002",
        "ID": "164",
        "Authors": [
            "Qiong Liu",
            "Don Kimber",
            "Lynn Wilcox",
            "Matthew Cooper",
            "Jonathan Foote",
            "John Boreczky"
        ],
        "Title": "MANAGING A CAMERA SYSTEM TO SERVE DIFFERENT VIDEO REQUESTS",
        "Abstract": "This paper presents a camera system called FlySPEC.  In contrast to a traditional camera system that provides the same video stream to every user, FlySPEC can simultaneously serve different video-viewing requests.  This flexibility allows users to conveniently participate in a seminar or meeting at their own pace.  Meanwhile, the FlySPEC system provides a seamless blend of manual control and automation.  With this control mix, users can easily make tradeoffs between video capture effort and video quality.  The FlySPEC camera is constructed by installing a set of Pan/Tilt/Zoom (PTZ) cameras near a high-resolution panoramic camera.  While the panoramic camera provides the basic functionality of serving different viewing requests, the PTZ camera is managed by our algorithm to improve the overall video quality that may affect users watching details.  The video resolution improvements from using different camera management strategies are compared in the experimental section."
    },
    {
        "Projects": [
            "PIPs"
        ],
        "keywords": [
            "21stCenturyComputing",
            "quantum"
        ],
        "AcceptDate": "04/15/2002",
        "palwebID": "PR-02-165",
        "Venue": "Journal of Mathematical Physics, September 2002 special\r\nissue on Quantum Information Theory, Vol. 43 (9), pp. 4376 - 7381.",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-165/FXPAL-PR-02-165.pdf",
            "http://palweb/files/PR/2002/PR-02-165/FXPAL-PR-02-165.ps"
        ],
        "PublicationDate": "09/07/2002",
        "ID": "165",
        "Authors": [
            "Eleanor Rieffel",
            "Christof Zalka"
        ],
        "Title": "Quantum Operations that\r\ncannot be Implemented using a Small Mixed Environment",
        "Abstract": "To implement any quantum operation (a.k.a. ``superoperator'' or ``CP map'') on a d-dimensional quantum system, it is\r\n     enough to apply a suitable overall unitary transformation to the system and a d^2-dimensional environment which is\r\n     initialized in a fixed pure state. It has been suggested that a d-dimensional environment might be enough if we could\r\n     initialize the environment in a mixed state of our choosing. In this note we show with elementary means that certain\r\n     explicit quantum operations cannot be realized in this way. Our counterexamples map some pure states to pure states,\r\n     giving strong and easily manageable conditions on the overall unitary transformation. Everything works in the more\r\n     general setting of quantum operations from d-dimensional to d'-dimensional spaces, so we place our counterexamples\r\n     within this more general framework. "
    },
    {
        "Projects": [
            "PIPs"
        ],
        "keywords": [
            "ubiquitous",
            "pips"
        ],
        "AcceptDate": "06/06/2002",
        "palwebID": "PR-02-166",
        "Venue": "The 4th International Conference on Ubiquitous Computing (UbiComp 2002).",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-166/FXPAL-PR-02-166.pdf"
        ],
        "PublicationDate": "09/29/2002",
        "ID": "166",
        "Authors": [
            "Jonathan Trevor",
            "David Hilbert",
            "Bill Schilit"
        ],
        "Title": "Issues in Personalizing Shared Ubiquitous Devices",
        "Abstract": "As ubiquitous computing becomes widespread, we are increasingly coming into contact with \"shared\" computer-enhanced devices, such as cars, televisions, and photocopiers. Our interest is in identifying general issues in personalizing such shared everyday devices. Our approach is to compare alternative personalization methods by deploying and using alternative personalization interfaces (portable and embedded) for three shared devices in our workplace (a presentation PC, a plasma display for brainstorming, and a multi-function copier). This paper presents the comparative prototyping methodology we employed, the experimental system we deployed, observations and feedback from use, and resulting issues in designing personalized shared ubiquitous devices."
    },
    {
        "Projects": [],
        "keywords": [
            "NL"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-169",
        "Venue": "Communication of the ACM, February 2002. Volume 45 Number 2. 55-60.",
        "palwebURL": [],
        "PublicationDate": "02/01/2002",
        "ID": "169",
        "Authors": [
            "Livia Polanyi",
            "Martin van den Berg",
            "Daniel Bobrow",
            "Cleo Condoravdi",
            "Richard Crouch",
            "John Everett",
            "Reinhard Stolle",
            "Valeria di Paiva"
        ],
        "Title": "Making Ontologies Work for Resolving Redundancies Across Documents",
        "Abstract": ""
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "similarity",
            "media",
            "audio",
            "music"
        ],
        "AcceptDate": "07/07/2002",
        "palwebID": "PR-02-171",
        "Venue": "2002 International Symposium on Music Information Retrieval",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-171/FXPAL-PR-02-171.pdf"
        ],
        "PublicationDate": "10/13/2002",
        "ID": "171",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote"
        ],
        "Title": "Automatic Music Summarization via Similarity Analysis",
        "Abstract": "We present methods for automatically producing summary excerpts or thumbnails of music. To find the most representative excerpt, we maximize the average segment similarity to the entire work. After window-based audio parameterization, a quantitative similarity measure is calculated between every pair of windows, and the results\r\nare embedded in a 2-D similarity matrix. Summing the similarity matrix over the support of a segment results in a measure of how similar that segment is to the whole. This measure is maximized to find the segment that best represents the entire work. We discuss variations on the method, and present experimental results for orchestral music, popular songs, and jazz. These results demonstrate that the method finds significantly representative excerpts, using very few assumptions about the source audio."
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "media",
            "similarity",
            "music",
            "audio"
        ],
        "AcceptDate": "07/07/2002",
        "palwebID": "PR-02-172",
        "Venue": "2002 International Symposium on Music Information Retrieval",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-172/FXPAL-PR-02-172.pdf"
        ],
        "PublicationDate": "10/13/2002",
        "ID": "172",
        "Authors": [
            "Jonathan Foote",
            "Matthew Cooper",
            "Unjung Nam"
        ],
        "Title": "Audio Retrieval by Rhythmic Similarity",
        "Abstract": "We present a method for characterizing both the rhythm and\r\ntempo of music. We also present ways to quantitatively measure the rhythmic similarity between two or more works of music. This allows rhythmically similar works to be retrieved from a large collection. A related application is to sequence music by rhythmic similarity, thus providing an automatic \"disc jockey\" function for musical libraries. Besides specific analysis and retrieval methods, we present small-scale experiments that demonstrate ranking and retrieving musical audio by rhythmic similarity.\r\n"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "06/09/2002",
        "palwebID": "PR-02-173",
        "Venue": "ACM 2002 Conference on Computer Supported Cooperative Work",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-173/FXPAL-PR-02-173.pdf"
        ],
        "PublicationDate": "11/16/2002",
        "ID": "173",
        "Authors": [
            "Andreas Girgensohn",
            "Alison Lee"
        ],
        "Title": "Making Web Sites Be Places for Social Interaction",
        "Abstract": "Technology can play an important role in enabling people to interact with each other. The Web is one such technology with the affordances for sharing information and for connecting people to people. In this paper, we describe the design of two social interaction Web sites for two different social groups. We review several related efforts to provide principles for creating social interaction environments and describe the specific principles that guided our design. To examine the effectiveness of the two sites, we analyze the usage data. Finally, we discuss approaches for encouraging participation and lessons learned."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-02-174",
        "Venue": "International Journal of Human-Computer Studies, 56, pp. 75-107",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-174/FXPAL-PR-02-174.pdf"
        ],
        "PublicationDate": "02/01/2002",
        "ID": "174",
        "Authors": [
            "Alison Lee",
            "Andreas Girgensohn"
        ],
        "Title": "Design, Experiences, and User Preferences for a Web-based Awareness Tool",
        "Abstract": "We describe our experiences with the design, implementation, deployment, and evaluation of a Portholes tool which provides\r\ngroup and collaboration awareness through the Web. The research objective was to explore how such a system would improve\r\ncommunication and facilitate a shared understanding among distributed development groups. During the deployment of our Portholes\r\nsystem, we conducted a naturalistic study by soliciting user feedback and evolving the system in response. Many of the initial reactions of\r\npotential users indicated that our system projected the wrong image so that we designed a new version that provided explicit cues about\r\nbeing in public and who is looking back to suggest a social rather than information interface. We implemented the new design as a Java\r\napplet and evaluated design choices with a preference study. Our experiences with different Portholes versions and user reactions to them\r\nprovide insights for designing awareness tools beyond Portholes systems. Our approach is for the studies to guide and to provide feedback\r\nfor the design and technical development of our system."
    },
    {
        "Projects": [
            "Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "media",
            "video",
            "audio",
            "similarity"
        ],
        "AcceptDate": "07/11/2002",
        "palwebID": "PR-02-175",
        "Venue": "ACM Multimedia 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-175/FXPAL-PR-02-175.pdf"
        ],
        "PublicationDate": "12/01/2002",
        "ID": "175",
        "Authors": [
            "Jonathan Foote",
            "Matthew Cooper",
            "Andreas Girgensohn"
        ],
        "Title": "Creating Music Videos using Automatic Media Analysis",
        "Abstract": "We present methods for automatic and semi-automatic creation of music videos, given an arbitrary audio soundtrack and source video. Significant audio changes are automatically detected; similarly, the source video is automatically segmented and analyzed for suitability based on camera motion and exposure. Video with excessive camera motion or poor contrast is penalized with a high unsuitability score, and is more likely to be discarded in the final edit. High quality video clips are then automatically selected and aligned in time with significant audio changes. Video clips are adjusted to match the audio segments by selecting the most suitable region of the desired length. Besides a fully automated solution, our system can also start with clips manually selected and ordered using a graphical interface. The video is then created by truncating the selected clips (preserving the high quality portions) to produce a video digest that is synchronized with the soundtrack music, thus enhancing the impact of both. "
    },
    {
        "Projects": [
            "FlyCam",
            "FlySPEC"
        ],
        "keywords": [
            "immersive",
            "flyspec",
            "spec",
            "flycam"
        ],
        "AcceptDate": "07/11/2002",
        "palwebID": "PR-02-176",
        "Venue": "ACM Multimedia 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-176/FXPAL-PR-02-176.pdf"
        ],
        "PublicationDate": "12/01/2002",
        "ID": "176",
        "Authors": [
            "Qiong Liu",
            "Don Kimber",
            "Jonathan Foote",
            "Lynn Wilcox",
            "John Boreczky"
        ],
        "Title": "FLYSPEC: A Multi-User Video Camera System with \r\nHybrid Human and Automatic Control\r\n",
        "Abstract": "FlySPEC is a video camera system designed for real-time remote operation. A hybrid design combines the high resolution possible using an optomechanical video camera, with the wide field of view always available from a panoramic camera. The control system integrates requests from multiple users with the result that each controls a virtual camera. The control system seamlessly integrates manual and fully automatic control. It supports a range of options from untended automatic to full manual control, and the system can learn control strategies from user requests. Additionally, the panoramic view is always available for an intuitive interface, and objects are never out of view regardless of the zoom factor. We present the system architecture, an information-theoretic approach to combining panoramic and zoomed images to optimally satisfy user requests, and experimental results that show the FlySPEC system significantly assists users in a remote inspection tasks.  "
    },
    {
        "Projects": [],
        "keywords": [
            "ubiquitous",
            "context-aware"
        ],
        "AcceptDate": "10/15/2002",
        "palwebID": "PR-02-177",
        "Venue": "IEEE Wireless Communications Magazine, Vol. 9, No. 5.",
        "palwebURL": [],
        "PublicationDate": "10/15/2002",
        "ID": "177",
        "Authors": [
            "Bill Schilit",
            "David Hilbert",
            "Jonathan Trevor"
        ],
        "Title": "Context-Aware Communication",
        "Abstract": "This paper describes how the changing information about an individual's location, environment, and social situation can be used to initiate and facilitate people's interactions with one another, individually and in groups. Context-aware communication is contrasted with other forms of context-aware computing and we characterize applications in terms of design decisions along two dimensions: the extent of autonomy in context sensing and the extent of autonomy in communication action. A number of context-aware communication applications from the research literature are presented in five application categories. Finally, a number of issues related to the design of context-aware communication applications are presented."
    },
    {
        "Projects": [
            "FlyAbout",
            "FlyCam"
        ],
        "keywords": [
            "flyabout",
            "flycam",
            "immersive"
        ],
        "AcceptDate": "05/15/2002",
        "palwebID": "PR-02-179",
        "Venue": "IEEE International Conference on Multimedia and Expo 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-179/FXPAL-PR-02-179.pdf"
        ],
        "PublicationDate": "08/26/2002",
        "ID": "179",
        "Authors": [
            "Xinding Sun",
            "Don Kimber",
            "Jonathan Foote",
            "B. Manjunath"
        ],
        "Title": "Detecting Path Intersections in Panoramic Video",
        "Abstract": "Given panoramic video taken along a self-intersecting path, we present a method for detecting the intersection points. This allows \"virtual tours\" to be synthesized by splicing the panoramic video at the intersection points. Spatial intersections are detected by finding the best-matching panoramic images from a number of nearby candidates. Each panoramic image is segmented into horizontal strips. Each strip is averaged in the vertical direction. The Fourier coefficients of the resulting 1-D data capture the rotation-invariant horizontal texture of each panoramic image. The distance between two panoramic images is calculated as the sum of the distances between their strip texture pairs at the same row positions. The intersection is chosen as the two candidate panoramic images that have the minimum distance.\r\n"
    },
    {
        "Projects": [
            "M-Links"
        ],
        "keywords": [
            "ubiquitous",
            "m-links"
        ],
        "AcceptDate": "08/15/2002",
        "palwebID": "PR-02-180",
        "Venue": "IEEE Computer Magazine, Cover Feature, Vol. 35, No. 10.",
        "palwebURL": [],
        "PublicationDate": "10/15/2002",
        "ID": "180",
        "Authors": [
            "Bill Schilit",
            "Jonathan Trevor",
            "David Hilbert",
            "T.K. Koh"
        ],
        "Title": "Web Interaction Using Very Small Internet Devices",
        "Abstract": "Squeezing desktop Web content into smart phones and text pagers is more practical with separate interfaces for navigation and content manipulation. m-Links, a middleware proxy system, supports this dual-mode browsing, offering phonetop users an extendable set of actions."
    },
    {
        "Projects": [
            "PIPs"
        ],
        "keywords": [
            "ubiquitous",
            "pips"
        ],
        "AcceptDate": "08/27/2002",
        "palwebID": "PR-02-181",
        "Venue": "Workshop on User centered Evaluations for Ubiquitous Computing Systems: Best Known Methods, The 4th International Conference on Ubiquitous Computing (UbiComp 2002).",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-181/FXPAL-PR-02-181.pdf"
        ],
        "PublicationDate": "09/29/2002",
        "ID": "181",
        "Authors": [
            "Jonathan Trevor",
            "David Hilbert"
        ],
        "Title": "A Comparative Prototype Research Methodology",
        "Abstract": "Evaluating ubiquitous systems is hard, and has attracted the attention of others in the research community. These investigators, like others in CSCW, argue there is a basic mismatch between traditional evaluation techniques and the needs posed by ubiquitous systems. Namely, these systems are embedded in a variety of complex real world environments that cannot be easily modeled (as required by theoretical analyses), simulated, measured, or controlled (as required by laboratory experiments). As a result, many investigators have abandoned traditional comparative evaluation techniques and opted instead for techniques adapted from the social sciences, such as anthropology. We wanted to perform a comparative evaluation similar to a laboratory experiment, but in such a way that we could observe the effects of our design decisions in relatively unconstrained, real world use. This led us to the process described in this paper."
    },
    {
        "Projects": [],
        "keywords": [
            "Hypertext",
            "navigation",
            "user interface",
            "hcir"
        ],
        "AcceptDate": "04/15/2002",
        "palwebID": "PR-02-182",
        "Venue": "Proceedings of ACM Hypertext 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-182/FXPAL-PR-02-182.pdf"
        ],
        "PublicationDate": "06/11/2002",
        "ID": "182",
        "Authors": [
            "Gene Golovchinsky"
        ],
        "Title": "Going Back in Hypertext",
        "Abstract": "Hypertext interfaces typically involve navigation, the act (and\r\ninteraction) of moving from one piece of information to another.\r\nNavigation can be exploratory, or it may involve backtracking to\r\nsome previously-visited node. While backtracking interfaces are\r\ncommon, they may not reflect differences in readers' purposes and\r\nmental models. This paper draws on some empirical evidence\r\nregarding navigation between and within documents to suggest\r\nimprovements on traditional hypertext navigation, and proposes a\r\ntime-based view of backtracking."
    },
    {
        "Projects": [
            "Xlibris"
        ],
        "keywords": [
            "XLibris",
            "Annotation"
        ],
        "AcceptDate": "06/16/2002",
        "palwebID": "PR-02-183",
        "Venue": "Proceedings of ACM UIST 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-183/FXPAL-PR-02-183.pdf"
        ],
        "PublicationDate": "10/27/2002",
        "ID": "183",
        "Authors": [
            "Gene Golovchinsky",
            "Laurent Denoue"
        ],
        "Title": "Moving Markup: Repositioning Freeform Annotations",
        "Abstract": "Freeform digital ink annotation allows readers to interact\r\nwith documents in an intuitive and familiar manner. Such\r\nmarks are easy to manage on static documents, and provide\r\na familiar annotation experience. In this paper, we describe\r\nan implementation of a freeform annotation system that\r\naccommodates dynamic document layout. The algorithm\r\npreserves the correct position of annotations when\r\ndocuments are viewed with different fonts or font sizes,\r\nwith different aspect ratios, or on different devices. We\r\nexplore a range of heuristics and algorithms required to\r\nhandle common types of annotation, and conclude with a\r\ndiscussion of possible extensions to handle special kinds of\r\nannotations and changes to documents."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "06/03/2002",
        "palwebID": "PR-02-184",
        "Venue": "In proceedings of Mobile HCI 2002. (Pisa, Italy,2002), Springer-Verlag, Lecture notes in computer science #2411,pp.369-372.",
        "palwebURL": [],
        "PublicationDate": "09/18/2002",
        "ID": "184",
        "Authors": [
            "Tomas Sokoler",
            "Les Nelson",
            "Elin Pedersen"
        ],
        "Title": "Low-Resolution Supplementary Tactile Cues for Navigational Assistance",
        "Abstract": "The TactGuide is a mobile navigation device 'displaying' personalized direction cues by means of a tactile and 'tactful' representation. The TactGuide is operated by tactile inspection which is subtle enough to allow the users to engage/disengage in device interaction while preserving their visual, auditory and kinesthetic senses for inspection of the environment. The TactGuide design thereby accommodates the users' need to economize their attentional resources between device and environment while navigating through physical space. Preliminary experiments indicates that users readily map the tactile cues to spatial directions and that TactGuide can be operated as a supplement to, and without compromising, the use of our existing wayfinding abilities. substituting the use of our natural abilities and earned skills for wayfinding. "
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "09/06/2002",
        "palwebID": "PR-02-185",
        "Venue": "IEEE InfoVis '02 Interactive Poster and Demo",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-185/FXPAL-PR-02-185.pdf"
        ],
        "PublicationDate": "10/28/2002",
        "ID": "185",
        "Authors": [
            "Patrick Chiu",
            "Khai Truong"
        ],
        "Title": "Interactive space-time maps for document visualization",
        "Abstract": "This work presents constructs called interactive space-time maps along with an application called the SpaceTime Browser for visualizing and retrieving documents.  A 3D visualization with 2D planar maps and a time line is employed. Users can select regions on the maps and choose precise time intervals by sliding the maps along the telescopic time line. Regions are highlighted to indicate the presence of documents with matching space-time attributes, and documents are retrieved and displayed in an adjoining workspace. We provide two examples: (1) organizing travel photos, (2) managing documents created by room location-aware devices in a building."
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "similarity",
            "media",
            "music",
            "audio"
        ],
        "AcceptDate": "10/28/2002",
        "palwebID": "PR-03-186",
        "Venue": " Proc. SPIE Storage and Retrieval for Multimedia Databases, Vol. 5021, pp. 167-75",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-186/FXPAL-PR-03-186.pdf"
        ],
        "PublicationDate": "01/20/2003",
        "ID": "186",
        "Authors": [
            "Jonathan Foote",
            "Matthew Cooper"
        ],
        "Title": "Media Segementation using Self-Similarity Decomposition",
        "Abstract": "We present a framework for analyzing the structure of digital media streams.  Though our methods work for\r\nvideo,text,and audio,we concentrate on detecting the structure of digital music \u00ef\u00ac\u0081les.  In the \u00ef\u00ac\u0081rst step,spectral\r\ndata is used to construct a similarity matrix calculated from inter-frame spectral similarity.  The digital audio\r\ncan be robustly segmented by correlating a ernel along the diagonal of the similarity matrix.  Once segmented,\r\nspectral statistics of each segment are computed.In the second step,segments are clustered based on the self-\r\nsimilarity of their statistics.  This reveals the structure of the digital music in a set of segment boundaries and\r\nlabels.Finally,the music can be summarized by selecting clusters with repeated segments throughout the piece.\r\nThe summaries can be customized for various applications based on the structure of the original music."
    },
    {
        "Projects": [],
        "keywords": [
            "NL"
        ],
        "AcceptDate": "11/30/2002",
        "palwebID": "PR-03-187",
        "Venue": "Journal of Logic, Language and Information, Kluwer Academic Publishers, Dordrecht, The Netherlands",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-187/FXPAL-PR-03-187.pdf"
        ],
        "PublicationDate": "08/15/2003",
        "ID": "187",
        "Authors": [
            "Livia Polanyi",
            "Martin van den Berg",
            "David Ahn"
        ],
        "Title": "Discourse Structure and Sentential Information Structure\r\nAn Initial Proposal\r\n",
        "Abstract": "In this article we argue that discourse structure constrains the set of possible constituents in a discourse that can provide the relevant context for structuring information in a target sentence, while information structure critically constrains discourse structure ambiguity. \r\nFor the speaker, the  discourse structure provides a set of possible contexts for continuation while information structure assignment is independent of  discourse structure.  For the hearer, the information structure of a  sentence together with discourse structure instructs dynamic semantics  how rhematic information should be used to update the meaning  representation of the discourse (Polanyi and van den Berg, 1996)."
    },
    {
        "Projects": [
            "MBase"
        ],
        "keywords": [
            "similarity",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-188",
        "Venue": "IEEE Multimedia Signal Processing Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-188/FXPAL-PR-02-188.PDF"
        ],
        "PublicationDate": "12/11/2002",
        "ID": "188",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote"
        ],
        "Title": "Summarizing Video using Non-Negative Similarity Matrix Factorization",
        "Abstract": "We present a novel approach to automatically ex-tracting\r\nsummary excerpts from audio and video. Our approach is to maximize the average similarity between the excerpt and the\r\nsource. We first calculate a similarity matrix by comparing each pair of time samples using a quantitative similarity measure. To determine the segment with highest average similarity, we maximize the summation of the self-similarity matrix over the support of the segment. To select multiple excerpts while avoiding redundancy, we compute the non-negative matrix factorization (NMF) of the similarity matrix into its essential structural components. We then build a summary comprised of excerpts from the main components, selecting the excerpts for maximum average similarity within each component. Variations integrating segmentation and other information are also discussed, and experimental results are presented."
    },
    {
        "Projects": [
            "Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "10/01/2002",
        "palwebID": "PR-02-189",
        "Venue": "ACM Multimedia 2002",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-189/FXPAL-PR-02-189.pdf"
        ],
        "PublicationDate": "12/10/2002",
        "ID": "189",
        "Authors": [
            "Lynn Wilcox",
            "John Doherty",
            "Andreas Girgensohn"
        ],
        "Title": "A Hitchcock Assisted Video Edited Night at the Opera",
        "Abstract": "Hitchcock is a semi-automatic video editing system.  This video shows users collaboratively authoring a home video."
    },
    {
        "Projects": [
            "M-Links"
        ],
        "keywords": [
            "ubiquitous",
            "m-links"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-190",
        "Venue": "Fuji Xerox Technical Report, No. 14, 2002",
        "palwebURL": [],
        "PublicationDate": "06/25/2002",
        "ID": "190",
        "Authors": [
            "David Hilbert",
            "Bill Schilit",
            "Jonathan Trevor",
            "T.K. Koh"
        ],
        "Title": "The Elusive Ubiquitous Information System and m-Links",
        "Abstract": "A basic objective of Weiser's Ubiquitous Computing vision is ubiquitous information access:  being able to utilize any content or service (e.g., all the rich media content and services on the WWW), using devices that are always \"at hand\" (embedded in environments or portable), over a network with universal coverage and adequate bandwidth. Although much progress has been made, the ideal remains elusive.  This paper examines the inter-relations among three dimensions of ubiquitous information systems: (1) ubiquitous content; (2) ubiquitous devices; and (3) ubiquitous networking. We use the space defined by these dimensions to reflect on the tradeoffs designers make and to chart some past and current information systems. Given this background, we present m-Links (mobile links), a new system that takes aim at the elusive ideal of ubiquitous information. Our approach builds on wireless web phone technologies because of their trend towards ubiquitous devices and networking (the second and third dimensions). Yet such very small devices sacrifice usability as rich media Internet terminals (the first dimension). To offset this limitation, we propose a new information access model for very small devices that supports a much wider range of content and services than previously possible. We have built this system with an emphasis on open systems extensibility and describe its design and implementation."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "messtop"
        ],
        "AcceptDate": "",
        "palwebID": "PR-03-191",
        "Venue": "ACM Intelligent User Interface (IUI) 2003, Miami Beach, FL, pp 326",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-191/FXPAL-PR-03-191.pdf"
        ],
        "PublicationDate": "01/12/2003",
        "ID": "191",
        "Authors": [
            "Les Nelson",
            "Laurent Denoue",
            "Elizabeth Churchill"
        ],
        "Title": "AttrActive Windows: Active Windows for Pervasive Computing Applications",
        "Abstract": "We introduce the AttrActive Windows user interface, a novel\r\napproach for presenting interactive content on large screen,\r\ninteractive, digital, bulletin boards. Moving away from the\r\ndesktop metaphor, AttrActive Windows are dynamic, non-uniform\r\nwindows that can appear in different orientations and have\r\nautonomous behaviours to attract passers-by and invite\r\ninteractions."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-01-192",
        "Venue": "WebNet 2001 World Conference on the WWW and Internet, Orlando, FL",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-192/FXPAL-PR-01-192.pdf"
        ],
        "PublicationDate": "01/17/2001",
        "ID": "192",
        "Authors": [
            "Laurent Denoue"
        ],
        "Title": "Personal Information Organization using Web Annotations",
        "Abstract": "As more information is made available online, users collect information in\r\npersonal information spaces like bookmarks and emails. While most users feel that\r\norganizing these collections is crucial to improve access, studies have shown that this\r\nactivity is time consuming and highly cognitive. Automatic classification has been used\r\nbut by relying on the full text of the documents, they do not generate personalized\r\nclassifications. Our approach is to give users the ability to annotate their documents as\r\nthey first access them. This annotation tool is unobtrusive and welcome by most users\r\nwho generally miss this facility when dealing with digital documents. Our experiments\r\nshow that these annotations can be used to generate personalized classifications of\r\nannotated Web pages."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/18/2002",
        "palwebID": "PR-02-193",
        "Venue": "Proceedings of the IFIP International Conference on Decision Making and Decision Support in the Internet Age",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-193/FXPAL-PR-02-193.doc",
            "http://palweb/files/PR/2002/PR-02-193/FXPAL-PR-02-193.htm",
            "http://palweb/files/PR/2002/PR-02-193/FXPAL-PR-02-193.pdf",
            "http://palweb/files/PR/2002/PR-02-193/FXPAL-PR-02-193.prn"
        ],
        "PublicationDate": "07/04/2002",
        "ID": "193",
        "Authors": [
            "Steve Smoliar",
            "Ralph Sprague"
        ],
        "Title": "Communication and Understanding for Decision Support",
        "Abstract": "As the technology for communication changes, the role of communication in the conduct of business changes with it. Communication is no longer just a technical matter of separating signal from noise and managing bandwidth but also a social matter in which negotiating differences in understanding among and between communicators is a primary business priority. Addressing this priority requires an understanding of how individuals interact in the course of their decision making activities. Using the work of Anthony Giddens as a point of departure, this paper views interaction in communication as consisting of three dimensions - meaning, authority, and trust. These three dimensions are used to identify new opportunities for advances in decision making technology which help deal with potential breakdowns in social interaction."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/04/2000",
        "palwebID": "PR-00-194",
        "Venue": "Multimedia Modeling:  Modeling Multimedia Information and Systems, Nagano, Japan",
        "palwebURL": [
            "http://palweb/files/PR/2000/PR-00-194/FXPAL-PR-00-194.pdf",
            "http://palweb/files/PR/2000/PR-00-194/submission.doc",
            "http://palweb/files/PR/2000/PR-00-194/Tina-Schneider.prn"
        ],
        "PublicationDate": "11/12/2000",
        "ID": "194",
        "Authors": [
            "Steve Smoliar",
            "Tina Schneider"
        ],
        "Title": "A Multi-Channel Infrastructure for Presenting Nonlinear Hypermedia",
        "Abstract": "While hypermedia is usually presented as a way to offer content in a nonlinear manner, hypermedia structure tends to reinforce the assumption that reading is basically a linear process.  Link structures provide a means by which the reader may choose different paths to traverse;  but each of these paths is fundamentally linear, revealed through either a block of text or a well-defined chain of links.  While there are experiences that get beyond such linear constraints, such as driving a car, it is very hard to capture this kind of non-linearity, characterized by multiple sources of stimuli competing for attention, in a hypermedia document.  This paper presents a multi-channel document infrastructure that provides a means by which all such sources of attention are presented on a single \"page\" (i.e., a display with which the reader interacts) and move between background and foreground in response to the activities of the reader.  The infrastructure thus controls the presentation of content with respect to four dimensions:   visual, audio, interaction support, and rhythm."
    },
    {
        "Projects": [
            "M-Links"
        ],
        "keywords": [
            "ubiquitous",
            "m-links"
        ],
        "AcceptDate": "12/16/2002",
        "palwebID": "PR-03-195",
        "Venue": "HCI International 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-195/FXPAL-PR-03-195.pdf"
        ],
        "PublicationDate": "06/22/2003",
        "ID": "195",
        "Authors": [
            "David Hilbert",
            "Jonathan Trevor",
            "Bill Schilit"
        ],
        "Title": "Supporting ubiquitous information on very small devices is harder than you think",
        "Abstract": "A basic objective of ubiquitous computing research is ubiquitous information: the ability to utilize any content or service, using devices that are always at hand, over networks that don't tie us down. Although much progress has been made, the ideal remains elusive. This paper reflects on the interrelations among three dimensions of ubiquitous information: content, devices, and networks. We use our understanding of these dimensions to motivate our own attempt to create a ubiquitous information system by combining unlimited World Wide Web content with mobile phones and mobile phone networks. We briefly describe a middleware proxy system we developed to increase the usefulness of very small devices as Internet terminals. We conclude with a post-mortem analysis highlighting lessons learned for others interested in information systems for very small devices. "
    },
    {
        "Projects": [
            "PIPs"
        ],
        "keywords": [
            "ubiquitous",
            "pips"
        ],
        "AcceptDate": "12/16/2002",
        "palwebID": "PR-03-196",
        "Venue": "HCI International 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-196/FXPAL-PR-03-196.pdf"
        ],
        "PublicationDate": "06/22/2003",
        "ID": "196",
        "Authors": [
            "David Hilbert",
            "Jonathan Trevor"
        ],
        "Title": "Embedded versus portable interfaces for personalizing\r\nshared ubiquitous devices",
        "Abstract": "Everywhere we go, we are surrounded by shared devices: TVs, stereos, and appliances in the home; copiers, fax machines, and projectors in the office; phones and vending machines in public. Because these devices don't know who we are, they provide the same user interface and functionality to everyone. This paper describes a system for personalizing workplace document devices- projectors, public displays, and multi-function copiers-that has been in use for over two years in our organization. We compare user interfaces that are embedded (i.e., integrated or co-located with the shared device) versus portable (i.e., accessible via portable devices such as mobile phones or PDAs). We summarize lessons learned for others designing interfaces for shared ubiquitous devices."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "plasma poster",
            "digital community bulletin board",
            "social computing",
            "SocComp"
        ],
        "AcceptDate": "04/18/2003",
        "palwebID": "PR-03-197",
        "Venue": "Human-Computer Interaction INTERACT '03, IOS Press, pp. 599-606",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-197/FXPAL-PR-03-197.pdf"
        ],
        "PublicationDate": "09/01/2003",
        "ID": "197",
        "Authors": [
            "Elizabeth Churchill",
            "Les Nelson",
            "Laurent Denoue",
            "Andreas Girgensohn"
        ],
        "Title": "The Plasma Poster Network: Posting Multimedia Content in Public Places",
        "Abstract": "Much effort has been expended in creating online information resources to foster social networks, create synergies between collocated and remote colleagues, and enhance social capital within organizations. Following the observation that physical bulletin boards serve an important community building and maintenance function, in this paper we describe a network of large screen, digital bulletin boards, the Plasma Poster Network. The function of this system is to bridge the gap between online community interactions and shared physical spaces. We describe our motivation, a fieldwork study of information sharing practices within our organization, and an internal deployment of Plasma Posters."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "plasma poster",
            "digital community poster board",
            "deployment",
            "social computing",
            "SocComp"
        ],
        "AcceptDate": "04/22/2003",
        "palwebID": "PR-03-198",
        "Venue": "Communities and Technologies, Amsterdam, The Netherlands, September 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-198/FXPAL-PR-03-198.doc",
            "http://palweb/files/PR/2003/PR-03-198/FXPAL-PR-03-198.pdf"
        ],
        "PublicationDate": "09/05/2003",
        "ID": "198",
        "Authors": [
            "Elizabeth Churchill",
            "Les Nelson",
            "Laurent Denoue"
        ],
        "Title": "Multimedia Fliers: Informal Information Sharing With Digital Community Bulletin Boards\r\n",
        "Abstract": "Community poster boards serve an important community building function. Posted fliers advertise services, events and people's interests, and invite community members to communicate, participate, interact and transact. In this paper we describe the design, development and deployment of the Plasma Poster Network, a network of large screen, digital community poster boards, the Plasma Posters. An initial deployment of Plasma Posters is within our own organization, a software research community made up of technologists and designers. We present our motivation and two fieldwork studies of online and offline information sharing before describing the Plasma Posters and the underlying information storage and distribution infrastructure. Finally, we summarize findings from qualitative and quantitative evaluations of Plasma Poster usage and conclude by elaborating on socio-technical challenges that have been faced in the design and deployment of the Plasma Poster Network."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing",
            "messtop",
            "SocComp"
        ],
        "AcceptDate": "04/07/2003",
        "palwebID": "PR-03-199",
        "Venue": "Siggraph 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-199/FXPAL-PR-03-199.pdf"
        ],
        "PublicationDate": "07/27/2003",
        "ID": "199",
        "Authors": [
            "Laurent Denoue",
            "Les Nelson",
            "Elizabeth Churchill"
        ],
        "Title": "Implementing a paper flier metaphor using cloth simulation",
        "Abstract": "This paper describes the technical details of the Messtop (also know as 'AttrActive Windows') animated paper flier interface for the Plasma Posters. "
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "rmo",
            "photo",
            "media",
            "similarity"
        ],
        "AcceptDate": "04/10/2003",
        "palwebID": "PR-03-200",
        "Venue": "Proc. IEEE Intl. Conf. on Image Processing",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-200/FXPAL-PR-03-200.pdf"
        ],
        "PublicationDate": "09/14/2003",
        "ID": "200",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote",
            "Andreas Girgensohn"
        ],
        "Title": "Automatically Organizing Digital Photographs Using Time and Content",
        "Abstract": "We present similarity-based methods to cluster digital photos\r\nby time and image content. This approach is general, unsupervised, and makes minimal assumptions regarding\r\nthe structure or statistics of the photo collection. We describe versions of the algorithm using temporal similarity\r\nwith and without content-based similarity, and compare the\r\nalgorithms with existing techniques, measured against\r\nground-truth clusters created by humans."
    },
    {
        "Projects": [],
        "keywords": [
            "social computing"
        ],
        "AcceptDate": "02/10/2003",
        "palwebID": "PR-03-201",
        "Venue": "Angent Supported Cooperative Work, Published by Kluwer Adacemic Press",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-201/FXPAL-PR-03-201.doc"
        ],
        "PublicationDate": "04/06/2003",
        "ID": "201",
        "Authors": [
            "Yiming Ye",
            "Elizabeth Churchill"
        ],
        "Title": "Agent Supported Cooperative Work: An introduction and overview",
        "Abstract": "This chapter is an introduction to an edited volume on Agnet supported cooperative work."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "plasma poster",
            "digital community bulletin board",
            "online community",
            "social computing",
            "SocComp"
        ],
        "AcceptDate": "05/25/2003",
        "palwebID": "PR-03-202",
        "Venue": "Human-Computer Interaction INTERACT '03, IOS Press, pp. 729-732",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-202/FXPAL-PR-03-202.pdf"
        ],
        "PublicationDate": "09/01/2003",
        "ID": "202",
        "Authors": [
            "Elizabeth Churchill",
            "Andreas Girgensohn",
            "Les Nelson",
            "Alison Lee"
        ],
        "Title": "Weaving Between Online and Offline Community Participation",
        "Abstract": "Much effort has been expended in creating online spaces for people to meet, network, share and organize.\r\nHowever, there is relatively little work, in comparison, that has addressed creating awareness of online community\r\nactivities for those gathered together physically. We describe our efforts to advertise the online community\r\nspaces of CHIplace and CSCWplace using large screen, interactive bulletin boards that show online community\r\ninformation mixed with content generated at the conference itself. Our intention was to raise awareness of the\r\nonline virtual community within the offline, face-to-face event. We describe the two deployments, at CHI 2002\r\nand at CSCW 2002, and provide utilization data regarding people's participation within the physical and virtual\r\nlocales."
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "similarity",
            "media"
        ],
        "AcceptDate": "06/27/2003",
        "palwebID": "PR-03-204",
        "Venue": "2003 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-204/FXPAL-PR-03-204.pdf"
        ],
        "PublicationDate": "10/19/2003",
        "ID": "204",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote"
        ],
        "Title": "Summarizing Popular Music via Structural Similarity Analysis",
        "Abstract": "We present a framework for summarizing digital media based on structural analysis. Though these methods are applicable to general media, we concentrate here on characterizing repetitive structure in popular music. In the first step, a similarity matrix is calculated from inter-frame spectral similarity.  Segment boundaries, such as verse-chorus transitions, are found by correlating a kernel along the diagonal of the matrix. Once segmented, spectral statistics of each segment are computed. In the second step, segments are clustered based on the pairwise similarity of their statistics, using a matrix decomposition approach. Finally, the audio is summarized by combining segments representing\r\nthe clusters most frequently repeated throughout the piece. We present results on a small corpus showing more than 90% correct detection of verse and chorus segments."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "social computing",
            "poster",
            "messtop",
            "SocComp"
        ],
        "AcceptDate": "07/02/2003",
        "palwebID": "PR-03-205",
        "Venue": "UIST 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-205/FXPAL-PR-03-205.pdf"
        ],
        "PublicationDate": "11/02/2003",
        "ID": "205",
        "Authors": [
            "Laurent Denoue",
            "Les Nelson",
            "Elizabeth Churchill"
        ],
        "Title": "A fast, interactive 3D paper-flier metaphor for digital bulletin boards",
        "Abstract": "We describe a novel interface for presenting interactive content on public digital bulletin boards. Inspired by paper fliers on physical bulletin boards, posted content is displayed using 3D virtual fliers attached to a virtual corkboard by virtual pushpins. Fliers appear in different orientations, creating an attractive, informal look, and have autonomous behaviors like fluttering in the wind. Passers-by can rotate, move and fold fliers; they can also interact with fliers' live content. Flier content is streamed from a server and represented by the system on large screen displays using a real-time cloth simulation algorithm. We describe our prototype, and offer the results of an initial evaluative user study."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "plasma poster",
            "social computing",
            "messtop"
        ],
        "AcceptDate": "03/02/2003",
        "palwebID": "PR-03-206",
        "Venue": "CHI 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-206/FXPAL-PR-03-206.pdf"
        ],
        "PublicationDate": "04/07/2003",
        "ID": "206",
        "Authors": [
            "Laurent Denoue",
            "Les Nelson",
            "Elizabeth Churchill"
        ],
        "Title": "AttrActive Windows: Dynamic Windows for Digital Bulletin Boards",
        "Abstract": "In this paper we describe AttrActive Windows, a novel\r\ninterface for presenting live, interactive, multimedia content\r\non a network of public, digital, bulletin boards.\r\nImplementing a paper flyer metaphor, AttrActive Windows\r\nare paper-like in appearance and are attached to a virtual\r\ncorkboard by virtual pushpins. Windows can therefore\r\nappear in different orientations, creating an attractive,\r\ninformal look. Attractive Windows can also have\r\nautonomous behaviors that are consistent with the\r\ncorkboard metaphor, like fluttering in the wind. We\r\ndescribe the AttrActive Windows prototype, and offer the\r\nresults of an initial evaluative user study."
    },
    {
        "Projects": [
            "SharedTextInput"
        ],
        "keywords": [
            "immersive",
            "annotation",
            "sti"
        ],
        "AcceptDate": "03/02/2003",
        "palwebID": "PR-03-207",
        "Venue": "CHI 2003",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-207/FXPAL-PR-03-207.pdf"
        ],
        "PublicationDate": "04/07/2003",
        "ID": "207",
        "Authors": [
            "Laurent Denoue",
            "Patrick Chiu",
            "Tohru Fuse"
        ],
        "Title": "Shared Freeform Input for Note Taking across Devices",
        "Abstract": "Shared freeform input is a technique for facilitating note\r\ntaking across devices during a meeting. Laptop users enter\r\ntext with a keyboard, whereas PDA and Tablet PC users\r\ninput freeform ink with their stylus. Users can quickly\r\nreuse text and freeform ink already entered by others. We\r\nshow how a new technique, freeform pasting, allowed us to\r\ndeal with a variety of design issues such as quick and\r\ninformal ink sharing, screen real estate, privacy and mixing\r\nink-based and textual material.\r\n"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "05/07/2002",
        "palwebID": "PR-03-208",
        "Venue": "Business Process Management Journal, Volume 9, Number 3, 2003, pages 337-353",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-208/FXPAL-PR-03-208.doc",
            "http://palweb/files/PR/2003/PR-03-208/FXPAL-PR-03-208.pdf",
            "http://palweb/files/PR/2003/PR-03-208/FXPAL-PR-03-208.prn"
        ],
        "PublicationDate": "06/09/2003",
        "ID": "208",
        "Authors": [
            "Steve Smoliar"
        ],
        "Title": "Interaction management:  the next (and necessary) step beyond knowledge management",
        "Abstract": "Purveyors of knowledge management software have a disconcerting tendency to promote the myth that all problems may be solved by more powerful tools for the exchange of information in the workplace.  This fallacy is based on the faulty assumption that knowledge management is about the management of knowledge (as if knowledge were a commodity that could be managed), as opposed to the management of people whose work depends critically on what they know.  The origins of knowledge management are far more firmly rooted in the psychological legacy of organizational communication than they are in the technological legacy of information management systems.  However, even organizational communication is an inadequate foundation, since various schools of thought in social theory, particularly the structuration theory of Anthony Giddens, inform us that interaction (in the workplace or in any other social setting) is not strictly limited to communication.  Knowledge management thus requires moving beyond simplistic models of information exchange to more challenging problems of leveraging social interaction to the advantage of the enterprise.  This paper focuses on the claim of structuration theory that the dimension of communication should be supplemented with additional dimensions of power and sanction.  This perspective is then examined in light of a case study of crisis management practices, and the case study provides a basis for addressing implications for technological support."
    },
    {
        "Projects": [],
        "keywords": [
            "NL"
        ],
        "AcceptDate": "07/07/2003",
        "palwebID": "PR-03-210",
        "Venue": "Multiple Approaches to Discourse 2003",
        "palwebURL": [],
        "PublicationDate": "10/22/2003",
        "ID": "210",
        "Authors": [
            "Livia Polanyi",
            "Annie Zaenen"
        ],
        "Title": "Shifting Attitudes",
        "Abstract": ""
    },
    {
        "Projects": [
            "FlySPEC"
        ],
        "keywords": [
            "immersive",
            "SPEC",
            "flyspec"
        ],
        "AcceptDate": "03/07/2003",
        "palwebID": "PR-03-211",
        "Venue": "2003 International Conference on Multimedia and Expo",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-211/FXPAL-PR-03-211.pdf"
        ],
        "PublicationDate": "07/06/2003",
        "ID": "211",
        "Authors": [
            "Qiong Liu",
            "Don Kimber",
            "Jonathan Foote",
            "Chunyuan Liao"
        ],
        "Title": "MULTICHANNEL VIDEO/AUDIO ACQUISITION FOR IMMERSIVE CONFERENCING",
        "Abstract": "This paper presents an information-driven audiovisual signal acquisition approach.  This approach has several advantages: users are encouraged to assist in signal acquisition; available sensors are managed based on both signal characteristics and users' suggestions.  The problem formulation is consistent with many well-known empirical approaches widely used in previous systems and may provide analytical explanations to these approaches.  We demonstrate the use of this approach to pan/tilt/zoom (PTZ) camera management with field data."
    },
    {
        "Projects": [],
        "keywords": [
            "media"
        ],
        "AcceptDate": "",
        "palwebID": "PR-03-212",
        "Venue": "IEEE International Conference on Multimedia and Expo, v. I, pp. 221-224",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-212/FXPAL-PR-03-212.pdf"
        ],
        "PublicationDate": "07/07/2003",
        "ID": "212",
        "Authors": [
            "Jonathan Foote",
            "John Adcock",
            "Andreas Girgensohn"
        ],
        "Title": "Time Base Modulation: A New Approach to Watermarking Audio",
        "Abstract": "A novel method is presented for inaudibly hiding information in an audio signal by subtly applying time-scale modification to segments of the signal. The sequence, duration, and degree of the time-scale modifications are the parameters which encode information in the altered signal. By comparing the altered signal with a reference copy, compressed and expanded regions can be identified and the hidden data recovered. This approach is novel and has several advantages over other methods: it is theoretically noiseless, it introduces no spectral distortion, and it is robust to all known methods of reproduction, compression, and transmission."
    },
    {
        "Projects": [
            "Manga"
        ],
        "keywords": [
            "manga",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-03-213",
        "Venue": "IEEE International Conference on Multimedia and Expo, v. II, pp. 77-80",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-213/FXPAL-PR-03-213.pdf"
        ],
        "PublicationDate": "07/07/2003",
        "ID": "213",
        "Authors": [
            "Andreas Girgensohn"
        ],
        "Title": "A Fast Layout Algorithm for Visual Video Summaries",
        "Abstract": "We created an improved layout algorithm for automatically generating visual video summaries reminiscent of comic book pages. The summaries are comprised of images from the video that are sized according to their importance. The algorithm performs a global optimization with respect to a layout cost function that encompasses features such as the number of resized images and the amount of whitespace in the presentation. The algorithm creates summaries that: always fit exactly into the requested area, are varied by containing few rows with images of the same size, and have little whitespace at the end of the last row. The layout algorithm is fast enough to allow the interactive resizing of the summaries and the subsequent generation of a new layout."
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-03-214",
        "Venue": "IEEE International Conference on Multimedia and Expo, v. II, pp. 753-756",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-214/FXPAL-PR-03-214.pdf"
        ],
        "PublicationDate": "07/07/2003",
        "ID": "214",
        "Authors": [
            "Frank Shipman",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Creating Navigable Multi-Level Video Summaries",
        "Abstract": "We created an alternative approach to existing video summaries that gives viewers control over the summaries by selecting hyperlinks to other video with additional information. We structure such summaries as \"detail-on-demand\" video, a subset of general hypervideo in which at most one link to another video sequence is available at any given time. Our editor for such video, Hyper-Hitchcock, provides a workspace in which an author can select and arrange video clips, generate composites from clips and from other composites, and place links between composites. To simplify dealing with a large number of clips, Hyper-Hitchcock generates iconic representations for composites that can be used to manipulate the composite as a whole. In addition to providing an authoring environment, Hyper-Hitchcock can automatically generate multi-level hypervideo summaries for immediate use or as the starting point for author modification. "
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "rmo",
            "photo",
            "similarity",
            "media"
        ],
        "AcceptDate": "08/13/2003",
        "palwebID": "PR-03-215",
        "Venue": "Proc. ACM Multimedia 2003. pp. 364-373",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-215/FXPAL-PR-03-215.pdf"
        ],
        "PublicationDate": "11/02/2003",
        "ID": "215",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Temporal Event Clustering for Digital Photo Collections",
        "Abstract": "We present similarity-based methods to cluster digital photos by time and image content. The approach is general, unsupervised, and makes minimal assumptions regarding the\r\nstructure or statistics of the photo collection. We present\r\nresults for the algorithm based solely on temporal similarity, and jointly on temporal and content-based similarity. We also describe a supervised algorithm based on learning vector quantization. Finally, we include experimental results for the proposed algorithms and several competing approaches on two test collections."
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "XLibris",
            "annotation",
            "reading",
            "e-books",
            "field work",
            "user interface",
            "digital libraries"
        ],
        "AcceptDate": "05/14/2003",
        "palwebID": "PR-03-216",
        "Venue": "7th European Conference on Research and Advanced Technology for Digital Libraries (ECDL 2003) Trondheim, Norway, August 17-22, 2003.",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-216/FXPAL-PR-03-216.pdf"
        ],
        "PublicationDate": "08/17/2003",
        "ID": "216",
        "Authors": [
            "Frank Shipman",
            "Morgan Price",
            "Catherine Marshall",
            "Gene Golovchinsky"
        ],
        "Title": "Identifying Useful Passages in Documents based on Annotation Patterns",
        "Abstract": "Many readers annotate passages that are important to their work. If we\r\nunderstand the relationship between the types of marks on a passage and the passage's\r\nultimate utility in a task, then we can design e-book software to facilitate\r\naccess to the most important annotated parts of the documents. To investigate\r\nthis hypothesis and to guide software design, we have analyzed annotations collected\r\nduring an earlier study of law students reading printed case law and\r\nwriting Moot Court briefs. This study has allowed us to characterize the relationship\r\nbetween the students' annotations and the citations they use in their final\r\nwritten briefs. We think of annotations that relate directly to the written brief as\r\nhigh-value annotations; these annotations have particular, detectable characteristics.\r\nBased on this study we have designed a mark parser that analyzes freeform\r\ndigital ink to identify such high-value annotations."
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "05/23/2003",
        "palwebID": "PR-03-219",
        "Venue": "Human-Computer Interaction INTERACT '03, IOS Press, pp. 33-40",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-219/FXPAL-PR-03-219.pdf"
        ],
        "PublicationDate": "09/01/2003",
        "ID": "219",
        "Authors": [
            "Frank Shipman",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Hyper-Hitchcock: Towards the Easy Authoring of Interactive Video",
        "Abstract": "To simplify the process of editing interactive video, we developed the concept of \"detail-on-demand\" video as a subset of general hypervideo where a single button press reveals additional information about the current video sequence. Detail-on-demand video keeps the authoring and viewing interfaces relatively simple while supporting a wide range of interactive video applications. Our editor, Hyper-Hitchcock, builds on prior work on automatic analysis to find the best quality video clips. It introduces video composites as an abstraction for grouping and manipulating sets of video clips. Navigational links can be created between any two video clips or composites. Such links offer a variety of return behaviors for when the linked video is completed that can be tailored to different materials. Initial impressions from a pilot study indicate that Hyper-Hitchcock is easy to learn although the behavior of links is not immediately intuitive for all users."
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "rmo",
            "photo",
            "media"
        ],
        "AcceptDate": "05/23/2003",
        "palwebID": "PR-03-220",
        "Venue": "Human-Computer Interaction INTERACT '03, IOS Press, pp. 196-203",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-220/FXPAL-PR-03-220.pdf"
        ],
        "PublicationDate": "09/01/2003",
        "ID": "220",
        "Authors": [
            "Andreas Girgensohn",
            "John Adcock",
            "Matthew Cooper",
            "Jonathan Foote",
            "Lynn Wilcox"
        ],
        "Title": "Simplifying the Management of Large Photo Collections",
        "Abstract": "With digital still cameras, users can easily collect thousands of photos. Our goal is to make organizing and browsing photos simple and quick, while retaining scalability to large collections. To that end, we created a photo management application concentrating on areas that improve the overall experience without neglecting the mundane components of such an application. Our application automatically divides photos into meaningful events such as birthdays or trips. Several user interaction mechanisms enhance the user experience when organizing photos. Our application combines a light table for showing thumbnails of the entire photo collection with a tree view that supports navigating, sorting, and filtering photos by categories such as dates, events, people, and locations. A calendar view visualizes photos over time and allows for the quick assignment of dates to scanned photos. We fine-tuned our application by using it with large personal photo collections provided by several users."
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "06/01/2003",
        "palwebID": "PR-03-221",
        "Venue": "SPIE Information Technologies and Communications",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-221/FXPAL-PR-03-221.pdf"
        ],
        "PublicationDate": "09/09/2003",
        "ID": "221",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "Hypervideo Summaries",
        "Abstract": "Hypervideo is a form of interactive video that allows users to follow links to other video. A simple form of hypervideo,\r\ncalled \"detail-on-demand video,\" provides at most one link from one segment of video to another, supporting a singlebutton\r\ninteraction. Detail-on-demand video is well suited for interactive video summaries, because the user can request a\r\nmore detailed summary while watching the video. Users interact with the video is through a special hypervideo player\r\nthat displays keyframes with labels indicating when a link is available. While detail-on-demand summaries can be\r\nmanually authored, it is a time-consuming task. To address this issue, we developed an algorithm to automatically\r\ngenerate multi-level hypervideo summaries. The highest level of the summary consists of the most important clip from\r\neach take or scene in the video. At each subsequent level, more clips from each take or scene are added in order of their\r\nimportance. We give one example in which a hypervideo summary is created for a linear training video. We also show\r\nhow the algorithm can be modified to produce a hypervideo summary for home video."
    },
    {
        "Projects": [
            "FlySPEC"
        ],
        "keywords": [
            "SPEC",
            "flyspec",
            "immersive",
            "video"
        ],
        "AcceptDate": "04/10/2003",
        "palwebID": "PR-03-222",
        "Venue": "Proc. IEEE Intl. Conf. on Image Processing ",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-222/FXPAL-PR-03-222.doc",
            "http://palweb/files/PR/2003/PR-03-222/FXPAL-PR-03-222.pdf"
        ],
        "PublicationDate": "09/14/2003",
        "ID": "222",
        "Authors": [
            "Qiong Liu",
            "Don Kimber"
        ],
        "Title": "LEARNING AUTOMATIC VIDEO CAPTURE FROM HUMAN'S CAMERA OPERATIONS",
        "Abstract": "This paper presents a video acquisition system that can learn automatic video capture from human's camera operations.  Unlike a predefined camera control system, this system can easily adapt to its environment changes with users' help.  By collecting users' camera-control operations under various environments, the control system can learn video capture from human, and use these learned skills to operate its cameras when remote viewers don't, won't, or can't operate the system.  Moreover, this system allows remote viewers to control their own virtual cameras instead of watching the same video produced by a human operator or a fully automatic system.  The online learning algorithm and the camera management algorithm are demonstrated using field data."
    },
    {
        "Projects": [],
        "keywords": [
            "meaning",
            "authority",
            "trust",
            "communication",
            "decision making"
        ],
        "AcceptDate": "01/31/2003",
        "palwebID": "PR-03-223",
        "Venue": "Journal of Decision Systems, Volume 12, Number 2, pages 123-139",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-223/FXPAL-PR-03-223.doc",
            "http://palweb/files/PR/2003/PR-03-223/FXPAL-PR-03-223.pdf",
            "http://palweb/files/PR/2003/PR-03-223/FXPAL-PR-03-223.prn"
        ],
        "PublicationDate": "09/24/2003",
        "ID": "223",
        "Authors": [
            "Steve Smoliar",
            "Ralph Sprague"
        ],
        "Title": "Technology Support for Communication and Understanding",
        "Abstract": "As the Internet and related technologies for communication change, the role of communication in the conduct of business changes with it. Communication used to be viewed as a technical problem of separating signal from noise and managing bandwidth. Now it is a social matter in which negotiating differences in understanding among communicators is a primary business priority. Addressing this priority requires an understanding of how individuals interact in the course of their decision making activities. Using the work of Anthony Giddens as a point of departure, this paper views interaction in communication as consisting of three dimensions - meaning, authority, and trust. These three dimensions are used to identify new opportunities for advances in decision making technology that help deal with potential breakdowns in social interaction."
    },
    {
        "Projects": [
            "PALBar",
            "VideoGuestbook"
        ],
        "keywords": [
            "ubiquitous",
            "palbar",
            "guestbook"
        ],
        "AcceptDate": "10/30/2003",
        "palwebID": "PR-04-224",
        "Venue": "International Conference on Intelligent User Interfaces (IUI 2004)",
        "palwebURL": [],
        "PublicationDate": "01/13/2004",
        "ID": "224",
        "Authors": [
            "Jonathan Trevor",
            "David Hilbert",
            "Daniel Billsus",
            "Jim Vaughan",
            "Quan Tran"
        ],
        "Title": "Contextual Contact Retrieval",
        "Abstract": "People routinely rely on physical and electronic systems to remind themselves of details regarding personal and organizational contacts. These systems include rolodexes, directories and contact databases. In order to access details regarding contacts, users must typically shift their attention from tasks they are performing to the contact system itself in order to manually look-up contacts. This paper presents an approach for automatically retrieving contacts based on users' current context.  Results are presented to users in a manner that does not disrupt their tasks, but which allows them to access contact details with a single interaction. The approach promotes the discovery of new contacts that users may not have found otherwise and supports serendipity."
    },
    {
        "Projects": [],
        "keywords": [
            "21stCenturyComputing",
            "bioinformatics"
        ],
        "AcceptDate": "09/10/2003",
        "palwebID": "PR-03-225",
        "Venue": "Bioinformatics. ",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-225/FXPAL-PR-03-225.pdf"
        ],
        "PublicationDate": "09/10/2003",
        "ID": "225",
        "Authors": [
            "Morgan Price",
            "Eleanor Rieffel"
        ],
        "Title": "Finding Coexpressed Genes in Counts-Based Data: An Improved Measure with Validation Experiments",
        "Abstract": "Motivation:\r\nEST data reflects variation in gene expression, but\r\nprevious methods for finding coexpressed genes in EST data\r\nare subject to bias and vastly overstate the statistical significance of\r\nputatively coexpressed genes.\r\n\r\nResults:\r\nWe introduce a new method (LNP) that reports reasonable $p$-values\r\nand also\r\ndetects more biological\r\nrelationships in human dbEST than do previous methods.\r\nIn simulations with human dbEST library\r\nsizes, previous methods report $p$-values as low as $10^{-30}$ on 1/1,000\r\nuncorrelated pairs, while LNP reports significance correctly. We\r\nvalidate the analysis on real human genes by comparing coexpressed pairs\r\nto GO annotations and find that LNP is more sensitive than three previous\r\nmethods. We also find a small but statistically significant level of\r\ncoexpression between interacting proteins relative to randomized\r\ncontrols. The LNP method is based on a log-normal prior on the\r\ndistribution of expression levels.\r\n\r\nAvailability: Source code in Java or R is available at http://ests.sourceforge.net/\r\n\r\n"
    },
    {
        "Projects": [
            "FlyCam",
            "FlySPEC",
            "NoteLook"
        ],
        "keywords": [
            "multiple displays",
            "gestural interfaces",
            "augmented reality",
            "slide presentation",
            "pen-based systems",
            "immersive",
            "kumo",
            "NoteLook",
            "NoteLook3",
            "flyspec",
            "spec",
            "flycam"
        ],
        "AcceptDate": "03/28/2003",
        "palwebID": "PR-03-227",
        "Venue": "Proceedings of INTERACT '03,  pp. 583-590.",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-227/FXPAL-PR-03-227.pdf"
        ],
        "PublicationDate": "09/01/2003",
        "ID": "227",
        "Authors": [
            "Patrick Chiu",
            "Qiong Liu",
            "John Boreczky",
            "Jonathan Foote",
            "Tohru Fuse",
            "Don Kimber",
            "Surapong Lertsithichai",
            "Chunyuan Liao"
        ],
        "Title": "Manipulating and annotating slides in a multi-display environment",
        "Abstract": "In a meeting room environment with multiple public wall displays and personal notebook computers, it is possible to design a highly interactive experience for manipulating and annotating slides. For the public displays, we present the ModSlideShow system with a discrete modular model for linking the displays into groups, along with a gestural interface for manipulating the flow of slides within a display group. For the applications on personal devices, an augmented reality widget with panoramic video supports interaction among the various displays. This widget is integrated into our NoteLook 3.0 application for annotating, capturing and beaming slides on pen-based notebook computers."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "Palimpsests",
            "Annotating Community Content",
            "SocComp"
        ],
        "AcceptDate": "",
        "palwebID": "PR-03-228",
        "Venue": "UBICOMP, Seattle, October 12-15th",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-228/FXPAL-PR-03-228.pdf"
        ],
        "PublicationDate": "10/12/2003",
        "ID": "228",
        "Authors": [
            "Scott Carter",
            "Elizabeth Churchill",
            "Laurent Denoue",
            "Jonathan  Helfman",
            "Paul Murphy",
            "Les Nelson"
        ],
        "Title": "Palimpsests on Public View:\r\nAnnotating Community Content with Personal Devices",
        "Abstract": "This demonstration introduces UbiComp attendees to a\r\nsystem for content annotation and open-air, social blogging\r\non interactive, publicly situated, digital poster boards using public and personal devices. We describe our motivation, a scenario of use, our prototype, and an outline of the demonstration."
    },
    {
        "Projects": [
            "FlyCam",
            "FlySPEC"
        ],
        "keywords": [
            "Collaborative device control",
            "video enabled device control",
            "gesture based device control",
            "panoramic video",
            "video communication",
            "video conferencing",
            "distance learning",
            "immersive",
            "flyspec",
            "spec",
            "flycam"
        ],
        "AcceptDate": "06/30/2003",
        "palwebID": "PR-03-229",
        "Venue": "Proc. ACM Multimedia 2003, pp. 546-554 ",
        "palwebURL": [],
        "PublicationDate": "11/02/2003",
        "ID": "229",
        "Authors": [
            "Chunyuan Liao",
            "Qiong Liu",
            "Don Kimber",
            "Patrick Chiu",
            "Jonathan Foote",
            "Lynn Wilcox"
        ],
        "Title": "Shared Interactive Video for Teleconferencing",
        "Abstract": "We present a system that allows remote and local participants to control devices in a meeting environment using mouse or pen based gestures \"through\" video windows.  Unlike state-of-the-art device control interfaces that require interaction with text commands, buttons, or other artificial symbols, our approach allows users to interact with devices through live video of the environment.  This naturally extends our video supported pan/tilt/zoom (PTZ) camera control system, by allowing gestures in video windows to control not only PTZ cameras, but also other devices visible in video images.  For example, an authorized meeting participant can show a presentation on a screen by dragging the file on a personal laptop and dropping it on the video image of the presentation screen. This paper presents the system architecture, implementation tradeoffs, and various meeting control scenarios."
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "06/30/2003",
        "palwebID": "PR-03-246",
        "Venue": "Proc. ACM Multimedia 2003. pp. 92-93",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-246/FXPAL-PR-03-246.pdf"
        ],
        "PublicationDate": "11/02/2003",
        "ID": "246",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "Hyper-Hitchcock: Authoring Interactive Videos and Generating Interactive Summaries",
        "Abstract": "To simplify the process of editing interactive video, we developed the concept of \"detail-on-demand\" video as a subset of general hypervideo. Detail-on-demand video keeps the authoring and viewing interfaces relatively simple while supporting a wide range of interactive video applications. Our editor, Hyper-Hitchcock, provides a direct manipulation environment in which authors can combine video clips and place hyperlinks between them. To summarize a video, Hyper-Hitchcock can also automatically generate a hypervideo composed of multiple video summary levels and navigational links between these summaries and the original video. Viewers may interactively select the amount of detail they see, access more detailed summaries, and navigate to the source video through the summary. "
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "06/30/2003",
        "palwebID": "PR-03-247",
        "Venue": "Proc. ACM Multimedia 2003. pp. 392-401",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-247/FXPAL-PR-03-247.pdf"
        ],
        "PublicationDate": "11/02/2003",
        "ID": "247",
        "Authors": [
            "Frank Shipman",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Generation of Interactive Multi-Level Video Summaries",
        "Abstract": "In this paper, we describe how a detail-on-demand representation for interactive video is used in video summarization. Our approach automatically generates a hypervideo composed of multiple video summary levels and navigational links between these summaries and the original video. Viewers may interactively select the amount of detail they see, access more detailed summaries, and navigate to the source video through the summary. We created a representation for interactive video that supports a wide range of interactive video applications and Hyper-Hitchcock, an editor and player for this type of interactive video. Hyper-Hitchcock employs methods to determine (1) the number and length of levels in the hypervideo summary, (2) the video clips for each level in the hypervideo, (3) the grouping of clips into composites, and (4) the links between elements in the summary. These decisions are based on an inferred quality of video segments and temporal relations those segments."
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "rmo",
            "photo",
            "media"
        ],
        "AcceptDate": "06/30/2003",
        "palwebID": "PR-03-248",
        "Venue": "Proc. ACM Multimedia 2003. pp. 598-599",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-248/FXPAL-PR-03-248.pdf"
        ],
        "PublicationDate": "11/02/2003",
        "ID": "248",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "John Doherty",
            "Jonathan Foote",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Managing Digital Memories with the FXPAL Photo Application",
        "Abstract": "The FXPAL Photo Application is designed to faciliate the\r\norganization of digital images from digital cameras and other\r\nsources through automated organization and intuitive user\r\ninterfaces."
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "06/30/2003",
        "palwebID": "PR-03-249",
        "Venue": "Proc. ACM Multimedia 2003. pp. 600-601",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-249/FXPAL-PR-03-249.pdf"
        ],
        "PublicationDate": "11/02/2003",
        "ID": "249",
        "Authors": [
            "John Doherty",
            "Andreas Girgensohn",
            "Jonathan  Helfman",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "Detail-on-Demand Hypervideo",
        "Abstract": "We demonstrate the use of detail-on-demand hypervideo in\r\ninteractive training and video summarization. Detail-on-demand\r\nvideo allows viewers to watch short video segments and to follow\r\nhyperlinks to see additional detail. The player for detail-ondemand\r\nvideo displays keyframes indicating what links are\r\navailable at each point in the video. The Hyper-Hitchcock\r\nauthoring tool helps users create hypervideo by automatically\r\ndividing video into clips that can be combined in a direct\r\nmanipulation interface. Clips can be grouped into composites and\r\nhyperlinks can be placed between clips and composites. A\r\nsummarization algorithm creates multi-level hypervideo\r\nsummaries from linear video by automatically selecting clips and\r\nplacing links between them."
    },
    {
        "Projects": [
            "Hitchcock",
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "hitchcock",
            "hyperhitchcock",
            "media",
            "video"
        ],
        "AcceptDate": "",
        "palwebID": "PR-03-250",
        "Venue": "Proceedings of Hypertext '03, pp. 124-125",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-250/FXPAL-PR-03-250.pdf"
        ],
        "PublicationDate": "08/26/2003",
        "ID": "250",
        "Authors": [
            "Frank Shipman",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Combining Spatial and Navigational Structure in the Hyper-Hitchcock Hypervideo Editor",
        "Abstract": "Existing hypertext systems have emphasized either the navigational or spatial expression of relationships between objects. We are exploring the combination of these modes of expression in Hyper-Hitchcock, a hypervideo editor. Hyper-Hitchcock supports a form of hypervideo called \"detail-on-demand video\" due to its applicability to situations where viewers need to take a link to view more details on the content currently being presented. Authors of detail-on-demand video select, group, and spatially arrange video clips into linear sequences in a two-dimensional workspace. Hyper-Hitchcock uses a simple spatial parser to determine the temporal order of selected video clips. Authors add navigational links between the elements in those sequences. This combination of navigational and spatial hypertext modes of expression separates the clip sequence from the navigational structure of the hypervideo. Such a combination can be useful in cases where multiple forms of inter-object relationships must be expressed on the same content."
    },
    {
        "Projects": [],
        "keywords": [
            "Mobility",
            "office",
            "wireless",
            "CSCW",
            "workplace",
            "field work"
        ],
        "AcceptDate": "09/20/2001",
        "palwebID": "PR-01-251",
        "Venue": "ACM SIGGROUP Bulletin, Volume 22, Issue 3, Pp3-9, Publisher ACM Press, New York, NY, USA",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-251/FXPAL-PR-01-251.pdf"
        ],
        "PublicationDate": "12/08/2001",
        "ID": "251",
        "Authors": [
            "Elizabeth Churchill",
            "Alan Munro"
        ],
        "Title": "Work/place: mobile technologies and arenas of activity \r\n\r\n",
        "Abstract": "The increasing number of wireless, portable devices has led inevitably to lyrical rhetorics of business cost-cutting and increased efficiency as workers can be productive while on the and offices become streamlined areas of efficient activity.  In this short paper, we raise a number if issues that have been appearing in common discourses the (most) modern office, and the impact of wireless technologies thereupon. We also present an overview of a workshop held at ECSCW in Bonn in September of 2001 on this topic, giving an overview of the comments and discussions that took place at the workshop. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/01/2002",
        "palwebID": "PR-02-253",
        "Venue": "New York: ACM Press. 2000. ",
        "palwebURL": [],
        "PublicationDate": "09/01/2002",
        "ID": "253",
        "Authors": [
            "Chris Greenhalgh",
            "Elizabeth Churchill",
            "Wolfgang Broll"
        ],
        "Title": "CVE 2002. Proceedings of the ACM Conference on Collaborative Virtual Environments, Bonn Germany, September 30th - October 2nd 2002.\r\n",
        "Abstract": "This volume is the edited proceedings of the ACM conference on Collabroative Virtual Environments."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/01/2003",
        "palwebID": "PR-03-254",
        "Venue": "Mass,USA: Kluwer Academic Publishers, 2003",
        "palwebURL": [],
        "PublicationDate": "06/01/2003",
        "ID": "254",
        "Authors": [
            "Yiming Ye",
            "Elizabeth Churchill"
        ],
        "Title": "Agent Supported Cooperative Work. ",
        "Abstract": "This is a volume, edited by Ye and Churchill. The chapters detail the design of agent-baed technologies in service of collaborative and cooperative work practices. "
    },
    {
        "Projects": [],
        "keywords": [
            "digital video",
            "asynchronous sharing",
            "interviews",
            "observations",
            "field work"
        ],
        "AcceptDate": "09/01/2002",
        "palwebID": "PR-02-255",
        "Venue": "Proceedings of American Anthropological Association, 101st Annual Meeting / November 20-24, 2002, New Orleans, LA\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2002/PR-02-255/FXPAL-PR-02-255.pdf"
        ],
        "PublicationDate": "11/20/2002",
        "ID": "255",
        "Authors": [
            "Elizabeth Churchill"
        ],
        "Title": "Online and offline, together and apart: Sharing memories with digital video",
        "Abstract": ""
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-04-257",
        "Venue": "London: Springer-Verlag, 2003",
        "palwebURL": [],
        "PublicationDate": "01/05/2004",
        "ID": "257",
        "Authors": [
            "David Snowdon",
            "Elizabeth Churchill",
            "Emmanuel Frecon"
        ],
        "Title": "Inhabited Information Spaces: Living with Your Data\r\n",
        "Abstract": "This edited volume brings together projects funded by, or related to, the European i3 initiative. Projects address the design, development and use of rich, digital information spaces for collocated and distributed collaboration."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "CSCW",
            "HCI",
            "public display",
            "social interaction"
        ],
        "AcceptDate": "12/01/2003",
        "palwebID": "PR-03-258",
        "Venue": "Lond: Kluwer Academic Publishers",
        "palwebURL": [],
        "PublicationDate": "12/31/2003",
        "ID": "258",
        "Authors": [
            "Kenton Ohara",
            "Mark Perry",
            "Elizabeth Churchill",
            "Daniel  Russell"
        ],
        "Title": "Public and Situated Displays. Social and Interactional Aspects of Shared Display Technologies",
        "Abstract": "Public and situated display technologies have an important impact on individual and social behaviour and present us with particular interesting new design considerations and challenges. While there is a growing body of research exploring these design considerations and social impacts this work remains somewhat disparate, making it difficult to assimilate in a coherent manner. This book brings together the perspective of key researchers in the area of public and situated display technology. The chapters detail research representing the social, technical and interactional aspects of public and sitauted display technologies. The underlying concern common to these chapters is how these displays can be best designed for collaboration, coordination, community building and mobility. "
    },
    {
        "Projects": [],
        "keywords": [
            "communities of practice and interest",
            "large screen displays",
            "installation",
            "evaluation"
        ],
        "AcceptDate": "12/10/2003",
        "palwebID": "PR-04-259",
        "Venue": "Communications of the ACM, February 2004, Vol. 47, No. 2, pp. 38-44",
        "palwebURL": [],
        "PublicationDate": "02/01/2004",
        "ID": "259",
        "Authors": [
            "Elizabeth Churchill",
            "Andreas Girgensohn",
            "Les Nelson",
            "Alison Lee"
        ],
        "Title": "Blending Digital and Physical Spaces for Ubiquitous Community Participation. ",
        "Abstract": "Blurring the boundary between the digital and physical in social activity spaces helps blend - and motivate - online and face-to-face community participation. This paper discusses two experimental installations of large screen displays at conferences - CHI 2002 and CSCW 2002. The displays offered a window in the conference arena onto online community information. "
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "Plasma Poster Network",
            "information distribution",
            "public displays",
            "social networking",
            "SocComp"
        ],
        "AcceptDate": "12/01/2003",
        "palwebID": "PR-03-260",
        "Venue": "In Public and Situated Displays. Social and Interactional Aspects of Shared Display Technologies. K. O'Hara, M.Perry, E. Churchill and D. Russell (Eds) London: Kluwer Acamdemic Publishers",
        "palwebURL": [
            "http://palweb/files/PR/2003/PR-03-260/FXPAL-PR-03-260.pdf"
        ],
        "PublicationDate": "12/31/2003",
        "ID": "260",
        "Authors": [
            "Elizabeth Churchill",
            "Les Nelson",
            "Laurent Denoue",
            "Paul Murphy",
            "Jonathan  Helfman"
        ],
        "Title": "THE PLASMA POSTER NETWORK Social Hypermedia on Public Display\r\n",
        "Abstract": "The sharing of digital materials within online communities has increased significantly in recent years. Our work focuses on promoting community information sharing in public spaces using large screen, interactive, digital poster boards called the Plasma Posters. In this chapter we first describe our fieldwork-led, iterative design process, and elaborate a number of design guidelines that resulted. Following this, the design and development of the Plasma Posters themselves and the underlying network infrastructure is discussed. Finally, we present results from qualitative and quantitative evaluations over the course of a ten-month deployment of three Plasma Posters within our own organization, a software research community made up of technologists and designers. We conclude with observations regarding ergonomic, social and other factors that were raised during the design and deployment and offer  reflections on factors in the success of this deployment. "
    },
    {
        "Projects": [],
        "keywords": [
            "hypertext",
            "video",
            "narrative",
            "description"
        ],
        "AcceptDate": "07/31/2000",
        "palwebID": "PR-01-261",
        "Venue": "Proceedings of the Thirty-Fourth Annual Hawaii International Conference on System Sciences",
        "palwebURL": [
            "http://palweb/files/PR/2001/PR-01-261/FXPAL-PR-01-261.PDF"
        ],
        "PublicationDate": "01/03/2001",
        "ID": "261",
        "Authors": [
            "Steve Smoliar",
            "Tina Schneider"
        ],
        "Title": "Description and Narrative in Hypervideo",
        "Abstract": "While hypertext was originally conceived for the management of scientific and technical information, it has been embraced with great enthusiasm by several members of the literary community for the promises it offers towards new approaches to narrative.  Experiments with hypertext-based interactive narrative were originally based solely on verbal text but have more recently extended to include digital video artifacts.  The most accomplished of these experiments, HyperCafe, provided new insights into the nature of narrative and how it may be presented;  but it also offered an opportunity to reconsider other text types.  This paper is an investigation of the application of an approach similar to HyperCafe to a descriptive text.  We discuss how the approach serves the needs of description and illustrate the discussion with a concrete example.  We then conclude by considering the extent to which our experiences with description may be applied to our continuing interest in narrative."
    },
    {
        "Projects": [
            "PlasmaPoster\r\nconversation",
            "digital bulletin board",
            "evaluation",
            "adoption",
            "SocComp"
        ],
        "keywords": [
            "Interactive public displays",
            "community",
            "social capital",
            "conversation",
            "digital bulletin board",
            "evaluation",
            "adoption",
            "SocComp"
        ],
        "AcceptDate": "08/01/2004",
        "palwebID": "PR-04-262",
        "Venue": "ACM DIS 2004, Cambridge, August 1-4, 2004. New York: ACM",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-262/FXPAL-PR-04-262.pdf"
        ],
        "PublicationDate": "04/18/2004",
        "ID": "262",
        "Authors": [
            "Elizabeth Churchill",
            "Les Nelson",
            "Laurent Denoue",
            "Jonathan  Helfman",
            "Paul Murphy"
        ],
        "Title": "Sharing Multimedia Content with Interactive Displays: A Case Study",
        "Abstract": "The Plasma Posters are large screen, digital, interactive posterboards designed for informal content sharing within teams, groups, organizations and communities. Leveraging the fact that the physical world is often used as a canvas for asynchronous information exchange via paper fliers and posters, the Plasma Posters provide a platform for sharing interactive digital content in public places. People serendipitously encounter multimedia content usually only encountered from the desktop, while going about their daily business. In this paper we describe the Plasma Poster interface in detail, and offer and overview of the underlying information authoring, parsing, storage, distribution and publishing infrastructure, the Plasma Poster Network. We report qualitative and quantitative data collected over 14 months of use that demonstrate the Plasma Posters have become an integral part of information sharing within our organization. We conclude the paper by reflecting on the patterns of adoption, and speculate on factors that have contributed to the system's success. Finally we briefly describe three other installations of the Plasma Poster Network and new interfaces that have been designed."
    },
    {
        "Projects": [],
        "keywords": [
            "plasma poster",
            "annotation",
            "digital community poster boards",
            "threaded discussion",
            "blogging",
            "SocComp"
        ],
        "AcceptDate": "",
        "palwebID": "PR-04-263",
        "Venue": "CHI 2004, Vienna, Austria, April 24-29, 2004. New York: ACM Publications.",
        "palwebURL": [],
        "PublicationDate": "02/26/2004",
        "ID": "263",
        "Authors": [
            "Scott Carter",
            "Elizabeth Churchill",
            "Laurent Denoue",
            "Jonathan  Helfman",
            "Les Nelson"
        ],
        "Title": "Digital Graffiti: Public Annotation of Multimedia Content",
        "Abstract": "Our physical environment is increasingly filled with multimedia content on situated, community public displays. We are designing methods for people to post and acquire digital information to and from public digital displays, and to modify and annotate previously posted content to create publicly observable threads. We support in-the-moment and on-site \"person-to-place-to-people-to-persons\" content interaction, annotation, augmentation and publication. We draw design inspiration from field work observations of how people remove, modify and mark up paper postings. We present our initial designs in this arena, and some initial user reactions."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "Content repurposing",
            "interactive public displays",
            "SocComp"
        ],
        "AcceptDate": "04/24/2004",
        "palwebID": "PR-04-265",
        "Venue": "CHI 2004, Vienna, Austria, April 24-29, 2004. New York: ACM Publications. ",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-265/FXPAL-PR-04-265.pdf"
        ],
        "PublicationDate": "02/20/2004",
        "ID": "265",
        "Authors": [
            "Les Nelson",
            "Elizabeth Churchill",
            "Laurent Denoue",
            "Jonathan  Helfman",
            "Paul Murphy"
        ],
        "Title": "Gooey Interfaces: An Approach for Rapidly Repurposing Digital Content",
        "Abstract": "With the acceleration of technological development we are reaching the point where our systems and their user interfaces become to some degree outdated 'legacy systems' as soon as they are released. This raises the question of how can we maintain, extend, override, and adapt these systems while preserving what people depend on in them? In this paper we describe an approach for dynamically restructuring user interfaces into a set of communicating processes that 1) provide methods for changing their appearance, behavior, and state; and 2) report their proposed state changes so that other processes may override their actions in updating themselves to a new state. We do this for both new and wrapped legacy user interface components, thereby allowing us to repurpose user interfaces for our evolving needs. We describe how this approach has been successfully used in rapidly creating and deploying interfaces that repurpose content for new appearances and behaviors. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/30/2002",
        "palwebID": "PR-03-266",
        "Venue": "Human Computer Interaction, Volume 18, Nos. 1&2, 2003 London: Lawrence Erlbaum Assoc.",
        "palwebURL": [],
        "PublicationDate": "03/31/2003",
        "ID": "266",
        "Authors": [
            "Elizabeth Churchill",
            "Tom Erickson"
        ],
        "Title": "Talking About Things in Mediated Conversations: An Introduction",
        "Abstract": "An introduction to a special issue on mediated communication. "
    },
    {
        "Projects": [
            "InteractiveVideoSearch"
        ],
        "keywords": [
            "trecvid",
            "video segmentation",
            "videosegmentation"
        ],
        "AcceptDate": "11/02/2003",
        "palwebID": "PR-04-267",
        "Venue": "Proceedings TRECVID 2003",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-267/FXPAL-PR-04-267.pdf"
        ],
        "PublicationDate": "03/01/2004",
        "ID": "267",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote",
            "John Adcock",
            "Sandeep Casi"
        ],
        "Title": "Shot boundary detection via similarity analysis",
        "Abstract": "In this paper, we present a framework for analyzing video using self-similarity.  Video scenes are located by analyzing\r\ninter-frame similarity matrices. The approach is flexible to the choice of both feature parametrization and similarity measure and it is robust because the data is used to model itself. We present the approach and its application to shot boundary detection."
    },
    {
        "Projects": [
            "SharedTextInput"
        ],
        "keywords": [
            "shared text input",
            "pda",
            "note-taking",
            "immersive"
        ],
        "AcceptDate": "02/25/2004",
        "palwebID": "PR-04-268",
        "Venue": "ED-Media 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-268/FXPAL-PR-04-268.pdf"
        ],
        "PublicationDate": "06/21/2004",
        "ID": "268",
        "Authors": [
            "Laurent Denoue"
        ],
        "Title": "Taking Notes on PDAs with Shared Text Input",
        "Abstract": "This paper presents a system designed to support note taking by students on wirelessly connected PDAs in a classroom. The system leverages the devices' wireless connectivity to allow students to share their notes in real time and quickly reuse words from their fellow note takers. In addition, presentation material such as Powerpoint slides is also extracted when presented by the instructor, giving students further means for reusing words. We describe the system and report our findings on an initial user study where the system was used for four months during a graduate level course."
    },
    {
        "Projects": [],
        "keywords": [
            "Handheld devices",
            "wireless networking",
            "note taking",
            "collaboration",
            "immersive"
        ],
        "AcceptDate": "01/15/2004",
        "palwebID": "PR-04-269",
        "Venue": "WMTE 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-269/FXPAL-PR-04-269.pdf"
        ],
        "PublicationDate": "03/23/2004",
        "ID": "269",
        "Authors": [
            "Laurent Denoue"
        ],
        "Title": "Collaborative Note Taking",
        "Abstract": "Collaborative note taking enables students in a class to take notes on their PDAs and share them with their \"study group\" in real-time. Students receive instructor\u00e2\u20ac\u2122s slides on their PDAs as they are displayed by the instructor. As the individual members of the group take notes pertaining to the slide being presented, their notes are automatically sent to all members of the group. In addition, to reduce their typing, students can use text they receive from other students and from the instructors slides to construct their notes. This system has been used in actual practice for a graduate level course on wireless mobile computing. In developing this system, special attention has been paid to the task of inputting text on PDAs, efficient use of the screen real estate, dynamics among students, privacy and ease of use issues."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/28/2004",
        "palwebID": "PR-04-270",
        "Venue": "CHI 2004 short paper",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-270/FXPAL-PR-04-270.pdf"
        ],
        "PublicationDate": "04/27/2004",
        "ID": "270",
        "Authors": [
            "Maryam Kamvar",
            "Patrick Chiu",
            "Lynn Wilcox",
            "Sandeep Casi",
            "Surapong Lertsithichai"
        ],
        "Title": "MiniMedia Surfer: Browsing Video Segments on Small Displays",
        "Abstract": "It is challenging to browse multimedia on mobile devices with small displays. We present MiniMedia Surfer, a prototype application for interactively searching a multimedia collection for video segments of interest.  Transparent layers are used to support browsing subtasks: keyword query, exploration of results through keyframes, and playback of video.  This layered interface smoothly blends the key tasks of the browsing process and deals with the small screen size.  During exploration, the user can adjust the transparency levels of the layers using pen gestures.  Details of the video segments are displayed in an expandable timeline that supports gestural interaction."
    },
    {
        "Projects": [
            "Hitchcock"
        ],
        "keywords": [
            "media",
            "hitchcock",
            "video",
            "Hypervideo"
        ],
        "AcceptDate": "02/04/2004",
        "palwebID": "PR-04-271",
        "Venue": "Proceedings of the Working Conference on Advanced Visual Interfaces, AVI 2004, pp. 290-297",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-271/FXPAL-PR-04-271.pdf"
        ],
        "PublicationDate": "05/25/2004",
        "ID": "271",
        "Authors": [
            "Andreas Girgensohn",
            "Lynn Wilcox",
            "Frank Shipman",
            "Sara Bly"
        ],
        "Title": "Designing Affordances for the Navigation of Detail-on-Demand Hypervideo",
        "Abstract": "We introduced detail-on-demand video as a simple type of hypervideo that allows users to watch short video segments and to follow hyperlinks to see additional detail. Such video lets users quickly access desired information without having to view the entire contents linearly. A challenge for presenting this type of video is to provide users with the appropriate affordances to understand the hypervideo structure and to navigate it effectively. Another challenge is to give authors tools that allow them to create good detail-on-demand video. Guided by user feedback, we iterated designs for a detail-on-demand video player. We also conducted two user studies to gain insight into people's understanding of hypervideo and to improve the user interface. We found that the interface design was tightly coupled to understanding hypervideo structure and that different designs greatly affected what parts of the video people accessed. The studies also suggested new guidelines for hypervideo authoring."
    },
    {
        "Projects": [
            "PIPs"
        ],
        "keywords": [
            "ubiquitous",
            "pips"
        ],
        "AcceptDate": "02/27/2004",
        "palwebID": "PR-04-273",
        "Venue": "ACM Interactions Magazine",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-273/FXPAL-PR-04-273.pdf"
        ],
        "PublicationDate": "05/01/2004",
        "ID": "273",
        "Authors": [
            "David Hilbert",
            "Jonathan Trevor"
        ],
        "Title": "Personalizing shared ubiquitous devices",
        "Abstract": "This article describes two years of experience with a research prototype for personalizing shared workplace devices such as projectors, public displays, and multi-function copiers.  The system combines users' networked resources-or \"personal information clouds\"\u00e2\u20ac\u201dwith device-specific user interfaces for performing common device tasks. We developed and compared personal interfaces that are embedded (i.e., integrated or co-located with the shared device) and portable (i.e., accessible via personal devices such as mobile phones and PDAs). \r\n\r\nOur experience indicates that a little personalization can go a long way toward improving user friendliness, efficiency, and capabilities of shared document devices, helping them \"weave themselves into the fabric of everyday life\".  We also gained important insights into subtle differences between embedded and portable approaches to ubiquitous computing systems."
    },
    {
        "Projects": [
            "StainedGlassCollage"
        ],
        "keywords": [
            "media",
            "video",
            "stainedglass",
            "stained glass visualization",
            "video summaries",
            "video content analysis",
            "video visualization"
        ],
        "AcceptDate": "03/05/2004",
        "palwebID": "PR-04-275",
        "Venue": "Proceedings of 2004 IEEE International Conference on Multimedia and Expo (ICME 2004).",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-275/FXPAL-PR-04-275.pdf"
        ],
        "PublicationDate": "06/27/2004",
        "ID": "275",
        "Authors": [
            "Patrick Chiu",
            "Andreas Girgensohn",
            "Qiong Liu"
        ],
        "Title": "Stained-Glass Visualization for Highly Condensed Video Summaries",
        "Abstract": "This paper presents a method for creating highly condensed video summaries called Stained-Glass visualizations. These are especially suitable for small displays on mobile devices. A morphological grouping technique is described for finding 3D regions of high activity or motion from a video embedded in x-y-t space. These regions determine areas in the keyframes, which can be subsumed in a more general geometric framework of germs and supports: germs are the areas of interest, and supports give the context. Algorithms for packing and laying out the germs are provided. Gaps between the germs are filled using a Voronoi-based method. Irregular shapes emerge, and the result looks like stained glass. "
    },
    {
        "Projects": [],
        "keywords": [
            "immersive",
            "Immersive conferencing",
            "tele-robot",
            "remote environment control",
            "remote control",
            "video based control",
            "device operation learning"
        ],
        "AcceptDate": "03/02/2004",
        "palwebID": "PR-04-276",
        "Venue": "Proceedings of 2004 IEEE International Conference on Multimedia and Expo (ICME 2004).",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-276/FXPAL-PR-04-276.doc",
            "http://palweb/files/PR/2004/PR-04-276/FXPAL-PR-04-276.pdf"
        ],
        "PublicationDate": "06/27/2004",
        "ID": "276",
        "Authors": [
            "Chunyuan Liao",
            "Qiong Liu",
            "Don Kimber",
            "Surapong Lertsithichai"
        ],
        "Title": "A Tele-robot Assistant for Remote Environment Management",
        "Abstract": "Using a machine to assist remote environment management can save people's time, effort, and traveling cost.  This paper proposes a trainable mobile robot system, which allows people to watch a remote site through a set of cameras installed on the robot, drive the platform around, and control remote devices using mouse or pen based gestures performed in video windows.  Furthermore, the robot can learn device operations when it is being used by humans.  After being used for a while, the robot can automatically select device control interfaces, or launch a pre-defined operation sequence based on its sensory inputs."
    },
    {
        "Projects": [
            "ePic"
        ],
        "keywords": [
            "immersive",
            "Immersive conferencing",
            "presentation authoring tool",
            "multi-channel presentation",
            "presentation preview and playback."
        ],
        "AcceptDate": "03/02/2004",
        "palwebID": "PR-04-277",
        "Venue": "Proceedings of 2004 IEEE International Conference on Multimedia and Expo (ICME 2004).",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-277/FXPAL-PR-04-277.pdf"
        ],
        "PublicationDate": "06/27/2004",
        "ID": "277",
        "Authors": [
            "Hangjin Zhang",
            "Qiong Liu",
            "Surapong Lertsithichai",
            "Chunyuan Liao",
            "Don Kimber"
        ],
        "Title": "A Presentation Authoring Tool for Media Devices Distributed Environments",
        "Abstract": "Many conference rooms are now equipped with multiple multi-media devices, such as plasma displays and surrounding speakers, to enhance presentation quality. However, most existing presentation authoring tools are based on the one-display-and-one-speaker assumption, which makes it difficult to organize and playback a presentation dispatched to multiple devices, thus hinders users from taking full advantage of additional multimedia devices. In this paper, we propose and implement a tool to facilitate authoring and playback of a multi-channel presentation in a media devices distributed environment. The tool, named PreAuthor, provides an intuitive and visual way to author a multi-channel presentation by dragging and dropping \"hyper-slides\" on corresponding visual representations of various devices. PreAuthor supports \"hyper-slide\" synchronization among various output devices during preview and playback. It also offers multiple options for the presenter to view the presentation in a rendered image sequence, live video, 3D VRML model, or real environment. "
    },
    {
        "Projects": [],
        "keywords": [
            "Hypertext",
            "Archiving",
            "Digital preservation"
        ],
        "AcceptDate": "04/24/2004",
        "palwebID": "PR-04-278",
        "Venue": "In Proceedings of Hypertext 2004, ACM Press.",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-278/FXPAL-PR-04-278.pdf"
        ],
        "PublicationDate": "08/09/2004",
        "ID": "278",
        "Authors": [
            "Catherine Marshall",
            "Gene Golovchinsky"
        ],
        "Title": "Saving Private Hypertext: Requirements and pragmatic dimensions for preservation",
        "Abstract": "The preservation of literary hypertexts presents significant challenges if we are to ensure continued access to them as the underlying technology changes. Not only does such an effort involve standard digital preservation problems of representing and refreshing metadata, any constituent media types, and structure; hypertext preservation poses additional dimensions that arise from the work's on-screen appearance, its interactive behavior, and the ways a reader's interaction with the work is recorded. In this paper, we describe aspects of preservation introduced by literary hypertexts such as the need to reproduce their modes of interactivity and their means of capturing and using records of reading. We then suggest strategies for addressing the pragmatic dimensions of hypertext preservation and discuss their status within existing digital preservation schemes. Finally, we examine the possible roles various stakeholders within and outside of the hypertext community might assume, including several social and legal issues that stem from preservation."
    },
    {
        "Projects": [],
        "keywords": [
            "NL",
            "Natural Language",
            "discourse parsing",
            "summarization",
            "text",
            "Linguistic Discourse Model",
            "LDM",
            "U-LDM"
        ],
        "AcceptDate": "",
        "palwebID": "PR-04-279",
        "Venue": "Proceedings of the 5th SIGdial Workshop in Discourse And Dialogue. Cambridge, MA USA pp. 108-117.",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-279/FXPAL-PR-04-279.pdf"
        ],
        "PublicationDate": "05/01/2004",
        "ID": "279",
        "Authors": [
            "Livia Polanyi",
            "Christopher Culy",
            "Martin van den Berg",
            "Gian Lorenzo Thione"
        ],
        "Title": "A Rule Based Approach to Discourse Parsing",
        "Abstract": "In this paper we present recent developments in discourse theory and parsing under the Linguistic Discourse Model framework, a semantic theory of discourse structure. We give a novel approach to the problems of discourse segmentation based on discourse semantics and sketch a limited but robust approach to symbolic discourse parsing based on syntactic, semantic and lexical rules. To demonstrate the utilioty of the system in a real application, we briefly describe the architecture of the PALSUMM System, a symbolic smmarization system being developed at FX Palo Alto Laboratory that uses discourse structures constructed usding the theory otlined to summarize written English texts."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "05/20/2004",
        "palwebID": "PR-04-280",
        "Venue": "IEEE Computer Graphics & Applications, pp. 66-75",
        "palwebURL": [],
        "PublicationDate": "09/01/2004",
        "ID": "280",
        "Authors": [
            "Alison Lee",
            "Andreas Girgensohn",
            "Jun Zhang"
        ],
        "Title": "Browsers to Support Awareness and Social Interaction",
        "Abstract": "Information sharing, computation and social interaction are main features of the Web that has enabled online communities to abound and flourish. However, this trend has not been coupled with the development of cues and browsing mechanisms for the social space. On the flip side, active contributors to social spaces (i.e., Web communities) lack the means to present a public face to visitors that can be important for social organizations. Social browsers that combine social visualization and tools can enable newcomers and visitors to view and explore  information and patterns. We present two social browsers for two Web communities. The CHIplace People browser provides an abstract graphical view of the CHIplace community based on the self-described work roles of its membership. The Portkey eTree browser uses a life-like tree ecosystem metaphor to reflect the people, activities and discussions occurring on the Portkey Web site."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-04-281",
        "Venue": "Journal of Human Interface Society, 6(2), pp. 51-58",
        "palwebURL": [],
        "PublicationDate": "06/01/2004",
        "ID": "281",
        "Authors": [
            "Andreas Girgensohn"
        ],
        "Title": "FX Palo Alto Laboratory: Shaping the Office of the Future",
        "Abstract": "FX Palo Alto Laboratory provides multimedia and information\r\ntechnology research for the Fuji Xerox corporation based in Tokyo,\r\nJapan. FXPAL's mission is to help Fuji Xerox with a digital\r\ninformation technology infrastructure to support services in Fuji\r\nXerox's Open Office Frontier. Our research spans interactive\r\nmedia, immersive conferencing, social computing, mobile and\r\nadaptive computing, natural language inquiry, and emerging technologies\r\nsuch as quantum computing and bioinformatics. Our\r\nresearch methods combine determining user needs, inventing new\r\ntechnologies, building prototype systems, informing professional\r\ncommunities, and transferring technology to Fuji Xerox. The\r\nphysical distance between our laboratory and our parent company\r\nmakes it natural for us to research problems with collaborations\r\nacross time zones and cultures. To address these problems,\r\nto test our ideas, and to prepare for technology transfers, we actively\r\ncreate prototype systems for interactive media, immersive\r\nconferencing, and social and mobile computing. We also foster\r\ncollaboration with our Japanese colleagues through a combination\r\nof face-to-face visits and both synchronous and asynchronous\r\nremote communication."
    },
    {
        "Projects": [
            "PlasmaPoster"
        ],
        "keywords": [
            "situated display",
            "information sharing",
            "distant communities",
            "video capturing",
            "public commentary",
            "annotation",
            "SocComp"
        ],
        "AcceptDate": "07/14/2004",
        "palwebID": "PR-04-282",
        "Venue": "UIST 2004, the Seventeenth Annual ACM Symposium on User Interface Software and Technology, October 24-27, 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-282/FXPAL-PR-04-282.pdf"
        ],
        "PublicationDate": "10/24/2004",
        "ID": "282",
        "Authors": [
            "Toshiya Yamada",
            "Jun Shingu",
            "Elizabeth Churchill",
            "Les Nelson",
            "Jonathan  Helfman",
            "Paul Murphy"
        ],
        "Title": "Who cares? Reflecting who is reading what on distributed community bulletin boards \r\n",
        "Abstract": "In this paper, we describe the YeTi information sharing system that has been designed to foster community building through informal digital content sharing. The YeTi system is a general information parsing, hosting and distribution infrastructure, with interfaces designed for individual and public content reading. In this paper we describe the YeTi public display interface, with a particular focus on tools we have designed to provide lightweight awareness of others' interactions with and interest in posted content. Our tools augment content with metadata that reflect people's reading of content - captured video clips of who's reading and interacting with content, tools to allow people to leave explicit freehand annotations about content, and a visualization of the content access history to show when content is interacted with. Results from an initial evaluation are presented and discussed. "
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "media",
            "rmo",
            "photo",
            "face recognition"
        ],
        "AcceptDate": "07/30/2004",
        "palwebID": "PR-04-283",
        "Venue": "Proceedings of the International Workshop on Multimedia Information Retrieval, ACM Press, pp. 99-106",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-283/FXPAL-PR-04-283.pdf"
        ],
        "PublicationDate": "10/10/2004",
        "ID": "283",
        "Authors": [
            "Andreas Girgensohn",
            "John Adcock",
            "Lynn Wilcox"
        ],
        "Title": "Leveraging Face Recognition Technology to Find and Organize Photos",
        "Abstract": "With digital still cameras, users can easily collect thousands of photos. We have created a photo management application with the goal of making photo organization and browsing simple and quick, even for very large collections. A particular concern is the management of photos depicting people. We present a semi-automatic approach designed to facilitate the task of labeling photos with people that opportunistically takes advantage of the strengths of current state-of-the-art technology in face detection and recognition. In particular, an accurate face detector is used to automatically extract faces from photos while the less accurate face recognizer is used not to classify the detected faces, but to sort faces by their similarity to a chosen model. This sorting is used to present candidate faces within a user interface designed for quick and easy face labeling. We present results of a simulation of the usage model that demonstrate the improved ease that is achieved by our method."
    },
    {
        "Projects": [],
        "keywords": [
            "NL",
            "discourse",
            "summarization",
            "discourse analysis",
            "Natural Language Processing",
            "LDM",
            "Linguistic Discourse Model"
        ],
        "AcceptDate": "05/20/2004",
        "palwebID": "PR-04-284",
        "Venue": "Proceedings of the ACL2004 Workshop Text Summarization Branches Out, Barcelona, Spain, July 25-26, 2004. \r\n",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-284/FXPAL-PR-04-284.doc",
            "http://palweb/files/PR/2004/PR-04-284/FXPAL-PR-04-284.pdf"
        ],
        "PublicationDate": "07/25/2004",
        "ID": "284",
        "Authors": [
            "Gian Lorenzo Thione",
            "Martin van den Berg",
            "Livia Polanyi",
            "Christopher Culy"
        ],
        "Title": "Hybrid Text Summarization: Combining external relevance measures with Structural Analysis\r\n",
        "Abstract": "A novel linguistically advanced text summarization system is described for reducing the minimum size of highly readable variable-sized summaries of digitized text documents produced by text summarization methods that use discourse analysis to rank sentences for in-clusion in the final summary. The basic algorithm used in FXPAL's PALSUMM text summarization system combines text structure methods that preserve readability and correct reference resolution with statistical methods to reduce overall summary length while promoting the inclusion of important material."
    },
    {
        "Projects": [],
        "keywords": [
            "NL",
            "discourse",
            "summarization",
            "syntax",
            "discourse analysis",
            "Natural Language Processing",
            "LDM",
            "Linguistic Discourse Model"
        ],
        "AcceptDate": "05/20/2004",
        "palwebID": "PR-04-285",
        "Venue": "Proceedings of the ACL2004 Workshop on Discourse Annotation,\r\nBarcelona, Spain, July 25-26, 2004.\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-285/FXPAL-PR-04-285.doc",
            "http://palweb/files/PR/2004/PR-04-285/FXPAL-PR-04-285.pdf"
        ],
        "PublicationDate": "07/25/2004",
        "ID": "285",
        "Authors": [
            "Livia Polanyi",
            "Christopher Culy",
            "Martin van den Berg",
            "Gian Lorenzo Thione",
            "David Ahn"
        ],
        "Title": "Sentential Structure and Discourse Parsing",
        "Abstract": "In this paper, we describe how the LIDAS System (Linguistic Discourse Analysis System), a discourse parser built as an implementation of the Unified Linguistic Discourse Model (U-LDM) uses information from sentential syntax and semantics along with lexical semantic information to build the Open Right Discourse Parse Tree (DPT) that serves as a representation of the structure of the discourse (Polanyi et al., 2004; Thione 2004a,b). More specifically, we discuss how discourse segmentation, sentence-level discourse parsing, and text-level discourse parsing depend on the relationship between sentential syntax and discourse. Specific discourse rules that use syntactic information are used to identify possible attachment points and attachment relations for each Basic Discourse Unit to the DPT. "
    },
    {
        "Projects": [],
        "keywords": [
            "NL",
            "discourse",
            "summarization",
            "discourse analysis",
            "Natural Language Processing",
            "LDM",
            "Linguistic Discourse Model"
        ],
        "AcceptDate": "05/20/2004",
        "palwebID": "PR-04-286",
        "Venue": "Proceedings of the ACL2004 Workshop on Discourse Annotation, Barcelona, Spain, July 25-26, 2004. ",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-286/FXPAL-PR-04-286.doc",
            "http://palweb/files/PR/2004/PR-04-286/FXPAL-PR-04-286.pdf"
        ],
        "PublicationDate": "07/25/2004",
        "ID": "286",
        "Authors": [
            "Gian Lorenzo Thione",
            "Martin van den Berg",
            "Christopher Culy",
            "Livia Polanyi"
        ],
        "Title": "LiveTree: An Integrated Workbench for Discourse Processing",
        "Abstract": "In this paper, we introduce LiveTree, a core component of LIDAS, the Linguistic Discourse Analysis System for automatic discourse parsing with the Unified Linguistic Discourse Model. LiveTree is an integrated workbench for supervised and unsupervised creation, storage and manipulation of the discourse structure of text documents under the U-LDM. The LiveTree environment provides tools for manual and automatic U-LDM segmentation and discourse parsing. Document management, grammar testing, manipulation of discourse structures and creation and editing of discourse relations are also supported."
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "media",
            "rmo",
            "photo",
            "face recognition"
        ],
        "AcceptDate": "",
        "palwebID": "PR-04-287",
        "Venue": "UIST 2004 Companion, pp. 37-38\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-287/FXPAL-PR-04-287.pdf"
        ],
        "PublicationDate": "10/24/2004",
        "ID": "287",
        "Authors": [
            "Andreas Girgensohn",
            "John Adcock",
            "Lynn Wilcox"
        ],
        "Title": "Organizing Photos of People",
        "Abstract": "As the size of the typical personal digital photo collection reaches well into the thousands or photos, advanced tools to manage these large collections are more and more necessary. In this demonstration, we present a semi-automatic approach that opportunistically takes advantage of the current state-of-the-art technology in face detection and recognition and combines it with user interface techniques to facilitate the task of labeling people in photos. We show how we use an accurate face detector to automatically extract faces from photos. Instead of having a less accurate face recognizer classify faces, we use it to sort faces by their similarity to a face model. We demonstrate our photo application that uses the extracted faces as UI proxies for actions on the underlying photos along with the sorting strategy to identify candidate faces for quick and easy face labeling."
    },
    {
        "Projects": [
            "DigitalPhotographManagement",
            "StainedGlassCollage"
        ],
        "keywords": [
            "media",
            "rmo",
            "stainedglass",
            "photo",
            "stained glass visualization",
            "face recognition"
        ],
        "AcceptDate": "",
        "palwebID": "PR-04-288",
        "Venue": "UIST 2004 Companion, pp. 13-14",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-288/FXPAL-PR-04-288.pdf"
        ],
        "PublicationDate": "10/24/2004",
        "ID": "288",
        "Authors": [
            "Andreas Girgensohn",
            "Patrick Chiu"
        ],
        "Title": "Stained Glass Photo Collages",
        "Abstract": "We developed a novel technique for creating visually pleasing collages from photo regions. The technique is called \"stained glass\" because the resulting collage with irregular shapes is reminiscent of a stained glass window. The collages reuse photos in novel ways to present photos with faces that can be printed, included in Web pages, or shared via email. The poster describes the requirements for creating stained glass visualizations from photos of faces, our approach for creating face stained glass, and techniques used to improve the aesthetics and flexibility of the stained glass generation. Early user feedback with face stained glass have been very positive. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-97-291",
        "Venue": "Computer Networks and ISDN Systems, 29(8-13), pp. 1531-1542",
        "palwebURL": [
            "http://palweb/files/PR/1997/PR-97-291/FXPAL-PR-97-291.pdf"
        ],
        "PublicationDate": "09/30/1997",
        "ID": "291",
        "Authors": [
            "Andreas Girgensohn",
            "Alison Lee"
        ],
        "Title": "Seamless Integration of Interactive Forms into the Web",
        "Abstract": "The phenomenal interest and growth of the World Wide Web as an application server has pushed the Web model to its limits. Specifically, the Web offers limited interactivity and versatility as a platform for networked applications. One major challenge for the HCI community is to determine how to improve the human-computer interface for Web-based applications. This paper focuses on a significant Web deficiency - supporting truly interactive and dynamic form-based input. We propose a well-worked form interaction abstraction that alleviates this Web deficiency. We describe how the abstraction is seamlessly integrated into the Web framework by leveraging on the virtues of the Web and fitting within the interaction and usage model of the Web."
    },
    {
        "Projects": [
            "iLight"
        ],
        "keywords": [
            "iLight",
            "immersive"
        ],
        "AcceptDate": "",
        "palwebID": "PR-04-293",
        "Venue": "Proc. ACM Multimedia 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-293/FXPAL-PR-04-293.pdf"
        ],
        "PublicationDate": "10/12/2004",
        "ID": "293",
        "Authors": [
            "Jonathan Foote",
            "Don Kimber",
            "Kazutaka Hirata"
        ],
        "Title": "Remote Interactive Graffiti",
        "Abstract": "We present an installation that allows distributed internet\r\nparticipants to \"draw\" on a public scene using light. The\r\niLight system is a camera/projector system designed for remote collaboration. Using a familiar digital drawing interface, remote users \"draw\" on a live video image of a real-life object or scene. Graphics drawn by the user are then projected onto the scene, where they are visible in the camera image. Because camera distortions are corrected and the video is aligned with the image canvas, drawn graphics appear exactly where desired. Thus the remote users may\r\nharmlessly mark a physical object to serve their own their\r\nartistic and/or expressive needs. We also describe how local\r\nparticipants may interact with remote users through the\r\nprojected images. Besides the intrinsic \"neat factor\" of action at a distance, this installation serves as an experiment in how multiple users from different locales and cultures can create a social space that interacts with a physical one, as well as raising issues of free expression in a non-destructive context."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-04-294",
        "Venue": "OZCHI 2004, November 22-24, Wollongong, Australia",
        "palwebURL": [],
        "PublicationDate": "11/22/2004",
        "ID": "294",
        "Authors": [
            "Eriko Tamaru",
            "Kei Tanaka",
            "K Hasuike",
            "Gene Golovchinsky",
            "Takeshi Nagamine"
        ],
        "Title": "Reading Marks: An Exploration of Online Reading and\r\nAnnotation\r\n",
        "Abstract": ""
    },
    {
        "Projects": [
            "PALBar",
            "VideoGuestbook"
        ],
        "keywords": [
            "mic",
            "palbar",
            "guestbook"
        ],
        "AcceptDate": "11/03/2004",
        "palwebID": "PR-05-296",
        "Venue": "International Conference on Intelligent User Interfaces (IUI 2005)",
        "palwebURL": [],
        "PublicationDate": "01/09/2005",
        "ID": "296",
        "Authors": [
            "Daniel Billsus",
            "David Hilbert",
            "Dan Maynes-Aminzade"
        ],
        "Title": "Improving Proactive Information Systems",
        "Abstract": "Proactive contextual information systems help people locate information by automatically suggesting potentially relevant resources based on their current tasks or interests. Such systems are becoming increasingly popular, but designing user interfaces that effectively communicate recommended information is a challenge: the interface must be unobtrusive, yet communicate enough information at the right time to provide value to the user. In this paper we describe our experience with the FXPAL Bar, a proactive information system designed to provide contextual access to corporate and personal resources. In particular, we present three features designed to communicate proactive recommendations more effectively: translucent recommendation windows increase the user's awareness of particularly highly-ranked recommendations, query term highlighting communicates the relationship between a recommended document and the user's current context, and a novel recommendation digest function allows users to return to the most relevant previously recommended resources. We present empirical evidence supporting our design decisions and relate lessons learned for other designers of contextual recommendation systems."
    },
    {
        "Projects": [
            "ePic",
            "FlySPEC",
            "iLight",
            "NoteLook"
        ],
        "keywords": [
            "iLight",
            "notelook",
            "imcon",
            "epic",
            "spec"
        ],
        "AcceptDate": "06/01/2004",
        "palwebID": "PR-04-299",
        "Venue": "Springer Lecture Notes in Computer Science - Advances in Multimedia Information Processing,  Proc. PCM 2004  5th Pacific Rim Conference on Multimedia, Tokyo, Japan\r\nAizawa, K., Nakamura, Y., Satoh, S. (Eds.), Vol. 3333, 2005, ISBN 3-540-23985-5, pp 73--80",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-299/FXPAL-PR-04-299.pdf"
        ],
        "PublicationDate": "12/01/2004",
        "ID": "299",
        "Authors": [
            "Jonathan Foote",
            "Qiong Liu",
            "Don Kimber",
            "Patrick Chiu",
            "Frank Zhao"
        ],
        "Title": "Reach-Through-the-Screen: A New Metaphor for Remote Collaboration",
        "Abstract": "For some years, our group at FX Palo Alto Laboratory has\r\nbeen developing technologies to support meeting recording, collaboration,\r\nand videoconferencing. This paper presents several systems that\r\nuse video as an active interface, allowing remote devices and information\r\nto be accessed \"through the screen.\" For example, SPEC enables collaborative\r\nand automatic camera control through an active video window.\r\nThe NoteLook system allows a user to grab an image from a computer\r\ndisplay, annotate it with digital ink, then drag it to that or a different\r\ndisplay. The ePIC system facilitates natural control of multi-display and\r\nmulti-device presentation spaces, while the iLight system allows remote\r\nusers to \"draw\" with light on a local object. All our systems serve as\r\nplatforms for researching more sophisticated algorithms to support additional\r\nfunctionality and ease of use."
    },
    {
        "Projects": [
            "ePic"
        ],
        "keywords": [
            "immersive conferencing",
            "immersive"
        ],
        "AcceptDate": "07/07/2004",
        "palwebID": "PR-04-303",
        "Venue": "Proc. of ACM Multimedia 2004, October 10, 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-303/FXPAL-PR-04-303.pdf"
        ],
        "PublicationDate": "10/10/2004",
        "ID": "303",
        "Authors": [
            "Frank Zhao",
            "Qiong Liu"
        ],
        "Title": "A Web Based Multi-display Presentation System",
        "Abstract": "In this demonstration, we are going to illustrate how to give a presentation using multiple displays connected to the Internet."
    },
    {
        "Projects": [
            "ePic"
        ],
        "keywords": [
            "Immersive Conferencing",
            "immersive"
        ],
        "AcceptDate": "07/02/2004",
        "palwebID": "PR-04-304",
        "Venue": "Proc. of ACM Multimedia 2004, October 10, 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-304/FXPAL-PR-04-304.pdf"
        ],
        "PublicationDate": "10/10/2004",
        "ID": "304",
        "Authors": [
            "Qiong Liu",
            "Frank Zhao",
            "John Doherty",
            "Don Kimber"
        ],
        "Title": "An EPIC Enhanced Meeting Environment",
        "Abstract": "ePic is an integrated presentation authoring and playback system that makes it easy to use a wide range of devices installed in one or multiple multimedia venues."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "mediamagic",
            "video",
            "media"
        ],
        "AcceptDate": "01/30/2005",
        "palwebID": "PR-05-306",
        "Venue": "CHI 2005 Extended Abstracts, ACM Press, pp. 1395-1398",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-306/FXPAL-PR-05-306.pdf"
        ],
        "PublicationDate": "04/02/2005",
        "ID": "306",
        "Authors": [
            "Andreas Girgensohn",
            "John Adcock",
            "Matthew Cooper",
            "Lynn Wilcox"
        ],
        "Title": "Interactive Search in Large Video Collections",
        "Abstract": "We present a search interface for large video collections with time-aligned text transcripts. The system is designed for users such as intelligence analysts that need to quickly find video clips relevant to a topic expressed in text and images. A key component of the system is a powerful and flexible user interface that incorporates dynamic visualizations of the underlying multimedia objects. The interface displays search results in ranked sets of story keyframe collages, and lets users explore the shots in a story. By adapting the keyframe collages based on query relevance and indicating which portions of the video have already been explored, we enable users to quickly find relevant sections. We tested our system as part of the NIST TRECVID interactive search evaluation, and found that our user interface enabled users to find more relevant results within the allotted time than those of many systems employing more sophisticated analysis techniques."
    },
    {
        "Projects": [],
        "keywords": [
            "NL",
            "discourse",
            "attitute"
        ],
        "AcceptDate": "12/06/1995",
        "palwebID": "PR-04-308",
        "Venue": "in: Yan Qu, James Shanahan, and Janyce Wiebe, Cochairs. 2004. Exploring Attitude and Affect in Text: Theories and Applications. Technical Report SS-04-07, AAAI Press, ISBN 1-57735-219-x\r\n\r\n",
        "palwebURL": [],
        "PublicationDate": "12/06/2004",
        "ID": "308",
        "Authors": [
            "Livia Polanyi",
            "Annie Zaenen"
        ],
        "Title": "Contextual Lexical Valence Shifters",
        "Abstract": ""
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "TRECVID",
            "video segmentation",
            "video search and retrieval",
            "trecvid"
        ],
        "AcceptDate": "10/31/2004",
        "palwebID": "PR-05-313",
        "Venue": "Proceedings of TRECVID 2004",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-313/FXPAL-PR-05-313.pdf"
        ],
        "PublicationDate": "03/01/2005",
        "ID": "313",
        "Authors": [
            "John Adcock",
            "Andreas Girgensohn",
            "Matthew Cooper",
            "Ting Liu",
            "Eleanor Rieffel",
            "Lynn Wilcox"
        ],
        "Title": "FXPAL Experiments for TRECVID 2004",
        "Abstract": "Presentation of FXPAL experiments in the 2004 TREC Video Retrieval Evaluations (TRECVID 2004). FXPAL participated in the shot boundary determination task, and the interactive search task."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "similarity",
            "video segmentation",
            "videosegmentation"
        ],
        "AcceptDate": "",
        "palwebID": "PR-04-314",
        "Venue": "ACM Multimedia 2004",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-314/FXPAL-PR-04-314.pdf"
        ],
        "PublicationDate": "10/28/2004",
        "ID": "314",
        "Authors": [
            "Matthew Cooper"
        ],
        "Title": "Video Segmentation Combining Similarity Analysis and Classification",
        "Abstract": "In this paper, we compare several recent approaches to video segmentation using pairwise similarity.  We first review and contrast the approaches within the common framework of\r\nsimilarity analysis and kernel correlation. We then combine these approaches with non-parametric supervised classification for shot boundary detection.  Finally, we discuss comparative experimental results using the 2002 TRECVID shot boundary detection test collection."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-05-315",
        "Venue": "Presentation given to visitor's from Fujitsu, who asked for a copy of the slides.",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-315/FXPAL-PR-05-315.ppt"
        ],
        "PublicationDate": "04/05/2005",
        "ID": "315",
        "Authors": [
            "Candy Kamm"
        ],
        "Title": "Research at FX Palo Alto Laboratory",
        "Abstract": ""
    },
    {
        "Projects": [
            "DigitalPhotographManagement"
        ],
        "keywords": [
            "digital photograph management",
            "similarity analysis",
            "rmo",
            "similarity"
        ],
        "AcceptDate": "03/31/2005",
        "palwebID": "PR-05-316",
        "Venue": "ACM Transactions on Multimedia Computing, Communications, and Applications",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-316/FXPAL-PR-05-316.pdf"
        ],
        "PublicationDate": "08/08/2005",
        "ID": "316",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Temporal Event Clustering for Digital Photo Collections",
        "Abstract": "Organizing digital photograph collections according to events such as holiday gatherings or vacations is a common practice among photographers. To support photographers in this task, we present similarity-based methods to cluster digital photos by time and image content.  The approach is general, unsupervised, and makes minimal assumptions regarding the structure or statistics of the photo collection.  We present several variants of an automatic unsupervised algorithm to partition a collection of digital photographs based either on temporal similarity alone, or on temporal and content-based similarity. First, inter-photo similarity is quantified at multiple temporal scales to identify likely event clusters. Second, the final clusters are determined according to one of three clustering goodness criteria.  The clustering criteria trade off computational complexity and performance. We also describe a supervised clustering method based on learning vector quantization. Finally, we review the results of an experimental evaluation of the proposed algorithms and existing approaches on two test collections."
    },
    {
        "Projects": [],
        "keywords": [
            "3D Syllabus",
            "education applications",
            "multimedia",
            "visualization"
        ],
        "AcceptDate": "05/12/2005",
        "palwebID": "PR-05-319",
        "Venue": "INTERACT '05 short paper.",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-319/FXPAL-PR-05-319.pdf"
        ],
        "PublicationDate": "09/12/2005",
        "ID": "319",
        "Authors": [
            "Kyuman Song",
            "Surapong Lertsithichai",
            "Patrick Chiu"
        ],
        "Title": "Interactive visualization of indexes to multimedia training content",
        "Abstract": "Indexes such as bookmarks and recommendations are helpful for accessing multimedia documents. This paper describes the 3D Syllabus system, which is designed to visualize indexes to multimedia training content along with the information structures. A double-sided landscape with balloons and cubes represents the personal and group indexes, respectively. The 2D ground plane organizes the indexes as a table and the third dimension of height indicates their importance scores. Additional visual properties of the balloons and cubes provide other information about the indexes and their content. Paths are\r\nrepresented by pipes connecting the balloons. A reliminary evaluation of the 3D Syllabus prototype suggests that it is more efficient than a typical training CD-ROM and is more enjoyable to use."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "video",
            "media",
            "trecvid",
            "video search",
            "video segmentation",
            "mediamagic"
        ],
        "AcceptDate": "04/04/2005",
        "palwebID": "PR-05-320",
        "Venue": "International Conference on Image and Video Retrieval 2005",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-320/FXPAL-PR-05-320.pdf",
            "http://palweb/files/PR/2005/PR-05-320/FXPAL-PR-05-320.ppt"
        ],
        "PublicationDate": "07/21/2005",
        "ID": "320",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Interactive Video Search Using Multilevel Indexing",
        "Abstract": "Large video collections present a unique set of challenges\r\nto the search system designer. Text transcripts do not always provide an accurate index to the visual content, and the performance of visually based semantic extraction techniques is often inadequate for search tasks. The searcher must be relied upon to provide detailed judgment of the relevance of specific video segments. We describe a video search system that facilitates this user task by efficiently presenting search results in semantically meaningful units to simplify exploration of query results\r\nand query reformulation. We employ a story segmentation system and\r\nsupporting user interface elements to effectively present query results at\r\nthe story level. The system was tested in the 2004 TRECVID interactive\r\nsearch evaluations with very positive results."
    },
    {
        "Projects": [
            "ProjectorBox"
        ],
        "keywords": [
            "mic",
            "pbox"
        ],
        "AcceptDate": "06/27/2005",
        "palwebID": "PR-05-321",
        "Venue": "World Conference on E-Learning in Corporate, Government, Healthcare, & Higher Education (E-Learn 2005)",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-321/FXPAL-PR-05-321.pdf"
        ],
        "PublicationDate": "10/24/2005",
        "ID": "321",
        "Authors": [
            "Laurent Denoue",
            "David Hilbert",
            "John Adcock",
            "Daniel Billsus",
            "Matthew Cooper"
        ],
        "Title": "ProjectorBox: Seamless presentation capture for classrooms",
        "Abstract": "Automatic lecture capture can help students, instructors, and educational institutions. Students can focus less on note-taking and more on what the instructor is saying. Instructors can provide access to lecture archives to help students study for exams and make-up missed classes. And online lecture recordings can be used to support distance learning. For these and other reasons, there has been great interest in automatically capturing classroom presentations. However, there is no simple solution that is completely automatic. ProjectorBox is our attempt to create a \"zero user interaction\" appliance that automatically captures, indexes, and manages presentation multimedia. It operates continuously to record the RGB information sent from presentation devices, such as an instructor's laptop, to display devices such as a projector. It seamlessly captures high-resolution slide images, text, and audio. A web-based user interface allows students to browse, search, replay, and export captured presentations."
    },
    {
        "Projects": [
            "HitchCock"
        ],
        "keywords": [
            "media",
            "hitchcock"
        ],
        "AcceptDate": "06/01/2005",
        "palwebID": "PR-05-322",
        "Venue": "Sixteenth ACM Conference on Hypertext and Hypermedia",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-322/FXPAL-PR-05-322.pdf"
        ],
        "PublicationDate": "09/06/2005",
        "ID": "322",
        "Authors": [
            "Frank Shipman",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Hypervideo Expression: Experiences with Hyper-Hitchcock",
        "Abstract": "Hyper-Hitchcock is a hypervideo editor enabling the direct manipulation authoring of a particular form of hypervideo called \"detail-on-demand video.\" This form of hypervideo allows a single link out of the currently playing video to provide more details on the content currently being presented. The editor includes a workspace to select, group, and arrange video clips into several linear sequences. Navigational links placed between the video elements are assigned labels and return behaviors appropriate to the goals of the hypervideo and the role of the destination video. Hyper-Hitchcock was used by students in a Computers and New Media class to author hypervideos on a variety of topics. The produced hypervideos provide examples of hypervideo structures and the link properties and behaviors needed to support them. Feedback from students identified additional link behaviors and features required to support new hypervideo genres. This feedback is valuable for the redesign of Hyper-Hitchcock and the design of hypervideo editors in general."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "media",
            "trecvid"
        ],
        "AcceptDate": "03/15/2005",
        "palwebID": "PR-05-323",
        "Venue": "INTERACT 2005, LNCS 3585, pp. 781-794",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-323/FXPAL-PR-05-323.pdf"
        ],
        "PublicationDate": "09/12/2005",
        "ID": "323",
        "Authors": [
            "Andreas Girgensohn",
            "John Adcock",
            "Matthew Cooper",
            "Lynn Wilcox"
        ],
        "Title": "A Synergistic Approach to Efficient Interactive Video Retrieval",
        "Abstract": "A video database can contain a large number of videos ranging from several minutes to several hours in length. Typically, it is not sufficient to search just for relevant videos, because the task still remains to find the relevant clip, typically less than one minute of length, within the video. This makes it important to direct the users attention to the most promising material and to indicate what material they already investigated. Based on this premise, we created a video search system with a powerful and flexible user interface that incorporates dynamic visualizations of the underlying multimedia objects. The system employes an automatic story segmentation, combines text and visual search, and displays search results in ranked sets of story keyframe collages. By adapting the keyframe collages based on query relevance and indicating which portions of the video have already been explored, we enable users to quickly find relevant sections. We tested our system as part of the NIST TRECVID interactive search evaluation, and found that our user interface enabled users to find more relevant results within the allotted time than other systems employing more sophisticated analysis techniques but less helpful user interfaces."
    },
    {
        "Projects": [
            "VideoKeyframes"
        ],
        "keywords": [
            "keyframe selection",
            "media analysis"
        ],
        "AcceptDate": "04/15/2005",
        "palwebID": "PR-05-324",
        "Venue": "2005 IEEE International Conference on Multimedia & Expo",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-324/FXPAL-PR-05-324.pdf"
        ],
        "PublicationDate": "07/06/2005",
        "ID": "324",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote"
        ],
        "Title": "Discriminative Techniques for Keyframe Selection",
        "Abstract": "A convenient representation of a video segment is a single keyframe.  Keyframes are widely used in applications such as non-linear browsing and video editing. With existing methods of keyframe selection, similar video segments result in very similar keyframes, with the drawback that  actual differences between the segments may be obscured. We present methods for keyframe selection based on two criteria: capturing the similarity to the represented segment, and\r\npreserving the differences from other segment keyframes, so that different segments will have visually distinct representations. We present two discriminative keyframe\r\nselection methods, and an example of experimental results."
    },
    {
        "Projects": [],
        "keywords": [
            "digital photo"
        ],
        "AcceptDate": "07/01/2005",
        "palwebID": "PR-05-325",
        "Venue": "ERCIM News No. 62 July 2005",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-325/FXPAL-PR-05-325.doc"
        ],
        "PublicationDate": "07/15/2005",
        "ID": "325",
        "Authors": [
            "Lynn Wilcox"
        ],
        "Title": "Managing Digital Photo Collections",
        "Abstract": "The FXPAL photo application automatically organizes digital photo collections based on date, event, person, or place. "
    },
    {
        "Projects": [],
        "keywords": [
            "WST",
            "web services",
            "documents",
            "mobile computing",
            "printing"
        ],
        "AcceptDate": "07/15/2005",
        "palwebID": "PR-05-327",
        "Venue": "IEEE International Conference on Next Generation Web Services Practices (NWeSP'05), Seoul, Korea",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-327/FXPAL-PR-05-327.pdf"
        ],
        "PublicationDate": "08/22/2005",
        "ID": "327",
        "Authors": [
            "Gene Golovchinsky",
            "Jonathan Trevor"
        ],
        "Title": "DoKumobility: Web services for the mobile worker",
        "Abstract": "Mobile users often require access to their documents while away from the office. While pre-loading documents in a repository can make those documents available remotely, people need to know in advance which documents they might need. Furthermore, it may be difficult to view, print, or share the document through a portable device such as cell phone. We implemented DoKumobility, a network of web services for mobile users for managing, printing, and sharing documents. In this paper, we describe the infrastructure and illustrate its use with several applications"
    },
    {
        "Projects": [],
        "keywords": [
            "Software Engineering",
            "CVS",
            "SCCS",
            "Deltas",
            "Parallel Changes",
            "Semantic Interference"
        ],
        "AcceptDate": "05/15/2005",
        "palwebID": "PR-05-328",
        "Venue": "The 29th Annual International Computer Software and Applications Conference (COMPSAC 2005), Edinburgh, Scotland",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-328/FXPAL-PR-05-328.pdf"
        ],
        "PublicationDate": "07/26/2005",
        "ID": "328",
        "Authors": [
            "Gian Lorenzo Thione",
            "Dewayne Perry"
        ],
        "Title": "Parallel Changes: Detecting Semantic Interferences",
        "Abstract": "Parallel changes are a basic fact of modern software\r\ndevelopment. Where previously we looked at prima facie\r\ninterference, here we investigate a less direct form that we\r\ncall semantic interference.\r\nWe reduce the forms of semantic interference that we\r\nare interested in to overlapping def-use pairs. Using\r\nprogram slicing and data flow analysis, we present\r\nalgorithms for detecting semantic interference for both\r\nconcurrent changes (allowed in optimistic version\r\nmanagement systems) and sequential parallel changes\r\n(supported in pessimistic version management systems),\r\nand for changes that are both immediate and distant in\r\ntime. We provide these algorithms for changes that are\r\nadditions, showing that interference caused by deletions\r\ncan be detected by considering the two sets of changes in\r\nreverse-time order."
    },
    {
        "Projects": [
            "EyeTracking"
        ],
        "keywords": [
            "Conversation",
            "Collaboration",
            "Eye tracking",
            "Eye-gaze patterns"
        ],
        "AcceptDate": "",
        "palwebID": "PR-05-330",
        "Venue": "M.F. Costabile and F. Patern\u00c3\u00b2 (Eds.): INTERACT 2005, LNCS 3585",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-330/FXPAL-PR-05-330.pdf"
        ],
        "PublicationDate": "09/12/2005",
        "ID": "330",
        "Authors": [
            "Pernilla Qvarfordt",
            "David Beymer",
            "Shumin Zhai"
        ],
        "Title": "RealTourist - A Study of Augmenting Human-Human\r\nand Human-Computer Dialogue with Eye-Gaze Overlay",
        "Abstract": "We developed and studied an experimental system, RealTourist, which lets a user to plan a conference trip with the help of a remote tourist consultant who could view the tourist's eye-gaze superimposed onto a shared\r\nmap. Data collected from the experiment were analyzed in conjunction with literature review on speech and eye-gaze patterns. This inspective, exploratory research identified various functions of gaze-overlay on shared spatial material including: accurate and direct display of partner's eye-gaze, implicit deictic referencing, interest detection, common focus and topic switching, increased\r\nredundancy and ambiguity reduction, and an increase of assurance, confidence, and understanding. This study serves two purposes. The first is to identify patterns that can serve as a basis for designing multimodal human-computer dialogue systems with eye-gaze locus as a contributing channel. The second is to investigate how computer-mediated communication can be supported by the\r\ndisplay of the partner's eye-gaze."
    },
    {
        "Projects": [
            "ProjectorBox"
        ],
        "keywords": [
            "mic",
            "pbox"
        ],
        "AcceptDate": "06/16/2005",
        "palwebID": "PR-05-331",
        "Venue": "Internet Multimedia Management Systems VI (SPIE Optics East 2005)\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-331/FXPAL-PR-05-331.pdf"
        ],
        "PublicationDate": "10/26/2005",
        "ID": "331",
        "Authors": [
            "David Hilbert",
            "Matthew Cooper",
            "Laurent Denoue",
            "John Adcock",
            "Daniel Billsus"
        ],
        "Title": "Seamless presentation capture, indexing, and management",
        "Abstract": "Technology abounds for capturing presentations.  However, no simple solution exists that is completely automatic. ProjectorBox is a \"zero user interaction\" appliance that automatically captures, indexes, and manages presentation multimedia. It operates continuously to record the RGB information sent from presentation devices, such as a presenter's laptop, to display devices, such as a projector. It seamlessly captures high-resolution slide images, text and audio. It requires no operator, specialized software, or changes to current presentation practice. Automatic media analysis is used to detect presentation content and segment presentations.  The analysis substantially enhances the web-based user interface for browsing, searching, and exporting captured presentations. ProjectorBox has been in use for over a year in our corporate conference room, and has been deployed in two universities. Our goal is to develop automatic capture services that address both corporate and educational needs."
    },
    {
        "Projects": [],
        "keywords": [
            "media"
        ],
        "AcceptDate": "04/07/2005",
        "palwebID": "PR-05-332",
        "Venue": "Media Impact Column, Ed. Frank Nack, IEEE Multimedia Vol 12 No. 3. pp 4--7, July 2005 ",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-332/FXPAL-PR-05-332.pdf"
        ],
        "PublicationDate": "08/15/2005",
        "ID": "332",
        "Authors": [
            "Jonathan Foote"
        ],
        "Title": "Kooks, Obsessives, Sturgeon's Law, and the Real Meaning of Search",
        "Abstract": "(no abstract)"
    },
    {
        "Projects": [],
        "keywords": [
            "MediaMetro",
            "multimedia applications",
            "3D user interfaces",
            "city metaphor",
            "visualization",
            "navigation",
            "video",
            "multimedia document."
        ],
        "AcceptDate": "08/20/2005",
        "palwebID": "PR-05-334",
        "Venue": "ACM Multimedia 2005, Technical Demonstrations.",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-334/FXPAL-PR-05-334.pdf"
        ],
        "PublicationDate": "11/06/2005",
        "ID": "334",
        "Authors": [
            "Patrick Chiu",
            "Andreas Girgensohn",
            "Surapong Lertsithichai",
            "Wolfgang Polak",
            "Frank Shipman"
        ],
        "Title": "MediaMetro: Browsing Multimedia Document Collections with a 3D City Metaphor",
        "Abstract": "The MediaMetro application provides an interactive 3D\r\nvisualization of multimedia document collections using a city metaphor. The directories are mapped to city layouts using algorithms similar to treemaps. Each multimedia document is represented by a building and visual summaries of the different constituent media types are rendered onto the sides of the building. From videos, Manga storyboards with keyframe images are created and shown on the fa\u00c3\u00a7ade; from slides and text, thumbnail images are produced and subsampled for display on the building sides. The images resemble windows on a building and can be selected for media playback. To support more facile navigation between high overviews and low detail views, a novel swooping technique was developed that combines altitude and tilt\r\nchanges with zeroing in on a target."
    },
    {
        "Projects": [],
        "keywords": [
            "Overlay Networks",
            "Collaboration",
            "Distributed Hash Table"
        ],
        "AcceptDate": "09/06/2005",
        "palwebID": "PR-05-337",
        "Venue": "IEEE CollaborateCom 2005 - The First IEEE International Conference on Collaborative Computing: Networking, Applications and Worksharing",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-337/FXPAL-PR-05-337.pdf"
        ],
        "PublicationDate": "12/19/2005",
        "ID": "337",
        "Authors": [
            "Cheng-Jia Lai",
            "Richard Muntz"
        ],
        "Title": "On-Demand Overlay Networking of Collaborative Applications",
        "Abstract": "We propose a new overlay network, called Generic Identifier Network (GIN), for collaborative nodes to share objects with transactions across affiliated organizations by merging the organizational local namespaces upon mutual agreement. Using local namespaces instead of a global namespace can avoid excessive dissemination of organizational information, reduce maintenance costs, and improve robustness against external security attacks. GIN can forward a query with an O(1) latency stretch with high probability and achieve high performance. In the absence of a complete distance map, its heuristic algorithms for self configuration are scalable and efficient. Routing tables are maintained using soft-state mechanisms for fault tolerance and adapting to performance updates of network distances. Thus, GIN has significant new advantages for building an efficient and scalable Distributed Hash Table for modern collaborative applications across organizations."
    },
    {
        "Projects": [
            "DICE",
            "USE"
        ],
        "keywords": [
            "USE",
            "DICE",
            "conference rooms",
            "immersive conferencing",
            "rich media",
            "mobile devices",
            "smart spaces",
            "collaboration",
            "collaborative device control",
            "multiple displays",
            "multimedia",
            "CSCW",
            "HCI",
            "design"
        ],
        "AcceptDate": "",
        "palwebID": "PR-05-338",
        "Venue": "We organized and ran a full-day workshop at the UbiComp 2005 Conference in Tokyo, Japan, September 11, 2005.  ",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-338/FXPAL-PR-05-338.pdf"
        ],
        "PublicationDate": "09/29/2005",
        "ID": "338",
        "Authors": [
            "Maribeth Back",
            "Patrick Chiu",
            "Jeffrey Huang",
            "Kazunori Horikiri",
            "Jun Miyazaki",
            "Mark Newman"
        ],
        "Title": "Ubiquitous computing in next generation conference rooms: interweaving rich media, mobile devices, and smart environments\r\n",
        "Abstract": "Designing the technologies, applications, and physical spaces for next-generation conference rooms \r\n\r\n(This is a day-long workshop in Tokyo.)\r\n\r\nNext-generation conference rooms are often designed to anticipate the onslaught of new rich media presentation and ideation systems. Throughout the past couple of decades, many researchers have attempted to reinvent the conference room, aiming at shared online or visual/virtual spaces, smart tables or walls, media support and tele-conferencing systems of varying complexity. \r\n\r\n \r\n\r\nCurrent research in high-end room systems often features a multiplicity of thin, bright display screens (both large and small), along with interactive whiteboards, robotic cameras, and smart remote conferencing systems. Added into the mix one can find a variety of meeting capture and metadata management systems, automatic or not, focused on capturing different aspects of meetings in different media: to the Web, to one's PDA or phone, or to a company database. Smart spaces and interactive furniture design projects have shown systems embedded in tables, podiums, walls, chairs and even floors and lighting. \r\n\r\n \r\n\r\nExploiting the capabilities of all these technologies in one room, however, is a daunting task. For example, faced with three or more display screens, all but a few presenters are likely to opt for simply replicating the same image on all of them. Even more daunting is the design challenge: how to choose which capabilities are vital to particular tasks, or for a particular room, or are well suited to a particular culture. \r\n\r\n \r\n\r\nIn this workshop we'll explore how the design of next-generation conference rooms can be informed by the most recent research in rich media, context-aware mobile systems, ubiquitous displays, and interactive physical environments. How should conference room systems reflect the rapidly changing expectations around personal devices and smart spaces? What kinds of systems are needed to support meetings in technologically complex environments? How can design of conference room spaces and technologies account for differing social and cultural practices around meetings? What requirements are imposed by security and privacy issues in public spaces? What aspects of meeting capture and access technologies have proven to be useful, and how should a smart environment enable them? What intersections exist with other research areas such as digital libraries? \r\n\r\n \r\n\r\nConference room research has been and remains a focal point for some of the most interesting and applied work in ubiquitous computing. What lessons can we take from the research to date as we move forward? We are confident that a lively and useful discussion will be engendered by bringing directions from recent ubicomp research in games, multimedia applications, and social software to ongoing research in conference rooms systems: integrating architecture and tangible media, information design and display, and mobile and computer-mediated communications.\r\n"
    },
    {
        "Projects": [
            "ConvertiblePodium",
            "USE"
        ],
        "keywords": [
            "Immersive conferencing",
            "interactive furniture",
            "HCI",
            "CSCW",
            "interaction techniques",
            "multiple displays",
            "teleconferencing",
            "tangible media",
            "physical computing."
        ],
        "AcceptDate": "07/15/2005",
        "palwebID": "PR-05-339",
        "Venue": "Short presentation in UbiComp 2005 workshop in Tokyo, Japan.\r\n\r\n",
        "palwebURL": [],
        "PublicationDate": "09/11/2005",
        "ID": "339",
        "Authors": [
            "Maribeth Back",
            "Surapong Lertsithichai",
            "Patrick Chiu",
            "Jonathan Foote",
            "John Boreczky",
            "Qiong Liu",
            "Don Kimber",
            "Frank Zhao"
        ],
        "Title": "The Convertible Podium: a rich media control station",
        "Abstract": "As the use of rich media in mobile devices and smart environments becomes more sophisticated, so must the design of the everyday objects used as containers or controllers. Rather than simply tacking electronics onto existing furniture or other objects, the design of a smart object can enhance existing ap-plications in unexpected ways.  The Convertible Podium is an experiment in the design of a smart object with complex integrated systems, combining the highly designed look and feel of a modern lectern with systems that allow it to serve as a central control station for rich media manipulation in next-generation confer-ence rooms.  It enables easy control of multiple independent screens, multiple media sources (including mobile devices) and multiple distribution channels. The Podium is designed to ease the tasks involved in authoring and presenting in a rich media meeting room, as well as supporting remote telepresence and in-tegration with mobile devices. "
    },
    {
        "Projects": [
            "ConvertiblePodium",
            "USE"
        ],
        "keywords": [
            "Tangible media",
            "rich media",
            "educational technology",
            "multimedia",
            "distance learning",
            "CSCW",
            "HCI",
            "educational games",
            "RFID",
            "interactive furniture."
        ],
        "AcceptDate": "",
        "palwebID": "PR-05-340",
        "Venue": "Paper presented at SIGGRAPH 2005, Los Angeles.",
        "palwebURL": [],
        "PublicationDate": "09/29/2005",
        "ID": "340",
        "Authors": [
            "Maribeth Back",
            "Surapong Lertsithichai",
            "Patrick Chiu",
            "John Boreczky",
            "Jonathan Foote",
            "Don Kimber",
            "Qiong Liu",
            "Frank Zhao",
            "Takashi Matsumoto"
        ],
        "Title": "The Convertible Podium:  \r\nA rich media teaching tool for next-generation classrooms\r\n",
        "Abstract": "The Convertible Podium is a central control station for rich media in next-generation classrooms.  It integrates flexible control systems for multimedia software and hardware, and is designed for use in classrooms with multiple screens, multiple media sources and multiple distribution channels.  The built-in custom electronics and unique convertible podium frame allows intuitive conversion between use modes (either manual or automatic). The at-a-touch sound and light control system gives control over the classroom environment. Presentations can be pre-authored for effective performance, and quickly altered on the fly. The counter-weighted and motorized conversion system allows one person to change modes simply by lifting the top of the Podium to the correct position for each mode.\r\n\r\nThe Podium is lightweight, mobile, and wireless, and features an onboard 21\" LCD display, document cameras and other capture devices, tangible controls for hardware and software, and also possesses embedded RFID sensing for automatic data retrieval and file management. It is designed to ease the tasks involved in authoring and presenting in a rich media classroom, as well as supporting remote telepresence and integration with other mobile devices.  \r\n"
    },
    {
        "Projects": [
            "Post-Bits"
        ],
        "keywords": [
            "Tangible media",
            "interactive video",
            "e-paper",
            "handheld devices",
            "CSCW",
            "HCI."
        ],
        "AcceptDate": "07/15/2005",
        "palwebID": "PR-05-341",
        "Venue": "Video track, ACM Multimedia 2005.",
        "palwebURL": [],
        "PublicationDate": "11/13/2005",
        "ID": "341",
        "Authors": [
            "Takashi Matsumoto",
            "Maribeth Back",
            "Tony Dunnigan"
        ],
        "Title": "<img src=\"/images/best.png\" title=\"Best Vision Video Award\" border=\"0\" />Post-Bit: Multimedia E-paper Stickies",
        "Abstract": "A Post-Bit is a prototype of a small ePaper device for handling multimedia content, combining interaction control and display into one package. Post-Bits are modeled after paper Post-Its\u00e2\u201e\u00a2; the functions of each Post-Bit combine the affordances of physical tiny sticky memos and digital handling of information.  Post-Bits enable us to arrange multimedia contents in our embodied physical spaces. Tangible properties of paper such as flipping, flexing, scattering and rubbing are mapped to controlling aspects of the content. In this paper, we introduce the integrated design and functionality of the Post-Bit system, including four main components:  the ePaper sticky memo/player, with integrated sensors and connectors; a small container/binder that a few Post-Bits can fit into, for ordering and multiple connections; the data and power port that allows communication with the host com-puter; and finally the software and GUI interface that reside on the host PC and manage multimedia transfer."
    },
    {
        "Projects": [
            "Post-Bits"
        ],
        "keywords": [
            "Tangible media",
            "handheld displays",
            "HCI",
            "CSCW",
            "e-paper",
            "interaction design",
            "mobile computing",
            "interactive video."
        ],
        "AcceptDate": "06/15/2005",
        "palwebID": "PR-05-342",
        "Venue": "Demo and presentation in UbiComp 2005 workshop in Tokyo, Japan.",
        "palwebURL": [],
        "PublicationDate": "09/11/2005",
        "ID": "342",
        "Authors": [
            "Takashi Matsumoto",
            "Maribeth Back"
        ],
        "Title": "Post-Bits: an e-paper sticky memo system",
        "Abstract": " A Post-Bit is a prototype of a small ePaper device for handling multimedia content, combining interaction control and display into one package. Post-Bits are modeled after paper Post-Its\u00e2\u201e\u00a2; the functions of each Post-Bit combine the affordances of physical tiny sticky memos and digital handling of information.  Post-Bits enable us to arrange multimedia contents in our embodied physical spaces. Tangible properties of paper such as flipping, flexing, scattering and rubbing are mapped to controlling aspects of the content. In this paper, we introduce the integrated design and functionality of the Post-Bit system, including four main components:  the ePaper sticky memo/player, with integrated sensors and connectors; a small container/binder that a few Post-Bits can fit into, for ordering and multiple connections; the data and power port that allows communication with the host com-puter; and finally the software and GUI interface that reside on the host PC and manage multimedia transfer."
    },
    {
        "Projects": [
            "FlyCam"
        ],
        "keywords": [
            "FlyCam"
        ],
        "AcceptDate": "",
        "palwebID": "PR-05-344",
        "Venue": "IEEE Trans. Multimedia, Vol. 7 No. 5, pp. 981-990",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-344/FXPAL-PR-05-344.pdf"
        ],
        "PublicationDate": "10/11/2005",
        "ID": "344",
        "Authors": [
            "Xinding Sun",
            "Jonathan Foote",
            "Don Kimber",
            "B. Manjunath"
        ],
        "Title": "Region of Interest Extraction and Virtual Camera Control Based on Panoramic Video Capturing ",
        "Abstract": "Abstract-We present a system for automatically extracting the region of interest and controlling virtual cameras control based on panoramic video. It targets applications such as classroom lectures and video conferencing. For capturing panoramic video, we use the FlyCam system that produces high resolution, wide-angle video by stitching video images from multiple stationary cameras. To generate conventional video, a region of interest (ROI) can be cropped from the panoramic video. We propose methods for ROI detection, tracking, and virtual camera control that work in both the uncompressed and compressed domains. The ROI is located from motion and color information in the uncompressed domain and macroblock information in the compressed domain, and tracked using a Kalman filter. This results in virtual camera control that simulates human controlled video recording. The system has no physical camera motion and the virtual camera parameters are readily available for video indexing."
    },
    {
        "Projects": [],
        "keywords": [
            "WST",
            "Document services",
            "printing",
            "service orchestration."
        ],
        "AcceptDate": "11/23/2005",
        "palwebID": "PR-06-353",
        "Venue": "International Journal of Web Services Practices",
        "palwebURL": [],
        "PublicationDate": "01/17/2006",
        "ID": "353",
        "Authors": [
            "Gene Golovchinsky",
            "Gerry Filby"
        ],
        "Title": "DoKumobility: A Document-based Service Architecture",
        "Abstract": "Mobile users often require access to their documents while away from the office. While pre-loading documents in a repository can make those documents available remotely, people need to know in advance which documents they might need. Furthermore, it may be difficult to view, print, or share the document through a portable device such as cell phone. We describe DoKumobility, a network of web services for mobile users for managing, printing, and sharing documents. In this paper, we describe the infrastructure and illustrate its use with several applications. We conclude with a discussion of lessons learned and future work."
    },
    {
        "Projects": [],
        "keywords": [
            "ubisight"
        ],
        "AcceptDate": "03/31/2005",
        "palwebID": "PR-05-354",
        "Venue": "IEEE International Conference on Multimedia & Expo\r\nJuly 6-8,  2005,  Amsterdam, The Netherlands",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-354/FXPAL-PR-05-354.pdf"
        ],
        "PublicationDate": "07/06/2005",
        "ID": "354",
        "Authors": [
            "Qiong Liu",
            "Xiaojin Shi",
            "Don Kimber",
            "Frank Zhao",
            "Frank Raab"
        ],
        "Title": "AN ONLINE VIDEO COMPOSITION SYSTEM",
        "Abstract": "This paper presents an information-driven online video composition system.  The composition work handled by the system includes dynamically setting multiple pan/tilt/zoom (PTZ) cameras to proper poses and selecting the best close-up view for passive viewers.  The main idea of the composition system is to maximize captured video information with limited cameras.  Unlike video composition based on heuristic rules, our video composition is formulated as a process of minimizing distortions between ideal signals (i.e. signals with infinite spatial-temporal resolution) and displayed signals.  The formulation is consistent with many well-known empirical approaches widely used in previous systems and may provide analytical explanations to those approaches.  Moreover, it provides a novel approach for studying video composition tasks systematically.  The composition system allows each user to select a personal close-up view.  It manages PTZ cameras and a video switcher based on both signal characteristics and users' view selections.  Additionally, it can automate the video composition process based on past users' view-selections when immediate selections are not available.  We demonstrate the performance of this system with real meetings."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/16/2005",
        "palwebID": "PR-05-355",
        "Venue": "Proceedings of SPIE International Symposium ITCom 2005 on Multimedia Systems and Applications VIII, Boston, Massachusetts, USA, October 2005.",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-355/FXPAL-PR-05-355.pdf"
        ],
        "PublicationDate": "12/07/2005",
        "ID": "355",
        "Authors": [
            "Qiong Liu",
            "Don Kimber",
            "Frank Zhao",
            "Jeffrey Huang"
        ],
        "Title": "Framework for effective use of multiple displays",
        "Abstract": "Meeting environments, such as conference rooms, executive briefing centers, and exhibition spaces, are now commonly\r\nequipped with multiple displays, and will become increasingly display-rich in the future. Existing authoring /\r\npresentation tools such as PowerPoint, however, provide little support for effective utilization of multiple displays. Even\r\nusing advanced multi-display enabled multimedia presentation tools, the task of assigning material to displays is tedious\r\nand distracts presenters from focusing on content.\r\nThis paper describes a framework for automatically assigning presentation material to displays, based on a model of the\r\nquality of views of audience members. The framework is based on a model of visual fidelity which takes into account\r\npresentation content, audience members' locations, the limited resolution of human eyes, and display location,\r\norientation, size, resolution, and frame rate. The model can be used to determine presentation material placement\r\nbased on average or worst case audience member view quality, and to warn about material that would be illegible.\r\nBy integrating this framework with a previous system for multi-display presentation [PreAuthor, others], we created a\r\ntool that accepts PowerPoint and/or other media input files, and automatically generates a layout of material onto\r\ndisplays for each state of the presentation. The tool also provides an interface allowing the presenter to modify the\r\nautomatically generated layout before or during the actual presentation. This paper discusses the framework, possible\r\napplication scenarios, examples of the system behavior, and our experience with system use."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-04-356",
        "Venue": "JOINT AMI/PASCAL/IM2/M4 Workshop on Multimodal Interaction and Related Machine Learning Algorithms",
        "palwebURL": [
            "http://palweb/files/PR/2004/PR-04-356/FXPAL-PR-04-356.pdf"
        ],
        "PublicationDate": "06/22/2004",
        "ID": "356",
        "Authors": [
            "Jonathan Foote",
            "Qiong Liu",
            "Don Kimber",
            "Patrick Chiu"
        ],
        "Title": "Immersive Conferencing Directions at FX Palo Alto Laboratory",
        "Abstract": "For some years, our group at FX Palo Alto Laboratory\r\nhas been developing technologies to support meeting\r\nrecording, collaboration, and videoconferencing. This\r\npaper presents a few of our more interesting research\r\ndirections. Many of our systems use a video image as an\r\ninterface, allowing devices and information to be accessed\r\n\"through the screen.\" For example, SPEC enables hybrid\r\ncollaborative and automatic camera control through an\r\nactive video window. The NoteLook system allows a user\r\nto grab an image from a computer display, annotate it\r\nwith digital ink, then drag it to that or a different display,\r\nwhile automatically generating timestamps for later video\r\nreview. The ePIC system allows natural use and control of\r\nmulti-display and multi-device presentation spaces, and\r\nthe iLight system allows remote users to \"draw\" with light\r\non a local object. All our systems serve as platforms for\r\nresearching more sophisticated algorithms that will\r\nhopefully support additional advanced functions and ease\r\nof use."
    },
    {
        "Projects": [
            "MusicSummarization"
        ],
        "keywords": [
            "music visualization",
            "music information retrieval",
            "media analysis",
            "similarity analysis"
        ],
        "AcceptDate": "01/15/2005",
        "palwebID": "PR-06-358",
        "Venue": "Computer Music Journal Vol. 30, Issue 2, pp. 42-62, 2006.",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-358/FXPAL-PR-06-358.doc"
        ],
        "PublicationDate": "06/06/2006",
        "ID": "358",
        "Authors": [
            "Matthew Cooper",
            "Jonathan Foote",
            "Elias Pampalk",
            "George Tzanetakis"
        ],
        "Title": "Visualization in Audio-Based Music Information Retrieval \r\n",
        "Abstract": "Music Information Retrieval (MIR) is an emerging research area that explores how music stored digitally can be effectively organized, searched, retrieved and browsed. The explosive growth of online music distribution, portable music players and lowering costs of recording indicate that in the near future most of recorded music in human history will be available digitally. MIR is steadily growing as a research area as can be evidenced by the international conference on music information retrieval (ISMIR) series soon in its sixth year and the increasing number of MIR-related publications in the Computer Music Journal as well as other journals and conferences. "
    },
    {
        "Projects": [],
        "keywords": [
            "3d",
            "illustration",
            "history"
        ],
        "AcceptDate": "08/01/2005",
        "palwebID": "PR-05-359",
        "Venue": "Layers Magazine October 2005",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-359/FXPAL-PR-05-359.jpg"
        ],
        "PublicationDate": "10/01/2005",
        "ID": "359",
        "Authors": [
            "Tony Dunnigan"
        ],
        "Title": "Discover 3D, More to Explore",
        "Abstract": "An illustration from the Enji project was chosen for use in an advertisement for Strata 3D. Strata 3D makes the software that was used to produce the illustration."
    },
    {
        "Projects": [],
        "keywords": [
            "3D",
            "Illustration",
            "History",
            "Enji"
        ],
        "AcceptDate": "08/01/2005",
        "palwebID": "PR-05-360",
        "Venue": "http://www.strata.com/gallery_detail.asp?id=1480&page=1&category=48",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-360/FXPAL-PR-05-360.jpg"
        ],
        "PublicationDate": "10/01/2005",
        "ID": "360",
        "Authors": [
            "Tony Dunnigan"
        ],
        "Title": "American History: The Early Colonial Period",
        "Abstract": "I produced these Illustrations for two multimedia applications that were developed by FX Palo Alto Laboratory and California State University at Sacramento's Department of Psychology. The applications were part of a study to see how primary school age children learn with certain multimedia tools. Each illustration was viewed as part of a fairly complex screen of information as well as on its own."
    },
    {
        "Projects": [],
        "keywords": [
            "routing",
            "networks",
            "tunnel vector",
            "scalability",
            "DHT"
        ],
        "AcceptDate": "03/11/2006",
        "palwebID": "PR-06-361",
        "Venue": "The 9th IEEE Global Internet Symposium in conjunction with the 25th IEEE INFOCOM Conference, Barcelona, Catalunya, Spain, April 28 - 29, 2006",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-361/FXPAL-PR-06-361.pdf"
        ],
        "PublicationDate": "04/28/2006",
        "ID": "361",
        "Authors": [
            "Cheng-Jia Lai",
            "Richard Muntz"
        ],
        "Title": "Tunnel Vector: A New Routing Algorithm with Scalability",
        "Abstract": "Routing algorithms such as Distance Vector and Link States have the routing table size as O(n), where n is the number of destination identifiers, thus providing only limited scalability for large networks when n is high. As the distributed hash table (DHT) techniques are extraordinarily scalable with n, our work aims at adapting a DHT approach to the design of a network-layer routing algorithm so that the average routing table size can be significantly reduced to O(log n) without losing much routing efficiency. Nonetheless, this scheme requires a major breakthrough to address some fundamental challenges. Specifically, unlike a DHT, a network-layer routing algorithm must (1) exchange its control messages without an underlying network, (2) handle link insertion/deletion and link-cost updates, and (3) provide routing efficiency. Thus, we are motivated to propose a new network-layer routing algorithm, Tunnel Vector (TV), using DHT-like multilevel routing without an underlying network. TV exchanges its control messages only via physical links and is self-configurable in response to linkage updates. In TV, the routing path of a packet is near optimal while the routing table size is O(log n) per node, with high probability. Thus, TV is suitable for routing in a very large network."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [
            "Object Recognition",
            "SIFT",
            "retrieval"
        ],
        "AcceptDate": "05/10/2005",
        "palwebID": "PR-05-362",
        "Venue": "In Proceedings of International Conference on Computer Vision, 2005, page 1026-1033",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-362/FXPAL-PR-05-362.pdf"
        ],
        "PublicationDate": "10/17/2005",
        "ID": "362",
        "Authors": [
            "Hanning Zhou",
            "Thomas Huang"
        ],
        "Title": "Okapi-Chamfer Matching for Articulate Object Recognition",
        "Abstract": "Recent years have witnessed the rise of many effective text information retrieval systems. By treating local visual features as terms, training images as documents and input images as queries, we formulate the problem of object recognition into that of text retrieval. Our formulation opens up the opportunity to integrate some powerful text retrieval tools with computer vision techniques. In this paper, we propose to improve the efficiency of articulated object recognition by an Okapi-Chamfer matching algorithm. The algorithm is based on the inverted index technique.\r\n\r\nThe inverted index is a widely used way to effectively organize a collection of text documents. With the inverted index, only documents that contain query terms are accessed and used for matching. To enable inverted indexing in an image database, we build a lexicon of local visual features by clustering the features extracted from the training images. Given a query image, we extract visual features and quantize them based on the lexicon, and then look up the inverted index to identify the subset of training images with non-zero matching score. To evaluate the matching scores in the subset, we combined the modified Okapi weighting formula with the Chamfer distance. The performance of the Okapi-Chamfer matching algorithm is evaluated on a hand posture recognition system. We test the system with both synthesized and real world images. Quantitative results demonstrate the accuracy and efficiency our system. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-05-363",
        "Venue": "ICME 2005",
        "palwebURL": [
            "http://palweb/files/PR/2005/PR-05-363/FXPAL-PR-05-363.pdf"
        ],
        "PublicationDate": "07/20/2005",
        "ID": "363",
        "Authors": [
            "Kazumasa Murai",
            "Don Kimber",
            "Jonathan Foote",
            "Qiong Liu",
            "John Doherty"
        ],
        "Title": "Mediated Meeting Interaction for Teleconferencing",
        "Abstract": "A common problem with teleconferences is\r\nawkward turn-taking - particularly 'collisions,'\r\nwhereby multiple parties inadvertently speak over each\r\nother due to communication delays. We propose a\r\nmodel for teleconference discussions including the\r\neffects of delays, and describe tools that can improve\r\nthe quality of those interactions. We describe an\r\ninterface to gently provide latency awareness, and to\r\ngive advanced notice of 'incoming speech' to help\r\nparticipants avoid collisions. This is possible when\r\ncodec latencies are significant, or when a low\r\nbandwidth side channel or out-of-band signaling is\r\navailable with lower latency than the primary video\r\nchannel. We report on results of simulations, and of\r\nexperiments carried out with transpacific meetings, that\r\ndemonstrate these tools can improve the quality of\r\nteleconference discussions."
    },
    {
        "Projects": [
            "mTable"
        ],
        "keywords": [
            "Visual interfaces",
            "information visualization",
            "sense-making",
            "grouping",
            "large displays",
            "mTable"
        ],
        "AcceptDate": "03/02/2006",
        "palwebID": "PR-06-368",
        "Venue": "Proceedings of AVI '06 (Short Paper), ACM Press, pp. 258-261.",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-368/FXPAL-PR-06-368.pdf"
        ],
        "PublicationDate": "05/23/2006",
        "ID": "368",
        "Authors": [
            "Xiaohua Sun",
            "Patrick Chiu",
            "Jeffrey Huang",
            "Maribeth Back",
            "Wolfgang Polak"
        ],
        "Title": "Implicit Brushing and Target Snapping: Data Exploration and Sense-making on Large Displays",
        "Abstract": "During grouping tasks for data exploration and sense-making, the criteria are normally not well-defined. When users are bringing together data objects thought to be similar in some way, implicit brushing continually detects for groups on the freeform workspace, analyzes the groups' text content or metadata, and draws attention to related data by displaying visual hints and animation. This provides helpful tips for further grouping, group meaning refinement and structure discovery. The sense-making process is further enhanced by retrieving relevant information from a database or network during the brushing. Closely related to implicit brushing, target snapping provides a useful means to move a data object to one of its related groups on a large display. Natural dynamics and smooth animations also help to prevent distractions and allow users to concentrate on the grouping and thinking tasks. Two different prototype applications, note grouping for brainstorming and photo browsing, demonstrate the general applicability of the technique."
    },
    {
        "Projects": [],
        "keywords": [
            "Author Keywords\r\nDesign methods",
            "design critique",
            "design review",
            "design edu-cation",
            "design realization.\r\n\r\nACM Classification Keywords\r\nH5.2",
            "H.5.m. User Interfaces: User centered design",
            "interac-tion styles",
            "input devices and strategies",
            "design methods."
        ],
        "AcceptDate": "",
        "palwebID": "PR-06-369",
        "Venue": "Proceedings of ACM DIS (Designing Interactive Systems) 2006, Penn State, Penn. ",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-369/FXPAL-PR-06-369.pdf"
        ],
        "PublicationDate": "04/05/2006",
        "ID": "369",
        "Authors": [
            "Maribeth Back",
            "Steve Harrison",
            "Deborah Tatar"
        ],
        "Title": "\"It's Just A Method!\"  A Pedagogical Experiment in Interdisciplinary Design",
        "Abstract": "What does a student need to know to be a designer? Beyond  a list of separate skills, what mindset does a student need to develop for designerly action now and into the future? In the excitement of the cognitive revolution, Simon proposed a way of thinking about design that promised to make it more manageable and cognitive: to think of design as a planning problem.  Yet, as Suchman argued long ago, planning accounts may be applied to problems that are not at base accomplished by planning, to the detriment of design vision. This paper reports on a pedagogy that takes Suchman's criticism to heart and avoids dressing up design methods as more systematic and predictive than they in fact are. The idea is to teach design through expo-sure to not just one, but rather, many methods---that is, sets of rules or behaviors that produce artifacts for further reflec-tion and development. By introducing a large number of design methods, decoupled from theories, models or frame-works, we teach (a) important cross-methodological regu-larities in competence as a designer, (b) that the practice of design can itself be designed and (c) that method choice affects design outcomes. This provides a rich and produc-tive notion of design particularly necessary for the world of pervasive and ubiquitous computing. "
    },
    {
        "Projects": [
            "CorporateMemory",
            "ProjectBox",
            "PALBar",
            "VideoGuestbook"
        ],
        "keywords": [
            "corpmem",
            "pbox",
            "palbar",
            "guestbook"
        ],
        "AcceptDate": "03/11/2006",
        "palwebID": "PR-06-370",
        "Venue": "The 15th International World Wide Web Conference (WWW2006)",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-370/FXPAL-PR-06-370.pdf"
        ],
        "PublicationDate": "05/23/2006",
        "ID": "370",
        "Authors": [
            "David Hilbert",
            "Daniel Billsus",
            "Laurent Denoue"
        ],
        "Title": "Seamless Capture and Discovery for Corporate Memory",
        "Abstract": "In a landmark article, over a half century ago, Vannevar Bush envisioned a \"Memory Extender\" device he dubbed the \"memex\". Bush's ideas anticipated and inspired numerous breakthroughs, including hypertext, the Internet, the World Wide Web, and Wikipedia. However, despite these triumphs, the memex has still not lived up to its potential in corporate settings. One reason is that corporate users often don't have sufficient time or incentives to contribute to a corporate memory or to explore others' contributions. At FXPAL, we are investigating ways to automatically create and retrieve useful corporate memories without any added burden on anyone. In this paper we discuss how ProjectorBox a smart appliance for automatic presentation capture and PAL Bar a system for proactively retrieving contextually relevant corporate memories have enabled us to integrate content from a variety of sources to create a cohesive multimedia corporate memory for our organization."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "TRECVID",
            "MediaMagic",
            "Multimedia",
            "media annotation"
        ],
        "AcceptDate": "03/01/2006",
        "palwebID": "PR-06-371",
        "Venue": "Proceedings of TRECVID 2005",
        "palwebURL": [],
        "PublicationDate": "03/15/2006",
        "ID": "371",
        "Authors": [
            "Matthew Cooper",
            "John Adcock",
            "Robert Chen",
            "Hanning Zhou"
        ],
        "Title": "FXPAL at TRECVID 2005",
        "Abstract": "In 2005 FXPAL submitted results for 3 tasks at TRECVID: shot boundary detection, high-level feature extraction, and interactive search."
    },
    {
        "Projects": [],
        "keywords": [
            "PLSA",
            "LSA",
            "initialization",
            "text segmentation",
            "information retrieval"
        ],
        "AcceptDate": "01/12/2006",
        "palwebID": "PR-06-372",
        "Venue": "EACL (11th Conference of the European Chapter of the Association for Computational Linguistics)",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-372/FXPAL-PR-06-372.pdf"
        ],
        "PublicationDate": "04/03/2006",
        "ID": "372",
        "Authors": [
            "Ayman Farahat",
            "Francine Chen"
        ],
        "Title": "Improving Probabilistic Latent Semantic Analysis with Principal Component Analysis",
        "Abstract": "Probabilistic Latent Semantic Analysis (PLSA) models have been shown to provide a better model for capturing polysemy and synonymy than Latent Semantic Analysis (LSA).  However, the parameters of a PLSA model are trained using the Expectation Maximization (EM) algorithm, and as a result, the trained model is dependent on the initialization values so that performance can be highly variable.  In this paper we present a method for using LSA analysis to initialize a PLSA model.  We also investigated the performance of our method for the tasks of text segmentation and retrieval on personal-size corpora, and present results demonstrating the efficacy of our proposed approach."
    },
    {
        "Projects": [
            "USE",
            "DICE"
        ],
        "keywords": [
            "USE",
            "DICE",
            "usability",
            "usable ubiquitous computing",
            "smart conference rooms",
            "mobile devices",
            "meeting support",
            "rich media",
            "context-aware computing",
            "collaboration",
            "knowledge management",
            "multimedia",
            "tele-conferencing",
            "active learning",
            "interactive furniture."
        ],
        "AcceptDate": "04/28/2006",
        "palwebID": "PR-06-373",
        "Venue": "International workshop at UbiComp 2006. ",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-373/FXPAL-PR-06-373.pdf"
        ],
        "PublicationDate": "09/17/2006",
        "ID": "373",
        "Authors": [
            "Maribeth Back",
            "Kazunori Horikiri",
            "Jef Huang",
            "Surapong Lertsithichai",
            "Rafael (Tico) Ballagas",
            "Masatomi Inagaki",
            "Saadi Lahlou"
        ],
        "Title": "Usable ubiquitous computing in next generation conference rooms:  design, architecture and evaluation",
        "Abstract": "In the UbiComp 2005 workshop \"Ubiquitous computing in next generation conference rooms\" we learned that usability is one of the primary challenges in these spaces.  Nearly all \"smart\" rooms, though they often have interesting and effective functionality, are very difficult to simply walk in and use. Most such rooms have resident experts who keep the room's systems functioning, and who often must be available on an everyday basis to enable the meeting technologies. The systems in these rooms are designed for and assume the presence of these human \"wizards\"; they are seldom designed with usability in mind.  In addition, people don't know what to expect in these rooms; as yet there is no technology standard for next-generation conference rooms. \r\n\r\nThe challenge here is to strike an effective balance between usability and new kinds of functionality (such as multiple displays, new interfaces, rich media systems, new uploading/access/security systems, robust mobile integration, to name just a few of the functions we saw in last year's workshop).  So, this year, we propose a workshop to focus more specifically on how the design of next-generation conference rooms can support usability: the tasks facing the real people who use these rooms daily.  \r\n\r\nUsability in ubiquitous computing has been the topic of several papers and workshops.  Focusing on usability in next-generation conference rooms lets us bring to bear some of the insights from this prior work in a delineated application space. In addition the workshop will be informed by the most recent usability research in ubiquitous computing, rich media, context-aware mobile systems, multiple display environments, and interactive physical environments.  We also are vitally concerned with how usability in smart environments tracks (or doesn't) across cultures.\r\n\r\nConference room research has been and remains a focal point for some of the most interesting and applied work in ubiquitous computing. It is also an area where there are many real-world applications and daily opportunities for user feed-back: in short, a rich area for exploring usable ubiquitous computing.  We see a rich opportunity to draw together researchers not only from conference room research but also from areas such as interactive furniture/smart environments, rich media, social computing, remote conferencing, and mobile devices for a lively exchange of ideas on usability in applied ubicomp systems for conference rooms.\r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "Technolgy",
            "Complexity",
            "Self-organized Criticality"
        ],
        "AcceptDate": "04/13/2006",
        "palwebID": "PR-06-374",
        "Venue": "Complexity, Vol 11, No 5.",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-374/FXPAL-PR-06-374.pdf"
        ],
        "PublicationDate": "06/03/2006",
        "ID": "374",
        "Authors": [
            "Wolfgang Polak",
            "Brian Arthur"
        ],
        "Title": "The Evolution of Technology within a Simple Computer Model",
        "Abstract": "Technology-the collection of devices and methods available to human society-evolves by\r\nconstructing new devices and methods from ones that previously exist, and in turn offering these as\r\npossible components-building blocks-for the construction of further new devices and elements.\r\nThe collective of technology in this way forms a network of elements where novel elements are\r\ncreated from existing ones and where more complicated elements evolve from simpler ones. We\r\nmodel this evolution within a simple artificial system on the computer. The elements in our system\r\nare logic circuits. New elements are formed by combination from simpler existing elements\r\n(circuits), and if a novel combination satisfies one of a set of needs it is retained as a building block\r\nfor further combination. We study the properties of the resulting buildout. We find that our\r\nartificial system can create complicated technologies (circuits), but only by first creating simpler\r\nones as building blocks. Our results mirror Lenski et al.'s, that complex features can be created in\r\nbiological evolution only if simpler functions are first favored and act as stepping stones. We also\r\nfind evidence that the resulting collection of technologies exists at self-organized criticality."
    },
    {
        "Projects": [
            "USE",
            "DICE"
        ],
        "keywords": [
            "USE",
            "DICE",
            "Smart environments",
            "USE Usable smart environments",
            "conference rooms",
            "teleconferencing",
            "video conference",
            "physical computing",
            "ubiquitous computing",
            "CSCW"
        ],
        "AcceptDate": "",
        "palwebID": "PR-06-375",
        "Venue": "UbiComp 2006 Workshop position paper",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-375/FXPAL-PR-06-375.pdf"
        ],
        "PublicationDate": "09/20/2006",
        "ID": "375",
        "Authors": [
            "Maribeth Back",
            "Gene Golovchinsky",
            "John Adcock",
            "John Boreczky",
            "Laurent Denoue",
            "John Doherty",
            "Tony Dunnigan",
            "Gerry Filby",
            "Pernilla Qvarfordt",
            "Bill van Melle"
        ],
        "Title": "The USE Project: Designing Smart Spaces for Real People",
        "Abstract": "We describe our work-in-progress: a \"wizard-free\" conference room designed for ease of use, yet retaining next-generation functionality.  Called USE (Usable Smart Environments), our system uses multi-display systems, immersive conferencing, and secure authentication.  It is based in cross-cultural ethnographic studies on the way people use conference rooms. \r\n\r\n<P>\r\nThe USE project has developed a flexible, extensible architecture specifically designed to enhance ease of use in smart environment technologies. The architecture allows customization and personalization of smart environments for particular people and groups, types of work, and specific physical spaces.  The system consists of a database of devices with attributes, rooms and meetings that implements a prototype-instance inheritance mechanism through which contextual information (e.g. IP addresses application settings, phone numbers for teleconferencing systems, etc.) can be associated "
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [
            "Coupled Hidden Markov Model",
            "Event Detection",
            "Video Surveillance"
        ],
        "AcceptDate": "04/20/2006",
        "palwebID": "PR-06-376",
        "Venue": "International Conference on Pattern Recognition",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-376/FXPAL-PR-06-376.pdf"
        ],
        "PublicationDate": "08/20/2006",
        "ID": "376",
        "Authors": [
            "Hanning Zhou",
            "Don Kimber"
        ],
        "Title": "Unusual Event Detection via Multi-camera Video Mining",
        "Abstract": "This paper describes a framework for detecting unusual events in surveillance videos. Most surveillance systems consist of multiple video streams, but traditional event detection systems treat individual video streams independently or combine them in the feature extraction level through geometric reconstruction. Our framework combines multiple video streams in the inference level, with a coupled hidden Markov Model (CHMM). We use two-stage training to bootstrap a set of usual events, and train a CHMM over the set. By thresholding the likelihood of a test segment being generated by the model, we build a unusual event detector.\r\n\r\nWe evaluate the performance of our detector through qualitative and quantitative experiments on two sets of real world videos. "
    },
    {
        "Projects": [
            "Hitchcock",
            "Interactive Video Search"
        ],
        "keywords": [
            "hitchcock",
            "video",
            "hypervideo",
            "media",
            "trecvid",
            "video search",
            "video segmentation"
        ],
        "AcceptDate": "",
        "palwebID": "PR-06-377",
        "Venue": "Interactive Video; Algorithms and Technologies\r\nHammoud, Riad (Ed.)\r\n2006, XVI, 250 p., 109 illus., Hardcover. \r\npages 207-224",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-377/FXPAL-PR-06-377.pdf"
        ],
        "PublicationDate": "06/07/2006",
        "ID": "377",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "John Adcock",
            "Matthew Cooper",
            "Lynn Wilcox"
        ],
        "Title": "Locating Information in Video by Browsing and Searching",
        "Abstract": "This chapter describes tools for browsing and searching through video\r\nto enable users to quickly locate video passages of interest. Digital video databases\r\ncontaining large numbers of video programs ranging from several minutes to several\r\nhours in length are becoming increasingly common. In many cases, it is not sufficient\r\nto search for relevant videos, but rather to identify relevant clips, typically less than\r\none minute in length, within the videos. We offer two approaches for finding information\r\nin videos. The first approach provides an automatically generated interactive\r\nmulti-level summary in the form of a hypervideo. When viewing a sequence of short\r\nvideo clips, the user can obtain more detail on the clip being watched. For situations\r\nwhere browsing is impractical, we present a video search system with a flexible user\r\ninterface that incorporates dynamic visualizations of the underlying multimedia objects.\r\nThe system employs automatic story segmentation, and displays the results\r\nof text and image-based queries in ranked sets of story summaries. Both approaches\r\nhelp users to quickly drill down to potentially relevant video clips and to determine\r\nthe relevance by visually inspecting the material."
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [
            "DOTS"
        ],
        "AcceptDate": "10/27/2006",
        "palwebID": "PR-06-380",
        "Venue": "In Proceedings of the fourth ACM International Workshop on Video Surveillance & Sensor Networks VSSN '06, Santa Barbara, CA, pp. 19-26",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-380/FXPAL-PR-06-380.pdf"
        ],
        "PublicationDate": "10/27/2006",
        "ID": "380",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Tony Dunnigan",
            "Thea Turner",
            "Lynn Wilcox"
        ],
        "Title": "Support for Effective Use of Multiple Video Streams in Security",
        "Abstract": "Video surveillance systems have become common across a wide number of environments.  While these installations have included more video streams, they also have been placed in contexts with limited personnel for monitoring the video feeds.  In such settings, limited human attention, combined with the quantity of video, makes it difficult for security personnel to identify activities of interest and determine interrelationships between activities in different video streams. We have developed applications to support security personnel both in analyzing previously recorded video and in monitoring live video streams.  For recorded video, we created storyboard visualizations that emphasize the most important activity as heuristically determined by the system.  We also developed an interactive multi-channel video player application that connects camera views to map locations, alerts users to unusual and suspicious video, and visualizes unusual events along a timeline for later replay.  We use different analysis techniques to determine unusual events and to highlight them in video images.  These tools aid security personnel by directing their attention to the most important activity within recorded video or among several live video streams.\r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "news",
            "personalization",
            "user modeling",
            "machine learning"
        ],
        "AcceptDate": "09/15/2006",
        "palwebID": "PR-07-382",
        "Venue": "Book chapter in \"The Adaptive Web: Methods and Strategies of Web Personalization\" (Springer, LNCS #4321)",
        "palwebURL": [],
        "PublicationDate": "02/01/2007",
        "ID": "382",
        "Authors": [
            "Daniel Billsus",
            "Michael Pazzani"
        ],
        "Title": "Adaptive News Access",
        "Abstract": "This chapter describes how the adaptive web technologies discussed in this book have been applied to news access. First, we provide an overview of different types of adaptivity in the context of news access and identify corre-sponding algorithms. For each adaptivity type, we briefly discuss representative systems that use the described techniques. Next, we discuss an in-depth case study of a personalized news system. As part of this study, we outline a user modeling approach specifically designed for news personalization, and present results from an evaluation that attempts to quantify the effect of adaptive news access from a user perspective. We conclude by discussing recent trends and novel systems in the adaptive news space."
    },
    {
        "Projects": [],
        "keywords": [
            "recommendation systems",
            "content",
            "machine learning",
            "user modeling"
        ],
        "AcceptDate": "02/01/2007",
        "palwebID": "PR-07-383",
        "Venue": "Book chapter in \"The Adaptive Web: Methods and Strategies of Web Personalization\" (Springer, LNCS #4321)",
        "palwebURL": [],
        "PublicationDate": "02/01/2007",
        "ID": "383",
        "Authors": [
            "Michael Pazzani",
            "Daniel Billsus"
        ],
        "Title": "Content-based Recommendation Systems",
        "Abstract": "This chapter discusses content-based recommendation systems, i.e., systems that recommend an item to a user based upon a description of the item and a profile of the user's interests.  Content-based recommendation systems may be used in a variety of domains ranging from recommending web pages, news articles, restau-rants, television programs, and items for sale. Although the details of various systems differ, content-based recommendation systems share in common a means for describing the items that may be recommended, a means for creating a profile of the user that describes the types of items the user likes, and a means of comparing items to the user profile to determine what to recommend.  The user profile is often created and updated automatically in response to feedback on the desirability of items that have been presented to the user."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [
            "queue",
            "cluster",
            "load balance",
            "service",
            "collaborative"
        ],
        "AcceptDate": "10/04/2006",
        "palwebID": "PR-06-384",
        "Venue": "MobCops 2006 Workshop in conjunction with IEEE/ACM CollaborateCom 2006, Atlanta, Georgia, USA.\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-384/FXPAL-PR-06-384.pdf"
        ],
        "PublicationDate": "11/17/2006",
        "ID": "384",
        "Authors": [
            "Cheng-Jia Lai",
            "Wolfgang Polak"
        ],
        "Title": "A Collaborative Approach to Stochastic Load Balancing with Networked Queues of Autonomous Service Clusters",
        "Abstract": "Load balancing has been an increasingly important issue for handling computational intensive tasks in a distributed system such as in Grid and cluster computing. In such systems, multiple server instances are installed for handling requests from client applications, and each request (or task) typically needs to stay in a queue before an available server is assigned to process it. In this paper, we propose a high-performance queueing method for implementing a shared queue for collaborative clusters of servers. Each cluster of servers maintains a local queue and queues of different clusters are networked to form a unified (or shared) queue that may dispatch tasks to all available servers. We propose a new randomized algorithm for forwarding requests in an overcrowded local queue to a networked queue based on load information of the local and neighboring clusters.  The algorithm achieves both load balancing and locality awareness."
    },
    {
        "Projects": [],
        "keywords": [
            "Retrieval models",
            "Random Fields",
            "Maximum Entropy",
            "Context-based retrieval"
        ],
        "AcceptDate": "10/07/2006",
        "palwebID": "PR-06-385",
        "Venue": "CIKM (Conference on information and Knowledge Management) 2006, Arlington, VA\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-385/FXPAL-PR-06-385.ps"
        ],
        "PublicationDate": "11/07/2006",
        "ID": "385",
        "Authors": [
            "Jeremy Pickens",
            "Andrew MacFarlane"
        ],
        "Title": "Term Context Models for Information Retrieval",
        "Abstract": "At their heart, most if not all information retrieval models\r\nutilize some form of term frequency. The notion is that the\r\nmore often a query term occurs in a document, the more likely it is that document meets an information need. We examine an alternative. We propose a model which assesses the presence of a term in a document not by looking at the actual occurrence of that term, but by a set of nonindependent supporting terms, i.e. context. This yields a weighting for terms in documents which is different from and complementary to tf-based methods, and is beneficial for retrieval."
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-06-386",
        "Venue": "UIST 2006 Companion",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-386/FXPAL-PR-06-386.pdf"
        ],
        "PublicationDate": "10/16/2006",
        "ID": "386",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Thea Turner",
            "Lynn Wilcox"
        ],
        "Title": "Interface Components for Monitoring Security Video",
        "Abstract": "Video surveillance requires keeping the human in the loop. Software can aid security personnel in monitoring and using video. We have developed a set of interface components designed to locate and follow important activity within security video. By recognizing and visualizing localized activity, presenting overviews of activity over time, and temporally and geographically contextualizing video playback, we aim to support security personnel in making use of the growing quantity of security video."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-06-387",
        "Venue": "UIST 2006 Companion",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-387/FXPAL-PR-06-387.pdf"
        ],
        "PublicationDate": "10/16/2006",
        "ID": "387",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Thea Turner",
            "Lynn Wilcox"
        ],
        "Title": "Video Surveillance: Keeping the Human in the Loop",
        "Abstract": "With the growing quantity of security video, it becomes vital that video surveillance software be able to support security personnel in monitoring and tracking activities.  We have developed a multi-stream video player that plays recorded and live videos while drawing the users' attention to activity in the video.  We will demonstrate the features of the video player and in particular, how it focuses on keeping the human in the loop and drawing their attention to activities in the video."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [
            "Image identification",
            "multiple displays",
            "mobile camera",
            "cell phone",
            "document",
            "interaction with physical meeting space",
            "user interface"
        ],
        "AcceptDate": "06/08/2006",
        "palwebID": "PR-06-388",
        "Venue": "Proceedings of IEEE Multimedia Signal Processing 2006",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-388/FXPAL-PR-06-388.pdf"
        ],
        "PublicationDate": "10/03/2006",
        "ID": "388",
        "Authors": [
            "Qiong Liu",
            "Don Kimber",
            "Patrick Chiu",
            "Paul McEvoy",
            "Hanning Zhou"
        ],
        "Title": "ON REDIRECTING DOCUMENTS WITH A MOBILE CAMERA",
        "Abstract": "This paper presents a method for facilitating document\r\nredirection in a physical environment via a mobile camera.\r\nWith this method, a user is able to move documents among\r\nelectronic devices, post a paper document to a selected\r\npublic display, or make a printout of a white board with\r\nsimple point-and-capture operations. More specifically, the\r\nuser can move a document from its source to a destination\r\nby capturing a source image and a destination image in a\r\nconsecutive order. The system uses SIFT (Scale Invariant\r\nFeature Transform) features of captured images to identify\r\nthe devices a user is pointing to, and issues corresponding\r\ncommands associated with identified devices. Unlike RF/IR\r\nbased remote controls, this method uses object visual\r\nfeatures as an all time 'transmitter' for many tasks, and\r\ntherefore is easy to deploy. We present experiments on\r\nidentifying three public displays and a document scanner in\r\na conference room for evaluation."
    },
    {
        "Projects": [],
        "keywords": [
            "Mobile camera supported document redirection",
            "device control."
        ],
        "AcceptDate": "07/01/2006",
        "palwebID": "PR-06-389",
        "Venue": "Proceeeding of ACM Multimedia 2006",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-389/FXPAL-PR-06-389.pdf"
        ],
        "PublicationDate": "10/23/2006",
        "ID": "389",
        "Authors": [
            "Qiong Liu",
            "Paul McEvoy",
            "Cheng-Jia Lai"
        ],
        "Title": "Mobile Camera Supported Document Redirection",
        "Abstract": "In this demonstration, we are going to illustrate how to use a mobile camera to redirect documents to various devices connected to the same network"
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "TRECVID",
            "video shot boundary detection",
            "video segmentation",
            "trecvid",
            "videosegmentation"
        ],
        "AcceptDate": "08/01/2006",
        "palwebID": "PR-07-390",
        "Venue": "IEEE Transactions on Multimedia",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-390/FXPAL-PR-07-390.pdf"
        ],
        "PublicationDate": "04/01/2007",
        "ID": "390",
        "Authors": [
            "Matthew Cooper",
            "Ting Liu",
            "Eleanor Rieffel"
        ],
        "Title": "Video Segmentation via Temporal Pattern Classification",
        "Abstract": "We present a general approach to temporal media segmentation using supervised classification.  Given standard low-level features representing each time sample, we build intermediate features via pairwise similarity.  The intermediate features comprehensively characterize local temporal structure, and are input to an efficient supervised classifier to identify shot boundaries. We integrate discriminative feature selection based on mutual information to enhance performance and reduce processing requirements. Experimental results using large-scale test sets provided by the TRECVID evaluations for abrupt and gradual shot boundary detection are presented, demonstrating excellent performance."
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [
            "Video surveillance",
            "activity tracking",
            "multiple video streams",
            "security cameras",
            "geographic context",
            "DOTS"
        ],
        "AcceptDate": "02/19/2007",
        "palwebID": "PR-07-391",
        "Venue": "CHI 2007, pp. 1167-1176",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-391/FXPAL-PR-07-391.pdf"
        ],
        "PublicationDate": "04/28/2007",
        "ID": "391",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Thea Turner",
            "Lynn Wilcox"
        ],
        "Title": "Effects of Presenting Geographic Context on Tracking Activity between Cameras",
        "Abstract": "A common video surveillance task is to keep track of people moving around the space being monitored. It is often difficult to track activity between cameras because locations such as hallways in office buildings can look quite similar and do not indicate the spatial proximity of the cameras. We describe a spatial video player that orients nearby video feeds with the field of view of the main playing video to aid in tracking between cameras. This is compared with the traditional bank of cameras with and without interactive maps for identifying and selecting cameras. We additionally explore the value of static and rotating maps for tracking activity between cameras. The study results show that both the spatial video player and the map improve user performance when compared to the camera-bank interface. Also, subjects change cameras more often with the spatial player than either the camera bank or the map, when available."
    },
    {
        "Projects": [],
        "keywords": [
            "Momento"
        ],
        "AcceptDate": "01/26/2007",
        "palwebID": "PR-07-392",
        "Venue": "CHI 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-392/FXPAL-PR-07-392.pdf"
        ],
        "PublicationDate": "04/28/2007",
        "ID": "392",
        "Authors": [
            "Scott Carter",
            "Jennifer Mankoff",
            "Jeffrey Heer"
        ],
        "Title": "Momento: Support for Situated Ubicomp Experimentation",
        "Abstract": "We present the iterative design of Momento, a tool that provides integrated support for situated evaluation of ubiquitous computing applications. We derived requirements for Momento from a user-centered design process that included interviews, observations and field studies of early versions of the tool. Motivated by our findings, Momento supports remote testing of ubicomp applications, helps with participant adoption and retention by minimizing the need for new hardware, and supports mid-to-long term studies to address infrequently occurring data. Also, Momento can gather log data, experience sampling, diary, and other qualitative data."
    },
    {
        "Projects": [],
        "keywords": [
            "Search",
            "mobile code",
            "multimedia",
            "distributed computing",
            "Java",
            "middleware",
            "Web services"
        ],
        "AcceptDate": "",
        "palwebID": "PR-06-394",
        "Venue": "Henry Hexmoor, Marcin Paprzycki, Niranjan Suri (eds)\r\nScalable Computing: Practice and Experience\r\nVolume 7, No. 4, December 2006\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-394/FXPAL-PR-06-394.pdf"
        ],
        "PublicationDate": "12/23/2006",
        "ID": "394",
        "Authors": [
            "Volker Roth",
            "Jan Peters",
            "Ulrich Pinsdorf"
        ],
        "Title": "A Distributed Content-Based Search Engine Based on Mobile Code and Web Service Technology",
        "Abstract": "Current search engines crawl the Web, download content, and digest this content locally. For multimedia content, this involves considerable volumes of data. Furthermore, this process covers only publicly available content because content providers are concerned that they otherwise loose control over the distribution of their intellectual property. We present the prototype of our secure and distributed search engine, which dynamically pushes content based feature extraction to image providers. Thereby, the volume of data that is transported over the network is significantly reduced, and the concerns mentioned above are alleviated. The distribution of feature extraction and matching algorithms is done by mobile software agents. Subsequent search requests performed upon the resulting feature indices by means of remote feature comparison can either be realized through mobile software agents, or by the use of implicitly created Web services which wrap the remote comparison functionality, and thereby improve the interoperability of the search engine. We give a description of the search engine's architecture and implementation, depict our concepts to integrate agent and Web service technology, and present quantitative evaluation results. Furthermore, we discuss related security mechanisms for content protection and server security."
    },
    {
        "Projects": [],
        "keywords": [
            "Mobile code",
            "Java",
            "VM",
            "security",
            "risks",
            "denial of service"
        ],
        "AcceptDate": "",
        "palwebID": "PR-06-395",
        "Venue": "Henry Hexmoor, Marcin Paprzycki, Niranjan Suri (eds)\r\nScalable Computing: Practice and Experience\r\nVolume 7, No. 4, December 2006",
        "palwebURL": [
            "http://palweb/files/PR/2006/PR-06-395/FXPAL-PR-06-395.pdf"
        ],
        "PublicationDate": "12/23/2006",
        "ID": "395",
        "Authors": [
            "Walter Binder",
            "Volker Roth"
        ],
        "Title": "Security Risks in Java-based Mobile Code Systems",
        "Abstract": "Java is the predominant language for mobile agent systems, both for implementing mobile agent execution environments and for writing mobile agent applications. This is due to inherent support for code mobility by means of dynamic class loading and separable class name spaces, as well as a number of security properties, such as language safety and access control by means of stack introspection. However, serious questions must be raised whether Java is actually up to the task of providing a secure execution environment for mobile agents. At the time of writing, it has neither resource control nor proper application separation. In this article we take an in-depth look at Java as a foundation for secure mobile agent systems."
    },
    {
        "Projects": [],
        "keywords": [
            "quantum computing",
            "quantum information processing",
            "quantum mechanics",
            "probability theory",
            "certainty",
            "uncertainty."
        ],
        "AcceptDate": "01/20/2007",
        "palwebID": "PR-07-396",
        "Venue": "Proceedings of the AAAI Spring Symposium 2007 on quantum interaction organized by Keith von Rijsbergen, Peter Bruza, Bill Lawless, and Don Sofge",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-396/FXPAL-PR-07-396.pdf"
        ],
        "PublicationDate": "03/26/2007",
        "ID": "396",
        "Authors": [
            "Eleanor Rieffel"
        ],
        "Title": "Certainty and Uncertainty in Quantum Information Processing",
        "Abstract": "This survey, aimed at information processing researchers,\r\nhighlights intriguing but lesser known results, corrects\r\nmisconceptions, and suggests research areas.\r\nThemes include: certainty in quantum algorithms; the \"fewer worlds\"\r\ntheory of quantum mechanics; quantum learning; probability theory\r\nversus quantum mechanics.\r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "ubicomp"
        ],
        "AcceptDate": "02/15/2008",
        "palwebID": "PR-08-397",
        "Venue": "Human-Computer Interaction Journal",
        "palwebURL": [],
        "PublicationDate": "02/15/2008",
        "ID": "397",
        "Authors": [
            "Scott Carter",
            "Jennifer Mankoff",
            "Scott Klemmer",
            "Tara Matthews"
        ],
        "Title": "Exiting the Cleanroom: On Ecological Validity and Ubiquitous Computing",
        "Abstract": "Over the past decade and a half, corporations and academies have invested considerable time and money in the realization of ubiquitous computing. Yet design approaches that yield ecologically valid understandings of ubiquitous computing systems, which can help designers make design decisions based on how systems perform in the context of actual experience, remain rare. The central question underlying this paper is: what barriers stand in the way of real-world, ecologically valid design for ubicomp? Using a literature survey and interviews with 28 developers, we illustrate how issues of sensing and scale cause ubicomp systems to resist iteration, prototype creation, and ecologically valid evaluation. In particular, we found that developers have difficulty creating prototypes that are both robust enough for realistic use and able to handle ambiguity and error, and that they struggle to gather useful data from evaluations either because critical events occur infrequently, because the level of use necessary to evaluate the system is difficult to maintain, or because the evaluation itself interferes with use of the system. We outline pitfalls for developers to avoid as well as practical solutions, and we draw on our results to outline research challenges for the future. Crucially, we do not argue for particular processes, sets of metrics, or intended outcomes but rather focus on prototyping tools and evaluation methods that support realistic use in realistic settings that can be selected according to the needs and goals of a particular developer or researcher."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "TRECVID",
            "Multimedia",
            "MediaMagic",
            "media annotation"
        ],
        "AcceptDate": "10/01/2006",
        "palwebID": "PR-07-398",
        "Venue": "Proceedings of TRECVID 2006 Workshop",
        "palwebURL": [],
        "PublicationDate": "03/01/2007",
        "ID": "398",
        "Authors": [
            "Matthew Cooper",
            "John Adcock",
            "Francine Chen"
        ],
        "Title": "FXPAL at TRECVID 2006",
        "Abstract": "In 2006 FXPAL submitted results for shot boundary detection, high-level feature extraction, and interactive search."
    },
    {
        "Projects": [],
        "keywords": [
            "3D",
            "2D",
            "Video",
            "Motion Graphics",
            "Special Effects",
            "FX"
        ],
        "AcceptDate": "10/01/2006",
        "palwebID": "PR-07-399",
        "Venue": "PSD Magazine 2/2007 - Photoshop Art & Special Effects",
        "palwebURL": [],
        "PublicationDate": "02/01/2007",
        "ID": "399",
        "Authors": [
            "Tony Dunnigan"
        ],
        "Title": "Walking Down a Futuristic Street - Using Still Imagery In Motion Graphics",
        "Abstract": "With the techniques covered in this tutorial you will be able to produce two classic visual effects. First, I'll show you how to make animated titles by importing Photoshop files into Aftereffects. Next we'll add new scenic elements to some video footage, again using Photoshop. This technique will allow you to add or remove elements like tree or buildings from a shot. \r\n\r\nThese techniques, especially the one we will use to alter the scene, are common to most visual effects.\r\nWatch the classic old 1933 version of King Kong. Willis O'Brien, the stop motion genius that animated Kong, pioneered the art of extending, or completely fabricating, scenery. Layering several elements painted on glass in front his puppets and rear projected footage allowed O'brien and RKO's visual effects artist Linwood Dunn to create King Kong's fantastic jungle scenes. It is said that these set-ups could be many feet deep. "
    },
    {
        "Projects": [],
        "keywords": [
            "Illustration",
            "2d",
            "3d"
        ],
        "AcceptDate": "02/01/2007",
        "palwebID": "PR-07-400",
        "Venue": "PSD Magazine 4, 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-400/FXPAL-PR-07-400.jpg",
            "http://palweb/files/PR/2007/PR-07-400/FXPAL-PR-07-400.pdf",
            "http://palweb/files/PR/2007/PR-07-400/Thumbs.db"
        ],
        "PublicationDate": "04/01/2007",
        "ID": "400",
        "Authors": [
            "Tony Dunnigan"
        ],
        "Title": "Turning A 3D Rendering Into An Illustration - Using Photoshop to add personality to 3D renderings",
        "Abstract": "3D renderings can often look cold and impersonal or even cartoonish. They can also appear too crisply detailed . This can cause viewers to concentrate on specific details when they should be focusing on a more general idea or concept. With the techniques covered in this tutorial you will be able to turn your 3D renderings into \"hand drawn\" looking illustrations."
    },
    {
        "Projects": [],
        "keywords": [
            "ubidaptive"
        ],
        "AcceptDate": "01/08/2007",
        "palwebID": "PR-07-401",
        "Venue": "UNESCO Encyclopedia of Life Support Systems",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-401/FXPAL-PR-07-401.pdf"
        ],
        "PublicationDate": "04/01/2007",
        "ID": "401",
        "Authors": [
            "Bill Schilit",
            "David Hilbert",
            "Jonathan Trevor"
        ],
        "Title": "Context-Aware Telecommunication Services",
        "Abstract": "This chapter describes how the changing information about an individual's location, environment, and social situation can be used to initiate and facilitate people's interactions with one another, individually and in groups. Context-aware communication is contrasted with other forms of context-aware computing and we characterize applications in terms of design decisions along two dimensions: the extent of autonomy in context sensing and the extent of autonomy in communication action. A number of context-aware communication applications from the research literature are presented in five application categories. Finally, a number of issues related to the design of context-aware communication applications are presented."
    },
    {
        "Projects": [
            "AnySpot",
            "PIPs"
        ],
        "keywords": [
            "AnySpot",
            "PIPs",
            "ubidaptive"
        ],
        "AcceptDate": "08/08/2006",
        "palwebID": "PR-07-402",
        "Venue": "IEEE Pervasive Computing Magazine, Vol. 6, No. 3, Jul-Sep 2007.",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-402/FXPAL-PR-07-402.pdf"
        ],
        "PublicationDate": "07/01/2007",
        "ID": "402",
        "Authors": [
            "Jonathan Trevor",
            "David Hilbert"
        ],
        "Title": "AnySpot: Pervasive document access and sharing",
        "Abstract": "AnySpot is a web service-based platform for seamlessly connecting people to their personal and shared documents wherever they go.  We describe the principles behind AnySpot's design and report our experience deploying it in a large, multi-national organization."
    },
    {
        "Projects": [
            "USE"
        ],
        "keywords": [
            "USE"
        ],
        "AcceptDate": "09/25/2006",
        "palwebID": "PR-07-403",
        "Venue": "Book chapter in: A Document (Re)turn. Contributions from a Research Field in Transition (Taschenbuch), Roswitha Skare, Niels Windfeld Lund, Andreas V\u00c3\u00a5rheim (eds.), Peter Lang Publishing, Incorporated, 2007.",
        "palwebURL": [],
        "PublicationDate": "02/19/2007",
        "ID": "403",
        "Authors": [
            "Maribeth Back",
            "Daniel Billsus",
            "Laurent Denoue",
            "David Hilbert"
        ],
        "Title": "Designing complex document sharing spaces: a research vision of next-generation conference rooms",
        "Abstract": "When people are checking in to flights, making reports to their company manager, composing music, delivering papers for exams in schools, or examining patients in hospitals, they all deal with documents and processes of documentation. In earlier times, documentation took place primarily in libraries and archives. While the latter are still important document institutions, documents today play a far more essential role in social life in many different domains and cultures. In this book, which celebrates the ten year anniversary of documentation studies in Troms\u00c3\u00b8, experts from many different disciplines, professional domains as well as cultures around the world present their way of dealing with documents, demonstrating many potential directions for the emerging broad field of documentation studies."
    },
    {
        "Projects": [],
        "keywords": [
            "DOTS"
        ],
        "AcceptDate": "06/05/2007",
        "palwebID": "PR-07-404",
        "Venue": "ICME 2007, pp. 1015-1018",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-404/FXPAL-PR-07-404.pdf"
        ],
        "PublicationDate": "07/02/2007",
        "ID": "404",
        "Authors": [
            "Don Kimber",
            "Tony Dunnigan",
            "Andreas Girgensohn",
            "Frank Shipman",
            "Thea Turner",
            "Tao Yang"
        ],
        "Title": "Trailblazing: Video Playback Control by Direct Object Manipulation",
        "Abstract": "We describe a new interaction technique that allows users to control nonlinear video playback by directly manipulating objects seen in the video. This interaction technique is simi-lar to video \"scrubbing\" where the user adjusts the playback time by moving the mouse along a slider. Our approach is superior to variable-scale scrubbing in that the user can con-centrate on interesting objects and does not have to guess how long the objects will stay in view. Our method relies on a video tracking system that tracks objects in fixed cameras, maps them into 3D space, and handles hand-offs between cameras. In addition to dragging objects visible in video windows, users may also drag iconic object representations on a floor plan. In that case, the best video views are se-lected for the dragged objects."
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [
            "surveillance",
            "tracking"
        ],
        "AcceptDate": "07/02/2007",
        "palwebID": "PR-07-405",
        "Venue": "ICME 2007, pp. 675-678",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-405/FXPAL-PR-07-405.pdf"
        ],
        "PublicationDate": "07/02/2007",
        "ID": "405",
        "Authors": [
            "Tao Yang",
            "Francine Chen",
            "Don Kimber",
            "Jim Vaughan"
        ],
        "Title": "Robust People Detection and Tracking in a Multi-camera Indoor Visual Surveillance System",
        "Abstract": "In this paper we describe the analysis component of an indoor, real-time, multi-camera surveillance system. The analysis includes: (1) a novel feature-level foreground segmentation method which achieves efficient and reliable segmentation results even under complex conditions, (2) an efficient greedy search based approach for tracking multiple people through occlusion, and (3) a method for multi-camera handoff that associates individual trajectories in adjacent cameras. The analysis is used for an 18 camera surveillance system that has been running continuously in an indoor business over the past several months. Our experiments demonstrate that the processing method for people detection and tracking across multiple cameras is fast and robust."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/06/2007",
        "palwebID": "PR-07-406",
        "Venue": "ICME 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-406/FXPAL-PR-07-406.pdf"
        ],
        "PublicationDate": "07/02/2007",
        "ID": "406",
        "Authors": [
            "Chang Hu",
            "Qiong Liu",
            "Xuemin Liu",
            "Paul McEvoy"
        ],
        "Title": "POEMS: A Paper Based Meeting Service Management Tool",
        "Abstract": "As more and more tools are developed for meeting support\r\ntasks, properly using these tools to get expected results\r\nbecomes too complicated for many meeting participants. To\r\naddress this problem, we propose POEMS (Paper Offered\r\nEnvironment Management Service) that allows meeting\r\nparticipants to control services in a meeting environment\r\nthrough a digital pen and an environment photo on digital\r\npaper. Unlike state-of-the-art device control interfaces that\r\nrequire interaction with text commands, buttons, or other\r\nartificial symbols, our photo enabled service access is more\r\nintuitive. Compared with PC and PDA supported control,\r\nthis new approach is more flexible and cheap. With this\r\nsystem, a meeting participant can initiate a whiteboard on a\r\nselected public display by tapping the display image in the\r\nphoto, or print out a display by drawing a line from the\r\ndisplay image to a printer image in the photo. The user can\r\nalso control video or other active applications on a display\r\nby drawing a link between a printed controller and the image\r\nof the display. This paper presents the system architecture,\r\nimplementation tradeoffs, and various meeting control\r\nscenarios."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/06/2007",
        "palwebID": "PR-07-407",
        "Venue": "ICME 2007",
        "palwebURL": [],
        "PublicationDate": "07/02/2007",
        "ID": "407",
        "Authors": [
            "Qiong Liu",
            "Xuemin Liu",
            "Chang Hu"
        ],
        "Title": "Pen based meeting service control (demo)",
        "Abstract": "As more and more tools are developed for meeting support\r\ntasks, properly using these tools to get expected results\r\nbecomes very complicated for many meeting participants.\r\nTo address this problem, we propose POEMS (Paper\r\nOffered Environment Management Service) that can\r\nfacilitate the activation of various services with a pen and\r\npaper based interface. With this tool, meeting participants\r\ncan control meeting support devices on the same paper that\r\nthey take notes. Additionally, a meeting participant can also\r\nshare his/her paper drawings on a selected public display or\r\ninitiate a collaborative discussion on a selected public\r\ndisplay with a page of paper. Compared with traditional\r\ninterfaces, such as tablet PC or PDA based interfaces, the\r\ninterface of this tool has much higher resolution and is much cheaper and easier to deploy. The paper interface is also natural to use for ordinary people."
    },
    {
        "Projects": [
            "DICE",
            "USE"
        ],
        "keywords": [
            "Meeting rooms",
            "mobile interaction",
            "tangible interaction",
            "sensing",
            "ubiquitous computing",
            "smart conference rooms",
            "meeting support",
            "rich media",
            "context-aware computing",
            "collaboration",
            "knowledge management",
            "multimedia",
            "tele-conferencing",
            "active learning",
            "interactive furniture",
            "USE",
            "DICE"
        ],
        "AcceptDate": "05/15/2007",
        "palwebID": "PR-07-408",
        "Venue": "Workshop at Ubicomp 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-408/FXPAL-PR-07-408.pdf"
        ],
        "PublicationDate": "09/16/2007",
        "ID": "408",
        "Authors": [
            "Maribeth Back",
            "Saadi Lahlou",
            "Scott Carter",
            "Masatomi Inagaki",
            "Kazunori Horikiri",
            "Jef Huang"
        ],
        "Title": "Embodied Meeting Support: Mobile, Tangible, Senseable Interaction in Smart Environments",
        "Abstract": "The past two years at UbiComp, our workshops on design and usability in next generation conference rooms engendered lively conversations in the community of people working in smart environments. The community is clearly vital and growing. This year we would like to build on the energy from previous workshops while taking on a more interactive and exploratory format. The theme for this workshop is \"embodied meeting support\" and includes three tracks: mobile interaction, tangible interaction, and sensing in smart environments. We encourage participants to present work that focuses on one track or that attempts to bridge multiple tracks."
    },
    {
        "Projects": [],
        "keywords": [
            "Multiple display systems",
            "slideshows",
            "gesture interfaces",
            "ModSlideShow"
        ],
        "AcceptDate": "04/27/2007",
        "palwebID": "PR-07-409",
        "Venue": "Pervasive 2007 Invited Demo.",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-409/FXPAL-PR-07-409.pdf"
        ],
        "PublicationDate": "05/13/2007",
        "ID": "409",
        "Authors": [
            "Patrick Chiu",
            "Surapong Lertsithichai",
            "Qiong Liu"
        ],
        "Title": "Interaction Models for Multi-Display Slideshows.",
        "Abstract": "We present an investigation of interaction models for slideshow applications in a multi-display\r\nenvironment. Three models are examined: Direct Manipulation, Billiard Ball, and Flow. These\r\nconcepts can be demonstrated by the ModSlideShow prototype, which is designed as a configurable\r\nmodular display system where each display unit communicates with its neighbors and fundamental\r\noperations that act locally can be composed to support the higher level interaction models. We also\r\ndescribe the gesture input scheme, animation feedback, and other enhancements."
    },
    {
        "Projects": [],
        "keywords": [
            "video",
            "summarization",
            "trecvid",
            "multimediasearch",
            "rushes",
            "videosummarization"
        ],
        "AcceptDate": "09/28/2007",
        "palwebID": "PR-07-410",
        "Venue": "TRECVID Video Summarization Workshop at ACM Multimedia 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-410/FXPAL-PR-07-410.pdf"
        ],
        "PublicationDate": "09/28/2007",
        "ID": "410",
        "Authors": [
            "Francine Chen",
            "Matthew Cooper",
            "John Adcock"
        ],
        "Title": "Video Summarization Preserving Dynamic Content",
        "Abstract": "This paper describes a system for selecting excerpts from\r\nunedited video and presenting the excerpts in a short sum-\r\nmary video for e\u000eciently understanding the video contents.\r\nColor and motion features are used to divide the video into\r\nsegments where the color distribution and camera motion\r\nare similar. Segments with and without camera motion are\r\nclustered separately to identify redundant video. Audio fea-\r\ntures are used to identify clapboard appearances for exclu-\r\nsion. Representative segments from each cluster are selected\r\nfor presentation. To increase the original material contained\r\nwithin the summary and reduce the time required to view\r\nthe summary, selected segments are played back at a higher\r\nrate based on the amount of detected camera motion in the\r\nsegment. Pitch-preserving audio processing is used to bet-\r\nter capture the sense of the original audio. Metadata about\r\neach segment is overlayed on the summary to help the viewer\r\nunderstand the context of the summary segments in the orig-\r\ninal video."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [
            "DOTS",
            "video surveillance",
            "multiple video streams",
            "security cameras",
            "person tracking"
        ],
        "AcceptDate": "08/15/2007",
        "palwebID": "PR-07-411",
        "Venue": "ACM Multimedia 2007, pp. 423-432",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-411/FXPAL-PR-07-411.pdf"
        ],
        "PublicationDate": "09/24/2007",
        "ID": "411",
        "Authors": [
            "Andreas Girgensohn",
            "Don Kimber",
            "Jim Vaughan",
            "Tao Yang",
            "Frank Shipman",
            "Thea Turner",
            "Eleanor Rieffel",
            "Lynn Wilcox",
            "Francine Chen",
            "Tony Dunnigan"
        ],
        "Title": "DOTS: Support for Effective Video Surveillance",
        "Abstract": "DOTS (Dynamic Object Tracking System) is an indoor, real-time, multi-camera surveillance system, deployed in a real office setting. DOTS combines video analysis and user interface components to enable security personnel to effectively monitor views of interest and to perform tasks such as tracking a person. The video analysis component performs feature-level foreground segmentation with reliable results even under complex conditions. It incorporates an efficient greedy-search approach for tracking multiple people through occlusion and combines results from individual cameras into multi-camera trajectories. The user interface draws the users' attention to important events that are indexed for easy reference. Different views within the user interface provide spatial information for easier navigation. DOTS, with over twenty video cameras installed in hallways and other public spaces in our office building, has been in constant use for a year. Our experiences led to many changes that improved performance in all system components."
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "TRECVID",
            "media annotation",
            "conditional random fields"
        ],
        "AcceptDate": "06/29/2007",
        "palwebID": "PR-07-412",
        "Venue": "IEEE Intl. Conf. on Semantic Computing",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-412/FXPAL-PR-07-412.pdf"
        ],
        "PublicationDate": "09/17/2007",
        "ID": "412",
        "Authors": [
            "Matthew Cooper"
        ],
        "Title": "Collective Media Annotation using Random Field\r\nModels",
        "Abstract": "We present methods for semantic annotation of multimedia data. The goal is to detect semantic attributes (also referred to as concepts) in clips of video via analysis of a single keyframe or set of frames. The proposed methods integrate high performance discriminative single concept detectors in a random field model for collective multiple concept detection. Furthermore, we describe a generic framework for semantic media classification capable of\r\ncapturing arbitrary complex dependencies between the semantic concepts.  Finally, we present initial experimental results comparing the proposed approach to existing methods."
    },
    {
        "Projects": [],
        "keywords": [
            "DOTS"
        ],
        "AcceptDate": "07/09/2007",
        "palwebID": "PR-07-413",
        "Venue": "ICDSC 2007, pp. 132-139",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-413/FXPAL-PR-07-413.pdf"
        ],
        "PublicationDate": "09/25/2007",
        "ID": "413",
        "Authors": [
            "Eleanor Rieffel",
            "Andreas Girgensohn",
            "Don Kimber",
            "Trista Chen",
            "Qiong Liu"
        ],
        "Title": "Geometric Tools for Multicamera Surveillance Systems",
        "Abstract": "Our analysis and visualization tools use 3D building geometry\r\nto support surveillance tasks. These tools are part of DOTS,\r\nour multicamera surveillance system; a system with over 20\r\ncameras spread throughout the public spaces of our building.\r\nThe geometric input to DOTS is a floor plan and information\r\nsuch as cubicle wall heights. From this input we construct\r\na 3D model and an enhanced 2D floor plan that are the bases\r\nfor more specific visualization and analysis tools. Foreground\r\nobjects of interest can be placed within these models and dynamically\r\nupdated in real time across camera views. Alternatively,\r\na virtual first-person view suggests what a tracked person\r\ncan see as she moves about. Interactive visualization tools\r\nsupport complex camera-placement tasks. Extrinsic camera\r\ncalibration is supported both by visualizations of parameter\r\nadjustment results and by methods for establishing correspondences\r\nbetween image features and the 3D model."
    },
    {
        "Projects": [
            "mTable"
        ],
        "keywords": [
            "PhotoPlay",
            "mTable",
            "photo tagging",
            "computer game"
        ],
        "AcceptDate": "10/07/2007",
        "palwebID": "PR-07-414",
        "Venue": "UIST 2007 Poster & Demo",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-414/FXPAL-PR-07-414.pdf"
        ],
        "PublicationDate": "10/07/2007",
        "ID": "414",
        "Authors": [
            "Nick Diakopoulos",
            "Patrick Chiu"
        ],
        "Title": "PhotoPlay: A Collocated Collaborative Photo Tagging Game on a Horizontal Display",
        "Abstract": "We are exploring the use of collaborative games to generate meaningful textual tags for photos. We have designed Pho-toPlay to take advantage of the social engagement typical of board games and provide a collocated ludic environment conducive to the creation of text tags. We evaluated Photo-Play and found that it was fun and socially engaging for players. The milieu of the game also facilitated playing with personal photos, which resulted in more specific tags such as named entities than when playing with randomly selected online photos. Players also had a preference for playing with personal photos.  "
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "TRECVID",
            "MediaMagic",
            "video search"
        ],
        "AcceptDate": "05/15/2007",
        "palwebID": "PR-07-415",
        "Venue": "ACM Conf. on Image and Video Retrieval 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-415/FXPAL-PR-07-415.pdf"
        ],
        "PublicationDate": "07/29/2007",
        "ID": "415",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "Francine Chen"
        ],
        "Title": "FXPAL MediaMagic Video Search System",
        "Abstract": "This paper describes FXPAL's interactive video search application, \"MediaMagic\". FXPAL has participated in the TRECVID interactive search task since 2004. In our search application we employ a rich set of redundant visual cues to help the searcher quickly sift through the video collection. A central element of the interface and underlying search engine is a segmentation of the video into stories, which allows the user to quickly navigate and evaluate the relevance of moderately-sized, semantically-related chunks."
    },
    {
        "Projects": [],
        "keywords": [
            "Computer Vision",
            "Articulated Body Tracking",
            "Multi-core"
        ],
        "AcceptDate": "04/04/2007",
        "palwebID": "PR-07-416",
        "Venue": "ICME 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-416/FXPAL-PR-07-416.pdf"
        ],
        "PublicationDate": "07/02/2007",
        "ID": "416",
        "Authors": [
            "Trista Chen"
        ],
        "Title": "Computer Vision on Multi-core Processors: Articulated Body Tracking",
        "Abstract": "The recent emergence of multi-core processors enables a new trend in the usage of computers. Computer vision applications, which require heavy computation and lots of bandwidth, usually cannot run in real-time. Recent multi-core processors can potentially serve the needs of such workloads. In addition, more advanced algorithms can be developed utilizing the new computation paradigm. In this paper, we study the performance of an articulated body tracker on multi-core processors. The articulated body tracking workload encapsulates most of the important aspects of a computer vision workload. It takes multiple camera inputs of a scene with a single human object, extracts useful features, and performs statistical inference to find the body pose. We show the importance of properly parallelizing the workload in order to achieve great performance: speedups of 26 on 32 cores. We conclude that: (1) data-domain parallelization is better than function-domain parallelization for computer vision applications; (2) data-domain parallelism by image regions and particles is very effective; (3) reducing serial code in edge detection brings significant performance improvements; (4) domain knowledge about low/mid/high level of vision computation is helpful in parallelizing the workload."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-07-417",
        "Venue": "ICME 2007",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-417/FXPAL-PR-07-417.pdf"
        ],
        "PublicationDate": "07/02/2007",
        "ID": "417",
        "Authors": [
            "Feng Guo",
            "Don Kimber",
            "Eleanor Rieffel"
        ],
        "Title": "Featured Wand for 3D Interaction",
        "Abstract": "Our featured wand, automatically tracked by video cameras,\r\nprovides an inexpensive and natural way for users to interact\r\nwith devices such as large displays. The wand supports\r\nsix degrees of freedom for manipulation of 3D applications\r\nlike Google Earth. Our system uses a 'line scan' to estimate\r\nthe wand pose tracking which simplifies processing. Several\r\napplications are demonstrated."
    },
    {
        "Projects": [],
        "keywords": [
            "Collaboration support",
            "control through image",
            "control through\r\nvideo",
            "control with a cell phone",
            "control with a digital pen",
            "remote\r\ncontrol",
            "collaborative and automatic camera control",
            "teleinteraction",
            "presentation authoring",
            "device control",
            "gesture based\r\ncamera control",
            "video production",
            "video communication",
            "video\r\nconferencing",
            "webcams",
            "collaborative device control",
            "distance\r\nlearning",
            "interactive image/video."
        ],
        "AcceptDate": "11/12/2007",
        "palwebID": "PR-07-418",
        "Venue": "The 3rd International Conference on Collaborative Computing:\r\nNetworking, Applications and Worksharing",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-418/FXPAL-PR-07-418.pdf"
        ],
        "PublicationDate": "11/12/2007",
        "ID": "418",
        "Authors": [
            "Qiong Liu",
            "Don Kimber",
            "Patrick Chiu"
        ],
        "Title": "Collaboration Support Using Environment Images and Videos",
        "Abstract": "This paper summarizes our environment-image/videosupported\r\ncollaboration technologies developed in the past\r\nseveral years. These technologies use environment images and\r\nvideos as active interfaces and use visual cues in these images and\r\nvideos to orient device controls, annotations and other\r\ninformation access. By using visual cues in various interfaces, we\r\nexpect to make the control interface more intuitive than buttonbased\r\ncontrol interfaces and command-based interfaces. These\r\ntechnologies can be used to facilitate high-quality audio/video\r\ncapture with limited cameras and microphones. They can also\r\nfacilitate multi-screen presentation authoring and playback, teleinteraction,\r\nenvironment manipulation with cell phones, and\r\nenvironment manipulation with digital pens."
    },
    {
        "Projects": [],
        "keywords": [
            "Device Pairing",
            "Evil Twin",
            "Usable Security",
            "Wireless Security"
        ],
        "AcceptDate": "03/31/2008",
        "palwebID": "PR-08-428",
        "Venue": "Proceedings ACM WiSec, pp. 220-235, 2008 ",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-428/FXPAL-PR-08-428.pdf"
        ],
        "PublicationDate": "03/31/2008",
        "ID": "428",
        "Authors": [
            "Volker Roth",
            "Wolfgang Polak",
            "Eleanor Rieffel",
            "Thea Turner"
        ],
        "Title": "Simple and Effective Defense Against Evil Twin Access Points",
        "Abstract": "Wireless networking is becoming widespread in many public places\r\nsuch as cafes.  Unsuspecting users may become victims of attacks\r\nbased on ``evil twin'' access points.  These rogue access points are\r\noperated by criminals in an attempt to launch\r\nman-in-the-middle attacks.  We present a simple protection\r\nmechanism against binding to an evil twin.  The mechanism leverages\r\nshort authentication string protocols for the exchange of\r\ncryptographic keys.  The short string verification is performed by\r\nencoding the short strings as a sequence of colors, rendered\r\nsequentially by the user's device and by the designated access point\r\nof the cafe.  The access point must have a light capable of\r\nshowing two colors and must be mounted prominently in a position\r\nwhere users can have confidence in its authenticity.  We conducted a\r\nusability study with patrons in several cafes and participants\r\nfound our protection mechanism very usable.\r\n\r\n"
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch",
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "video search",
            "collaborative search",
            "video",
            "search"
        ],
        "AcceptDate": "03/28/2008",
        "palwebID": "PR-08-431",
        "Venue": "ACM Conf. on Image and Video Retrieval (CIVR) 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-431/FXPAL-PR-08-431.pdf"
        ],
        "PublicationDate": "07/07/2008",
        "ID": "431",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "Jeremy Pickens"
        ],
        "Title": "Experiments in Interactive Video Search by Addition and Subtraction",
        "Abstract": "We have developed an interactive video search system that\r\nallows the searcher to rapidly assess query results and easily pivot on those results to form new queries. The system is intended to maximize the use of the discriminative power of the human searcher. This is accomplished by providing a hierarchical segmentation, streamlined interface, and redundant visual cues throughout. The typical search scenario includes a single searcher with the ability to search with text and content-based queries. In this paper, we evaluate new variations on our basic search system. In particular we test the system using only visual content-based search capabilities, and using paired searchers in a realtime collaboration. We present analysis and conclusions from these experiments."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch",
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "video search",
            "collaborative search",
            "search",
            "video",
            "collaborative",
            "CES"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-432",
        "Venue": "CIVR 2008 VideOlympics (Demo)",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-432/FXPAL-PR-08-432.pdf"
        ],
        "PublicationDate": "07/07/2008",
        "ID": "432",
        "Authors": [
            "John Adcock",
            "Jeremy Pickens"
        ],
        "Title": "FXPAL Collaborative Exploratory Video Search System",
        "Abstract": "This paper describes FXPAL's collaborative, exploratory\r\ninteractive video search application. We introduce a new\r\napproach to information retrieval: algorithmic mediation in\r\nsupport of intentional, synchronous collaborative exploratory\r\nsearch. Using our system, two or more users with a common\r\ninformation need search together, simultaneously. The\r\ncollaborative system provides tools, user interfaces and, most\r\nimportantly, algorithmically-mediated retrieval to focus, enhance\r\nand augment the team's search and communication activities."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [
            "CES"
        ],
        "AcceptDate": "11/02/2007",
        "palwebID": "PR-07-433",
        "Venue": "HCIR 2007, Boston, Massachusetts (HCIR = Human Computer Interaction and Information Retrieval)\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-433/FXPAL-PR-07-433.pdf"
        ],
        "PublicationDate": "11/02/2007",
        "ID": "433",
        "Authors": [
            "Jeremy Pickens",
            "Gene Golovchinsky"
        ],
        "Title": "Collaborative Exploratory Search",
        "Abstract": "We propose to mitigate the deficiencies of correlated search with collaborative search, that is, search in which a small group of people shares a common information need and actively (and synchronously) collaborates to achieve it. Furthermore, we propose a system architecture that mediates search activity of multiple people by combining their inputs and by specializing results delivered to them to take advantage of their skills and knowledge.\r\n"
    },
    {
        "Projects": [],
        "keywords": [
            "Collaborative Search",
            "Exploratory Search",
            "Multimedia Search",
            "MediaMagic",
            "CES",
            "trecvid",
            "TRECVID",
            "videosummarization"
        ],
        "AcceptDate": "11/01/2007",
        "palwebID": "PR-08-434",
        "Venue": "TRECVid 2007",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-434/FXPAL-PR-08-434.pdf"
        ],
        "PublicationDate": "03/01/2008",
        "ID": "434",
        "Authors": [
            "John Adcock",
            "Jeremy Pickens",
            "Matthew Cooper",
            "Francine Chen",
            "Pernilla Qvarfordt"
        ],
        "Title": "FXPAL Interactive Search Experiments for TRECVID 2007",
        "Abstract": "In 2007 FXPAL submitted results for two tasks: rushes summarization and interactive search. The rushes summarization task has been described at the ACM Multimedia workshop. Interested readers are referred to that publication for details. We describe our interactive search experiments in this notebook paper."
    },
    {
        "Projects": [
            "Hyper-Hitchcock"
        ],
        "keywords": [
            "Hypervideo",
            "video summarization",
            "link generation",
            "video editing"
        ],
        "AcceptDate": "01/22/2008",
        "palwebID": "PR-09-435",
        "Venue": "ACM Transactions on Multimedia Computing, Communications and Applications, Vol. 5, Issue 2",
        "palwebURL": [],
        "PublicationDate": "05/01/2009",
        "ID": "435",
        "Authors": [
            "Frank Shipman",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Authoring, Viewing, and Generating Hypervideo: An Overview of Hyper-Hitchcock",
        "Abstract": "Hyper-Hitchcock consists of three components for creating and viewing a form of interactive video called detail-on-demand video: a hypervideo editor, a hypervideo player, and algorithms for automatically generating hypervideo summaries. Detail-on-demand video is a form of hypervideo that supports one hyperlink at a time for navigating between video sequences. The Hyper-Hitchcock editor enables authoring of detail-on-demand video without programming and uses video processing to aid in the authoring process. The Hyper-Hitchcock player uses labels and keyframes to support navigation through and back hyperlinks. Hyper-Hitchcock includes techniques for automatically generating hypervideo summaries of one or more videos that take the form of multiple linear summaries of different lengths with links from the shorter to the longer summaries. User studies on authoring and viewing provided insight into the various roles of links in hypervideo and found that player interface design greatly affects people's understanding of hypervideo structure and the video they access."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/09/2008",
        "palwebID": "PR-08-443",
        "Venue": "IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-443/FXPAL-PR-08-443.pdf"
        ],
        "PublicationDate": "06/24/2008",
        "ID": "443",
        "Authors": [
            "Abhinav Gupta",
            "Trista Chen",
            "Francine Chen",
            "Don Kimber",
            "Larry Davis"
        ],
        "Title": "Context and Observation Driven Latent Variable Model for Human Pose Estimation",
        "Abstract": "Current approaches to pose estimation and tracking can\r\nbe classified into two categories: generative and discriminative. While generative approaches can accurately determine human pose from image observations, they are computationally intractable due to search in the high dimensional human pose space. On the other hand, discriminative approaches do not generalize well, but are computationally efficient. We present a hybrid model that combines the strengths of the two in an integrated learning and inference framework. We extend the Gaussian process latent variable model (GPLVM) to include an embedding from\r\nobservation space (the space of image features) to the latent space. GPLVM is a generative model, but the inclusion\r\nof this mapping provides a discriminative component,\r\nmaking the model observation driven. Observation Driven\r\nGPLVM (OD-GPLVM) not only provides a faster inference\r\napproach, but also more accurate estimates (compared to\r\nGPLVM) in cases where dynamics are not sufficient for the\r\ninitialization of search in the latent space.\r\n\r\nWe also extend OD-GPLVM to learn and estimate poses\r\nfrom parameterized actions/gestures. Parameterized gestures\r\nare actions which exhibit large systematic variation\r\nin joint angle space for different instances due to difference in contextual variables. For example, the joint angles in a forehand tennis shot are function of the height of the ball (Figure 2). We learn these systematic variations as a function of the contextual variables. We then present an approach to use information from scene/object to provide\r\ncontext for human pose estimation for such parameterized\r\nactions."
    },
    {
        "Projects": [],
        "keywords": [
            "Passive Thermal Video",
            "Infrared",
            "Vital Sign Esimation"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-444",
        "Venue": "IEEE Computer Society Conference on Computer Vision and Pattern Recognition",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-444/FXPAL-PR-08-444.pdf"
        ],
        "PublicationDate": "06/24/2008",
        "ID": "444",
        "Authors": [
            "Ming Yang",
            "Qiong Liu",
            "Thea Turner",
            "Y Wu"
        ],
        "Title": "Vital Sign Estimation from Passive Thermal Video",
        "Abstract": "Conventional wired detection of vital signs limits the\r\nuse of these important physiological parameters by many\r\napplications, such as airport health screening, elder care,\r\nand workplace preventive care. In this paper, we explore\r\ncontact-free heart rate and respiratory rate detection\r\nthrough measuring infrared light modulation emitted near\r\nsuperficial blood vessels or a nasal area respectively. To\r\ndeal with complications caused by subjects' movements,\r\nfacial expressions, and partial occlusions of the skin, we\r\npropose a novel algorithm based on contour segmentation\r\nand tracking, clustering of informative pixels, and dominant\r\nfrequency component estimation. The proposed method\r\nachieves robust subject regions-of-interest alignment and\r\nmotion compensation in infrared video with low SNR. It relaxes\r\nsome strong assumptions used in previous work and\r\nsubstantially improves on previously reported performance.\r\nPreliminary experiments on heart rate estimation for 20\r\nsubjects and respiratory rate estimation for 8 subjects exhibit promising results."
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [
            "DOTS"
        ],
        "AcceptDate": "09/01/2007",
        "palwebID": "PR-07-445",
        "Venue": "Fuji Xerox Technical Report No. 17, pp. 83-100",
        "palwebURL": [
            "http://palweb/files/PR/2007/PR-07-445/FXPAL-PR-07-445.pdf"
        ],
        "PublicationDate": "11/01/2007",
        "ID": "445",
        "Authors": [
            "Andreas Girgensohn",
            "Don Kimber",
            "Jim Vaughan",
            "Tao Yang",
            "Frank Shipman",
            "Thea Turner",
            "Eleanor Rieffel",
            "Lynn Wilcox",
            "Francine Chen",
            "Tony Dunnigan"
        ],
        "Title": "DOTS: Support for Effective Video Surveillance",
        "Abstract": "DOTS (Dynamic Object Tracking System) is an indoor, real-time, multi-camera surveillance system, deployed in a real office setting. DOTS combines video analysis and user interface components to enable security personnel to effectively monitor views of interest and to perform tasks such as tracking a person. The video analysis component performs feature-level foreground segmentation with reliable results even under complex conditions. It incorporates an efficient greedy-search approach for tracking multiple people through occlusion and combines results from individual cameras into multi-camera trajectories. The user interface draws the users' attention to important events that are indexed for easy reference. Different views within the user interface provide spatial information for easier navigation. DOTS, with over twenty video cameras installed in hallways and other public spaces in our office building, has been in constant use for a year. Our experiences led to many changes that improved performance in all system components."
    },
    {
        "Projects": [],
        "keywords": [
            "ebooks"
        ],
        "AcceptDate": "",
        "palwebID": "PR-02-448",
        "Venue": "Journal of Library Administration, 35:1-2, 99-123, Haworth",
        "palwebURL": [],
        "PublicationDate": "06/07/2002",
        "ID": "448",
        "Authors": [
            "Allen Renear",
            "Gene Golovchinsky"
        ],
        "Title": "Content Standards for Electronic Books: The OEBF Publication Structure and the Role of the Public Interest",
        "Abstract": "In the emerging world of electronic publishing how we create, distribute, and read books will be in a large part determined by an underlying framework of content standards that establishes the range of technological opportunities and constraints for publishing and reading systems. But efforts to develop content standards based on sound engineering models must skillfully negotiate competing and sometimes apparently irreconcilable objectives if they are to produce results relevant to the rapidly changing course of technology. The Open eBook Forum's Publication Structure, an XML-based specification for electronic books, is an example of the sort of timely and innovative problem solving required for successful real-world standards development. As a result of this effort, the electronic book industry will not only happen sooner and on a larger scale than it would have otherwise, but the electronic books it produces will be more functional, more interoperable, and more accessible to all readers. Public interest participants have a critical role in this process."
    },
    {
        "Projects": [
            "ProjectorBox"
        ],
        "keywords": [
            "pbox"
        ],
        "AcceptDate": "05/30/2008",
        "palwebID": "PR-08-451",
        "Venue": "IADIS e-Learning 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-451/FXPAL-PR-08-451.pdf"
        ],
        "PublicationDate": "07/22/2008",
        "ID": "451",
        "Authors": [
            "David Hilbert",
            "Thea Turner",
            "Laurent Denoue",
            "Kandha Sankarapandian"
        ],
        "Title": "Autonomous presentation capture in corporate and educational settings",
        "Abstract": "While researchers have been exploring automatic presentation capture since the 1990's, real world adoption has been limited. Our research focuses on simplifying presentation capture and retrieval to reduce adoption barriers. ProjectorBox is our attempt to create a smart appliance that seamlessly captures, indexes, and archives presentation media, with streamlined user interfaces for searching, skimming, and sharing content. In this paper we describe the design of ProjectorBox and compare its use across corporate and educational settings. While our evaluation confirms the usability and utility of our approach across settings, it also highlights differences in usage and user needs, suggesting enhancements for both markets. We describe new features we have implemented to address corporate needs for enhanced privacy and security, and new user interfaces for content discovery. "
    },
    {
        "Projects": [],
        "keywords": [
            "CES",
            "Information seeking",
            "collaboration",
            "CSCW"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-452",
        "Venue": "Information Seeking Support Systems Workshop. \r\nAn Invitational Workshop Sponsored by the National Science Foundation. Available online at http://www.ils.unc.edu/ISSS/",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-452/FXPAL-PR-08-452.pdf"
        ],
        "PublicationDate": "06/26/2008",
        "ID": "452",
        "Authors": [
            "Gene Golovchinsky",
            "Jeremy Pickens"
        ],
        "Title": "Collaborative Information Seeking in Electronic Environments\r\n",
        "Abstract": "Collaboration in information seeking, while common in practice, is just being recognized as an important research area. Several studies have documented various collaboration strategies that people have adopted (and adapted), and some initial systems have been built. This field is in its infancy, however. We need to understand which real-world tasks are best suited for collaborative work. We need to extend models of information seeking to accommodate explicit and implicit collaboration. We need to invent a suite of algorithms to mediate search activities. We need to devise evaluation metrics that take into account multiple people's contributions to search."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [
            "CES",
            "Collaborative Exploratory Search",
            "CSCW",
            "Information Seeking"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-453",
        "Venue": "JCDL 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-453/FXPAL-PR-08-453.pdf"
        ],
        "PublicationDate": "06/20/2008",
        "ID": "453",
        "Authors": [
            "Jeremy Pickens",
            "Gene Golovchinsky",
            "Meredith Ringel Morris"
        ],
        "Title": "1st International Workshop on \r\nCollaborative Information Retrieval",
        "Abstract": "Explicit support for collaboration is becoming increasingly important for certain kinds of collection-building activities in digital libraries. In the last few years, several research groups have also pursued various issues related to collaboration during search [4][5][6]. We can represent collaboration in search on two dimensions - synchrony and intent. Asynchronous collaboration means that people are not working on the same problem simultaneously; implicit collaboration occurs when the system uses information from others' use of the system to inform new searches, but does not guarantee consistency of search goals. In this workshop, we are concerned with the top-left quadrant of Figure 1 that represents small groups of people working toward a common goal at the same time. These synchronous, explicit collaborations could occur amongst remotely situated users, each with their own computers, or amongst a co-located group sharing devices; these spatial configurations add yet another dimension to be considered when designing collaborative search systems."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [
            "CES",
            "Information seeking",
            "collaboration",
            "CSCW",
            "taxonomy"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-454",
        "Venue": "1st International Workshop on Collaborative Information Retrieval. JCDL 2008.",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-454/FXPAL-PR-08-454.pdf"
        ],
        "PublicationDate": "06/20/2008",
        "ID": "454",
        "Authors": [
            "Gene Golovchinsky",
            "Jeremy Pickens",
            "Maribeth Back"
        ],
        "Title": "A Taxonomy of Collaboration in \r\nOnline Information Seeking\r\n",
        "Abstract": "People can help other people find information in networked information seeking environments. Recently, many such systems and algorithms have proliferated in industry and in academia. Unfortunately, it is difficult to compare the systems in meaningful ways because they often define collaboration in different ways. In this paper, we propose a model of possible kinds of collaboration, and illustrate it with examples from literature. The model contains four dimensions: intent, concurrency, depth and location. This model can be used to classify existing systems and to suggest possible opportunities for design in this space."
    },
    {
        "Projects": [
            "Kartta"
        ],
        "keywords": [
            "mobile",
            "media capture",
            "location-aware",
            "seamless"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-455",
        "Venue": "Social Mobile Media Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-455/FXPAL-PR-08-455.pdf"
        ],
        "PublicationDate": "08/01/2008",
        "ID": "455",
        "Authors": [
            "Scott Carter",
            "Arttu Perttula"
        ],
        "Title": "Retrospective vs. Prospective: A comparison of two approaches to mobile media capture and access",
        "Abstract": "Mobile media applications need to balance user and group goals, attentional constraints, and limited screen real estate. In this paper, we describe the development and testing of two application sketches designed to explore these tradeoffs. The first is retrospective and time-\r\nbased and the second is prospective and space-based. We found that attentional demands dominate and mobile media applications should therefore be lightweight and hands-free as much as possible."
    },
    {
        "Projects": [
            "AudioPrivacy"
        ],
        "keywords": [
            "surveillance",
            "privacy",
            "monitoring"
        ],
        "AcceptDate": "07/04/2008",
        "palwebID": "PR-08-456",
        "Venue": "ACM Multimedia 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-456/FXPAL-PR-08-456.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "456",
        "Authors": [
            "Francine Chen",
            "John Adcock",
            "Shruti Krishnagiri"
        ],
        "Title": "Audio Privacy: Reducing Speech Intelligibility while Preserving Environmental Sounds",
        "Abstract": "Audio monitoring has many applications but also raises pri-\r\nvacy concerns. In an attempt to help alleviate these con-\r\ncerns, we have developed a method for reducing the intelli-\r\ngibility of speech while preserving intonation and the ability to recognize most environmental sounds. The method is based on identifying vocalic regions and replacing the vocal tract transfer function of these regions with the transfer function from prerecorded vowels, where the identity of the replacement vowel is independent of the identity of the spoken syllable. The audio signal is then re-synthesized using the original pitch and energy, but with the modi\fed vocal tract transfer function. We performed an intelligibility study which showed that environmental sounds remained recognizable but speech intelligibility can be dramatically reduced to a 7% word recognition rate."
    },
    {
        "Projects": [
            "SeamlessDocuments"
        ],
        "keywords": [
            "automatic zooming",
            "document image analysis",
            "document viewing",
            "small displays",
            "seamless"
        ],
        "AcceptDate": "07/08/2008",
        "palwebID": "PR-08-457",
        "Venue": "Proceedings of ACM Multimedia '08, pp. 817-820 (Short Paper).",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-457/FXPAL-PR-08-457.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "457",
        "Authors": [
            "Patrick Chiu",
            "Koichi Fujii",
            "Qiong Liu"
        ],
        "Title": "Content Based Automatic Zooming: Viewing Documents on Small Displays \r\n",
        "Abstract": "We present an automatic zooming technique that leverages content analysis for viewing a document page on a small display such as a mobile phone or PDA. The page can come from a scanned document (bitmap image) or an electronic document (text and graphics data plus metadata). The page with text and graphics is segmented into regions. For each region, a scale-distortion function is constructed based on image analysis of the signal distortion that occurs at different scales.  During interactive viewing of the document, as the user navigates by moving the viewport around the page, the zoom factor is automatically adjusted by optimizing the scale-distortion functions of the regions visible in the viewport."
    },
    {
        "Projects": [],
        "keywords": [
            "tabletop display",
            "multimedia visualization",
            "photo browsing",
            "photo labeling",
            "video browsing"
        ],
        "AcceptDate": "07/08/2008",
        "palwebID": "PR-08-458",
        "Venue": "ACM Multimedia 2008 (Video)",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-458/FXPAL-PR-08-458.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "458",
        "Authors": [
            "Patrick Chiu",
            "Jeffrey Huang",
            "Maribeth Back",
            "Nick Diakopoulos",
            "John Doherty",
            "Wolfgang Polak",
            "Xiaohua Sun"
        ],
        "Title": "mTable: Browsing Photos and Videos on a Tabletop System",
        "Abstract": "In this video demo, we present mTable, a multimedia tabletop system for browsing photo and video collections.  We have developed a set of applications for visualizing and exploring photos, a board game for labeling photos, and a 3D cityscape metaphor for browsing videos.  The system is suitable for use in a living room or office lounge, and can support multiple displays by visualizing the collections on the tabletop and showing full-size images and videos on another flat panel display in the room."
    },
    {
        "Projects": [],
        "keywords": [
            "Collaborative information seeking",
            "collaborative information retrieval",
            "information retrieval",
            "collaboration",
            "collaborative information seeking",
            "CES",
            "collaborative exploratory search",
            "exploratory search"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-460",
        "Venue": "SIGIR 2008. (Singapore, Singapore, July 20 - 24, 2008). ACM, New York, NY, 315-322.",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-460/FXPAL-PR-08-460.pdf"
        ],
        "PublicationDate": "07/22/2008",
        "ID": "460",
        "Authors": [
            "Jeremy Pickens",
            "Gene Golovchinsky",
            "Chirag Shah",
            "Pernilla Qvarfordt",
            "Maribeth Back"
        ],
        "Title": "<img src=\"/images/best.png\" title=\"Best Paper Award\" border=\"0\" /> Algorithmic Mediation for Collaborative Exploratory Search",
        "Abstract": "We describe a new approach to information retrieval: algorithmic mediation for intentional, synchronous collabo-\r\nrative exploratory search. Using our system, two or more\r\nusers with a common information need search together, simultaneously. The collaborative system provides tools, user\r\ninterfaces and, most importantly, algorithmically-mediated\r\nretrieval to focus, enhance and augment the team's search\r\nand communication activities. Collaborative search outperformed post hoc merging of similarly instrumented single\r\nuser runs. Algorithmic mediation improved both collaborative search (allowing a team of searchers to \fnd relevant in-\r\nformation more efficiently and effectively), and exploratory\r\nsearch (allowing the searchers to find relevant information\r\nthat cannot be found while working individually)."
    },
    {
        "Projects": [
            "USE"
        ],
        "keywords": [
            "USE",
            "Multi-display envirnonments",
            "MDE"
        ],
        "AcceptDate": "07/03/2008",
        "palwebID": "PR-08-461",
        "Venue": "Workshop held in conjunction with CSCW2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-461/FXPAL-PR-08-461.pdf"
        ],
        "PublicationDate": "11/08/2008",
        "ID": "461",
        "Authors": [
            "Jacob Biehl",
            "Gene Golovchinsky",
            "Kent Lyons"
        ],
        "Title": "Beyond the Laboratory:\r\nSupporting Authentic Collaboration with Multiple Displays",
        "Abstract": "<p>It is increasingly common to find Multiple Display Environments (MDEs) in a variety of settings, including the workplace, the classroom, and perhaps soon, the home. While some technical challenges exist even in single-user MDEs, collaborative use of MDEs offers a rich set of opportunities for research and development. In this workshop, we will bring together experts in designing, developing, building and evaluating MDEs to improve our collective understanding of design guidelines, relevant real-world activities, evaluation methods and metrics, and opportunities for remote as well as collocated collaboration. We intend to create not only a broader understanding of this growing field, but also to foster a community of researchers interested in bringing these environments from the laboratory to the real world.</p>\r\n\r\n<p>In this workshop, we intended to explore the following research themes:</p>\r\n<ul>\r\n    <li>Elicitation and process of distilling design guidelines for MDE systems and interfaces.</li>\r\n    <li>Investigation and classification of activities suited for MDEs.</li>\r\n    <li>Exploration and assessment of how existing groupware theories apply to collaboration in MDEs.</li>\r\n    <li>Evaluation techniques and metrics for assessing effectiveness of prototype MDE systems and interfaces.</li>\r\n    <li>Exploration of MDE use beyond strictly collocated collaboration.</li>\r\n</ul>"
    },
    {
        "Projects": [
            "PicNTell"
        ],
        "keywords": [
            "screencasting",
            "natural input",
            "multimedia recording and playback",
            "seamless",
            "picntell"
        ],
        "AcceptDate": "07/14/2008",
        "palwebID": "PR-08-462",
        "Venue": "ACM Multimedia 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-462/FXPAL-PR-08-462.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "462",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue"
        ],
        "Title": "PicNTell: A camcorder metaphor for screen recording",
        "Abstract": "PicNTell is a new technique for generating compelling screencasts where users can quickly record desktop activities and generate videos that are embeddable on popular video sharing distributions such as YYouTube\u00c2\u00ae. While standard video editing and screen capture tools are useful for some editing tasks, they have two main drawbacks: (1) they require users to import and organize media in a separate interface, and (2) they do not support natural\r\n(or camcorder-like) screen recording, and instead usually require the user to define a specific region or window to record. In this paper we review current screen recording use, and present the PicNTell system, pilot studies, and a new six degree-of-freedom tracker we are developing in response to our findings."
    },
    {
        "Projects": [
            "SmartRooms"
        ],
        "keywords": [
            "Meeting support",
            "smart conference rooms",
            "design process",
            "evaluation",
            "augmented environments",
            "multimedia",
            "teleconferencing",
            "user centered design",
            "interactive furniture"
        ],
        "AcceptDate": "05/06/2008",
        "palwebID": "PR-08-463",
        "Venue": "Ubicomp 2008 (Workshop)",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-463/FXPAL-PR-08-463.pdf"
        ],
        "PublicationDate": "09/21/2008",
        "ID": "463",
        "Authors": [
            "Maribeth Back",
            "Saadi Lahlou",
            "Kazunori Horikiri",
            "Masatomi Inagaki",
            "Scott Carter",
            "Gerald Morrison"
        ],
        "Title": "UbiMEET: Design and Evaluation of Smart Environments in the Workplace",
        "Abstract": "This workshop is the fourth in a series of UbiComp\r\nworkshops on smart environment technologies and\r\napplications for the workplace. It offers a unique window\r\ninto the state of the art through the participation of a range\r\nof researchers, designers and builders who exchange both\r\nbasic research and real-world case experiences; and invites\r\nparticipants to share ideas about them. This year we focus\r\non understanding appropriate design processes and creating\r\nvalid evaluation metrics for smart environments (a recurrent\r\nrequest from previous workshop participants). What design\r\nprocesses allow integration of new ubicomp-style systems\r\nwith existing technologies in a room that is in daily use?\r\nWhat evaluation methods and metrics give us an accurate\r\npicture, and how can that information best be applied in an\r\niterative design process?"
    },
    {
        "Projects": [
            "SmartRooms"
        ],
        "keywords": [
            "Virtual reality",
            "mobile media",
            "collaboration",
            "smart rooms",
            "augmented environments",
            "meeting practices",
            "ubiquitous displays"
        ],
        "AcceptDate": "07/03/2008",
        "palwebID": "PR-08-464",
        "Venue": "CSCW 2008 (Workshop)",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-464/FXPAL-PR-08-464.pdf"
        ],
        "PublicationDate": "11/08/2008",
        "ID": "464",
        "Authors": [
            "Maribeth Back",
            "Scott Carter",
            "Saadi Lahlou",
            "Kazunori Horikiri",
            "Masatomi Inagaki",
            "Gerald Morrison"
        ],
        "Title": "Remix rooms: Redefining the smart conference room",
        "Abstract": "In this workshop we will explore how the experience of smart conference rooms can be broadened to include different contexts and media such as context-aware mobile systems, personal and professional videoconferencing, virtual worlds, and social software. How should the technologies behind conference room systems reflect the rapidly changing expectations around personal devices and social online spaces like Facebook, Twitter, and Second Life? What kinds of systems are needed to support meetings in technologically complex environments? How can a mashup of conference room spaces and technologies account for differing social and cultural practices around meetings? What requirements are imposed by security and privacy issues in public and semi-public spaces?"
    },
    {
        "Projects": [
            "Interactive Video Search"
        ],
        "keywords": [
            "trecvid",
            "videosummarization",
            "rushes"
        ],
        "AcceptDate": "07/15/2008",
        "palwebID": "PR-08-465",
        "Venue": "ACM Multimedia 2008 Workshop: TrecVid Summarization 2008 (TVS'08)",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-465/FXPAL-PR-08-465.pdf"
        ],
        "PublicationDate": "10/26/2008",
        "ID": "465",
        "Authors": [
            "Francine Chen",
            "John Adcock",
            "Matthew Cooper"
        ],
        "Title": "A Simplified Approach to Rushes Summarization",
        "Abstract": "In this paper we describe methods for video summarization \r\nin the context of the TRECVID 2008 BBC Rushes Summarization task. \r\nColor, motion, and audio features are used to segment, filter, and cluster the video. \r\nWe experiment with varying the segment similarity measure to improve the \r\njoint clustering of segments with and without camera motion.\r\nCompared to our previous effort for TRECVID 2007 we have reduced the \r\ncomplexity of the summarization process as well as the visual complexity of the\r\nsummaries themselves. We find our objective (inclusion) performance to be competitive with systems \r\nexhibiting similar subjective performance."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [
            "Camera enabled user interface",
            "document retrieval",
            "image local features."
        ],
        "AcceptDate": "07/01/2008",
        "palwebID": "PR-08-466",
        "Venue": "ACM Multimedia 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-466/FXPAL-PR-08-466.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "466",
        "Authors": [
            "Qiong Liu",
            "Patrick Chiu",
            "Lynn Wilcox"
        ],
        "Title": "Document Finder",
        "Abstract": "This demo introduces a tool for accessing an e-document by\r\ncapturing one or more images of a real object or document\r\nhardcopy. This tool is useful when a file name or location of the file is unknown or unclear. It can save field workers and office workers from remembering/exploring numerous directories and file names. Frequently, it can convert tedious keyboard typing in a search box to a simple camera click. Additionally, when a remote collaborator cannot clearly see an object or a document hardcopy through remote collaboration cameras, this tool can be used to automatically retrieve and send the original e-document to a remote screen or printer."
    },
    {
        "Projects": [],
        "keywords": [
            "Feature ranking",
            "metasearch",
            "score normalization"
        ],
        "AcceptDate": "07/15/2008",
        "palwebID": "PR-08-467",
        "Venue": "CIKM (Conference on Information and Knowledge Management) 2008, October, Napa, CA",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-467/FXPAL-PR-08-467.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "467",
        "Authors": [
            "Jeremy Pickens",
            "Gene Golovchinsky"
        ],
        "Title": "Ranked Feature Fusion Models for Ad Hoc Retrieval",
        "Abstract": "We introduce the Ranked Feature Fusion framework for information retrieval system design. Typical information retrieval\r\nformalisms such as the vector space model, the best-match model and the language model first combine features (such as\r\nterm frequency and document length) into a unified representation, and then use the representation to rank documents.\r\nWe take the opposite approach: Documents are first ranked by the relevance of a single feature value and are assigned\r\nscores based on their relative ordering within the collection. A separate ranked list is created for every feature\r\nvalue and these lists are then fused to produce a final document scoring. This new ``rank then combine'' approach is\r\nextensively evaluated and is shown to be as effective as traditional ``combine then rank'' approaches.  The model is\r\neasy to understand and contains fewer parameters than other approaches.  Finally, the model is easy to extend\r\n(integration of new features is trivial) and modify. This advantage includes but is not limited to relevance feedback\r\nand distribution flattening.\r\n"
    },
    {
        "Projects": [
            "XLibris"
        ],
        "keywords": [
            "EBooks",
            "annotation",
            "active reading",
            "reading device."
        ],
        "AcceptDate": "08/05/2008",
        "palwebID": "PR-08-468",
        "Venue": "BooksOnline'08, October 30, 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-468/FXPAL-PR-08-468.pdf"
        ],
        "PublicationDate": "10/30/2008",
        "ID": "468",
        "Authors": [
            "Gene Golovchinsky"
        ],
        "Title": "Reading in the Office",
        "Abstract": "Reading online poses a number of technological challenges. Advances in technology such as touch screens, light-weight high-power computers, and bi-stable displays have periodically renewed interest in online reading over the last twenty years, only to see that interest decline to a small early-adopter community. The recent release of the Kindle by Amazon is another attempt to create an online reading device. Has publicity surrounding Kindle and other such devices has reached critical mass to allow them to penetrate the consumer market successfully, or will we see a decline in interest over the next couple of years echoing the lifecycle of Softbook\u00e2\u201e\u00a2 and Rocket eBook\u00e2\u201e\u00a2 devices that preceded them? I argue that the true value of online reading lies in supporting activities beyond reading per se: activities such as annotation, reading and comparing multiple documents, transitions between reading, writing and retrieval, etc. Whether the current hardware will be successful in the long term may depend on its abilities to address the reading needs of knowledge workers, not just leisure readers."
    },
    {
        "Projects": [
            "VideoSurveillance"
        ],
        "keywords": [
            "video surveillance",
            "dots"
        ],
        "AcceptDate": "07/08/2008",
        "palwebID": "PR-08-469",
        "Venue": "ACM Multimedia",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-469/FXPAL-PR-08-469.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "469",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "Determining Activity Patterns in Retail Spaces through Video Analysis",
        "Abstract": "Retail establishments want to know about traffic flow and patterns of activity in order to better arrange and staff their business. A large number of fixed video cameras are commonly installed at these locations. While they can be used to observe activity in the retail environment, assigning personnel to this is too time consuming to be valuable for retail analysis. We have developed video processing and visualization techniques that generate presentations appropriate for examining traffic flow and changes in activity at different times of the day. Taking the results of video tracking software as input, our system aggregates activity in different regions of the area being analyzed, determines the average speed of moving objects in the region, and segments time based on significant changes in the quantity and/or location of activity. Visualizations present the results as heat maps to show activity and object counts and average velocities overlaid on the map of the space."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [
            "CES",
            "Collaborative Search",
            "Demo",
            "Cerchiamo"
        ],
        "AcceptDate": "08/25/2008",
        "palwebID": "PR-08-470",
        "Venue": "CSCW 2008 (Demo), San Diego, CA, ACM Press.",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-470/FXPAL-PR-08-470.pdf"
        ],
        "PublicationDate": "11/10/2008",
        "ID": "470",
        "Authors": [
            "Gene Golovchinsky",
            "John Adcock",
            "Jeremy Pickens",
            "Pernilla Qvarfordt",
            "Maribeth Back"
        ],
        "Title": "Cerchiamo: a collaborative exploratory search tool",
        "Abstract": "We describe Cerchiamo, a collaborative exploratory search system that allows teams of searchers to explore document collections synchronously. Working with Cerchiamo, team members use independent interfaces to run queries, browse results, and make relevance judgments. The system mediates the team members' search activity by passing and reordering search results and suggested query terms based on the teams' actions. The combination of synchronous influence with independent interaction allows team members to be more effective and efficient in performing search tasks."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch",
            "Interactive Video Search"
        ],
        "keywords": [
            "ces",
            "collaborative search",
            "trecvid"
        ],
        "AcceptDate": "09/01/2008",
        "palwebID": "PR-08-472",
        "Venue": "Fuji Xerox Technical Report",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-472/FXPAL-PR-08-472.pdf"
        ],
        "PublicationDate": "12/15/2008",
        "ID": "472",
        "Authors": [
            "Jeremy Pickens",
            "John Adcock",
            "Matthew Cooper",
            "Maribeth Back",
            "Pernilla Qvarfordt",
            "Gene Golovchinsky",
            "Andreas Girgensohn"
        ],
        "Title": "Interactive Multimedia Search: Systems for Exploration and Collaboration",
        "Abstract": "We have developed an interactive video search system that allows the searcher to rapidly assess query results and easily pivot off those results to form new queries. The system is intended to maximize the use of the discriminative power of the human searcher. The typical video search scenario we consider has a single searcher with the ability to search with text and content-based queries. In this paper, we evaluate a new collaborative modification of our search system. Using our system, two or more users with a common information need search together, simultaneously. The collaborative system provides tools, user interfaces and, most importantly, algorithmically-mediated retrieval to focus, enhance and augment the team's search and communication activities. In our evaluations, algorithmic mediation improved the collaborative performance of both retrieval (allowing a team of searchers to find relevant information more efficiently and effectively), and exploration (allowing the searchers to find relevant information that cannot be found while working individually). We present analysis and conclusions from comparative evaluations of the search system."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/15/2008",
        "palwebID": "PR-08-474",
        "Venue": "ACM Multimedia 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-474/FXPAL-PR-08-474.pdf"
        ],
        "PublicationDate": "10/27/2008",
        "ID": "474",
        "Authors": [
            "Don Kimber",
            "Eleanor Rieffel",
            "Jim Vaughan",
            "John Doherty"
        ],
        "Title": "Virtual Physics Circus (video)",
        "Abstract": ""
    },
    {
        "Projects": [],
        "keywords": [
            "Quantum computing; quantum cryptography; public key\r\ncryptography; simulation of quantum systems; qubits; entanglement; efficient algorithms"
        ],
        "AcceptDate": "07/11/2008",
        "palwebID": "PR-09-475",
        "Venue": "Entry in Wiley's The Handbook of Technology Management",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-475/FXPAL-PR-09-475.pdf"
        ],
        "PublicationDate": "12/31/2009",
        "ID": "475",
        "Authors": [
            "Eleanor Rieffel"
        ],
        "Title": "Quantum Computing",
        "Abstract": "Changing the model underlying information and computation from a classical mechanical to a quantum mechanical one yields faster algorithms, novel cryptographic mechanisms, and alternative methods of communication. Quantum algorithms can perform a select set of tasks vastly more efficiently than any classical algorithm, but for many\r\ntasks it has been proven that quantum algorithms provide no advantage. The breadth of quantum computing applications is still being explored. Major application areas include security and the many fields that would benefit from efficient quantum simulation. The quantum information processing viewpoint provides insight into classical algorithmic issues as well as a deeper understanding of entanglement and other non-classical aspects of quantum physics."
    },
    {
        "Projects": [],
        "keywords": [
            "security-mediated certificateless encryption",
            "timed-release"
        ],
        "AcceptDate": "06/03/2008",
        "palwebID": "PR-08-476",
        "Venue": "SCN 2008",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-476/FXPAL-PR-08-476.pdf"
        ],
        "PublicationDate": "09/10/2008",
        "ID": "476",
        "Authors": [
            "Sherman Chow",
            "Volker Roth",
            "Eleanor Rieffel"
        ],
        "Title": "General Certificateless Encryption and Timed-Release Encryption",
        "Abstract": "While recent timed-release encryption (TRE) schemes are\r\nimplicitly supported by a certificateless encryption (CLE) mechanism,\r\nthe security models of CLE and TRE differ and there is no generic trans-\r\nformation from a CLE to a TRE. This paper gives a generalized model for\r\nCLE that fulfills the requirements of TRE. This model is secure against\r\nadversaries with adaptive trapdoor extraction capabilities for arbitrary\r\nidentifiers, decryption capabilities for arbitrary public keys, and partial\r\ndecryption capabilities. It also supports hierarchical identifiers. We pro-\r\npose a concrete scheme under our generalized model and prove it secure\r\nwithout random oracles, yielding the first strongly-secure SMCLE and\r\nthe first TRE in the standard model. In addition, our technique of partial\r\ndecryption is different from the previous approach."
    },
    {
        "Projects": [],
        "keywords": [
            "iPhone",
            "small displays",
            "user interfaces",
            "multiple selection",
            "force directed UI layout",
            "text reading"
        ],
        "AcceptDate": "",
        "palwebID": "PR-08-477",
        "Venue": "Demonstration at UIST 2008",
        "palwebURL": [],
        "PublicationDate": "10/20/2008",
        "ID": "477",
        "Authors": [
            "Volker Roth"
        ],
        "Title": "What the iPhone can and can't do well: novel interaction techniques for touch enabled mobile devices",
        "Abstract": "The iPhone takes a fresh approach at defining the user interface for\r\nmobile devices, which invites further innovation for new generations\r\nof touch enabled mobile devices.  At the same time, some of its\r\ninteraction designs provide challenges.  For example, swiping gestures\r\ncan be used anywhere on the screen of an iPhone for navigation, no\r\nscroll bars are used.  This makes navigation remarkably seamless and\r\neasy, at the expense of selection tasks that would also be supported\r\nnaturally by the same gestures.  In this demo, we show techniques that\r\nenable both activities simultaneously with minimal interference.  We\r\nalso demonstrate other user interface designs that are driven by the\r\nfeatures and and a desire to overcome the limits of small displays for\r\niPhone-type devices.  This includes diagonal scrolling as a means to\r\nmaximize line width and font size for mobile reading, and a graphical\r\nauthentication method.\r\n\r\n"
    },
    {
        "Projects": [
            "ConvertiblePodium"
        ],
        "keywords": [
            "Interactive furniture",
            "meeting support",
            "teleconferencing",
            "multi-screen presentation",
            "rich media",
            "smart environments",
            "CSCW",
            "ubiquitous computing."
        ],
        "AcceptDate": "03/15/2007",
        "palwebID": "PR-08-481",
        "Venue": "Chapter in \"Interactive Artifacts and Furniture Supporting Collaborative Work and Learning\", ed. P. Dillenbourg, J. Huang, and M. Cherubini. Published Nov. 28, 2008, Springer. Computer Supported Collaborative Learning Series Vol. 10.",
        "palwebURL": [
            "http://palweb/files/PR/2008/PR-08-481/FXPAL-PR-08-481.doc",
            "http://palweb/files/PR/2008/PR-08-481/FXPAL-PR-08-481.zip"
        ],
        "PublicationDate": "11/28/2008",
        "ID": "481",
        "Authors": [
            "Maribeth Back",
            "Patrick Chiu",
            "Surapong Lertsithichai",
            "Don Kimber",
            "John Boreczky",
            "Qiong Liu",
            "Jonathan Foote",
            "Takashi Matsumoto"
        ],
        "Title": "Rethinking the Podium ",
        "Abstract": "As the use of rich media in mobile devices and smart environments becomes more sophisticated, so must the design of the everyday objects used as controllers and interfaces. Many new interfaces simply tack electronic systems onto existing forms. However, an original physical design for a smart artefact, that integrates new systems as part of the form of the device, can enhance the end-use experience. The Convertible Podium is an experiment in the design of a smart artefact with complex integrated systems for the use of rich media in meeting rooms. It combines the highly designed look and feel of a modern lectern with systems that allow it to serve as a central control station for rich media manipulation. The interface emphasizes tangibility and ease of use in controlling multiple screens, multiple media sources (including mobile devices) and multiple distribution channels, and managing both data and personal representation in remote telepresence."
    },
    {
        "Projects": [
            "device"
        ],
        "keywords": [
            "Bezel Swipe",
            "touch interaction",
            "multiple selection",
            "mobile\r\n  device"
        ],
        "AcceptDate": "12/08/2008",
        "palwebID": "PR-09-482",
        "Venue": "CHI 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-482/FXPAL-PR-09-482.mov",
            "http://palweb/files/PR/2009/PR-09-482/FXPAL-PR-09-482.ppt"
        ],
        "PublicationDate": "04/04/2009",
        "ID": "482",
        "Authors": [
            "Volker Roth",
            "Thea Turner"
        ],
        "Title": "Bezel Swipe: Conflict-Free Scrolling and Multiple Selection on Mobile Touch Screen Devices",
        "Abstract": "Zooming user interfaces are increasingly popular on mobile devices\r\n  with touch screens.  Swiping and pinching finger gestures anywhere\r\n  on the screen manipulate the displayed portion of a page, and taps\r\n  open objects within the page.  This makes navigation easy but limits\r\n  other manipulations of objects that would be supported naturally by\r\n  the same gestures, notably cut and paste, multiple selection, and\r\n  drag and drop.  A popular device that suffers from this limitation\r\n  is Apple's iPhone.  In this paper, we present Bezel Swipe, an\r\n  interaction technique that supports multiple selection, cut, copy,\r\n  paste and other operations without interfering with zooming,\r\n  panning, tapping and other pre-defined gestures.  Participants of\r\n  our user study found Bezel Swipe to be a viable alternative to\r\n  direct touch selection."
    },
    {
        "Projects": [
            "DICE",
            "USE"
        ],
        "keywords": [
            "DICE",
            "USE",
            "Ubiquitous computing",
            "smart environments",
            "usability"
        ],
        "AcceptDate": "12/05/2008",
        "palwebID": "PR-09-483",
        "Venue": "In Proceedings of CHI 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-483/FXPAL-PR-09-483.pdf"
        ],
        "PublicationDate": "04/04/2009",
        "ID": "483",
        "Authors": [
            "Gene Golovchinsky",
            "Pernilla Qvarfordt",
            "Bill van Melle",
            "Scott Carter",
            "Tony Dunnigan"
        ],
        "Title": "DICE: Designing Conference Rooms for Usability",
        "Abstract": "One of the core challenges now facing smart rooms is supporting realistic, everyday activities. While much research has been done to push forward the frontiers of novel interaction techniques, we argue that technology geared toward widespread adoption requires a design approach that emphasizes straightforward configuration and control, as well as flexibility. We examined the work practices of users of a large, multi-purpose conference room, and designed DICE, a system to help them use the room's capabilities. We describe the design process, and report findings about the system's usability and about people's use of a multi-purpose conference room."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [
            "CES"
        ],
        "AcceptDate": "11/15/2008",
        "palwebID": "PR-09-485",
        "Venue": "Computer, 42(3), IEEE",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-485/FXPAL-PR-09-485.pdf"
        ],
        "PublicationDate": "03/03/2009",
        "ID": "485",
        "Authors": [
            "Gene Golovchinsky",
            "Pernilla Qvarfordt",
            "Jeremy Pickens"
        ],
        "Title": "Collaborative Information Seeking",
        "Abstract": "An examination of the roles and dimensions\r\nof collaborative search reveals new\r\nopportunities for information-seeking support\r\ntools."
    },
    {
        "Projects": [
            "MediaGLOW"
        ],
        "keywords": [
            "Photo organization",
            "retrieval",
            "sharing",
            "MediaGLOW"
        ],
        "AcceptDate": "11/20/2008",
        "palwebID": "PR-09-486",
        "Venue": "IUI '09",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-486/FXPAL-PR-09-486.pdf"
        ],
        "PublicationDate": "02/08/2009",
        "ID": "486",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Lynn Wilcox",
            "Thea Turner",
            "Matthew Cooper"
        ],
        "Title": "MediaGLOW: Organizing Photos in a Graph-based Workspace",
        "Abstract": "We designed an interactive visual workspace, MediaGLOW, that supports users in organizing personal and shared photo collections. The system interactively places photos with a spring layout algorithm using similarity measures based on visual, temporal, and geographic features. These similarity \r\nmeasures are also used for the retrieval of additional photos. Unlike traditional spring-based algorithms, our approach provides users with several means to adapt the layout to their tasks. Users can group photos in stacks that in turn attract neighborhoods of similar photos. Neighborhoods partition the workspace by severing connections outside the neighborhood. By placing photos into the same stack, users can express a desired organization that the system can use to learn a neighborhood-specific combination of distances. "
    },
    {
        "Projects": [
            "EyeTracking"
        ],
        "keywords": [
            "Gaze",
            "eye tracking",
            "computer mediated communication",
            "remote collaboration",
            "multimodal interaction"
        ],
        "AcceptDate": "",
        "palwebID": "PR-09-487",
        "Venue": "Book chapter in Handbook of Research on Socio-Technical Design and Social Networking Systems, eds. Whitworth B., and de Moor, A. Information Science Reference, pp. 529-543. ",
        "palwebURL": [],
        "PublicationDate": "03/02/2009",
        "ID": "487",
        "Authors": [
            "Pernilla Qvarfordt",
            "Shumin Zhai"
        ],
        "Title": "Gaze-aided human-computer and human-human dialogue",
        "Abstract": "Eye-gaze plays an important role in face-to-face communication. This chapter presents research on exploiting the rich information contained in human eye-gaze for two types of applications. The first is to enhance computer mediated human-human communication by overlaying eye-gaze movement onto the shared visual spatial discussion material such as a map. The second is to manage multimodal human-computer dialogue by tracking the user's eye-gaze pattern as an indicator of user's interest. We briefly review related literature and summarize results from two research projects on human-human and human-computer communication. "
    },
    {
        "Projects": [
            "Pantheia"
        ],
        "keywords": [
            "MIR",
            "Pantheia",
            "marker-based virtual world creation",
            "virtual reality",
            "augmented reality",
            "cyberphysical"
        ],
        "AcceptDate": "02/14/2009",
        "palwebID": "PR-09-488",
        "Venue": "Immerscom 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-488/FXPAL-PR-09-488.pdf"
        ],
        "PublicationDate": "05/27/2009",
        "ID": "488",
        "Authors": [
            "Don Kimber",
            "Eleanor Rieffel",
            "Jun Shingu",
            "Jim Vaughan"
        ],
        "Title": "Marking up a World: Visual Markup for Creating and\r\nManipulating Virtual Models",
        "Abstract": "We describe Pantheia, a system that constructs virtual models\r\nof real spaces from collections of images, through the use\r\nof visual markers that guide and constrain model construction.\r\nTo create a model users simply `mark up' the real\r\nworld scene by placing pre-printed markers that describe\r\nscene elements or impose semantic constraints. Users then\r\ncollect still images or video of the scene. From this input,\r\nPantheia automatically and quickly produces a model. The\r\nPantheia system was used to produce models of two rooms\r\nthat demonstrate the e\u000bectiveness of the approach."
    },
    {
        "Projects": [
            "SeamlessDocuments"
        ],
        "keywords": [
            "Mobile applications",
            "mobile phone",
            "presentation viewing",
            "seamless"
        ],
        "AcceptDate": "03/03/2009",
        "palwebID": "PR-09-489",
        "Venue": "Pervasive 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-489/FXPAL-PR-09-489.pdf"
        ],
        "PublicationDate": "05/11/2009",
        "ID": "489",
        "Authors": [
            "Yukiyo Uehori",
            "Tohru Fuse",
            "Laurent Denoue",
            "Patrick Chiu"
        ],
        "Title": "Portable Presentation Player: Mobile Viewing of User-Controllable Movies of Slide Presentations",
        "Abstract": "Recorded presentations are difficult to watch on a mobile phone because of the small screen, and even more challenging when the user is traveling or commuting. This demo shows an application designed for viewing presentations in a mobile situation, and describes the design process that involved on-site observation and informal user testing at our lab. The system generates a user-controllable movie by capturing a slide presentation, extracting active regions of interest using cues from the presenter, and creating pan-and-zoom effects to direct the active regions within a small screen. During playback, the user can simply watch the movie in automatic mode using a minimal amount of effort to operate the application. When more flexible control is needed, the user can switch into manual mode to temporarily focus on specific regions of interest."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch",
            "Interactive Video Search"
        ],
        "keywords": [
            "TRECVID",
            "trecvid",
            "CES",
            "collaborative",
            "search",
            "video search",
            "videosummarization"
        ],
        "AcceptDate": "10/25/2008",
        "palwebID": "PR-09-492",
        "Venue": "Proceedings of TRECVID 2008 Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-492/FXPAL-PR-09-492.pdf"
        ],
        "PublicationDate": "03/01/2009",
        "ID": "492",
        "Authors": [
            "Jeremy Pickens",
            "Matthew Cooper",
            "John Adcock",
            "Andreas Girgensohn"
        ],
        "Title": "FXPAL Interactive Search Experiments for TRECVID 2008",
        "Abstract": "In 2008 FXPAL submitted results for two tasks: rushes summarization and interactive search. The rushes\r\nsummarization task has been described at the ACM Multimedia workshop [1]. Interested readers are referred\r\nto that publication for details. We describe our interactive search experiments in this notebook paper."
    },
    {
        "Projects": [
            "Pantheia"
        ],
        "keywords": [
            "Mixed reality",
            "Pantheia",
            "interactive virtual content",
            "marker-based model creation",
            "semantic markers"
        ],
        "AcceptDate": "04/05/2009",
        "palwebID": "PR-09-493",
        "Venue": "Computer Graphics and Virtual Reality (CGVR '09)",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-493/FXPAL-PR-09-493.pdf"
        ],
        "PublicationDate": "07/13/2009",
        "ID": "493",
        "Authors": [
            "Eleanor Rieffel",
            "Don Kimber",
            "Jim Vaughan",
            "Sagar Gattepally",
            "Jun Shingu"
        ],
        "Title": "Interactive Models from Images of a Static Scene\r\n",
        "Abstract": "FXPAL's Pantheia system enables users to create virtual models\r\nby 'marking up' a physical space with pre-printed visual\r\nmarkers. The meanings associated with the markers come\r\nfrom a markup language that enables the system to create\r\nmodels from a relatively sparse set of markers. This paper\r\ndescribes extensions to our markup language and system that\r\nsupport the creation of interactive virtual objects. Users place\r\nmarkers to define components such as doors and drawers with\r\nwhich an end user of the model can interact. Other interactive\r\nelements, such as controls for color changes or lighting\r\nchoices, are also supported. Pantheia produced a model of a\r\nroom with hinged doors, a cabinet with drawers, doors, and\r\ncolor options, and a railroad track."
    },
    {
        "Projects": [
            "WebNC"
        ],
        "keywords": [
            "screenio",
            "webnc"
        ],
        "AcceptDate": "03/13/2009",
        "palwebID": "PR-09-494",
        "Venue": "WWW 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-494/FXPAL-PR-09-494.pdf"
        ],
        "PublicationDate": "04/22/2009",
        "ID": "494",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "John Adcock",
            "Gene Golovchinsky",
            "Andreas Girgensohn"
        ],
        "Title": "WebNC: efficient sharing of web applications",
        "Abstract": "WebNC is a browser plugin that leverages the Document Object\r\nModel for efficiently sharing web browser windows or recording web browsing sessions to be replayed later. Unlike existing screen-sharing or screencasting tools, WebNC is optimized to work with web pages where a lot of scrolling happens. Rendered pages are captured as image tiles, and transmitted to a central server through http post. Viewers can watch the webcasts in realtime or asynchronously using a standard web browser: WebNC only relies on html and javascript to reproduce the captured web content. Along with the visual content of web pages, WebNC also captures their layout and textual content for later retrieval. The resulting webcasts require very little bandwidth, are viewable on any modern web browser including the iPhone and Android phones, and are searchable by keyword."
    },
    {
        "Projects": [
            "WebNC"
        ],
        "keywords": [
            "webnc",
            "screenio"
        ],
        "AcceptDate": "03/30/2009",
        "palwebID": "PR-09-495",
        "Venue": "Hypertext 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-495/FXPAL-PR-09-495.pdf"
        ],
        "PublicationDate": "06/29/2009",
        "ID": "495",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "John Adcock",
            "Gene Golovchinsky"
        ],
        "Title": "WebNC: efficient sharing of web applications",
        "Abstract": "WebNC is a system for efficiently sharing, retrieving and viewing web applications. Unlike existing screencasting and screensharing tools, WebNC is optimized to work with web pages where a lot of scrolling happens. WebNC uses a tile-based encoding to capture, transmit and deliver web applications, and relies only on dynamic HTML and JavaScript. The resulting webcasts require very little bandwidth and are viewable on any modern web browser\r\nincluding Firefox and Internet Explorer as well as browsers on the iPhone and Android platforms."
    },
    {
        "Projects": [],
        "keywords": [
            "quantum computing",
            "quantum algorithms"
        ],
        "AcceptDate": "",
        "palwebID": "PR-99-497",
        "Venue": "Int.J.Mod.Phys. C10 (1999) 1347-1362 ",
        "palwebURL": [
            "http://palweb/files/PR/1999/PR-99-497/FXPAL-PR-99-497.pdf"
        ],
        "PublicationDate": "10/29/1999",
        "ID": "497",
        "Authors": [
            "Tad Hogg",
            "Carlos Mochon",
            "Wolfgang Polak",
            "Eleanor Rieffel"
        ],
        "Title": "Tools for Quantum Algorithms",
        "Abstract": "We present efficient implementations of a number of operations for quantum computers. These include controlled phase adjustments of the amplitudes in a superposition, permutations, approximations of transformations and generalizations of the phase adjustments to block matrix transformations. These operations generalize those used in proposed quantum search algorithms. "
    },
    {
        "Projects": [
            "Post-Bits"
        ],
        "keywords": [
            "electronic paper applications",
            "multimedia interfaces",
            "physical/digital interfaces",
            "design tools",
            "tangible computing",
            "epaper"
        ],
        "AcceptDate": "01/02/2009",
        "palwebID": "PR-09-499",
        "Venue": "Journal article in Artificial Intelligence for Engineering Design, Analysis and Manufacturing (2009), 23, 263\u00e2\u20ac\u201c274. Printed in the USA.\r\n2009 Cambridge University Press. ",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-499/FXPAL-PR-09-499.pdf"
        ],
        "PublicationDate": "06/17/2009",
        "ID": "499",
        "Authors": [
            "Maribeth Back",
            "Takashi Matsumoto",
            "Tony Dunnigan"
        ],
        "Title": "Prototyping a tangible tool for design: Multimedia\r\ne-paper sticky notes",
        "Abstract": "Modern design embraces digital augmentation, especially in the interplay of digital media content and the physical dispersion and handling of information. Based on the observation that small paper memos with sticky backs (such as Post-Its TM) are a powerful and frequently used design tool, we have created Post-Bits, a new interface device with a physical embodiment that can be handled as naturally as paper sticky notes by designers, yet add digital information affordances as well.\r\n\r\nA Post-Bit is a design prototype of a small electronic paper device for handling multimedia content, with interaction control and display in one thin flexible sheet. Tangible properties of paper such as flipping, flexing, scattering, and rubbing are mapped to controlling aspects of the multimedia content such as scrubbing, sorting, or up- or downloading dynamic media (images, video, text). In this paperwe discuss both the design process involved in building a prototype of a tangible interface using new technologies, and how the use of Post-Bits as a tangible design tool can impact two common design tasks: design\r\nideation or brainstorming, and storyboarding for interactive systems or devices."
    },
    {
        "Projects": [
            "DICE",
            "USE"
        ],
        "keywords": [
            "smart environments",
            "conference rooms",
            "meeting rooms",
            "media control systems",
            "multi-display systems",
            "distributed collaboration",
            "collaboration support",
            "teleconferencing",
            "DICE",
            "USE"
        ],
        "AcceptDate": "10/15/2008",
        "palwebID": "PR-09-500",
        "Venue": "\t\r\nBook chapter in \"Designing User Friendly Augmented Work Environments\"\r\nSeries: Computer Supported Cooperative Work\r\nLahlou, Saadi (Ed.)\r\n2009, Approx. 340 p. 117 illus., Hardcover\r\nISBN: 978-1-84800-097-1",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-500/FXPAL-PR-09-500.pdf"
        ],
        "PublicationDate": "09/30/2009",
        "ID": "500",
        "Authors": [
            "Maribeth Back",
            "Gene Golovchinsky",
            "Pernilla Qvarfordt",
            "John Boreczky",
            "Tony Dunnigan",
            "Scott Carter",
            "Bill van Melle"
        ],
        "Title": "Designing an easy-to-use executive conference room system",
        "Abstract": "The Usable Smart Environment project (USE) aims at designing easy-to-use, highly functional\r\nnext-generation conference rooms. Our first design prototype focuses on creating a \"no wizards\"\r\nroom for an American executive; that is, a room the executive could walk into and use by himself,\r\nwithout help from a technologist. A key idea in the USE framework is that customization is one of the best ways to create a smooth user experience. Since the system needs to fit both with the personal leadership style of the executive and the corporation's meeting culture, we began the design process by exploring the work flow in and around meetings attended by the executive.\r\n\r\nBased on our work flow analysis and the scenarios we developed from it, USE developed a flexible, extensible architecture specifically designed to enhance ease of use in smart environment technologies. The architecture allows customization and personalization of smart environments for particular people and groups, types of work, and specific physical spaces. The first USE room was designed for FXPAL's executive \"Ian\" and installed in Niji, a small executive conference room at FXPAL.\r\n\r\nThe room Niji currently contains two large interactive whiteboards for projection of presentation\r\nmaterial, for annotations using a digital whiteboard, or for teleconferencing; a Tandberg teleconferencing system; an RFID authentication plus biometric identification system; printing via network; a PDA-based simple controller, and a tabletop touch-screen console. The console is used for the USE room control interface, which controls and switches between all of the equipment mentioned above."
    },
    {
        "Projects": [
            "SmartRooms"
        ],
        "keywords": [
            "next generation office",
            "smart environments",
            "multi-modal interface",
            "information mash-up",
            "interactive media",
            "personal devices"
        ],
        "AcceptDate": "07/03/2009",
        "palwebID": "PR-09-501",
        "Venue": "Book chapter in \"Understanding the New Generation Office:\r\nCollective Intelligence of 100 Specialists\" \r\n(book project in Japan, by New Era Office Research Center, Tokyo)\r\n",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-501/FXPAL-PR-09-501.pdf"
        ],
        "PublicationDate": "08/18/2009",
        "ID": "501",
        "Authors": [
            "Maribeth Back"
        ],
        "Title": "A personal interface for information mash-up: exploring worlds both physical and virtual",
        "Abstract": "This is a Big Idea piece for a collective intelligence book project by the New Era Office\r\nResearch Center, Tokyo. It is written at the invitation of FX colleague Koushi\r\nKawamoto. The project asks the same questions of 100 specialists:\r\nAnswer these four questions about an idea for a next-generation workplace:<BR>\r\n1. Want: what do I want to be able to do?<BR>\r\n2. Should: what should a system to support this \"want\" be able to do?<BR>\r\n3. Create: imagine what an instance of this idea might be.<BR>\r\n4. Can: how could this instance be realized in reality?<P>\r\n\r\nWANT: In my ideal work environment, the data I need on everything and everyone should be available at my fingertips, all the time, in many configurations that I can mix-and-match to suit the needs of any task. This includes things like:<P>\r\n\u00e2\u20ac\u00a2 documents of all types<BR>\r\n\u00e2\u20ac\u00a2 people's status, tasks, and availability<BR>\r\n\u00e2\u20ac\u00a2 audio, video, mobile, and virtual world communication channels<BR>\r\n\u00e2\u20ac\u00a2 links to the physical world as appropriate, for example sensors delivering factory data, or the state of the machines I use daily in the workplace (printers,\r\nmy PC, conference room systems), or awareness data about my colleagues.<P>\r\n\r\nCAN: How can we approach this problem? Let's consider the creation of a personal interface or instrument for information mashup, capable of interacting with complex data structures, for tuning smart environments, and for exploring worlds both physical and virtual, in\r\nbusiness, social and personal realms. Like any interactive system this idea has two parts: human-facing and system-facing. These can be called Interstitia I (extending human\r\ninteractivity) and Interstitia II (enabling smart environments)."
    },
    {
        "Projects": [
            "TheVirtualFactory"
        ],
        "keywords": [
            "industrial collaboration",
            "smart environments",
            "factories",
            "control systems",
            "3D environments",
            "virtual worlds",
            "mobile applications",
            "augmented reality",
            "mixed reality",
            "sensor networks."
        ],
        "AcceptDate": "05/28/2009",
        "palwebID": "PR-09-502",
        "Venue": "Presentation at SIGGRAPH 2009, New Orleans, LA. ACM.",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-502/FXPAL-PR-09-502.pdf"
        ],
        "PublicationDate": "08/03/2009",
        "ID": "502",
        "Authors": [
            "Maribeth Back",
            "Tony Dunnigan",
            "Sagar Gattepally",
            "Bee-Yian Liew",
            "Jim Vaughan",
            "Jonathan Foote",
            "Craig Latta"
        ],
        "Title": "High-tech Chocolate: exploring mobile and 3D applications for factories",
        "Abstract": "FXPAL, a research lab in Silicon Valley, and TCHO, a chocolate manufacturer in San Francisco,  have been\r\ncollaborating on exploring emerging technologies for\r\nindustry. The two companies seek ways to bring people\r\ncloser to the products they consume, clarifying end-to-end\r\nproduction processes with technologies like sensor\r\nnetworks for fine-grained monitoring and control, mobile\r\nprocess control, and real/virtual mashups using virtual and\r\naugmented realities. This work lies within and extends the\r\narea of research called mixed- or cross-reality"
    },
    {
        "Projects": [
            "TheVirtualFactory"
        ],
        "keywords": [
            "industrial collaboration",
            "smart environments",
            "factories",
            "control systems",
            "3D environments",
            "virtual worlds",
            "mobile applications",
            "augmented reality",
            "mixed reality",
            "sensor networks."
        ],
        "AcceptDate": "",
        "palwebID": "PR-09-503",
        "Venue": "IEEE Pervasive Computing July-August 2009 (Journal, Works in Progress section)",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-503/FXPAL-PR-09-503.jpg",
            "http://palweb/files/PR/2009/PR-09-503/FXPAL-PR-09-503.pdf"
        ],
        "PublicationDate": "07/18/2009",
        "ID": "503",
        "Authors": [
            "Maribeth Back",
            "John Doherty",
            "Tony Dunnigan",
            "Sagar Gattepally",
            "Bee-Yian Liew",
            "Jim Vaughan",
            "Craig Latta"
        ],
        "Title": "Mirror World Chocolate Factory",
        "Abstract": "FXPAL, a research lab in Silicon Valley, and TCHO, a chocolate manufacturer in San Francisco,  have been\r\ncollaborating on exploring emerging technologies for\r\nindustry. The two companies seek ways to bring people\r\ncloser to the products they consume, clarifying end-to-end\r\nproduction processes with technologies like sensor\r\nnetworks for fine-grained monitoring and control, mobile\r\nprocess control, and real/virtual mashups using virtual and\r\naugmented realities. "
    },
    {
        "Projects": [
            "Kartta"
        ],
        "keywords": [
            "Mobile",
            "navigation",
            "media",
            "seamless"
        ],
        "AcceptDate": "06/15/2009",
        "palwebID": "PR-09-504",
        "Venue": "Mobile HCI 2009 (poster)",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-504/FXPAL-PR-09-504.pdf"
        ],
        "PublicationDate": "09/15/2009",
        "ID": "504",
        "Authors": [
            "Arttu Perttula",
            "Scott Carter",
            "Laurent Denoue"
        ],
        "Title": "Kartta: Extracting Landmarks near Personalized Points-of-Interest from User Generated Content",
        "Abstract": "Most mobile navigation systems focus on answering the question, \"I know where I want to go, now can you show me exactly how to get there?\" While this approach works well for many tasks, it is not as useful for unconstrained situations in which user goals and spatial landscapes are more fluid, such as festivals or conferences. In this paper we describe the design and iteration of the Kartta system, which we developed to answer a slightly different question:\r\n\"What are the most interesting areas here and how do I find them?\""
    },
    {
        "Projects": [
            "EMM",
            "ScalableVisualSearch"
        ],
        "keywords": [
            "Document Retrieval",
            "Image Descriptor",
            "SIFT",
            "SURF",
            "Paper Document",
            "Cell Phone Interface"
        ],
        "AcceptDate": "03/11/2009",
        "palwebID": "PR-09-505",
        "Venue": "2009 IEEE International Conference on Multimedia and Expo (ICME)",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-505/FXPAL-PR-09-505.pdf"
        ],
        "PublicationDate": "06/30/2009",
        "ID": "505",
        "Authors": [
            "Qiong Liu",
            "Hironori Yano",
            "Don Kimber",
            "Chunyuan Liao",
            "Lynn Wilcox"
        ],
        "Title": "HIGH ACCURACY AND LANGUAGE INDEPENDENT DOCUMENT RETRIEVAL WITH A FAST INVARIANT TRANSFORM",
        "Abstract": "This paper presents a tool and a novel Fast Invariant Transform (FIT) algorithm for language independent e-documents access. The tool enables a person to access an e-document through an informal camera capture of a document hardcopy. It can save people from remembering/exploring numerous directories and file names, or even going through many pages/paragraphs in one document. It can also facilitate people\u00e2\u20ac\u2122s manipulation of a document or people\u00e2\u20ac\u2122s interactions through documents. Additionally, the algorithm is useful for binding multimedia data to language independent paper documents. Our document\r\nrecognition algorithm is inspired by the widely known SIFT\r\ndescriptor [4] but can be computed much more efficiently for both descriptor construction and search. It also uses much less storage space than the SIFT approach. By testing our algorithm with randomly scaled and rotated document pages, we can achieve a 99.73% page recognition rate on the 2188-page ICME06 proceedings and 99.9% page recognition rate on a 504-page Japanese math book."
    },
    {
        "Projects": [
            "PACER"
        ],
        "keywords": [
            "Camera phone",
            "paper interface",
            "fine-grained",
            "generic document"
        ],
        "AcceptDate": "07/16/2009",
        "palwebID": "PR-09-506",
        "Venue": "ACM Multimedia 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-506/FXPAL-PR-09-506.pdf"
        ],
        "PublicationDate": "10/19/2009",
        "ID": "506",
        "Authors": [
            "Chunyuan Liao",
            "Qiong Liu"
        ],
        "Title": "PACER: Toward A Cameraphone-based Paper Interface for Fine-grained and Flexible Interaction with Documents",
        "Abstract": "Existing cameraphone-based interactive paper systems fall short of the flexibility of GUIs, partly due to their deficient fine-grained interactions, limited interaction styles and inadequate targeted document types. We present PACER, a platform for applications to interact with document details (e.g. individual words, East Asian characters, math symbols, music notes, and user-specified arbitrary image regions) of generic paper documents through a camera phone. With a see-through phone interface, a user can discover symbol recurrences in a document by pointing the phone\u00e2\u20ac\u2122s crosshair to a symbol within a printout. The user can also continuously move the phone over a printout for gestures to copy and email an arbitrary region, or play music notes on the printout."
    },
    {
        "Projects": [],
        "keywords": [
            "Lighting Adjustment",
            "Image-based Rendering",
            "Image-based Relighting",
            "Object Image Browsing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-09-507",
        "Venue": "2009 IEEE International Conference on Multimedia and Expo (ICME)",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-507/FXPAL-PR-09-507.pdf"
        ],
        "PublicationDate": "06/30/2009",
        "ID": "507",
        "Authors": [
            "Jun Shingu",
            "Shingo Uchihashi",
            "Tetsuo Iyoda",
            "Don Kimber",
            "Eleanor Rieffel",
            "Jim Vaughan"
        ],
        "Title": "Image-based Lighting Adjustment Method for Browsing Object Images",
        "Abstract": "In this paper, we describe an automatic lighting adjustment\r\nmethod for browsing object images. From a set of images of an\r\nobject, taken under different lighting conditions, we generate two\r\ntypes of illuminated images: a textural image which eliminates\r\nunwanted specular reflections of the object, and a highlight image\r\nin which specularities of the object are highly preserved. Our user\r\ninterface allows viewers to digitally zoom into any region of the\r\nimage, and the lighting adjusted images are automatically\r\ngenerated for the selected region and displayed. Switching\r\nbetween the textural and the highlight images helps viewers to\r\nunderstand characteristics of the object surface."
    },
    {
        "Projects": [
            "ScalableVisualSearch"
        ],
        "keywords": [
            "image categorization",
            "boosting",
            "nearest neighbors"
        ],
        "AcceptDate": "07/17/2009",
        "palwebID": "PR-09-508",
        "Venue": "ACM Multimedia 2009 Workshop on Large-Scale Multimedia\r\nRetrieval and Mining",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-508/FXPAL-PR-09-508.pdf"
        ],
        "PublicationDate": "10/23/2009",
        "ID": "508",
        "Authors": [
            "Matthew Cooper"
        ],
        "Title": "Image Categorization Combining Neighborhood Methods and Boosting\r\n",
        "Abstract": "We describe an efficient and scalable system for automatic image categorization. Our approach seeks to marry scalable \u00e2\u20ac\u0153model-free\u00e2\u20ac\u009d neighborhood-based annotation with accurate boosting-based per-tag modeling. For accelerated neighborhood-based classification, we use a set of spatial data structures as weak classifiers for an arbitrary number of categories. We employ standard edge and color features and an approximation scheme that scales to large training sets. The weak classifier outputs are combined in a tag-dependent fashion via boosting to improve accuracy. The\r\nmethod performs competitively with standard SVM-based per-tag classification with substantially reduced computational requirements. We present multi-label image annotation experiments using data sets of more than two million photos."
    },
    {
        "Projects": [
            "Kartta"
        ],
        "keywords": [
            "Mobile",
            "navigation",
            "media",
            "seamless"
        ],
        "AcceptDate": "07/23/2009",
        "palwebID": "PR-09-509",
        "Venue": "ACM Mindtrek 2009",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-509/FXPAL-PR-09-509.pdf"
        ],
        "PublicationDate": "09/30/2009",
        "ID": "509",
        "Authors": [
            "Arttu Perttula",
            "Scott Carter",
            "Laurent Denoue"
        ],
        "Title": "Kartta: Using Multimedia and Context to Navigate\r\nUnfamiliar Environments",
        "Abstract": "Most mobile navigation systems focus on answering the question,\u00e2\u20ac\u0153I know where I want to go, now can you show me exactly how to get there?\u00e2\u20ac\u009d While this approach works well for many tasks, it is not as useful for unconstrained situations in which user goals and spatial landscapes are more fluid, such as festivals or conferences. In this paper we describe the design and iteration of the Kartta system,\r\nwhich we developed to answer a slightly different question: \u00e2\u20ac\u0153What are the most interesting areas here and how do I find them?\u00e2\u20ac\u009d"
    },
    {
        "Projects": [
            "SeamlessDocuments"
        ],
        "keywords": [
            "document reading",
            "mobile",
            "audio",
            "seereader",
            "seamless"
        ],
        "AcceptDate": "08/15/2009",
        "palwebID": "PR-09-510",
        "Venue": "IJCSI International Journal of Computer Science Issues. Vol. 1.",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-510/FXPAL-PR-09-510.pdf"
        ],
        "PublicationDate": "10/15/2009",
        "ID": "510",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue"
        ],
        "Title": "SeeReader: An (Almost) Eyes-Free Mobile Rich Document Viewer",
        "Abstract": "Reading documents on mobile devices is challenging. Not only are screens small and difficult to read, but also navigating an environment using limited visual attention can be difficult and potentially dangerous. Reading content aloud using text-to-speech (TTS) processing can mitigate these problems, but only for content that does not include rich visual information. In this paper, we introduce a new technique, SeeReader, that combines TTS with automatic content recognition and document presentation control that allows users to listen to documents while also being notified of important visual content. Together, these services allow users to read rich documents on mobile devices while maintaining awareness of their visual environment."
    },
    {
        "Projects": [
            "Pantheia"
        ],
        "keywords": [
            "Pantheia",
            "image-based modeling",
            "virtual environments"
        ],
        "AcceptDate": "",
        "palwebID": "PR-09-511",
        "Venue": "ACM Multimedia",
        "palwebURL": [
            "http://palweb/files/PR/2009/PR-09-511/FXPAL-PR-09-511.pdf"
        ],
        "PublicationDate": "10/21/2009",
        "ID": "511",
        "Authors": [
            "Eleanor Rieffel",
            "Sagar Gattepally",
            "Don Kimber",
            "Jun Shingu",
            "Jim Vaughan",
            "John Doherty"
        ],
        "Title": "Marking up a World: Physical Markup for Virtual Content Creation (Video)",
        "Abstract": "The Pantheia system enables users to create virtual models by `marking up' the real world with pre-printed markers.\r\nThe markers have prede\ffined meanings that guide the system as it creates models. Pantheia takes as input user captured images or video of the marked up space. This video\r\nillustrates the workings of the system and shows it being\r\nused to create three models, one of a cabinet, one of a lab,\r\nand one of a conference room. As part of the Pantheia system, we also developed a 3D viewer that spatially integrates\r\na model with images of the model."
    },
    {
        "Projects": [],
        "keywords": [
            "ces",
            "information exploration",
            "information seeking",
            "collaborative search"
        ],
        "AcceptDate": "11/16/2009",
        "palwebID": "PR-10-513",
        "Venue": "Information Processing & Management, 46 (6), pp. 629-631",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-513/FXPAL-PR-10-513.pdf"
        ],
        "PublicationDate": "11/01/2010",
        "ID": "513",
        "Authors": [
            "Gene Golovchinsky",
            "Meredith Ringel Morris",
            "Jeremy Pickens"
        ],
        "Title": "Introduction to Special Issue of Information Processing & Management on Collaborative Information Seeking",
        "Abstract": "This special issue brings together papers that describe some of the many ways that collaborative information seeking manifests itself. Some papers report on collaborative practices in a range of domains, including medical (Hertzum), legal (Attfield et al.), and online Q&A (Gazan). Others propose and evaluate models of collaborative activity (Evans and Chi; Evans et al.; Wilson and schraefel; Foley and Smeaton), and others describe systems and algorithms that support collaboration in various ways (Boydell and Smyth; Fernandez-Luna et al., Halvey et al., Morris et al.;  Shah et al.)."
    },
    {
        "Projects": [
            "Evaluation",
            "information seeking",
            "collaborative exploratory search"
        ],
        "keywords": [
            "ces",
            "Collaborative search",
            "Algorithmic mediation",
            "Evaluation",
            "information seeking",
            "collaborative exploratory search"
        ],
        "AcceptDate": "11/11/2009",
        "palwebID": "PR-10-514",
        "Venue": "Information Processing & Management, 46 (6), pp. 773-781",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-514/FXPAL-PR-10-514.pdf"
        ],
        "PublicationDate": "11/01/2010",
        "ID": "514",
        "Authors": [
            "Chirag Shah",
            "Jeremy Pickens",
            "Gene Golovchinsky"
        ],
        "Title": "Role-based results redistribution for collaborative information retrieval",
        "Abstract": "We describe a new approach for algorithmic mediation of a collaborative search process.\r\nUnlike most approaches to collaborative IR, we are designing systems that mediate explicitly-\r\ndefined synchronous collaboration among small groups of searchers with a shared\r\ninformation need. Such functionality is provided by first obtaining different rank-lists\r\nbased on searchers\u00e2\u20ac\u2122 queries, fusing these rank-lists, and then splitting the combined list\r\nto distribute documents among collaborators according to their roles. For the work\r\nreported here, we consider the case of two people collaborating on a search. We assign\r\nthem roles of Gatherer and Surveyor: the Gatherer is tasked with exploring highly promising\r\ninformation on a given topic, and the Surveyor is tasked with digging further to\r\nexplore more diverse information. We demonstrate how our technique provides the Gatherer\r\nwith high-precision results, and the Surveyor with information that is high in entropy."
    },
    {
        "Projects": [
            "EMM",
            "PACER",
            "ReBoard"
        ],
        "keywords": [
            "tags",
            "barcodes",
            "dynamink",
            "reboard",
            "pacer",
            "papiercraft",
            "EMM"
        ],
        "AcceptDate": "12/23/2009",
        "palwebID": "PR-10-546",
        "Venue": "IEEE Pervasive Computing. 9(2). 46-55.",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-546/FXPAL-PR-10-546.pdf"
        ],
        "PublicationDate": "03/15/2010",
        "ID": "546",
        "Authors": [
            "Scott Carter",
            "Chunyuan Liao",
            "Laurent Denoue",
            "Gene Golovchinsky",
            "Qiong Liu"
        ],
        "Title": "Linking digital media to physical documents: Comparing content-based and marker-based tags",
        "Abstract": "Paper is static but it is also light, flexible, robust, and has high resolution for reading documents in various scenarios. Digital devices will likely never match the flexibility of paper, but come with all of the benefits of computation and networking. Tags provide a simple means of bridging the gap between the two media to get the most out of both. In this paper, we explore the tradeoffs between two different types of tagging technologies \u00e2\u20ac\u201c marker-based and content-based \u00e2\u20ac\u201c through the lens of four systems we have developed and evaluated at our lab. From our experiences, we extrapolate issues for designers to consider when developing systems that transition between paper and digital content in a variety of different scenarios."
    },
    {
        "Projects": [
            "ReBoard",
            "USE"
        ],
        "keywords": [
            "USE",
            "whiteboards",
            "workflow",
            "information reuse and sharing",
            "reboard",
            "multimedia interfaces"
        ],
        "AcceptDate": "12/05/2009",
        "palwebID": "PR-10-547",
        "Venue": "In Proc. CHI 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-547/FXPAL-PR-10-547.pdf"
        ],
        "PublicationDate": "04/10/2010",
        "ID": "547",
        "Authors": [
            "Stacy Branham",
            "Gene Golovchinsky",
            "Scott Carter",
            "Jacob Biehl"
        ],
        "Title": "Let's Go from the Whiteboard: Supporting Transitions in\r\nWork through Whiteboard Capture and Reuse",
        "Abstract": "The use of whiteboards is pervasive across a wide range of\r\nwork domains. But some of the qualities that make them\r\nsuccessful\u00e2\u20ac\u201dan intuitive interface, physical working space,\r\nand easy erasure\u00e2\u20ac\u201dinherently make them poor tools for\r\narchival and reuse. If whiteboard content could be made\r\navailable in times and spaces beyond those supported by\r\nthe whiteboard alone, how might it be appropriated? We\r\nexplore this question via ReBoard, a system that\r\nautomatically captures whiteboard images and makes them\r\naccessible through a novel set of user-centered access tools.\r\nThrough the lens of a seven week workplace field study,\r\nwe found that by enabling new workflows, ReBoard\r\nincreased the value of whiteboard content for collaboration."
    },
    {
        "Projects": [
            "Unity",
            "USE"
        ],
        "keywords": [
            "USE",
            "Unity",
            "Communication",
            "Collaboration",
            "Computer Mediated\r\nCommunication",
            "Phone",
            "Email",
            "Instant Messaging",
            "Blogs",
            "Wiki",
            "Face-to-face",
            "Evaluation"
        ],
        "AcceptDate": "12/05/2009",
        "palwebID": "PR-10-548",
        "Venue": "In Proc. CHI 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-548/FXPAL-PR-10-548.pdf"
        ],
        "PublicationDate": "04/10/2010",
        "ID": "548",
        "Authors": [
            "Thea Turner",
            "Pernilla Qvarfordt",
            "Jacob Biehl",
            "Gene Golovchinsky",
            "Maribeth Back"
        ],
        "Title": "Exploring the Workplace Communication Ecology",
        "Abstract": "The modern workplace is inherently collaborative, and this\r\ncollaboration relies on effective communication among\r\ncoworkers. Many communication tools \u00e2\u20ac\u201c email, blogs,\r\nwikis, Twitter, etc. \u00e2\u20ac\u201c have become increasingly available\r\nand accepted in workplace communications. In this paper,\r\nwe report on a study of communications technologies used\r\nover a one year period in a small US corporation. We found\r\nthat participants used a large number of communication\r\ntools for different purposes, and that the introduction of\r\nnew tools did not impact significantly the use of\r\npreviously-adopted technologies. Further, we identified\r\ndistinct classes of users based on patterns of tool use. This\r\nwork has implications for the design of technology in the\r\nevolving ecology of communication tools."
    },
    {
        "Projects": [
            "SeamlessDocuments"
        ],
        "keywords": [
            "seamless"
        ],
        "AcceptDate": "",
        "palwebID": "PR-10-549",
        "Venue": "Fuji Xerox Technical Report, No.19, 2010, pp. 57-65.",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-549/FXPAL-PR-10-549.pdf"
        ],
        "PublicationDate": "01/12/2010",
        "ID": "549",
        "Authors": [
            "Tohru Fuse",
            "Yukiyo Uehori",
            "Patrick Chiu",
            "Laurent Denoue",
            "Koichi Fujii"
        ],
        "Title": "Seamless Document Handling",
        "Abstract": "The current trend toward high-performance mobile networks and increasingly sophisticated mobile devices has fostered the growth of mobile workers. In mobile environments, an urgent need exists for handling documents using a mobile phone, especially for browsing documents and viewing Rich Contents created on computers. This paper describes Seamless Document Handling, which is a technology for viewing electronic documents and Rich Contents on the small screen of a mobile phone. To enhance operability and readability, we devised a method of scrolling documents efficiently by applying document image processing technology, and designed a novel user interface with a pan-and-zoom technique. We conducted on-site observations to test usability of the prototype, and gained insights difficult to acquire in a lab that led to improved functions in the prototype."
    },
    {
        "Projects": [
            "PACER"
        ],
        "keywords": [
            "Cell phone",
            "camera",
            "touch",
            "gesture",
            "paper interface",
            "fine-grained",
            "embodied interface",
            "multimedia interfaces"
        ],
        "AcceptDate": "12/13/2009",
        "palwebID": "PR-10-550",
        "Venue": "In Proc. of CHI 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-550/FXPAL-PR-10-550.pdf"
        ],
        "PublicationDate": "04/10/2010",
        "ID": "550",
        "Authors": [
            "Chunyuan Liao",
            "Qiong Liu",
            "Bee-Yian Liew",
            "Lynn Wilcox"
        ],
        "Title": "PACER: Fine-grained Interactive Paper via Camera-touch Hybrid Gestures on a Cell Phone",
        "Abstract": "PACER is a gesture-based interactive paper system that\r\nsupports fine-grained paper document content manipulation\r\nthrough the touch screen of a cameraphone. Using the\r\nphone\u00e2\u20ac\u2122s camera, PACER links a paper document to its\r\ndigital version based on visual features. It adopts camera-based\r\nphone motion detection for embodied gestures (e.g.\r\nmarquees, underlines and lassos), with which users can\r\nflexibly select and interact with document details (e.g.\r\nindividual words, symbols and pixels). The touch input is\r\nincorporated to facilitate target selection at fine granularity,and to address some limitations of the embodied\r\ninteraction, such as hand jitter and low input sampling rate. This hybrid interaction is coupled with other techniques such as semi-real time document tracking and loose physical-digital document registration, offering a gesture-based\r\ncommand system. We demonstrate the use of\r\nPACER in various scenarios including work-related\r\nreading, maps and music score playing. A preliminary user\r\nstudy on the design has produced encouraging user\r\nfeedback, and suggested future research for better\r\nunderstanding of embodied vs. touch interaction and one vs.\r\ntwo handed interaction."
    },
    {
        "Projects": [
            "EMM\r\ninterface",
            "marker on paper",
            "document recognition",
            "EMM"
        ],
        "keywords": [
            "Augmented paper",
            "camera phone",
            "vision-based paper\r\ninterface",
            "marker on paper",
            "document recognition",
            "EMM"
        ],
        "AcceptDate": "11/23/2009",
        "palwebID": "PR-10-551",
        "Venue": "In Proc. of IUI 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-551/FXPAL-PR-10-551.pdf"
        ],
        "PublicationDate": "02/07/2010",
        "ID": "551",
        "Authors": [
            "Qiong Liu",
            "Chunyuan Liao",
            "Lynn Wilcox",
            "Tony Dunnigan",
            "Bee-Yian Liew"
        ],
        "Title": "<img src=\"/images/best.png\" title=\"Best Paper Award\" border=\"0\" /> Embedded Media Markers: Marks on Paper that Signify Associated Media",
        "Abstract": "Embedded Media Markers, or simply EMMs, are nearly\r\ntransparent iconic marks printed on paper documents that\r\nsignify the existence of media associated with that part of\r\nthe document. EMMs also guide users\u00e2\u20ac\u2122 camera operations\r\nfor media retrieval. Users take a picture of an EMMsignified\r\ndocument patch using a cell phone, and the media\r\nassociated with the EMM-signified document location is\r\ndisplayed on the phone. Unlike bar codes, EMMs are nearly\r\ntransparent and thus do not interfere with the document\r\ncontents. Retrieval of media associated with an EMM is\r\nbased on image local features of the captured EMMsignified\r\ndocument patch. This paper describes a technique\r\nfor semi-automatically placing an EMM at a location in a\r\ndocument, in such a way that it encompasses sufficient\r\nidentification features with minimal disturbance to the\r\noriginal document."
    },
    {
        "Projects": [
            "DocuBrowse",
            "DocumentGenreIdentification"
        ],
        "keywords": [
            "docubrowse",
            "genre"
        ],
        "AcceptDate": "",
        "palwebID": "PR-10-552",
        "Venue": "Fuji Xerox Technical Report No. 19, pp. 88-100",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-552/FXPAL-PR-10-552.pdf"
        ],
        "PublicationDate": "01/01/2010",
        "ID": "552",
        "Authors": [
            "Francine Chen",
            "Andreas Girgensohn",
            "Lynn Wilcox"
        ],
        "Title": "Automatic Document Genre Identification For Faceted Document Browsing And Searching",
        "Abstract": "Browsing and searching for documents in large, online enterprise document repositories is an increasingly common problem. While users are familiar and usually satisfied with Internet search results for information, enterprise search has not been as successful because of differences in data types and user requirements. To support users in finding the information they need from electronic and scanned documents in their online enterprise repository, we created an automatic detector for genres such as papers, slides, tables, and photos. Several of those genres correspond roughly to file name extensions but are identified automatically using features of the document. This genre identifier plays an important role in our faceted document browsing and search system. The system presents documents in a hierarchy as typically found in enterprise document collections. Documents and directories are filtered to show only documents matching selected facets and containing optional query terms and to highlight promising directories. Thumbnail images and automatically identified keyphrases help select desired documents."
    },
    {
        "Projects": [
            "EyeTracking"
        ],
        "keywords": [
            "gaze-enhanced visual search",
            "two-phase search",
            "multiple\r\ntargets."
        ],
        "AcceptDate": "12/06/2009",
        "palwebID": "PR-10-553",
        "Venue": "Symposium on Eye Tracking Research and Applications 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-553/FXPAL-PR-10-553.pdf"
        ],
        "PublicationDate": "03/22/2010",
        "ID": "553",
        "Authors": [
            "Pernilla Qvarfordt",
            "Jacob Biehl",
            "Gene Golovchinsky",
            "Tony Dunnigan"
        ],
        "Title": "Understanding the Benefits of Gaze Enhanced Visual Search",
        "Abstract": "In certain applications such as radiology and imagery analysis, it is important to minimize errors. In this paper we evaluate a structured inspection method that uses eye tracking information as a feedback mechanism to the image inspector. Our two-phase method starts with a free viewing phase during which gaze data is collected. During the next phase, we either segment the image, mask previously seen areas of the image, or combine the two techniques, and repeat the search. We compare the different methods proposed for the second search phase by evaluating the inspection method using true positive and false negative rates, and subjective workload. Results show that gaze-blocked configurations reduced the subjective workload, and that gaze-blocking without segmentation showed the largest increase in true positive identifications and the largest decrease in false negative identifications of previously unseen objects."
    },
    {
        "Projects": [],
        "keywords": [
            "Twitter",
            "CHI",
            "HCIR"
        ],
        "AcceptDate": "02/01/2010",
        "palwebID": "PR-10-555",
        "Venue": "In Proc. CHI2010 Workshop on Microblogging: What and How Can We Learn From It? April 11, 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-555/FXPAL-PR-10-555.pdf"
        ],
        "PublicationDate": "04/11/2010",
        "ID": "555",
        "Authors": [
            "Gene Golovchinsky",
            "Miles Efron"
        ],
        "Title": "Making sense of Twitter Search",
        "Abstract": "Twitter provides a search interface to its data, along the lines of traditional search engines. But the single ranked list is a poor way to represent the richly-structured Twitter data. A more structured approach that recognizes original messages, re-tweets, people, and documents as interesting constructs is more appropriate for this kind of data. In this paper, we describe a prototype for exploring search results delivered by Twitter. The design is based on our own experience with using Twitter search, and as well as on the results of an small online questionnaire."
    },
    {
        "Projects": [
            "DocuBrowse",
            "DocumentGenreIdentification"
        ],
        "keywords": [
            "DocuBrowse",
            "genre",
            "multimedia interfaces"
        ],
        "AcceptDate": "11/27/2009",
        "palwebID": "PR-10-566",
        "Venue": "IUI 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-566/FXPAL-PR-10-566.pdf"
        ],
        "PublicationDate": "02/08/2010",
        "ID": "566",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Francine Chen",
            "Lynn Wilcox"
        ],
        "Title": "DocuBrowse: Faceted Searching, Browsing, and Recommendations in an Enterprise Context",
        "Abstract": "Browsing and searching for documents in large, online\r\nenterprise document repositories are common activities.\r\nWhile internet search produces satisfying results for most\r\nuser queries, enterprise search has not been as successful\r\nbecause of differences in document types and user requirements.\r\nTo support users in finding the information they need\r\nin their online enterprise repository, we created Docu-\r\nBrowse, a faceted document browsing and search system.\r\nSearch results are presented within the user-created document\r\nhierarchy, showing only directories and documents\r\nmatching selected facets and containing text query terms. In\r\naddition to file properties such as date and file size, automatically\r\ndetected document types, or genres, serve as one\r\nof the search facets. Highlighting draws the user\u00e2\u20ac\u2122s attention\r\nto the most promising directories and documents while\r\nthumbnail images and automatically identified keyphrases\r\nhelp select appropriate documents. DocuBrowse utilizes\r\ndocument similarities, browsing histories, and recommender\r\nsystem techniques to suggest additional promising\r\ndocuments for the current facet and content filters."
    },
    {
        "Projects": [
            "TheVirtualFactory"
        ],
        "keywords": [
            "Virtual Factory",
            "virtual worlds",
            "factories",
            "mixed reality",
            "TCHO"
        ],
        "AcceptDate": "12/19/2009",
        "palwebID": "PR-10-567",
        "Venue": "IEEE Virtual Reality 2010 conference",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-567/FXPAL-PR-10-567.pdf"
        ],
        "PublicationDate": "03/19/2010",
        "ID": "567",
        "Authors": [
            "Maribeth Back",
            "Tony Dunnigan",
            "Sagar Gattepally",
            "Don Kimber",
            "Bee-Yian Liew",
            "Eleanor Rieffel",
            "Jun Shingu",
            "Jim Vaughan"
        ],
        "Title": "The Virtual Factory: Exploring 3D worlds as industrial collaboration and control environments",
        "Abstract": "This project investigates practical uses of virtual, mobile, and mixed reality systems in industrial settings, in particular control and collaboration applications for factories. In collaboration with TCHO, a chocolate maker start-up in San Francisco, we have built virtual mirror-world representations of a real-world chocolate factory and are importing its data and modeling its processes. The system integrates mobile devices such as cell phones and tablet computers. The resulting \"virtual factory\" is a cross-reality environment designed for simulation, visualization, and collaboration, using a set of interlinked, real-time 3D and 2D layers of information about the factory and its processes. "
    },
    {
        "Projects": [
            "TheVirtualFactory"
        ],
        "keywords": [
            "mixed reality",
            "3D applications",
            "advanced visualization",
            "remote collaboration",
            "virtual worlds",
            "virtual factory",
            "TCHO",
            "remote monitoring",
            "remote control",
            "data visualization",
            "collaborative tools",
            "pervasive computing",
            "simulation",
            "mobile computing",
            "ext_Web."
        ],
        "AcceptDate": "",
        "palwebID": "PR-10-568",
        "Venue": "ICME 2010, Singapore, July 19-23 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-568/FXPAL-PR-10-568.pdf"
        ],
        "PublicationDate": "07/19/2010",
        "ID": "568",
        "Authors": [
            "Maribeth Back",
            "Tony Dunnigan",
            "Sagar Gattepally",
            "Don Kimber",
            "Bee-Yian Liew",
            "Eleanor Rieffel",
            "Jun Shingu",
            "Jim Vaughan"
        ],
        "Title": "The Virtual Chocolate Factory: \r\nBuilding a real world mixed-reality system \r\nfor industrial collaboration and control \r\n",
        "Abstract": "Virtual, mobile, and mixed reality systems have diverse uses for data visualization and remote collaboration in industrial settings, especially factories. We report our experiences in designing complex mixed-reality collaboration, control, and display systems for a real-world factory, for delivering real-time factory information to multiple users.\r\nIn collaboration with (blank for review), a chocolate maker in San Francisco, our research group is building a virtual \u00e2\u20ac\u0153mirror\u00e2\u20ac\u009d world of a real-world chocolate factory and its processes. Real-world sensor data (such as temperature and machine state) is imported into the 3D environment from hundreds of sensors on the factory floor. Multi-camera imagery from the factory is also available in the multi-user 3D factory environment. The resulting \"virtual factory\" is designed for simulation, visualization, and collaboration, using a set of interlinked, real-time 3D and 2D layers of information about the factory and its processes.  \r\nWe are also looking at appropriate industrial uses for mobile devices such as cell phones and tablet computers, and how they intersect with virtual worlds and mixed realities. For example, an experimental iPhone web app provides mobile laboratory monitoring and control. The app allows a real-time view into the lab via steerable camera and remote control of lab machines. The mobile system is integrated with the database underlying the virtual factory world.  \r\nThese systems were deployed at the real-world factory and lab in 2009, and are now in beta development. Through this mashup of mobile, social, mixed and virtual technologies, we hope to create industrial systems for enhanced collaboration between physically remote people and places \u00e2\u20ac\u201c for example, factories in China with managers in Japan or the US.     \r\n"
    },
    {
        "Projects": [
            "Pantheia"
        ],
        "keywords": [
            "mixed reality",
            "virtual models",
            "image-based modeling",
            "computational geometry",
            "polyhedral reconstruction",
            "Pantheia",
            "markup strategies"
        ],
        "AcceptDate": "02/05/2010",
        "palwebID": "PR-10-570",
        "Venue": "SIAM MI'09 monograph.\r\n\r\nRelated talks:\r\nSIAM GPM'09,\r\nSIAM MI'09, and \r\nBAMA (Bay Area Mathematical Adventures)",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-570/FXPAL-PR-10-570.pdf"
        ],
        "PublicationDate": "05/01/2010",
        "ID": "570",
        "Authors": [
            "Eleanor Rieffel",
            "Don Kimber",
            "Jim Vaughan"
        ],
        "Title": "Geometric reconstruction from point-normal data",
        "Abstract": "Creating virtual models of real spaces and objects is cumber-\r\nsome and time consuming. This paper focuses on the prob-\r\nlem of geometric reconstruction from sparse data obtained\r\nfrom certain image-based modeling approaches. A number of\r\nelegant and simple-to-state problems arise concerning when\r\nthe geometry can be reconstructed. We describe results and\r\ncounterexamples, and list open problems."
    },
    {
        "Projects": [
            "MediaGLOW"
        ],
        "keywords": [
            "MediaGLOW",
            "multimedia interfaces"
        ],
        "AcceptDate": "03/12/2010",
        "palwebID": "PR-10-571",
        "Venue": "JCDL 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-571/FXPAL-PR-10-571.pdf"
        ],
        "PublicationDate": "06/21/2010",
        "ID": "571",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Thea Turner",
            "Lynn Wilcox"
        ],
        "Title": "Flexible Access to Photo Libraries via Time, Place, Tags, and Visual Features",
        "Abstract": "Photo libraries are growing in quantity and size, requiring better support for locating desired photographs. MediaGLOW is an interactive visual workspace designed to address this concern. It uses attributes such as visual appearance, GPS locations, user-assigned tags, and dates to filter and group photos. An automatic layout algorithm positions photos with similar attributes near each other to support users in serendipitously finding multiple relevant photos. In addition, the system can explicitly select photos similar to specified photos. We conducted a user evaluation to determine the benefit provided by similarity layout and the relative advantages offered by the different layout similarity criteria and attribute filters. Study participants had to locate photos matching probe statements. In some tasks, participants were restricted to a single layout similarity criterion and filter option. Participants used multiple attributes to filter photos. Layout by similarity without additional filters turned out to be one of the most used strategies and was especially beneficial for geographical similarity. Lastly, the relative appropriateness of the single similarity criterion to the probe significantly affected retrieval performance."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [
            "session-based search",
            "CES",
            "information seeking",
            "HCIR",
            "MAV",
            "sessionsearch"
        ],
        "AcceptDate": "05/28/2010",
        "palwebID": "PR-10-573",
        "Venue": "IIiX 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-573/FXPAL-PR-10-573.pdf"
        ],
        "PublicationDate": "08/18/2010",
        "ID": "573",
        "Authors": [
            "Gene Golovchinsky",
            "Jeremy Pickens"
        ],
        "Title": "Interactive Information Seeking via Selective Application of Contextual Knowledge",
        "Abstract": "Exploratory search is a difficult activity that requires iterative interaction. This iterative process helps the searcher to understand and to refine the information need. It also generates a rich set of data that can be used effectively to reflect on what has been found (and found useful). In this paper, we describe a framework for unifying transitions among various stages of exploratory search, and show how context from one stage can be applied to the next. The framework can be used both to describe existing information-seeking interactions, and as a means of generating novel ones. We illustrate the framework with examples from a session-based exploratory search system prototype that we have built."
    },
    {
        "Projects": [
            "DocumentGenreIdentification"
        ],
        "keywords": [
            "Picture detection",
            "page image",
            "entity extraction",
            "OCR",
            "document image analysis."
        ],
        "AcceptDate": "06/29/2010",
        "palwebID": "PR-10-574",
        "Venue": "ACM DocEng 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-574/FXPAL-PR-10-574.pdf"
        ],
        "PublicationDate": "09/21/2010",
        "ID": "574",
        "Authors": [
            "Patrick Chiu",
            "Francine Chen",
            "Laurent Denoue"
        ],
        "Title": "Picture Detection in Document Page Images",
        "Abstract": "We present a method for picture detection in document page images, which can come from scanned or camera images, or rendered from electronic file formats.  Our method uses OCR to separate out the text and applies the Normalized Cuts algorithm to cluster the non-text pixels into picture regions.  A refinement step uses the captions found in the OCR text to deduce how many pictures are in a picture region, thereby correcting for under- and over-segmentation.  A performance evaluation scheme is applied which takes into account the detection quality and fragmentation quality. We benchmark our method against the ABBYY application on page images from conference papers."
    },
    {
        "Projects": [
            "FormCracker"
        ],
        "keywords": [
            "Form filling",
            "interactive",
            "document processing",
            "image processing."
        ],
        "AcceptDate": "06/28/2010",
        "palwebID": "PR-10-575",
        "Venue": "Document Engineering 2010 (DocEng2010)",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-575/FXPAL-PR-10-575.pdf"
        ],
        "PublicationDate": "09/21/2010",
        "ID": "575",
        "Authors": [
            "Laurent Denoue",
            "John Adcock",
            "Scott Carter",
            "Patrick Chiu",
            "Francine Chen"
        ],
        "Title": "FormCracker: Interactive Web-based Form Filling",
        "Abstract": ""
    },
    {
        "Projects": [
            "Kartta"
        ],
        "keywords": [
            "Mobile",
            "capture and access",
            "prototyping",
            "maps",
            "social\r\ncomputing",
            "multimedia",
            "sharing",
            "collaborative",
            "attention",
            "location-based services"
        ],
        "AcceptDate": "07/08/2010",
        "palwebID": "PR-11-577",
        "Venue": "International Journal of Arts and Technology",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-577/FXPAL-PR-11-577.pdf"
        ],
        "PublicationDate": "07/25/2011",
        "ID": "577",
        "Authors": [
            "Arttu Perttula",
            "Scott Carter",
            "Laurent Denoue"
        ],
        "Title": "Retrospective vs. prospective: Two approaches\r\nto mobile media capture and access",
        "Abstract": "Mobile media applications need to balance user and\r\ngroup goals, attentional constraints, and limited screen real estate. In this paper, we describe the iterative development and testing of an application that explores these tradeo\u000bffs. We developed early prototypes of a retrospective, time-based system as well as a prospective and space-based system. Our experiences with the\r\nprototypes led us to focus on the prospective system. We argue that attentional demands dominate and mobile media applications should be lightweight and hands-free as much as possible."
    },
    {
        "Projects": [],
        "keywords": [
            "book review",
            "quantum computing"
        ],
        "AcceptDate": "",
        "palwebID": "PR-10-578",
        "Venue": "ACM SIGACT News, Vol 41, No. 3, 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-578/FXPAL-PR-10-578.pdf"
        ],
        "PublicationDate": "07/12/2010",
        "ID": "578",
        "Authors": [
            "Eleanor Rieffel"
        ],
        "Title": "Review of \"Quantum Computer Science: An Introduction\" by N. David Mermin",
        "Abstract": "Over the years I have enjoyed Mermin\u00e2\u20ac\u2122s colorful, idiosyncratic, and insightful papers. His interest in\r\nthe foundations of quantum mechanics has led him to discover alternative explanations for various\r\nquantum mechanical puzzles and protocols. These explanations are often superior to previous\r\nexplanations in both simplicity and insight, and even when they are not outright better, they\r\nprovide a valuable alternative point of view. His book is filled with such explanations, and with\r\nstrong, sometimes controversial, opinions on the right way of seeing something, which make his\r\nbook both valuable and entertaining."
    },
    {
        "Projects": [
            "TalkMiner"
        ],
        "keywords": [
            "talkminer",
            "video"
        ],
        "AcceptDate": "07/12/2010",
        "palwebID": "PR-10-579",
        "Venue": "ACM Multimedia 2010 - Industrial Exhibits",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-579/FXPAL-PR-10-579.pdf"
        ],
        "PublicationDate": "10/25/2010",
        "ID": "579",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "Laurent Denoue",
            "Hamed Pirsiavash",
            "Lawrence Rowe"
        ],
        "Title": "TalkMiner: A Search Engine for Online Lecture Video",
        "Abstract": "TalkMiner is a search engine for lecture webcasts. \r\nLecture videos are processed to recover a set of distinct slide images and OCR is used to generate a list of indexable terms from the slides. \r\nOn our prototype system, users can search and browse lists of lectures, slides in a specific lecture, and play the lecture video. Over 10,000 lecture videos have been indexed from a variety of sources. A public website now allows users to experiment with the search engine."
    },
    {
        "Projects": [
            "RivertedIndexing"
        ],
        "keywords": [
            "reverted indexing",
            "query expansion",
            "relevance feedback",
            "MAV",
            "revindex"
        ],
        "AcceptDate": "07/16/2010",
        "palwebID": "PR-10-581",
        "Venue": "ACM Conference on Information and Knowledge Management (CIKM 2010)",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-581/FXPAL-PR-10-581.pdf"
        ],
        "PublicationDate": "10/26/2010",
        "ID": "581",
        "Authors": [
            "Jeremy Pickens",
            "Matthew Cooper",
            "Gene Golovchinsky"
        ],
        "Title": "Reverted Indexing for Feedback and Expansion\r\n\r\n",
        "Abstract": "Traditional interactive information retrieval systems function by creating inverted lists, or term indexes.  For every term in the vocabulary, a list is created that contains the documents in which that term occurs and its relative frequency within each document.  Retrieval algorithms then use these term frequencies alongside other collection statistics to identify the matching documents for a query.  In this paper, we turn the process around: instead of indexing documents, we index query result sets.  First, queries are run through a chosen retrieval system.  For each query, the resulting document IDs are treated as terms and the score or rank of the document is used as the frequency statistic.  An index of documents retrieved by basis queries is created.  We call this index a reverted index.  Finally, with reverted indexes, standard retrieval algorithms can retrieve the matching queries (as results) for a set of documents (used as queries).  These recovered queries can then be used to identify additional documents, or to aid the user in query formulation, selection, and feedback."
    },
    {
        "Projects": [
            "NudgeCam"
        ],
        "keywords": [
            "Mobile",
            "multimedia",
            "capture",
            "intelligent capture",
            "nudgecam",
            "smart capture"
        ],
        "AcceptDate": "07/05/2010",
        "palwebID": "PR-10-582",
        "Venue": "ACM Multimedia 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-582/FXPAL-PR-10-582.pdf"
        ],
        "PublicationDate": "10/25/2010",
        "ID": "582",
        "Authors": [
            "Scott Carter",
            "John Adcock",
            "John Doherty",
            "Stacy Branham"
        ],
        "Title": "NudgeCam: Toward targeted, higher quality media capture",
        "Abstract": "NudgeCam is a mobile application that can help users capture more relevant, higher quality media. To guide users to capture media more relevant to a particular project, third-party template creators can show users media that demonstrates relevant content and can tell users what content should be present in each captured media using tags and other meta-data such as location and camera orientation.\r\nTo encourage higher quality media capture, NudgeCam provides real time feedback based on standard media capture\r\nheuristics, including face positioning, pan speed, audio quality, and many others. We describe an implementation of\r\nNudgeCam on the Android platform as well as fi\feld deployments of the application."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/10/2010",
        "palwebID": "PR-11-584",
        "Venue": "IS&T and SPIE International Conference on Multimedia Content Access: Algorithms and Systems",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-584/FXPAL-PR-11-584.pdf",
            "http://palweb/files/PR/2011/PR-11-584/Thumbs.db"
        ],
        "PublicationDate": "01/23/2011",
        "ID": "584",
        "Authors": [
            "Matthew Cooper",
            "John Adcock",
            "Andreas Girgensohn",
            "Jeremy Pickens",
            "Lynn Wilcox"
        ],
        "Title": "Multimedia Information Retrieval at FX Palo Alto Laboratory",
        "Abstract": "This paper describes research activities at FX Palo Alto Laboratory (FXPAL) in the area of multimedia browsing, search, and retrieval. We first consider interfaces for organization and management of personal photo collections. We then survey our work on interactive video search and retrieval. Throughout we discuss the evolution of both the research challenges in these areas and our proposed solutions."
    },
    {
        "Projects": [
            "TheVirtualFactory"
        ],
        "keywords": [
            "Mixed reality",
            "cross-reality",
            "3D applications",
            "data visualization",
            "remote collaboration",
            "virtual worlds",
            "virtual factory",
            "TCHO",
            "pervasive computing",
            "simulation",
            "mobile applications",
            "collaborative tools",
            "ext_Web"
        ],
        "AcceptDate": "07/10/2010",
        "palwebID": "PR-10-587",
        "Venue": "ACM Multimedia 2010 - Industrial Exhibits",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-587/FXPAL-PR-10-587.pdf",
            "http://palweb/files/PR/2010/PR-10-587/Thumbs.db"
        ],
        "PublicationDate": "10/25/2010",
        "ID": "587",
        "Authors": [
            "Maribeth Back",
            "Don Kimber",
            "Eleanor Rieffel",
            "Tony Dunnigan",
            "Bee-Yian Liew",
            "Sagar Gattepally",
            "Jonathan Foote",
            "Jun Shingu",
            "Jim Vaughan"
        ],
        "Title": "The Virtual Chocolate Factory:\r\nMixed Reality Industrial Collaboration and Control",
        "Abstract": "We will exhibit several aspects of a complex mixed reality system that we have built and deployed in a real-world factory setting. In our system, virtual worlds, augmented realities, and mobile applications are all fed from the same infrastructure. In collaboration with TCHO, a chocolate maker in San Francisco, we built a virtual \u00e2\u20ac\u0153mirror\u00e2\u20ac\u009d world of a real-world chocolate factory and its processes. Sensor data is imported into the multi-user 3D environment from hundreds of sensors on the factory floor. The resulting virtual factory is used for simulation, visualization, and collaboration, using a set of interlinked, real-time layers of information. Another part of our infrastructure is designed to support appropriate industrial uses for mobile devices such as cell phones and tablet computers. We deployed this system at the real-world factory in 2009, and it is now is daily use there. By simultaneously developing mobile, virtual, and web-based display and collaboration environments, we aimed to create an infrastructure that did not skew toward one type of application but that could serve many at once, interchangeably. Through this mixture of mobile, social, mixed and virtual technologies, we hope to create systems for enhanced collaboration in industrial settings between physically remote people and places, such as factories in China with managers in the US."
    },
    {
        "Projects": [
            "TalkMiner"
        ],
        "keywords": [
            "talkminer",
            "presentation",
            "webcast"
        ],
        "AcceptDate": "07/11/2010",
        "palwebID": "PR-10-592",
        "Venue": "ACM Multimedia 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-592/FXPAL-PR-10-592.pdf"
        ],
        "PublicationDate": "10/25/2010",
        "ID": "592",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "Laurent Denoue",
            "Hamed Pirsiavash",
            "Lawrence Rowe"
        ],
        "Title": "TalkMiner: A Lecture Webcast Search Engine",
        "Abstract": "The design and implementation of a search engine for lecture webcasts is described. A searchable text index is created allowing users to locate material within lecture videos found on a variety of websites such as YouTube and Berkeley webcasts. The index is created from words on the presentation slides appearing in the video along with any associated metadata such as the title and abstract when available. The video is analyzed to identify a set of distinct slide images, to which OCR and lexical processes are applied which in turn generate a list of indexable terms. \r\nSeveral problems were discovered when trying to identify\r\ndistinct slides in the video stream. For example, picture-in-picture compositing of a speaker and a presentation slide, switching cameras, and slide builds confuse basic frame-differencing algorithms for extracting keyframe slide images.\r\nAlgorithms are described that improve slide identification.\r\nA prototype system was built to test the algorithms and\r\nthe utility of the search engine. Users can browse lists of\r\nlectures, slides in a specific lecture, or play the lecture video.\r\nOver 10,000 lecture videos have been indexed from a variety\r\nof sources. A public website will be published in mid 2010\r\nthat allows users to experiment with the search engine."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [],
        "AcceptDate": "08/08/2010",
        "palwebID": "PR-10-624",
        "Venue": "ACM International Conference on Multimodal Interfaces",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-624/FXPAL-PR-10-624.pdf",
            "http://palweb/files/PR/2010/PR-10-624/Thumbs.db"
        ],
        "PublicationDate": "11/08/2010",
        "ID": "624",
        "Authors": [
            "Qiong Liu",
            "Chunyuan Liao",
            "Lynn Wilcox",
            "Tony Dunnigan"
        ],
        "Title": "Embedded Media Barcode Links: Optimally Blended Barcode Overlay on Paper for Linking to Associated Media",
        "Abstract": "Embedded Media Barcode Links, or simply EMBLs, are optimally blended iconic barcode marks, printed on paper documents, that signify the existence of multimedia associated with that part of the document content (Figure 1). EMBLs are used for multimedia retrieval with a camera phone. Users take a picture of an EMBL-signified document patch using a cell phone, and the multimedia associated with the EMBL-signified document location is displayed on the phone. Unlike a traditional barcode which requires an exclusive space, the EMBL construction algorithm acts as an agent to negotiate with a barcode reader for maximum user and document benefits. Because of this negotiation, EMBLs are optimally blended with content and thus have less interference with the original document layout and can be moved closer to a media associated location. Retrieval of media associated with an EMBL is based on the barcode identification of a captured EMBL. Therefore, EMBL retains nearly all barcode identification advantages, such as accuracy, speed, and scalability. Moreover, EMBL takes advantage of users' knowledge of a traditional barcode. Unlike Embedded Media Maker (EMM) which requires underlying document features for marker identification, EMBL has no requirement for the underlying features. This paper will discuss the procedures for EMBL construction and optimization. It will also give experimental results that strongly support the EMBL construction and optimization ideas."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [],
        "AcceptDate": "09/03/2010",
        "palwebID": "PR-11-625",
        "Venue": "Fuji Xerox Technical Report",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-625/FXPAL-PR-11-625.pdf",
            "http://palweb/files/PR/2011/PR-11-625/Thumbs.db"
        ],
        "PublicationDate": "01/01/2011",
        "ID": "625",
        "Authors": [
            "Qiong Liu",
            "Chunyuan Liao",
            "Lynn Wilcox",
            "Tony Dunnigan",
            "Bee-Yian Liew"
        ],
        "Title": "Embedded Media Markers: Marks on Paper that Signify Associated Media",
        "Abstract": "Embedded Media Markers, or simply EMMs, are nearly transparent iconic marks printed on paper documents that signify the existence of media associated with that part of the document. EMMs also guide users' camera operations for media retrieval. Users take a picture of an EMM-signified document patch using a cell phone, and the media associated with the EMM-signified document location is displayed on the phone. Unlike bar codes, EMMs are nearly transparent and thus do not interfere with the document appearance. Retrieval of media associated with an EMM is based on image local features of the captured EMM-signified document patch. This paper describes a technique for semi-automatically placing an EMM at a location in a document, in such a way that it encompasses sufficient identification features with minimal disturbance to the original document."
    },
    {
        "Projects": [],
        "keywords": [
            "Supervised Machine Learning; Learning with a Teacher; Learning from Labeled Data; Regression;\r\nClassification; Inductive Machine Learning; Active Learning; Semi-supervised Learning;"
        ],
        "AcceptDate": "04/06/2010",
        "palwebID": "PR-11-626",
        "Venue": "Encyclopledia of the Sciences of Learning",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-626/FXPAL-PR-11-626.pdf",
            "http://palweb/files/PR/2011/PR-11-626/Thumbs.db"
        ],
        "PublicationDate": "01/01/2011",
        "ID": "626",
        "Authors": [
            "Qiong Liu"
        ],
        "Title": "SUPERVISED LEARNING",
        "Abstract": "Supervised Learning is a machine learning paradigm for acquiring the input-output relationship information\r\nof a system based on a given set of paired input-output training samples. As the output is regarded as the\r\nlabel of the input data or the supervision, an input-output training sample is also called labelled training data,\r\nor supervised data. Occasionally, it is also referred to as Learning with a Teacher (Haykin 1998), Learning\r\nfrom Labelled Data, or Inductive Machine Learning (Kotsiantis, 2007). The goal of supervised learning is to\r\nbuild an artificial system that can learn the mapping between the input and the output, and can predict the\r\noutput of the system given new inputs. If the output takes a finite set of discrete values that indicate the class\r\nlabels of the input, the learned mapping leads to the classification of the input data. If the output takes continuous\r\nvalues, it leads to a regression of the input. The input-output relationship information is frequently\r\nrepresented with learning-model parameters. When these parameters are not directly available from training\r\nsamples, a learning system needs to go through an estimation process to obtain these parameters. Different\r\nform Unsupervised Learning, the training data for Supervised Learning need supervised or labelled information,\r\nwhile the training data for unsupervised learning are unsupervised as they are not labelled (i.e., merely\r\nthe inputs). If an algorithm uses both supervised and unsupervised training data, it is called a Semi-supervised\r\nLearning algorithm. If an algorithm actively queries a user/teacher for labels in the training process, the iterative\r\nsupervised learning is called Active Learning."
    },
    {
        "Projects": [
            "Pantheia\r\nRephotography",
            "Camera Pose Navigation",
            "Pantheia"
        ],
        "keywords": [
            "Augmented Reality",
            "Repeat Photography",
            "Rephotography",
            "Camera Pose Navigation",
            "Pantheia"
        ],
        "AcceptDate": "08/02/2010",
        "palwebID": "PR-10-635",
        "Venue": "ISMAR 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-635/FXPAL-PR-10-635.pdf"
        ],
        "PublicationDate": "10/13/2010",
        "ID": "635",
        "Authors": [
            "Jun Shingu",
            "Eleanor Rieffel",
            "Don Kimber",
            "Jim Vaughan",
            "Pernilla Qvarfordt",
            "Kathleen Tuite"
        ],
        "Title": "Camera Pose Navigation using Augmented Reality",
        "Abstract": "We propose an Augmented Reality (AR) system that helps users\r\ntake a picture from a designated pose, such as the position and\r\ncamera angle of an earlier photo. Repeat photography is\r\nfrequently used to observe and document changes in an object.\r\nOur system uses AR technology to estimate camera poses in real\r\ntime. When a user takes a photo, the camera pose is saved as a\r\n'view bookmark.' To support a user in taking a repeat photo, two\r\nsimple graphics are rendered in an AR viewer on the camera's\r\nscreen to guide the user to this bookmarked view. The system then\r\nuses image adjustment techniques to create an image based on the\r\nuser's repeat photo that is even closer to the original."
    },
    {
        "Projects": [],
        "keywords": [
            "security",
            "data aggregation",
            "differential privacy",
            "homomorphic encryption"
        ],
        "AcceptDate": "10/11/2010",
        "palwebID": "PR-11-636",
        "Venue": "NDSS 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-636/FXPAL-PR-11-636.pdf"
        ],
        "PublicationDate": "02/06/2011",
        "ID": "636",
        "Authors": [
            "Elaine Shi",
            "T-H Hubert Chan",
            "Eleanor Rieffel",
            "Richard  Chow",
            "Dawn Song"
        ],
        "Title": "Privacy-Preserving Aggregation of Time-Series Data",
        "Abstract": "We consider how an untrusted data aggregator can learn desired statistics over multiple participants\u00e2\u20ac\u2122\r\ndata, without compromising each individual\u00e2\u20ac\u2122s privacy. We propose a construction that allows a group\r\nof participants to periodically upload encrypted values to a data aggregator, such that the aggregator is\r\nable to compute the sum of all participants\u00e2\u20ac\u2122 values in every time period, but is unable to learn anything\r\nelse. We achieve strong privacy guarantees using two main techniques. First, we show how to utilize\r\napplied cryptographic techniques to allow the aggregator to decrypt the sum from multiple ciphertexts\r\nencrypted under different user keys. Second, we describe a distributed data randomization procedure\r\nthat guarantees the differential privacy of the outcome statistic, even when a subset of participants might\r\nbe compromised."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "10/16/2010",
        "palwebID": "PR-10-637",
        "Venue": "NPUC2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-637/FXPAL-PR-10-637.pdf"
        ],
        "PublicationDate": "10/22/2010",
        "ID": "637",
        "Authors": [
            "Eleanor Rieffel",
            "Jacob Biehl",
            "Bill van Melle",
            "Adam J. Lee"
        ],
        "Title": "\"Need to know\" security for data analysis (poster - the abstract will appear in the program)",
        "Abstract": "The massive amounts of information that are being collected about each\r\nof us will only increase as sensors become ever cheaper and more\r\npowerful. Analysis of this wealth of data supports advances in medicine\r\nand public health, improved software and services through user pattern\r\nanalysis, and more efficient economic mechanisms. At the same time, the\r\npotential for misuse of such data is significant. A long-term research\r\nquestion is how best to support beneficial uses while inhibiting misuse.\r\n\r\nOne approach is to enable individuals to maintain tighter control of\r\ntheir own data while still supporting the computation of group\r\nstatistics. Currently, analysts are usually given access to all data in\r\norder to compute statistics, and often use a third party service\r\nprovider to store, or even process, such data. Either the third party\r\nhas access to all data or the data are encrypted, in which case the\r\nthird party does no processing. An interesting research question is how\r\nto provide mechanisms to support \"need to know\" security in which an\r\nindividual has full access to her own data, the third party learns\r\nnothing about the data but can nevertheless contribute to the\r\nprocessing, and the analyst learns only the desired statistics. We have\r\nexplored \"need to know\" security in connection with MyUnity, a prototype awareness system.\r\n\r\nMyUnity collects data from a variety of sources and displays summary\r\npresence states, such as ``in office'' or ``with visitor,'' computed\r\nfrom the received data. MyUnity was deployed in a small research lab and\r\nhas been in use by over 30 people for more than a year.  To avoid\r\nconcerns about misuse, the system did not store any data initially. The\r\nresearchers developing the system were interested, however, in analyzing\r\nusage patterns, and users expressed interest in seeing personal trends,\r\nactivity patterns of coworkers, and long-term data pooled across groups\r\nof users, all requiring data to be stored. At the same time, users\r\ncontinued to be concerned about misuse of stored data. We looked at\r\n``need to know'' security for cases in which, at each time step, each\r\nmember of a group of users has a value (i.e., a presence state) to\r\ncontribute, and the group would like to provide only an aggregate view\r\nof those values to people outside their group.\r\n\r\nWe designed and implemented an efficient protocol that enables each user\r\nto encrypt under her own key in such a way that a third party can\r\ncompute an encryption of a sum across values encrypted under different\r\nkeys without the need for further interactions with the individuals. The\r\nprotocol provides means for an analyst to decrypt the encrypted sum. We\r\ndesigned key structures and extensions to provide a family of efficient\r\nnon-interactive ``need to know'' protocols for time series data in which\r\nthe analyst learns only the statistics, not the individual data values,\r\nand the third party learns nothing about the values.\r\n"
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [
            "Augmented paper",
            "barcode",
            "camera phone",
            "document recognition",
            "marker on paper",
            "vision-based paper interface",
            "EMM"
        ],
        "AcceptDate": "08/01/2010",
        "palwebID": "PR-10-638",
        "Venue": "ACM Multimedia 2010",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-638/FXPAL-PR-10-638.pdf"
        ],
        "PublicationDate": "10/25/2010",
        "ID": "638",
        "Authors": [
            "Qiong Liu",
            "Chunyuan Liao",
            "Lynn Wilcox",
            "Tony Dunnigan",
            "Bee-Yian Liew"
        ],
        "Title": "Embedded Media Markers: Linking Multimedia to Paper",
        "Abstract": "An Embedded Media Marker (EMM) is a transparent mark printed on a paper document that signifies the availability of additional media associated with that part of the document. Users take a picture of the EMM using a camera phone, and the media associated with that part of the document is displayed on the phone. Unlike bar codes, EMMs are nearly transparent and thus do not interfere with the document appearance. Retrieval of media associated with an EMM is based on image features of the document within the EMM boundary. Unlike other feature-based retrieval methods, the EMM clearly indicates to the user the existence and type of media associated with the document location. A semi-automatic authoring tool is used to place an EMM at a location in a document, in such a way that it encompasses sufficient identification features with minimal disturbance to the original document. We will demonstrate how to create an EMM-enhanced document, and how the EMM enables access to the associated media on a cell phone."
    },
    {
        "Projects": [
            "FACT"
        ],
        "keywords": [
            "Paper interface",
            "camera",
            "projector",
            "fine-grained",
            "cross-media",
            "multimedia interfaces"
        ],
        "AcceptDate": "07/05/2010",
        "palwebID": "PR-10-640",
        "Venue": "ACM Multimedia",
        "palwebURL": [
            "http://palweb/files/PR/2010/PR-10-640/FXPAL-PR-10-640.pdf"
        ],
        "PublicationDate": "10/25/2010",
        "ID": "640",
        "Authors": [
            "Chunyuan Liao",
            "Hao Tang",
            "Qiong Liu",
            "Patrick Chiu",
            "Francine Chen"
        ],
        "Title": "FACT: Fine-grained Cross-media Interaction with Documents via a Portable Hybrid Paper-Laptop Interface",
        "Abstract": "FACT is an interactive paper system for fine-grained interaction with documents across the boundary between paper and computers. It consists of a small camera-projector unit, a laptop, and ordinary paper documents. With the camera-projector unit pointing to a paper document, the system allows a user to issue pen gestures on the paper document for selecting fine-grained content and applying various digital functions. For example, the user can choose individual words, symbols, figures, and arbitrary regions for keyword search, copy and paste, web search, and remote sharing. FACT thus enables a computer-like user experience on paper. This paper interaction can be integrated with laptop interaction for cross-media manipulations on multiple documents and views. We present the infrastructure, supporting techniques and interaction design, and demonstrate the feasibility via a quantitative experiment. We also propose applications such as document manipulation, map navigation and remote collaboration. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/13/2010",
        "palwebID": "PR-11-641",
        "Venue": "CHI 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-641/FXPAL-PR-11-641.pdf"
        ],
        "PublicationDate": "05/07/2011",
        "ID": "641",
        "Authors": [
            "Patrick Chiu",
            "Chunyuan Liao",
            "Francine Chen"
        ],
        "Title": "Multi-touch Document Folding: \r\nGesture Models, Fold Directions and Symmetries",
        "Abstract": "For document visualization, folding techniques provide a focus-plus-context approach with fairly high legibility on flat sections.  To enable richer interaction, we explore the design space of multi-touch document folding.  We discuss several design considerations for simple modeless gesturing and compatibility with standard Drag and Pinch gestures, and categorize gesture models along the characteristics of Symmetric/Asymmetric and Sequential/Parallel, which yields three gesture models.  We built a prototype document workspace application that integrates folding and standard gestures, and a prototype for experimenting with the gesture models.  A user study was conducted to compare the three models and to analyze the factors of fold direction, target symmetry, and target tolerance in user performance of folding a document to a specific shape.  Our results indicate that all three factors were significant for task times, and parallelism was greater for symmetric targets."
    },
    {
        "Projects": [
            "DiG"
        ],
        "keywords": [
            "DiG"
        ],
        "AcceptDate": "11/05/2010",
        "palwebID": "PR-11-642",
        "Venue": "IUI",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-642/FXPAL-PR-11-642.pdf"
        ],
        "PublicationDate": "02/13/2011",
        "ID": "642",
        "Authors": [
            "Scott Carter",
            "Francine Chen",
            "Aditi Muralidharan",
            "Jeremy Pickens"
        ],
        "Title": "DiG: A task-based approach to product search",
        "Abstract": "While there are many commercial systems designed to help\r\npeople browse and compare products, these interfaces are\r\ntypically product centric. To help users more efficiently identify\r\nproducts that match their needs, we instead focus on\r\nbuilding a task centric interface and system. With this approach,\r\nusers initially answer questions about the types of\r\nsituations in which they expect to use the product. The interface\r\nreveals the types of products that match their needs\r\nand exposes high-level product features related to the kinds\r\nof tasks in which they have expressed an interest. As users\r\nexplore the interface, they can reveal how those high-level\r\nfeatures are linked to actual product data, including customer\r\nreviews and product specifications. We developed\r\nsemi-automatic methods to extract the high-level features\r\nused by the system from online product data. These methods\r\nidentify and group product features, mine and summarize\r\nopinions about those features, and identify product uses.\r\nUser studies verified our focus on high-level features for\r\nbrowsing and low-level features and specifications for comparison."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/11/2011",
        "palwebID": "PR-11-643",
        "Venue": "CHI 2011 Workshop on Mobile and Personal Projection (MP2)",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-643/FXPAL-PR-11-643.pdf"
        ],
        "PublicationDate": "05/08/2011",
        "ID": "643",
        "Authors": [
            "Chunyuan Liao",
            "Jochen Huber",
            "Qiong Liu"
        ],
        "Title": "Toward Bimanual Interactions with \r\nMobile Projectors on Non-planar Surfaces\r\n",
        "Abstract": "The field of personal mobile projection is advancing quickly and a variety of work focuses on enhancing physical objects in the real world with dynamically projected digital artifacts. Due to technological restrictions, none of them has yet investigated, what we feel is the most promising research direction: the (bi-manual) interaction with mobile projections on non-planar surfaces. To elicit the challenges of this field of research, we contribute (1) a technology-centered design space for mobile projector-based interfaces and discus related work in light thereof, (2) a discussion on lessons learnt from two of our research projects, which aim at improving both usability and user experience and (3) an outline of open research challenges within this field.\r\n\r\n"
    },
    {
        "Projects": [
            "VideoKeyframes"
        ],
        "keywords": [
            "Keyframes"
        ],
        "AcceptDate": "02/23/2011",
        "palwebID": "PR-11-644",
        "Venue": "ACM International Conference on Multimedia Retrieval (ICMR)",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-644/FXPAL-PR-11-644.pdf",
            "http://palweb/files/PR/2011/PR-11-644/Thumbs.db"
        ],
        "PublicationDate": "04/17/2011",
        "ID": "644",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "Adaptive Clustering and Interactive Visualizations to Support the Selection of Video Clips",
        "Abstract": "User-generated video from mobile phones, digital cameras, and other devices is increasing, yet people rarely want to watch all the captured video. More commonly, users want a single still image for printing or a short clip from the video for creating a panorama or for sharing. Our interface aims to help users search through video for these images or clips in a more efficient fashion than fast-forwarding or \"scrubbing\" through a video by dragging through locations on a slider. It is based on a hierarchical structure of keyframes in the video, and combines a novel user interface design for browsing a video segment tree with new algorithms for keyframe selection, segment identification, and clustering. These algorithms take into account the need for quality keyframes and balance the desire for short navigation paths and similarity-based clusters. Our user interface presents keyframe hierarchies and displays visual cues for keeping the user oriented while browsing the video. The system adapts to the task by using a non-temporal clustering algorithm when a the user wants a single image. When the user wants a video clip, the system selects one of two temporal clustering algorithm based on a measure of the repetitiveness of the video. User feedback provided us with valuable suggestions for improvements to our system."
    },
    {
        "Projects": [
            "PicNTell"
        ],
        "keywords": [
            "picntell"
        ],
        "AcceptDate": "02/07/2011",
        "palwebID": "PR-11-645",
        "Venue": "CHI 2011 workshop on Video interaction - Making broadcasting a successful social media",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-645/FXPAL-PR-11-645.pdf"
        ],
        "PublicationDate": "05/07/2011",
        "ID": "645",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue",
            "John Adcock"
        ],
        "Title": "mVideoCast: Mobile, real time ROI detection and streaming",
        "Abstract": "A variety of applications are emerging to support streaming video from mobile devices. However, many tasks can benefit\r\nfrom streaming specific content rather than the full video feed which may include irrelevant, private, or distracting content. We describe a system that allows users to capture and stream targeted video content captured with a mobile device. The application incorporates a variety of automatic and interactive techniques to identify and segment desired content, allowing the user to publish a more focused video stream."
    },
    {
        "Projects": [
            "EMM",
            "ScalableVisualSearch"
        ],
        "keywords": [],
        "AcceptDate": "02/11/2011",
        "palwebID": "PR-11-646",
        "Venue": "ACM International Conference on Multimedia Retrieval (ICMR) 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-646/FXPAL-PR-11-646.pdf"
        ],
        "PublicationDate": "04/17/2011",
        "ID": "646",
        "Authors": [
            "Xin Yang",
            "Qiong Liu",
            "Chunyuan Liao",
            "Andreas Girgensohn"
        ],
        "Title": "Large-Scale EMM Identification \u000bwith Geometry-constrained Visual Word Correspondence Voting",
        "Abstract": "Embedded Media Marker (EMM) identification system allows users to retrieve relevant dynamic media associated with a static paper document via camera phones. The user supplies a query image by capturing an EMM-signified patch of a paper document through a camera phone; the system recognizes the query and in turn retrieves and plays the corresponding media on the phone. Accurate image matching is crucial for positive user experience in this application.  To address the challenges posed by large datasets and variations in camera-phone-captured query images, we introduce a novel image matching scheme based on geometrically consistent correspondences. Two matching constraints - \"injection\" and \"approximate global geometric consistency\" (AGGC), which are unique in EMM identification, are presented. A hierarchical scheme, combined with two constraining functions, is designed to detect the \"injective-AGGC\" correspondences between images. A spatial neighborhood search approach is further proposed to address challenging cases with large translational shift. Experimental results on a 100k+ dataset show that our solution achieves high accuracy with low memory and time complexity and outperforms the standard bag-of-words approach."
    },
    {
        "Projects": [
            "DocumentGenreIdentification"
        ],
        "keywords": [
            "genre",
            "office documents",
            "image",
            "text",
            "classification",
            "GenIE"
        ],
        "AcceptDate": "03/14/2011",
        "palwebID": "PR-12-647",
        "Venue": "International Journal on Document Analysis and Recognition (IJDAR): Volume 15, Issue 3 (2012), pp. 167-182.",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-647/FXPAL-PR-12-647.pdf"
        ],
        "PublicationDate": "09/01/2012",
        "ID": "647",
        "Authors": [
            "Francine Chen",
            "Andreas Girgensohn",
            "Matthew Cooper",
            "Yijuan Lu",
            "Gerry Filby"
        ],
        "Title": "Genre identification for office document search and browsing",
        "Abstract": "When searching or browsing documents, the genre of a document is an important consideration that complements topical characterization. We examine design considerations for automatic tagging of office document pages with genre membership. These include selecting\r\nfeatures that characterize genre-related information in office documents, examining the utility of text-based features and image-based features, and proposing a simple ensemble method to improve genre identification performance. In the open-set identification of four office document genres, our experiments show that when combined with image-based\r\nfeatures, text-based features do not significantly influence performance. These results provide support for a\r\ntopic-independent approach to genre identification of office documents. Experiments also show that our simple ensemble method significantly improves performance relative to using a support vector machine (SVM) classifier alone.\r\nWe demonstrate the utility of our approach by integrating our automatic genre tags in a faceted search and browsing application for office document collections."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "02/07/2011",
        "palwebID": "PR-11-648",
        "Venue": "SECOTS 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-648/FXPAL-PR-11-648.pdf"
        ],
        "PublicationDate": "05/23/2011",
        "ID": "648",
        "Authors": [
            "Eleanor Rieffel",
            "Jacob Biehl",
            "Bill van Melle",
            "Adam J. Lee"
        ],
        "Title": "Secured histories for presence systems",
        "Abstract": "As sensors become ever more prevalent, more and\r\nmore information will be collected about each of us. A longterm\r\nresearch question is how best to support beneficial uses\r\nwhile preserving individual privacy. Presence systems are an\r\nemerging class of applications that support collaboration. These\r\nsystems leverage pervasive sensors to estimate end-user location,\r\nactivities, and available communication channels. Because such\r\npresence data are sensitive, to achieve wide-spread adoption,\r\nsharing models must reflect the privacy and sharing preferences\r\nof the users. To reflect users' collaborative relationships and\r\nsharing desires, we introduce CollaPSE security in which an\r\nindividual has full access to her own data, a third party processes\r\nthe data without learning anything about the data values, and\r\nusers higher up in the hierarchy learn only statistical information\r\nabout the employees under them. We describe simple schemes\r\nthat efficiently realize CollaPSE security for time series data.\r\nWe implemented these protocols using readily available cryptographic\r\nfunctions, and integrated the protocols with FXPAL's\r\nMyUnity presence system."
    },
    {
        "Projects": [
            "MagicMirror"
        ],
        "keywords": [
            "mirror worlds",
            "augmented reality",
            "3d models"
        ],
        "AcceptDate": "01/22/2011",
        "palwebID": "PR-11-649",
        "Venue": "Augmented Human 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-649/FXPAL-PR-11-649.pdf"
        ],
        "PublicationDate": "03/12/2011",
        "ID": "649",
        "Authors": [
            "Don Kimber",
            "Jim Vaughan",
            "Eleanor Rieffel"
        ],
        "Title": "Augmented Perception through Mirror Worlds",
        "Abstract": "We describe a system that mirrors a public physical space\r\ninto cyberspace to provide people with augmented awareness of that space. Through views on web pages, portable\r\ndevices, or on `Magic Window' displays located in the physical space, remote people may `look in' to the space, while people within the space are provided information not apparent through unaided perception. For example, by looking at a mirror display, people can learn how long others have been\r\npresent, where they have been, etc. People in one part of\r\na building can get a sense of the activities in the rest of\r\nthe building, who is present in their office, look in to a talk\r\nin another room, etc. We describe a prototype for such a\r\nsystem developed in our research lab and office space."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/18/2011",
        "palwebID": "PR-11-650",
        "Venue": "MIT Press",
        "palwebURL": [],
        "PublicationDate": "03/18/2011",
        "ID": "650",
        "Authors": [
            "Eleanor Rieffel",
            "Wolfgang Polak"
        ],
        "Title": "Quantum Computing: A Gentle Introduction",
        "Abstract": "The combination of two of the twentieth century\u00e2\u20ac\u2122s most influential and revolutionary scientific theories, information theory and quantum mechanics, gave rise to a radically new view of computing and information. Quantum information processing explores the implications of using quantum mechanics instead of classical mechanics to model information and its processing. Quantum computing is not about changing the physical substrate on which computation is done from classical to quantum but about changing the notion of computation itself, at the most basic level. The fundamental unit of computation is no longer the bit but the quantum bit or qubit. This comprehensive introduction to the field offers a thorough exposition of quantum computing and the underlying concepts of quantum physics, explaining all the relevant mathematics and offering numerous examples. With its careful development of concepts and thorough explanations, the book makes quantum computing accessible to students and professionals in mathematics, computer science, and engineering. A reader with no prior knowledge of quantum physics (but with sufficient knowledge of linear algebra) will be able to gain a fluent understanding by working through the book.\r\n\r\nThe text covers the basic building blocks of quantum information processing, quantum bits and quantum gates, showing their relationship to the key quantum concepts of quantum measurement, quantum state transformation, and entanglement between quantum subsystems; it treats quantum algorithms, discussing notions of complexity and describing a number of simple algorithms as well as the most significant algorithms to date; and it explores entanglement and robust quantum computation, investigating such topics as quantifying entanglement, decoherence, quantum error correction, and fault tolerance."
    },
    {
        "Projects": [],
        "keywords": [
            "temporal information retrieval",
            "MAV"
        ],
        "AcceptDate": "04/07/2011",
        "palwebID": "PR-11-651",
        "Venue": "SIGIR2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-651/FXPAL-PR-11-651.pdf"
        ],
        "PublicationDate": "07/24/2011",
        "ID": "651",
        "Authors": [
            "Miles Efron",
            "Gene Golovchinsky"
        ],
        "Title": "Estimation Methods for Ranking Recent Information",
        "Abstract": "Temporal aspects of documents can impact relevance for certain kinds of queries. In this paper, we build on earlier work of modeling temporal information. We propose an extension to the Query Likelihood Model that incorporates query-specific information to estimate rate parameters, and we introduce a temporal factor into language model smoothing and query expansion using pseudo-relevance feedback. We evaluate these extensions using a Twitter corpus and two newspaper article collections. Results suggest that, compared to prior approaches, our models are more effective at capturing the temporal variability of relevance associated with some topics."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "04/22/2011",
        "palwebID": "PR-11-652",
        "Venue": "MobileHCI",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-652/FXPAL-PR-11-652.pdf"
        ],
        "PublicationDate": "08/30/2011",
        "ID": "652",
        "Authors": [
            "Jason Wiese",
            "Jacob Biehl",
            "Thea Turner",
            "Bill van Melle",
            "Andreas Girgensohn"
        ],
        "Title": "Beyond 'yesterday's tomorrow': Towards the design of awareness technologies for the contemporary worker\r\n",
        "Abstract": "Modern office work practices increasingly breach traditional boundaries of time and place, increasing breakdowns workers encounter when coordinating interaction with colleagues. We conducted interviews with 12 workers and identified key problems introduced by these practices. To address these problems we developed myUnity, a fully functional platform enabling rich workplace awareness and coordination. myUnity is one of the first integrated platforms to span mobile and desktop environments, both in terms of access and sensing. It uses multiple sources to report user location, availability, tasks, and communication channels. A pilot field study of myUnity demonstrated the significant value of pervasive access to workplace awareness and communication facilities, as well as positive behavioral change in day-to-day communication practices for most users. We present resulting insights about the utility of awareness technology in flexible work environments.\r\n"
    },
    {
        "Projects": [
            "FACT"
        ],
        "keywords": [
            "interactive paper",
            "mouse",
            "keyboard",
            "cross-media",
            "document"
        ],
        "AcceptDate": "07/06/2011",
        "palwebID": "PR-11-653",
        "Venue": "UbiComp 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-653/FXPAL-PR-11-653.pdf"
        ],
        "PublicationDate": "09/17/2011",
        "ID": "653",
        "Authors": [
            "Chunyuan Liao",
            "Qiong Liu"
        ],
        "Title": "MixPad: Augmenting Interactive Paper with Mice & Keyboards for Fine-grained Cross-media Interaction with Documents",
        "Abstract": "This demo shows an interactive paper system called MixPad, which features using mice and keyboards to enhance the conventional pen-finger-gesture based interaction with paper documents. Similar to many interactive paper systems, MixPad adopts a mobile camera-projector unit to recognize paper documents, detect pen and finger gestures and provide visual feedback. Unlike these systems, MixPad allows using mice and keyboards to help users interact with fine-grained document content on paper (e.g. individual words and user-defined arbitrary regions), and to facilitate cross-media operations. For instance, to copy a document segment from paper to a laptop, one first points a finger of her non-dominant hand to the segment roughly, and then uses a mouse in her dominant hand to refine the selection and drag it to the laptop; she can also type text as a detailed comment on a paper document. This novel interaction paradigm combines the advantages of mice, keyboards, pens and fingers, and therefore enables rich digital functions on paper."
    },
    {
        "Projects": [
            "DigitalPhotoManagement"
        ],
        "keywords": [
            "rmo",
            "photo",
            "event clustering"
        ],
        "AcceptDate": "07/03/2011",
        "palwebID": "PR-11-654",
        "Venue": "ACM Multimedia 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-654/FXPAL-PR-11-654.pdf"
        ],
        "PublicationDate": "11/28/2011",
        "ID": "654",
        "Authors": [
            "Matthew Cooper"
        ],
        "Title": "Clustering Geo-tagged Photographs using Dynamic Programming",
        "Abstract": "This paper describes methods for clustering photos that include both time stamps and location coordinates.   We present versions of a two part method that first detects clusters using time and location information independently. These candidate clusters partition the set of time-ordered photos. A subset of the candidate clusters is selected by an efficient dynamic programming\r\n procedure to optimize a cost function.  We propose several cost functions to design clusterings that are coherent in space, time, or both.  One set of cost functions minimizes inter-photo distances directly.  A second set maximizes an information measure to select clusterings for consistency in both time and space across scale."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-11-655",
        "Venue": "CBDAR 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-655/FXPAL-PR-11-655.pdf"
        ],
        "PublicationDate": "09/18/2011",
        "ID": "655",
        "Authors": [
            "Qiong Liu",
            "Chunyuan Liao"
        ],
        "Title": "PaperUI",
        "Abstract": "Invited Talk. http://imlab.jp/cbdar2011/#keynote"
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [
            "EMM"
        ],
        "AcceptDate": "06/27/2011",
        "palwebID": "PR-11-656",
        "Venue": "ACM Multimedia 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-656/FXPAL-PR-11-656.pdf"
        ],
        "PublicationDate": "11/28/2011",
        "ID": "656",
        "Authors": [
            "Andreas Girgensohn",
            "Frank Shipman",
            "Lynn Wilcox",
            "Qiong Liu",
            "Chunyuan Liao",
            "Yuichi  Oneda"
        ],
        "Title": "A Tool for Authoring Unambiguous Links from Printed Content to Digital Media",
        "Abstract": "Embedded Media Markers (EMMs) are nearly transparent icons printed on paper documents that link to associated digital media. By using the document content for retrieval, EMMs are less visually intrusive than barcodes and other glyphs while still providing an indication for the presence of links. An initial implementation demonstrated good overall performance but exposed difficulties in guaranteeing the creation of unambiguous EMMs. We developed an EMM authoring tool that supports the interactive authoring of EMMs via visualizations that show the user which areas on a page may cause recognition errors and automatic feedback that moves the authored EMM away from those areas. The authoring tool and the techniques it relies on have been applied to corpora with different visual characteristics to explore the generality of our approach."
    },
    {
        "Projects": [
            "ActiveReadingApplication"
        ],
        "keywords": [
            "ara"
        ],
        "AcceptDate": "10/19/2011",
        "palwebID": "PR-11-657",
        "Venue": "ACM Multimedia Industrial Exhibit",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-657/FXPAL-PR-11-657.pdf"
        ],
        "PublicationDate": "11/28/2011",
        "ID": "657",
        "Authors": [
            "Gene Golovchinsky",
            "Scott Carter",
            "Tony Dunnigan"
        ],
        "Title": "ARA: The Active Reading Application",
        "Abstract": "The Active Reading Application (ARA) brings the familiar experience of writing on paper to the tablet. The application augments paper-based practices with audio, the ability\r\nto review annotations, and sharing. It is designed to make it easier to review, annotate, and comment on documents by\r\nindividuals and groups. ARA incorporates several patented technologies and draws on several years of research and experimentation."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "09/16/2011",
        "palwebID": "PR-11-658",
        "Venue": "ACM Multimedia Industrial Exhibits",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-658/FXPAL-PR-11-658.pdf"
        ],
        "PublicationDate": "11/28/2011",
        "ID": "658",
        "Authors": [
            "Jacob Biehl",
            "Thea Turner",
            "Bill van Melle",
            "Andreas Girgensohn"
        ],
        "Title": "myUnity: A new platform to support communication in the modern workplace",
        "Abstract": "Modern office work practices increasingly breach traditional boundaries of time and place, making it difficult to interact with colleagues. To address these problems, we developed myUnity, a software and sensor platform that enables rich workplace awareness and coordination. myUnity is an integrated platform that collects information from a set of independent sensors and external data aggregators to report user location, availability, tasks, and communication channels. myUnity's sensing architecture is component-based, allowing channels of awareness information to be added, updated, or removed at any time. Our current system includes a variety of sensor and data input, including camera-based activity classification, wireless location trilateration, and network activity monitoring. These and other input channels are combined and composited into a single, high-level presence state. Early studies of a myUnity deployment have demonstrated that use of the platform allows quick access to core awareness information and show it has become a useful tool supporting communication and collaboration in the modern workplace."
    },
    {
        "Projects": [
            "FACT"
        ],
        "keywords": [
            "paper document; camera phone; human-computer interface; human-computer interaction; document recognition; augmented paper",
            "vision-based paper interface."
        ],
        "AcceptDate": "10/01/2011",
        "palwebID": "PR-11-659",
        "Venue": "Springer LNCS",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-659/FXPAL-PR-11-659.pdf"
        ],
        "PublicationDate": "12/01/2011",
        "ID": "659",
        "Authors": [
            "Qiong Liu",
            "Chunyuan Liao"
        ],
        "Title": "PaperUI",
        "Abstract": "PaperUI is a human-information interface concept that advocates using paper as displays and using mobile devices, such as camera phones or camera pens, as traditional computer-mice. When emphasizing technical efforts, some researchers like to refer the PaperUI related underlying work as interactive paper system. We prefer the term PaperUI for emphasizing the final goal, narrowing the discussion focus, and avoiding terminology confusion between interactive paper system and interactive paper computer [40]. PaperUI combines the merits of paper and the mobile devices, in that users can comfortably read and flexibly arrange document content on paper, and access digital functions related to the document via the mobile computing devices. This concept aims at novel interface technology to seamlessly bridge the gap between paper and computers for better user experience in handling documents. Compared with traditional laptops and tablet PCs, devices involved in the PaperUI concept are more light-weight, compact, energy efficient, and widely adopted. Therefore, we believe this interface vision can make computation more convenient to access for general public."
    },
    {
        "Projects": [
            "Querium"
        ],
        "keywords": [
            "sessionsearch",
            "Querium",
            "exploratory search",
            "interactive information seeking"
        ],
        "AcceptDate": "09/30/2011",
        "palwebID": "PR-11-660",
        "Venue": "HCIR 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-660/FXPAL-PR-11-660.pdf"
        ],
        "PublicationDate": "10/20/2011",
        "ID": "660",
        "Authors": [
            "Gene Golovchinsky",
            "Abdigani  Diriye"
        ],
        "Title": "Session-based search with Querium",
        "Abstract": "We illustrate the use of Querium, a novel search system designed to support people\u00e2\u20ac\u2122s collaborative and multi-session search tasks, in the context of the HCIR 2011 Search Challenge. This report demonstrates how a Querium\u00e2\u20ac\u2122s interface and search engine can be used to search for documents in an open-ended, exploratory task. We illustrate the use of relevance feedback, faceted search, query fusion, and the search history, as well as commenting and overview functions."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/01/2011",
        "palwebID": "PR-11-662",
        "Venue": "Stanford Seminar on People, Computers, and Design",
        "palwebURL": [],
        "PublicationDate": "10/03/2011",
        "ID": "662",
        "Authors": [
            "Gene Golovchinsky"
        ],
        "Title": "Reading Appliances and the Future of Document Work",
        "Abstract": "Documents created, stored, and retrieved digitally are often printed on paper to be read for the purposes of producing new documents. The cycle of electronic document \"consumption\" and production is often broken in the middle by printing.\r\n\r\nOur research in XLibris has examined these transitions between the digital and paper worlds. Starting with interfaces for analytic reading, we have focused on annotation, on retrieval and re-retrieval, and on shared annotation. In this talk, I will describe the interfaces and the empirical evaluations we have conducted, and will discuss the potential of this technology in digital--and in physical--libraries."
    },
    {
        "Projects": [
            "Querium"
        ],
        "keywords": [
            "sessionsearch",
            "Querium",
            "exploratory search",
            "interactive information seeking"
        ],
        "AcceptDate": "09/12/2011",
        "palwebID": "PR-11-663",
        "Venue": "HCIR 2011",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-663/FXPAL-PR-11-663.pdf"
        ],
        "PublicationDate": "10/19/2011",
        "ID": "663",
        "Authors": [
            "Gene Golovchinsky",
            "Abdigani  Diriye",
            "Jeremy Pickens"
        ],
        "Title": "Designing for Collaboration in Information Seeking",
        "Abstract": "Information seeking is often a collaborative activity that can take can take many forms; in this paper we focus on explicit, intentional collaboration of small  and explore a range of design decisions that should be considered when building Human-Computer Information Retrieval (HCIR) tools that support collaboration. In particular, we are interested in exploring the interplay between algorithmic mediation of collaboration and the mediated communication among team members. We argue that certain characteristics of the group\u00e2\u20ac\u2122s information need call for different design decisions."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/30/2011",
        "palwebID": "PR-12-664",
        "Venue": "DAS 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-664/FXPAL-PR-12-664.pdf"
        ],
        "PublicationDate": "03/27/2012",
        "ID": "664",
        "Authors": [
            "Michael Cutter",
            "Patrick Chiu"
        ],
        "Title": "Capture and Dewarping of Page Spreads with a Handheld Compact 3D Camera",
        "Abstract": "This paper describes a system for capturing images\r\nof a book with a 3D stereo camera which performs\r\ndewarping to produce output images that are flattened. A\r\nFujifilm consumer grade 3D camera (FinePix W3) provides\r\na highly mobile and low cost 3D capture device. Applying\r\nstandard computer vision algorithms, the camera is calibrated\r\nand the captured images are stereo rectified. Due to technical\r\nlimitations, the resulting point cloud has defects such as\r\nsplotches and noise, which make it hard to recover the precise\r\n3D locations of the points on the book pages. We address this\r\nproblem by computing curve profiles of the depth map and\r\nusing them to build a cylinder model of the pages. We then\r\ngenerate a mesh M1 on the source image and project this into\r\na mesh M2 on the cylinder model in virtual space. Finally, the\r\nmesh M2 is flattened and the pixels in M1 are interpolated and\r\nrendered via M2 onto the output image. We have implemented\r\na prototype of the system and report on some preliminary\r\nevaluation results."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "12/16/2011",
        "palwebID": "PR-12-665",
        "Venue": "CHI 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-665/FXPAL-PR-12-665.pdf"
        ],
        "PublicationDate": "05/07/2012",
        "ID": "665",
        "Authors": [
            "Anbang Xu",
            "Jacob Biehl",
            "Eleanor Rieffel",
            "Thea Turner",
            "Bill van Melle"
        ],
        "Title": "Learning how to feel again: Towards affective workplace presence and communication technologies",
        "Abstract": "Affect influences workplace collaboration and thereby impacts a workplace\u00e2\u20ac\u2122s productivity. Participants in face-toface interactions have many cues to each other\u00e2\u20ac\u2122s affect, but work is increasingly carried out via computer-mediated channels that lack many of these cues. Current presence\r\nsystems enable users to estimate the availability of other users, but not their affect states or communication\r\npreferences. This work investigates relationships between affect state and communication preferences and demonstrates the feasibility of estimating affect state and communication preferences from a presence state stream."
    },
    {
        "Projects": [
            "EMM"
        ],
        "keywords": [
            "EMM"
        ],
        "AcceptDate": "09/11/2011",
        "palwebID": "PR-11-666",
        "Venue": "The 10th International Conference on Virtual Reality Continuum and Its Applications in Industry",
        "palwebURL": [
            "http://palweb/files/PR/2011/PR-11-666/FXPAL-PR-11-666.pdf"
        ],
        "PublicationDate": "12/11/2011",
        "ID": "666",
        "Authors": [
            "Xin Yang",
            "Chunyuan Liao",
            "Qiong Liu"
        ],
        "Title": "Minimum Correspondence Sets for \r\nImproving Large-Scale Augmented Paper\r\n",
        "Abstract": "Augmented Paper (AP) is an important area of Augmented Reality (AR). Many AP systems rely on visual features for paper doc-ument identification. Although promising, these systems can hardly support large sets of documents (i.e. one million documents) because of the high memory and time cost in handling high-dimensional features. On the other hand, general large-scale image identification techniques are not well customized to AP, costing unnecessarily more resource to achieve the identification accuracy required by AP.\r\nTo address this mismatching between AP and image identification techniques, we propose a novel large-scale image identification technique well geared to AP. At its core is a geometric verification scheme based on Minimum visual-word Correspondence Set (MICSs). MICS is a set of visual word (i.e. quantized visual fea-ture) correspondences, each of which contains a minimum number of correspondences that are sufficient for deriving a transformation hypothesis between a captured document image and an indexed image. Our method selects appropriate MICSs to vote in a Hough space of transformation parameters, and uses a robust dense region detection algorithm to locate the possible transformation models in the space.  The models are then utilized to verify all the visual word correspondence to precisely identify the matching indexed image. \r\nBy taking advantage of unique geometric constraints in AP, our method can significantly reduce the time and memory cost while achieving high accuracy. As showed in evaluation with two AP systems called FACT and EMM, over a dataset with 1M+ images, our method achieves 100% identification accuracy and 0.67% registration error for FACT; For EMM, our method outperforms the state-of-the-art image identification approach by achieving 4% improvements in detection rate and almost perfect precision, while saving 40% and 70% memory and time cost.\r\n"
    },
    {
        "Projects": [
            "Querium"
        ],
        "keywords": [
            "MAV",
            "Collaborative Search",
            "Querium",
            "sessionsearch"
        ],
        "AcceptDate": "11/20/2011",
        "palwebID": "PR-12-667",
        "Venue": "European Conference on Information Retrieval 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-667/FXPAL-PR-12-667.pdf"
        ],
        "PublicationDate": "04/01/2012",
        "ID": "667",
        "Authors": [
            "Abdigani  Diriye",
            "Gene Golovchinsky",
            "Tony Dunnigan"
        ],
        "Title": "Querium: A Session-Based Collaborative Search System",
        "Abstract": "People\u00e2\u20ac\u2122s information-seeking can span multiple sessions, and can be collaborative in nature. Existing commercial offerings do not effectively support searchers to share, save, collaborate or revisit their information. In this demo paper we present Querium: a novel session-based collaborative search system that lets users search, share, resume and collaborate with other users. Querium provides a number of novel search features in a collaborative setting, including relevance feedback, query fusion, faceted search, and search histories"
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "01/09/2012",
        "palwebID": "PR-12-668",
        "Venue": "Personal and Ubiquitous Computing (PUC)",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-668/FXPAL-PR-12-668.pdf"
        ],
        "PublicationDate": "02/01/2012",
        "ID": "668",
        "Authors": [
            "Jacob Biehl",
            "Eleanor Rieffel",
            "Adam J. Lee"
        ],
        "Title": "When Privacy and Utility are in Harmony: Towards Better Design of Presence Technologies\r\n",
        "Abstract": "Presence systems are valuable in supporting workplace communication and collaboration. These systems are only effective if widely adopted and used. User perceptions of the utility of the information being shared and their comfort sharing such information strongly impact adoption and use. This paper describes the results of a survey of user preferences regarding comfort with and utility of workplace presence systems; the effects of sampling frequency, fidelity, and aggregation; and design implications of these results. We present new results that extend some past findings while challenging others. We contribute new design insights that inform the design of presence technologies to increase both utility and adoption.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/30/2011",
        "palwebID": "PR-12-669",
        "Venue": "CHI 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-669/FXPAL-PR-12-669.pdf"
        ],
        "PublicationDate": "05/05/2012",
        "ID": "669",
        "Authors": [
            "Jochen Huber",
            "Chunyuan Liao",
            "Qiong Liu"
        ],
        "Title": "LightBeam: Nomadic Pico Projector Interaction with Real World Objects",
        "Abstract": "Abstract: Pico projectors have lately been investigated as mobile display and interaction devices. We propose to use them as \u00e2\u20ac\u02dclight beams\u00e2\u20ac\u2122: Everyday objects sojourning in a beam are turned into dedicated projection surfaces and tangible interaction devices. While this has been explored for large projectors, the affordances of pico projectors are fundamentally different: they have a very small and strictly limited projection ray and can be carried around in a nomadic way during the day. Thus it is unclear how this could be actually leveraged for tangible interaction with physical, real world objects. We have investigated this in an exploratory field study and contribute the results. Based upon these, we present exemplary interaction techniques and early user feedback."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-12-670",
        "Venue": "ACM Transactions on Computer Human Interaction ",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-670/FXPAL-PR-12-670.pdf"
        ],
        "PublicationDate": "03/01/2012",
        "ID": "670",
        "Authors": [
            "Chunyuan Liao"
        ],
        "Title": "Evaluating and Understanding the Usability of a Pen-based Command System for Interactive Paper",
        "Abstract": "To combine the affordances of paper and computers, prior research has proposed numerous interactive paper systems that link specific paper document content to digital operations such as multimedia playback and proofreading. Yet, it remains unclear to what degree these systems bridge the inherent gap between paper and computers when compared to existing paper-only and computer-only interfaces. In particular, given the special properties of paper, such as limited dynamic feedback, how well does an average new user learn to master the interactive paper system? What factors affect the user performance? And how does the paper interface work in a typical use scenario?\r\n\r\nTo answer these questions, we conducted two empirical experiments on a generic pen gesture based command system, called PapierCraft [Liao, et al., 2008], for paper-based interfaces. With it, people can select sections of printed document and issue commands such as copy and paste, linking and in-text search. The first experiment focused on the user performance of drawing pen gestures on paper. It proves that users can learn the command system in about 30 minutes and achieve a performance comparable to a Table PC-based interface supporting the same gestures. The second experiment examined the application of the command system in Active Reading tasks. The results show promise for seamless integration of paper and computers in Active Reading for their combined affordances. In addition, our study identifies some key design issues, such as the pen form factor and feedback of gestures. This paper contributes to better understanding on pros and cons of paper and computers, and sheds light on the design of future interfaces for document interaction. \r\n"
    },
    {
        "Projects": [
            "DisplayCast"
        ],
        "keywords": [
            "displaycast"
        ],
        "AcceptDate": "02/15/2012",
        "palwebID": "PR-12-671",
        "Venue": "ACM MMSYS 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-671/FXPAL-PR-12-671.pdf"
        ],
        "PublicationDate": "02/22/2012",
        "ID": "671",
        "Authors": [
            "Surendar Chandra",
            "Jacob Biehl",
            "John Boreczky",
            "Scott Carter",
            "Lawrence Rowe"
        ],
        "Title": "Understanding screen contents for effective screencasting (Poster)",
        "Abstract": "Poster"
    },
    {
        "Projects": [
            "Querium"
        ],
        "keywords": [
            "sessionsearch",
            "exploratory search",
            "interactive information seeking",
            "Querium"
        ],
        "AcceptDate": "02/10/2012",
        "palwebID": "PR-12-672",
        "Venue": "CHI 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-672/FXPAL-PR-12-672.pdf"
        ],
        "PublicationDate": "05/05/2012",
        "ID": "672",
        "Authors": [
            "Gene Golovchinsky",
            "Tony Dunnigan",
            "Abdigani  Diriye"
        ],
        "Title": "Designing a tool for \r\nexploratory information seeking\r\n",
        "Abstract": "In this paper we describe our on-going design process in building a search system designed to support people\u00e2\u20ac\u2122s multi-session exploratory search tasks. The system, called Querium, allows people to run queries and to examine results as do conventional search engines, but it also integrates a sophisticated search history that helps people make sense of their search activity over time. Information seeking is a cognitively demanding process that can benefit from many kinds of information, if that information is presented appropriately. Our design process has been focusing on creating displays that facilitate on-going sense-making while keeping the interaction efficient, fluid, and enjoyable."
    },
    {
        "Projects": [
            "TalkMiner"
        ],
        "keywords": [
            "Talkminer"
        ],
        "AcceptDate": "",
        "palwebID": "PR-12-673",
        "Venue": "Fuji Xerox Technical Report, No. 21, 2012, pp. 118-128",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-673/FXPAL-PR-12-673.pdf"
        ],
        "PublicationDate": "02/03/2012",
        "ID": "673",
        "Authors": [
            "John Adcock",
            "Matthew Cooper",
            "Laurent Denoue",
            "Hamed Pirsiavash",
            "Lawrence Rowe"
        ],
        "Title": "TalkMiner: A Lecture Video Search Engine",
        "Abstract": "The design and implementation of a search engine for lecture webcasts is described. A searchable text index is created allowing users to locate material within lecture videos found on a variety of websites such as YouTube and Berkeley webcasts. The searchable index is built from the text of presentation slides appearing in the video along with other associated metadata such as the title and abstract when available.\r\n\r\nThe automatic identification of distinct slides within the video stream presents several challenges. For example, picture-in-picture compositing of a speaker and a presentation slide, switching cameras, and slide builds confuse basic algorithms for extracting keyframe slide images. Enhanced algorithms are described that improve slide identification.\r\n\r\nA public system was deployed to test the algorithms and the utility of the search engine at www.talkminer.com. To date, over 17,000 lecture videos have been indexed from a variety of public sources."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "02/02/2012",
        "palwebID": "PR-12-674",
        "Venue": "Fuji Xerox Technical Report No.21 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-674/FXPAL-PR-12-674.pdf"
        ],
        "PublicationDate": "02/02/2012",
        "ID": "674",
        "Authors": [
            "Jacob Biehl",
            "Bill van Melle",
            "Thea Turner",
            "Andreas Girgensohn"
        ],
        "Title": "myUnity: A new platform to support communication in the modern workplace",
        "Abstract": "Modern office work practices increasingly breach traditional boundaries of time and place, making it difficult to interact with colleagues. To address these problems, we developed myUnity, a software and sensor platform that enables rich workplace awareness and coordination. myUnity is an integrated platform that collects information from a set of independent sensors and external data aggregators to report user location, availability, tasks, and communication channels. myUnity\u00c3\u00a2\u00e2\u0082\u00ac\u00e2\u0084\u00a2s sensing architecture is component-based,\r\nallowing channels of awareness information to be added, updated, or removed at any time. Multiple channels of input are combined and composited into a single, high-level presence state. Early studies of a myUnity deployment have demonstrated that the platform allows quick access to core awareness information and show that it has become a useful tool for supporting communication and collaboration in the modern workplace."
    },
    {
        "Projects": [
            "Querium"
        ],
        "keywords": [
            "sessionsearch",
            "exploratory search",
            "interactive information seeking",
            "Querium"
        ],
        "AcceptDate": "05/25/2012",
        "palwebID": "PR-12-675",
        "Venue": "IIiX 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-675/FXPAL-PR-12-675.pdf"
        ],
        "PublicationDate": "08/21/2012",
        "ID": "675",
        "Authors": [
            "Gene Golovchinsky",
            "Abdigani  Diriye",
            "Tony Dunnigan"
        ],
        "Title": "The future is in the past: Designing for exploratory search",
        "Abstract": "Exploratory search activities tend to span multiple sessions and involve finding, analyzing and evaluating information and collab-orating with others. Typical search systems, on the other hand, are designed to support a single searcher, precision-oriented search tasks. We describe a search interface and system design of a multi-session exploratory search system, discuss design challenges en-countered, and chronicle the evolution of our design. Our design describes novel displays for visualizing retrieval history infor-mation, and introduces ambient displays and persuasive elements to interactive information retrieval."
    },
    {
        "Projects": [
            "SmartDCap"
        ],
        "keywords": [
            "smart capture",
            "image quality"
        ],
        "AcceptDate": "06/15/2012",
        "palwebID": "PR-12-676",
        "Venue": "ICPR 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-676/FXPAL-PR-12-676.pdf"
        ],
        "PublicationDate": "11/11/2012",
        "ID": "676",
        "Authors": [
            "Jayant Kumar",
            "Francine Chen",
            "David Doermann"
        ],
        "Title": "Sharpness Estimation for Document and Scene Images",
        "Abstract": "Images of document pages have different characteristics\r\nthan images of natural scenes, and so the\r\nsharpness measures developed for natural scene images\r\ndo not necessarily extend to document images\r\nprimarily composed of text. We present an efficient\r\nand simple method for effectively estimating the sharpness/\r\nblurriness of document images that also performs\r\nwell on natural scenes. Our method can be used to\r\npredict the sharpness in scenarios where images are\r\nblurred due to camera-motion (or hand-shake), defocus,\r\nor inherent properties of the imaging system. The\r\nproposed method outperforms the perceptually-based,\r\nno-reference sharpness work of [1] and [4], which was\r\nshown to perform better than 14 other no-reference\r\nsharpness measures on the LIVE dataset."
    },
    {
        "Projects": [],
        "keywords": [
            "multimedia interfaces"
        ],
        "AcceptDate": "06/22/2012",
        "palwebID": "PR-12-677",
        "Venue": "ACM Multimedia 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-677/FXPAL-PR-12-677.pdf"
        ],
        "PublicationDate": "10/29/2012",
        "ID": "677",
        "Authors": [
            "Xin Yang",
            "Chunyuan Liao",
            "Qiong Liu"
        ],
        "Title": "MixPad: Augmenting Paper with Mice & Keyboards for Bimanual, Cross-media and Fine-grained Interaction with Documents",
        "Abstract": "Paper and Computers have complementary advantages and are used side by side in many scenarios. Interactive paper systems aim to combine the two media. However, most such systems only allow fingers and pens to interact with content on paper. This finger-pen-only input suffers from low precision, lag, instability and occlusion. Moreover, it incurs frequent device switch (e.g. pen vs. mouse) in users\u00e2\u20ac\u2122 hand during cross-media interactions, yielding inefficiency and interruptions of a document workspace continuum.   \r\nTo address these limitations, we propose MixPad, a novel interactive paper system which incorporates mice and keyboards to enhance the conventional pen-finger-based paper interaction. Similar to many other systems, MixPad adopts a mobile camera-projector unit to recognize paper documents, detect pen and finger gestures and provide visual feedback. Unlike these systems, MixPad supports users to use mice and keyboards to select fine-grained content and create annotation on paper, and to facilitate bimanual operations for more efficient and smoother cross-media interaction. This novel interaction style combines the advantages of mice, keyboards, pens and fingers, enabling richer digital functions on paper.    \r\n"
    },
    {
        "Projects": [
            "DisplayCast"
        ],
        "keywords": [
            "displaycast",
            "multimedia interfaces"
        ],
        "AcceptDate": "06/22/2012",
        "palwebID": "PR-12-678",
        "Venue": "ACM Multimedia 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-678/FXPAL-PR-12-678.pdf"
        ],
        "PublicationDate": "10/29/2012",
        "ID": "678",
        "Authors": [
            "Surendar Chandra",
            "Jacob Biehl",
            "John Boreczky",
            "Scott Carter",
            "Lawrence Rowe"
        ],
        "Title": "Understanding Screen Contents for Building a High Performance, Real Time Screen Sharing System",
        "Abstract": "Faithful sharing of screen contents is an important collaboration feature. Prior systems were designed to operate over constrained networks. They performed poorly even without such bottlenecks. To build a high performance screen sharing system, we empirically analyzed screen contents for a variety of scenarios. We showed that screen updates were sporadic with long periods of inactivity. When active, screens were updated at far higher rates than was supported by earlier systems. The mismatch was pronounced for interactive scenarios. Even during active screen updates, the number of updated pixels were frequently small. We showed that crucial information can be lost if individual updates were merged. When the available system resources could not support high capture rates, we showed ways in which updates can be effectively collapsed. We showed that Zlib lossless compression performed poorly for screen updates. By analyzing the screen pixels, we developed a practical transformation that significantly improved compression rates. Our system captured 240 updates per second while only using 4.6 Mbps for interactive scenarios. Still, while playing movies in fullscreen mode, our approach could not achieve higher capture rates than prior systems; the CPU remains the bottleneck. A system that incorporates our findings is deployed within the lab."
    },
    {
        "Projects": [
            "DisplayCast"
        ],
        "keywords": [
            "displaycast"
        ],
        "AcceptDate": "07/06/2012",
        "palwebID": "PR-12-679",
        "Venue": "ACM Multimedia '12",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-679/FXPAL-PR-12-679.pdf"
        ],
        "PublicationDate": "10/29/2012",
        "ID": "679",
        "Authors": [
            "Surendar Chandra",
            "Lawrence Rowe"
        ],
        "Title": "DisplayCast: a High Performance Screen Sharing System for Intranets",
        "Abstract": "DisplayCast is a many to many screen sharing system that is targeted towards Intranet scenarios. The capture software runs on all computers whose screens need to be shared. It uses an application agnostic screen capture mechanism that creates a sequence of pixmap images of the screen updates. It transforms these pixmaps to vastly improve the lossless Zlib compression performance. These algorithms were developed after an extensive analysis of typical screen contents. DisplayCast shares the processor and network resources required for screen capture, compression and transmission with host applications whose output needs to be shared. It balances the need for high performance screen capture with reducing its resource interference with user applications. DisplayCast uses Zeroconf for naming and asynchronous location. It provides support for Cisco WiFi and Bluetooth based localization. It also includes a HTTP/REST based controller for remote session initiation and control. DisplayCast supports screen capture and playback in computers running Windows 7 and Mac OS X operating systems. Remote screens can be archived into a H.264 encoded movie on a Mac. They can also be played back in real time on Apple iPhones and iPads. The software is released under a New BSD license."
    },
    {
        "Projects": [],
        "keywords": [
            "Mixed reality",
            "3D applications",
            "data visualization",
            "remote collaboration",
            "virtual worlds",
            "pervasive computing",
            "mobile mixed reality",
            "collaborative tools"
        ],
        "AcceptDate": "04/12/2012",
        "palwebID": "PR-12-680",
        "Venue": "DIS (Designing Interactive Systems) 2012 Demos track",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-680/FXPAL-PR-12-680.pdf"
        ],
        "PublicationDate": "06/11/2012",
        "ID": "680",
        "Authors": [
            "Maribeth Back",
            "Dave Arendash",
            "Tony Dunnigan",
            "Jim Vaughan"
        ],
        "Title": "Design Evolution of a Mixed Reality Factory System",
        "Abstract": "We will demonstrate successive and final stages in the iterative design of a complex mixed reality system in a real-world factory setting.  In collaboration with TCHO, a chocolate maker in San Francisco, we built a virtual \u00e2\u20ac\u0153mirror\u00e2\u20ac\u009d world of a real-world chocolate factory and its processes.  Sensor data is imported into the multi-user 3D environment from hundreds of sensors and a number of cameras on the factory floor. The resulting virtual factory is used for simulation, visualization, and collaboration, using a set of interlinked, real-time layers of information. It can be a stand-alone or a web-based application, and also works on iOS and Android cell phones and tablet computers. A unique aspect of our system is that it is designed to enable the incorporation of lightweight social media-style interactions with co-workers along with factory data. Through this mixture of mobile, social, mixed and virtual technologies, we hope to create systems for enhanced collaboration in industrial settings between physically remote people and places, such as factories in China with managers in the US."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "06/13/2012",
        "palwebID": "PR-12-681",
        "Venue": "Mobile HCI 2012 demo track",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-681/FXPAL-PR-12-681.pdf"
        ],
        "PublicationDate": "09/21/2012",
        "ID": "681",
        "Authors": [
            "Maribeth Back",
            "Tony Dunnigan",
            "Bee-Yian Liew",
            "Jim Vaughan"
        ],
        "Title": "Mobile Monitoring and Control System for a Food Industry Development Laboratory",
        "Abstract": "In this demonstration we will show a mobile remote control and monitoring application for a recipe development laboratory at a local chocolate production company. In collaboration with TCHO, a chocolate maker in San Francisco, we built a mobile Web app designed to allow chocolate makers to control their laboratory\u00e2\u20ac\u2122s machines.  Sensor data is imported into the app from each machine in the lab. The mobile Web app is used for control, monitoring, and collaboration. We have tested and deployed this system at the real-world factory and it is now in daily use. This project is designed as part of a research exploration into enhanced collaboration in industrial settings between physically remote people and places, e.g. factories in China with clients in the US."
    },
    {
        "Projects": [
            "ShowHow"
        ],
        "keywords": [
            "ShowHow"
        ],
        "AcceptDate": "08/22/2012",
        "palwebID": "PR-12-682",
        "Venue": "Workshop on Social Mobile Video and Panoramic Video",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-682/FXPAL-PR-12-682.pdf"
        ],
        "PublicationDate": "09/20/2012",
        "ID": "682",
        "Authors": [
            "Stacy Branham",
            "Scott Carter"
        ],
        "Title": "Who makes, shares Internet how-to videos?",
        "Abstract": "The ways in which we come to know and share what we know with others are deeply entwined with the technologies that enable us to capture and share information. As face-to-face communication has been supplemented with ever-richer media\u00e2\u20ac\u201c\u00e2\u20ac\u201ctextual books, illustrations and photographs, audio, film and video, and more\u00e2\u20ac\u201c\u00e2\u20ac\u201cthe possibilities for knowledge transfer have only expanded. One of the latest trends to emerge amidst the growth of Internet sharing and pervasive mobile devices is the mass creation of online instructional videos. We are interested in exploring how smart phones shape this sort of mobile, rich media documentation and sharing."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "09/07/2012",
        "palwebID": "PR-12-683",
        "Venue": "CIKM 2012 Books Online Workshop Keynote Address",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-683/FXPAL-PR-12-683.pdf"
        ],
        "PublicationDate": "10/29/2012",
        "ID": "683",
        "Authors": [
            "Maribeth Back"
        ],
        "Title": "Revisiting the Future of Reading:  \r\nThe Research and Design Behind XFR  \r\n",
        "Abstract": "Reading is part of how we understand the world, how we share knowledge, how we play, and even how we think. Although reading text is the dominant form of reading, most of the text we read\u00e2\u20ac\u201d letters, numbers, words, and sentences\u00e2\u20ac\u201dis surrounded by illustrations, photographs, and other kinds of symbols that we include as we read.  As dynamic displays migrate into the real world at many scales, whether personal devices, handhelds, or large screens in both interior and exterior spaces, opportunities for reading migrate as well.  As has happened continually throughout the history of reading, new technologies, physical forms and social patterns create new genres, which themselves may then combine or collide to morph into something new.\r\n\r\nAt PARC, the RED (Research in Experimental Design) group examined emerging technologies for impact on media and the human relationship to information, especially reading.  We explored new ways of experiencing text: new genres, new styles of interaction, and unusual media. Among the questions we considered: how might \u00e2\u20ac\u0153the book\u00e2\u20ac\u009d change? More particularly, how does the experience of reading change with the introduction of new technologies\u00e2\u20ac\u00a6and how does it remain the same?\r\n\r\nIn this talk, we'll discuss the ideas behind the design and research process that led to creating eleven different experiences of new forms of reading. We\u00e2\u20ac\u2122ll also consider how our technological context for reading has changed in recent years, and what influence the lessons from XFR may have on our ever-developing online reading experiences.\r\n"
    },
    {
        "Projects": [
            "TalkMiner"
        ],
        "keywords": [
            "Talkminer"
        ],
        "AcceptDate": "09/28/2012",
        "palwebID": "PR-13-684",
        "Venue": "SPIE Electronic Imaging, Multimedia Content Access",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-684/FXPAL-PR-13-684.pdf"
        ],
        "PublicationDate": "02/03/2013",
        "ID": "684",
        "Authors": [
            "Matthew Cooper"
        ],
        "Title": "Presentation Video Retrieval using Automatically Recovered Slide and Spoken Text",
        "Abstract": "Video is becoming a prevalent medium for e-learning. Lecture videos contain useful information in both the visual and aural channels: the presentation slides and lecturer's speech respectively. \r\nTo extract the visual information, we apply video content analysis to detect slides and optical character recognition (OCR) to obtain their text. Automatic speech recognition (ASR) is used similarly to extract spoken text from the recorded audio. These two text sources have distinct characteristics and relative strengths for video retrieval.\r\nWe perform controlled experiments with manually created ground truth for both the slide and spoken text from more than 60 hours of lecture video. We compare the automatically extracted slide and spoken text in terms of accuracy relative to ground truth, overlap with one another, and utility for video retrieval. Experiments reveal that automatically recovered slide text and spoken text contain different content with varying error profiles. Additional experiments demonstrate higher precision video retrieval using automatically extracted slide text."
    },
    {
        "Projects": [
            "MagicMirror"
        ],
        "keywords": [
            "mirror worlds",
            "augmented reality",
            "virtual reality",
            "3D models"
        ],
        "AcceptDate": "09/30/2012",
        "palwebID": "PR-12-685",
        "Venue": "IPIN2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-685/FXPAL-PR-12-685.pdf"
        ],
        "PublicationDate": "11/13/2012",
        "ID": "685",
        "Authors": [
            "Don Kimber",
            "Jacob Biehl",
            "Matthew Cooper",
            "David Lee",
            "Jim Vaughan",
            "Jun Shingu"
        ],
        "Title": "Mirror Worlds for Indoor Navigation and Awareness",
        "Abstract": "We describe Explorer, a system utilizing mirror worlds - dynamic 3D virtual models of physical spaces that reflect the structure and activities of those spaces to help support navigation, context awareness and tasks such as planning and recollection of events. A rich sensor network dynamically updates the models, determining the position of people, status of rooms, or updating textures to reflect displays or bulletin boards. Through views on web pages, portable devices, or on \u00e2\u20ac\u02dcmagic window\u00e2\u20ac\u2122 displays located in the physical space, remote people may \u00e2\u20ac\u02dclook in\u00e2\u20ac\u2122 to the space, while people within the space are provided with augmented views showing information not physically apparent.\r\nFor example, by looking at a mirror display, people can learn how long others have been present, or where they have been.  People in one part of a building can get a sense of activities in the rest of the building, know who is present in their office, and look in to presentations in other rooms. A  spatial graph is derived from the 3D models which is used both to navigational paths and for fusion of acoustic, WiFi, motion and image sensors\r\nused for positioning. We describe usage scenarios for the system as deployed in two research labs, and a conference venue.\r\n"
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "09/30/2012",
        "palwebID": "PR-12-686",
        "Venue": "IPIN2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-686/FXPAL-PR-12-686.pdf"
        ],
        "PublicationDate": "11/13/2012",
        "ID": "686",
        "Authors": [
            "Ish Rishabh",
            "Don Kimber",
            "John Adcock"
        ],
        "Title": "Indoor localization using controlled ambient sounds",
        "Abstract": "Audio-based receiver localization in indoor environ-ments has multiple\r\napplications including indoor navigation, loca-tion tagging, and\r\ntracking. Public places like shopping malls and consumer stores often\r\nhave loudspeakers installed to play music for public\r\nentertainment. Similarly, office spaces may have sound conditioning\r\nspeakers installed to soften other environmental noises. We discuss an\r\napproach to leverage this infrastructure to perform audio-based\r\nlocalization of devices requesting local-ization in such environments,\r\nby playing barely audible controlled sounds from multiple speakers at\r\nknown positions. Our approach can be used to localize devices such as\r\nsmart-phones, tablets and laptops to sub-meter accuracy. The user does\r\nnot need to carry any specialized hardware. Unlike acoustic approaches\r\nwhich use high-energy ultrasound waves, the use of barely audible (low\r\nenergy) signals in our approach poses very different challenges. We\r\ndiscuss these challenges, how we addressed those, and experimental\r\nresults on two prototypical implementations: a request-play-record\r\nlocalizer, and a continuous tracker. We evaluated our approach in a\r\nreal world meeting room and report promising initial results with\r\nlocalization accuracy within half a meter 94% of the time. The system\r\nhas been deployed in multiple zones of our office building and is now\r\npart of a location service in constant operation in our lab."
    },
    {
        "Projects": [
            "SmartDCap"
        ],
        "keywords": [
            "smart document capture",
            "SmartDCap"
        ],
        "AcceptDate": "12/19/2012",
        "palwebID": "PR-13-687",
        "Venue": "IUI 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-687/FXPAL-PR-13-687.pdf"
        ],
        "PublicationDate": "03/19/2013",
        "ID": "687",
        "Authors": [
            "Francine Chen",
            "Scott Carter",
            "Laurent Denoue",
            "Jayant Kumar"
        ],
        "Title": "SmartDCap: Semi-Automatic Capture of Higher Quality Document Images from a Smartphone",
        "Abstract": "People frequently capture photos with their smartphones, and some are starting to capture images of documents. However, the quality of captured document images is often lower than expected, even when applications that perform post-processing to improve the image are used. To improve the quality of captured images before post-processing, we developed a Smart Document Capture (SmartDCap) application that provides real-time feedback to users about the likely quality of a captured image.  The quality measures capture the sharpness and framing of a page or regions on a page, such as a set of one or more columns, a part of a column, a figure, or a table. Using our approach, while users adjust the camera position, the application automatically determines when to take a picture of a document to produce a good quality result. We performed a subjective evaluation comparing SmartDCap and the Android Ice Cream Sandwich (ICS) camera application; we also used raters to evaluate the quality of the captured images. Our results indicate that users find SmartDCap to be as easy to use as the standard ICS camera application. Additionally, images captured using SmartDCap are sharper and better framed on average than images using the ICS camera application."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/19/2012",
        "palwebID": "PR-13-688",
        "Venue": "IUI 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-688/FXPAL-PR-13-688.pdf"
        ],
        "PublicationDate": "03/19/2013",
        "ID": "688",
        "Authors": [
            "Sven Kratz"
        ],
        "Title": "Combining Acceleration and Gyroscope Data for Motion Gesture Recognition using Classifiers with Dimensionality Constraints",
        "Abstract": "Motivated by the addition of gyroscopes to a large number of new smart phones, we study the effects of combining accelerometer and gyroscope data on the recognition rate of motion gesture recognizers with dimensionality constraints. Using a large data set of motion gestures we analyze results for the following algorithms: Protractor3D, Dynamic Time Warping (DTW) and Regularized Logistic Regression (LR). We chose to study these algorithms because they are relatively easy to implement, thus well suited for rapid prototyping or early deployment during prototyping stages. For use in our analysis, we contribute a method to extend Protractor3D to work with the 6D data obtained by combining accelerometer and gyroscope data. Our results show that combining accelerometer and gyroscope data is beneficial also for algorithms with dimensionality constraints and improves the gesture recognition rate on our data set by up to 4%."
    },
    {
        "Projects": [
            "cemint",
            "ShowHow"
        ],
        "keywords": [
            "ShowHow"
        ],
        "AcceptDate": "01/30/2013",
        "palwebID": "PR-13-689",
        "Venue": "IUI 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-689/FXPAL-PR-13-689.pdf"
        ],
        "PublicationDate": "03/19/2013",
        "ID": "689",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Matthew Cooper",
            "John Adcock"
        ],
        "Title": "Real-time Direct Manipulation of Screen-based Videos",
        "Abstract": "We describe direct video manipulation interactions applied to screen-based tutorials. In addition to using the video timeline, users of our system can quickly navigate into the video by mouse-wheel, double click over a rectangular region to zoom in and out, or drag a box over the video canvas to select text and scrub the video until the end of a text line even if not shown in the current frame. We describe the video processing techniques developed to implement these direct video manipulation techniques, and show how there are implemented to run in most modern web browsers using HTML5\u00e2\u20ac\u2122s CANVAS and Javascript."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/14/2012",
        "palwebID": "PR-13-690",
        "Venue": "CHI 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-690/FXPAL-PR-13-690.pdf"
        ],
        "PublicationDate": "04/27/2013",
        "ID": "690",
        "Authors": [
            "Elena Agapie",
            "Gene Golovchinsky",
            "Pernilla Qvarfordt"
        ],
        "Title": "Leading People to Longer Queries",
        "Abstract": "Although longer queries can produce better results for information seeking tasks, people tend to type short queries. We created an interface designed to encourage people to type longer queries, and evaluated it in two Mechanical Turk experiments. Results suggest that our interface manipulation may be effective for eliciting longer queries."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch",
            "EyeTracking"
        ],
        "keywords": [
            "information seeking",
            "information retrieval",
            "hcir",
            "session search",
            "sessionsearch",
            "aim"
        ],
        "AcceptDate": "04/15/2013",
        "palwebID": "PR-13-691",
        "Venue": "SIGIR 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-691/FXPAL-PR-13-691.pdf"
        ],
        "PublicationDate": "07/28/2013",
        "ID": "691",
        "Authors": [
            "Pernilla Qvarfordt",
            "Gene Golovchinsky",
            "Tony Dunnigan",
            "Elena Agapie"
        ],
        "Title": "Looking Ahead: Query Preview in Exploratory Search",
        "Abstract": "Exploratory search is a complex, iterative information seeking activity that involves running multiple queries, finding and examining many documents. We introduced a query preview interface that visualizes the distribution of newly-retrieved and re-retrieved documents prior to showing the detailed query results. When evaluating the preview control with a control condition, we found effects on both people\u00e2\u20ac\u2122s information seeking behavior and improved retrieval performance. People spent more time formulating a query and were more likely to explore search results more deeply, retrieved a more diverse set of documents, and found more different relevant documents when using the preview.  With more time spent on query formulation, higher quality queries were produced and as consequence the retrieval results improved; both average residual precision and recall was higher with the query preview present."
    },
    {
        "Projects": [
            "cemint",
            "ShowHow"
        ],
        "keywords": [
            "multimedia document",
            "ShowHow"
        ],
        "AcceptDate": "06/14/2013",
        "palwebID": "PR-13-692",
        "Venue": "DocEng 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-692/FXPAL-PR-13-692.pdf"
        ],
        "PublicationDate": "09/10/2013",
        "ID": "692",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Matthew Cooper"
        ],
        "Title": "Content-based Copy and Paste from Video Documents",
        "Abstract": "Unlike text, copying and pasting parts of video documents is challenging. Yet, the huge amount of video documents now available in the form of how-to tutorials begs for simpler techniques that allow users to easily copy and paste fragments of video materials into new documents. We describe new direct video manipulation techniques that allow users to quickly copy and paste content from video documents such as how-to tutorials into a new document. While the video plays, users interact with the video canvas to select text regions, scrollable regions, slide sequences built up across many frames, or semantically meaningful regions such as dialog boxes. Instead of relying on the timeline to accurately select sub-parts of the video document, users navigate using familiar selection techniques such as mouse-wheel to scroll back and forward over a video region where content scrolls, double-clicks over rectangular regions to select them, or clicks and drags over textual regions of the video canvas to select them. We describe the video processing techniques that run in real-time in modern web browsers using HTML5 and JavaScript; and show how they help users quickly copy and paste video fragments into new documents, allowing them to efficiently reuse video documents for authoring or note-taking."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/30/2013",
        "palwebID": "PR-13-693",
        "Venue": "CBDAR 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-693/FXPAL-PR-13-693.pdf"
        ],
        "PublicationDate": "08/23/2013",
        "ID": "693",
        "Authors": [
            "Chelhwon Kim",
            "Patrick Chiu",
            "Surendar Chandra"
        ],
        "Title": "Dewarping Book Page Spreads Captured with a Mobile Phone Camera",
        "Abstract": "Capturing book images is more convenient with a mobile phone camera than with more specialized flat-bed scanners or 3D capture devices. We built an application for the iPhone 4S that captures a sequence of hi-res (8 MP) images of a page spread as the user sweeps the device across the book. To do the 3D dewarping, we implemented two algorithms: optical flow (OF) and structure from motion (SfM). Making further use of the image sequence, we examined the potential of multi-frame OCR. Preliminary evaluation on a small set of data shows that OF and SfM had comparable OCR performance for both single-frame and multi-frame techniques, and that multi-frame was substantially better than single-frame. The computation time was much less for OF than for SfM."
    },
    {
        "Projects": [
            "PointPose"
        ],
        "keywords": [
            "Mobile Device",
            "Touch Input",
            "Finger Pose",
            "Depth Sensor",
            "Point Cloud",
            "Mobile Interaction"
        ],
        "AcceptDate": "07/31/2013",
        "palwebID": "PR-13-694",
        "Venue": "Interactive Tabletops and Surfaces (ITS) 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-694/FXPAL-PR-13-694.pdf"
        ],
        "PublicationDate": "10/06/2013",
        "ID": "694",
        "Authors": [
            "Sven Kratz",
            "Patrick Chiu",
            "Maribeth Back"
        ],
        "Title": "PointPose: Finger Pose Estimation for Touch Input on Mobile Devices using a Depth Sensor",
        "Abstract": "The expressiveness of touch input can be increased by detecting additional finger pose information at the point of touch such as finger rotation and tilt. PointPose is a prototype that performs finger pose estimation at the location of touch using a short-range depth sensor viewing the touch screen of a mobile device. We present an algorithm that extracts finger rotation and tilt from a point cloud generated by a depth sensor oriented towards the device's touchscreen. The results of two user studies we conducted show that finger pose information can be extracted reliably using our proposed method. We show this for controlling rotation and tilt axes separately and also for combined input tasks using both axes. With the exception of the depth sensor, which is mounted directly on the mobile device, our approach does not require complex external tracking hardware, and, furthermore, external computation is unnecessary as the finger pose extraction algorithm can run directly on the mobile device. This makes PointPose ideal for prototyping and developing novel mobile user interfaces that use finger pose estimation."
    },
    {
        "Projects": [
            "Querium"
        ],
        "keywords": [
            "search results visualization",
            "search navigation support"
        ],
        "AcceptDate": "07/01/2013",
        "palwebID": "PR-13-695",
        "Venue": "EuroHCIR 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-695/FXPAL-PR-13-695.pdf"
        ],
        "PublicationDate": "08/01/2013",
        "ID": "695",
        "Authors": [
            "Simon Tretter",
            "Gene Golovchinsky",
            "Pernilla Qvarfordt"
        ],
        "Title": "SearchPanel: A browser extension for managing search activity",
        "Abstract": "People often use more than one query when searching for information; they also revisit search results to re-find information. These tasks are not well-supported by search interfaces and web browsers. We designed and built a Chrome browser extension that helps people manage their ongoing information seeking. The extension combines document and process metadata into an interactive representation of the retrieved documents that can be used for sense-making, for navigation, and for re-finding documents."
    },
    {
        "Projects": [
            "Showhow"
        ],
        "keywords": [
            "showhow"
        ],
        "AcceptDate": "09/03/2013",
        "palwebID": "PR-13-696",
        "Venue": "Education and Information Technologies journal",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-696/FXPAL-PR-13-696.pdf"
        ],
        "PublicationDate": "10/11/2013",
        "ID": "696",
        "Authors": [
            "Scott Carter",
            "John Adcock",
            "Matthew Cooper",
            "Stacy Branham"
        ],
        "Title": "Tools to support expository video capture and access",
        "Abstract": "Video tends to be imbalanced as a medium. Typically, content creators invest enormous effort creating work that is then watched passively. However, learning tasks require that users not only consume video but also engage, interact with, and repurpose content. Furthermore, to promote learning across domains where content creators are not necessarily videographers, it is important that capture tools facilitate creation of interactive content. In this paper, we describe some early experiments toward this goal. Specifically, we describe a needfinding study involving interviews with amateur video creators as well as our experience with an early prototype to support expository capture and access. Our findings led to a system redesign that can incorporate a broad set of video-creation and interaction styles."
    },
    {
        "Projects": [
            "Faunus"
        ],
        "keywords": [],
        "AcceptDate": "09/19/2012",
        "palwebID": "PR-12-697",
        "Venue": "USENIX/ACM/IFIP Middleware",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-697/FXPAL-PR-12-697.pdf"
        ],
        "PublicationDate": "09/19/2012",
        "ID": "697",
        "Authors": [
            "Surendar Chandra",
            "Maribeth Back"
        ],
        "Title": "Faunus: a flexible middleware for specifying and managing multimodal, multiparty collaborations",
        "Abstract": "Faunus addresses the challenge of specifying and managing complex collaboration sessions. Many entities from various administrative domains orchestrate such sessions. Faunus decouples the entities that specify the session from entities that activate and manage them. It restricts the operations to specific agents using capabilities. It unifies the specification and management operations through its naming system. Each Faunus name is persistent and globally unique. A collection of attributes are attached to each name. Together, they represent a collection of services that form a collaboration session. Anyone can create a name; the creator has full read and write privileges that can be delegated to others. With the proper capability, anyone can modify session attributes between an active and inactive state. Though the system is designed for Internet scale deployments, the security model for providing and revoking capabilities currently assumes an Intranet style deployment. We have incorporated Faunus into a DisplayCast system that originally used Zeroconf. We are incorporating Faunus into another project that will fully exercise the power of Faunus."
    },
    {
        "Projects": [
            "VPoint"
        ],
        "keywords": [],
        "AcceptDate": "04/15/2013",
        "palwebID": "PR-13-698",
        "Venue": "The International Symposium on Pervasive Displays",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-698/FXPAL-PR-13-698.pdf"
        ],
        "PublicationDate": "06/04/2013",
        "ID": "698",
        "Authors": [
            "Sven Kratz",
            "Maribeth Back",
            "Jim Vaughan"
        ],
        "Title": "VoroPoint: Improving Gesture-Based Target Selection on Large Displays (Poster)",
        "Abstract": "Existing user interfaces for the configuration of large shared displays with multiple inputs and outputs usually do not allow users easy and direct configuration of the display's properties such as window arrangement or scaling. To address this problem, we are exploring a gesture-based technique for manipulating display windows on shared display systems. To aid target selection under noisy tracking conditions, we propose VoroPoint, a modified Voronoi tessellation approach that increases the selectable target area of the display windows. By maximizing the available target area, users can select and interact with display windows with greater ease and precision."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "09/02/2013",
        "palwebID": "PR-13-699",
        "Venue": "IEEE ISM 2013",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-699/FXPAL-PR-13-699.pdf"
        ],
        "PublicationDate": "12/09/2013",
        "ID": "699",
        "Authors": [
            "Surendar Chandra",
            "Patrick Chiu",
            "Maribeth Back"
        ],
        "Title": "Towards portable multi-camera high definition video capture using smartphones for tele-immersion",
        "Abstract": "Real-time tele-immersion requires low latency, synchronized multi-camera capture. Prior high definition (HD) capture systems were bulky. We in vestigate the suitability of using flocks of smartphone cameras for tele-immersion. Smartphones can potentially integrate HD capture and streaming into a single portable package. However, they are designed for archiving the captured video into a movie. Hence, we create a sequence of H.264 movies and stream them. We lower the capture delay by reducing the number of frames in each movie segment. Increasing the number of movie segments adds compression overhead. Smartphone video encoders do not sacrifice video quality to lower the compression latency or the stream size. On an iPhone 4S, our application that uses published APIs streams 1920x1080 videos at 16.5 fps with a delay of 712 msec between a real-life event and displaying an uncompressed bitmap of this event on a local laptop. For comparison, the bulky Cisco Tandberg required 300 msec delay. Stereoscopic video from two unsynchronized smartphones showed minimal visual artifacts in an indoor teleconference setting."
    },
    {
        "Projects": [
            "Unity"
        ],
        "keywords": [],
        "AcceptDate": "05/28/2013",
        "palwebID": "PR-13-700",
        "Venue": "Future Generation Computer Systems",
        "palwebURL": [],
        "PublicationDate": "05/28/2013",
        "ID": "700",
        "Authors": [
            "Eleanor Rieffel",
            "Jacob Biehl",
            "Adam J. Lee",
            "Bill van Melle"
        ],
        "Title": "Private Aggregation for Presence Streams",
        "Abstract": "Collaboration technologies must support information sharing between collaborators, but must also take care not to share too much information or share information too widely. Systems that share information without requiring an explicit action by a user to initiate the sharing must be particularly cautious in this respect. Presence systems are an emerging class of applications that support collaboration. Through the use of pervasive sensors, these systems estimate user location, activities, and available communication channels. Because such presence data are sensitive, to achieve wide-spread adoption, sharing models must reflect the privacy and sharing preferences of their users. This paper looks at the role that privacy-preserving aggregation can play in addressing certain user sharing and privacy concerns with respect to presence data.\r\n\r\n<br><BR>\r\n\r\nWe define conditions to achieve CollaPSE (Collaboration Presence Sharing Encryption) security, in which (i) an individual has full access to her own data, (ii) a third party performs computation on the data without learning anything about the data values, and (iii) people with special privileges called \u00e2\u20ac\u0153analysts\u00e2\u20ac\u009d can learn statistical information about groups of individuals, but nothing about the individual values contributing to the statistic other than what can be deduced from the statistic. More specifically, analysts can decrypt aggregates without being able to decrypt the individual values contributing to the aggregate. Based in part on studies we carried out that illustrate the need for the conditions encapsulated by CollaPSE security, we designed and implemented a family of CollaPSE protocols. We analyze their security, discuss efficiency tradeoffs, describe extensions, and review more recent privacy-preserving aggregation work."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-13-701",
        "Venue": "ACM Trans. On Multimedia Computing, Communications and Applications (TOMCCAP)",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-701/FXPAL-PR-13-701.pdf"
        ],
        "PublicationDate": "10/01/2013",
        "ID": "701",
        "Authors": [
            "Lawrence Rowe"
        ],
        "Title": "Looking Forward Ten Years to Multimedia Successes",
        "Abstract": "A panel at ACM Multimedia 2012 addressed research successes in the past 20 years. While the panel focused on the past, this article discusses successes since the ACM SIGMM 2003 Retreat and suggests research directions in the next ten years. While significant progress has been made, more research is required to allow multimedia to impact our everyday computing environment. The importance of hardware changes on future research directions is discussed. We believe ubiquitous computing\u00e2\u20ac\u201dmeaning abundant computation and network bandwidth\u00e2\u20ac\u201dshould be applied in novel ways to solve multimedia grand challenges and continue the IT revolution of the past century."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-13-702",
        "Venue": "ACM Trans. On Multimedia Computing, Communications and Applications (TOMCCAP)",
        "palwebURL": [
            "http://palweb/files/PR/2013/PR-13-702/FXPAL-PR-13-702.pdf"
        ],
        "PublicationDate": "10/01/2013",
        "ID": "702",
        "Authors": [
            "Dick Bulterman",
            "Pablo Cesar",
            "Rodrigo Laiola Guimaraes"
        ],
        "Title": "Socially-Aware Multimedia Authoring: Past, Present, and Future",
        "Abstract": "Creating compelling multimedia productions is a nontrivial task. This is as true for creating professional content as it is for nonprofessional editors. During the past 20 years, authoring networked content has been a part of the research agenda of the multimedia community. Unfortunately, authoring has been seen as an initial enterprise that occurs before \u00e2\u20ac\u02dcreal\u00e2\u20ac\u2122 content processing takes place. This limits the options open to authors and to viewers of rich multimedia content for creating and receiving focused, highly personal media presentations. This article reflects on the history of multimedia authoring. We focus on the particular task of supporting socially-aware multimedia, in which the relationships within particular social groups among authors and viewers can be exploited to create highly personal media experiences. We provide an overview of the requirements and characteristics of socially-aware multimedia authoring within the context of exploiting community content. We continue with a short historical perspective on authoring support for these types of situations. We then present an overview of a current system for supporting socially-aware multimedia authoring within the community content. We conclude with a discussion of the issues that we feel can provide a fruitful basis for future multimedia authoring support. We argue that providing support for socially-aware multimedia authoring can have a profound impact on the nature and architecture of the entire multimedia information processing pipeline."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "01/21/2014",
        "palwebID": "PR-14-703",
        "Venue": "CHI 2014 (Interactivity)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-703/FXPAL-PR-14-703.pdf"
        ],
        "PublicationDate": "04/26/2014",
        "ID": "703",
        "Authors": [
            "Sven Kratz",
            "Tanvir Aumi"
        ],
        "Title": "AirAuth: A Biometric Authentication System using In-Air Hand Gestures",
        "Abstract": "AirAuth is a biometric authentication technique that uses in-air hand gestures to authenticate users tracked through a short-range depth sensor. Our method tracks multiple distinct points on the user's hand simultaneously that act as a biometric to further enhance security. We describe the details of our mobile demonstrator that will give Interactivity attendees an opportunity to enroll and verify our system's authentication method. We also wish to encourage users to design their own gestures for use with the system. Apart from engaging with the CHI community, a demonstration of AirAuth would also yield useful gesture data input by the attendees which we intend to use to further improve the prototype and, more importantly, make available publicly as a resource for further research into gesture-based user interfaces."
    },
    {
        "Projects": [
            "ScalableVisualSearch"
        ],
        "keywords": [],
        "AcceptDate": "01/20/2014",
        "palwebID": "PR-14-704",
        "Venue": "ACM ICMR 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-704/FXPAL-PR-14-704.pdf"
        ],
        "PublicationDate": "04/01/2014",
        "ID": "704",
        "Authors": [
            "Junjie Cai",
            "Qiong Liu",
            "Francine Chen",
            "Dhiraj Joshi",
            "Qi Tian"
        ],
        "Title": "Scalable Image Search with Multiple Index Tables",
        "Abstract": "Motivated by scalable partial-duplicate visual search, there has been growing interest on a wealth of compact and efficient binary feature descriptors(e.g. ORB, FREAK, BRISK).\r\nTypically, binary descriptors are clustered into codewords and quantized with Hamming distance, which follows conventional bag-of-words strategy. However, such codewords formulated in Hamming space did not present obvious indexing and search performance improvement as compared to the Euclidean ones. In this paper, without explicit codeword construction, we explore to utilize binary descriptors as direct codebook indices (addresses). We propose a novel approach to build multiple index tables which parallelly check the collision of same hash values. The evaluation is performed on two public image datasets: DupImage and Holidays. The experimental results demonstrate the index efficiency and retrieval accuracy of our approach."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "12/16/2013",
        "palwebID": "PR-14-705",
        "Venue": "HotMobile 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-705/FXPAL-PR-14-705.pdf"
        ],
        "PublicationDate": "02/26/2014",
        "ID": "705",
        "Authors": [
            "Mingming Fan",
            "Qiong Liu",
            "Henry Tang",
            "Patrick Chiu"
        ],
        "Title": "HiFi: Hide and Find Digital Contents Associated with Physical Objects via Coded Light",
        "Abstract": "In this paper, we propose HiFi system which enables users to interact with surrounding physical objects. It uses coded light to encode position in an environment. By attaching a tiny light sensor on a user\u00e2\u20ac\u2122s mobile device, the user can attach digital info to arbitrary static physical objects or retrieve/modify them anchored to these objects. With this system, a family member may attach a digital maintenance schedule to a fish tank or indoor plants, etc. In a store, a store manager may use such system to attach price tag, discount info and multimedia contents to any products and customers can get the attached info by moving their phone close to the focused product. Similarly, a museum can use this system to provide extra info of displayed items to visitors. Different from computer vision based systems, HiFi does not have requests on texture, bright illumination, etc. Different from regular barcode approaches, HiFi does not require extra physical attachments that may change an object\u00e2\u20ac\u2122s native appearance. HiFi has much higher spatial resolution for distinguishing close objects or attached parts of the same object. As HiFi system can track a mobile device at 80 positions per second, it also has much faster response than any above listed system."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/10/2014",
        "palwebID": "PR-14-706",
        "Venue": "CHI Extended Abstracts 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-706/FXPAL-PR-14-706.pdf"
        ],
        "PublicationDate": "04/26/2014",
        "ID": "706",
        "Authors": [
            "Tanvir Aumi",
            "Sven Kratz"
        ],
        "Title": "AirAuth: Towards Attack-Resilient Biometric Authentication Using In-Air Gestures",
        "Abstract": "AirAuth is a biometric, gesture-based authentication system based on\r\nin-air gesture input. We describe the operations necessary to sample\r\nenrollment gestures and to perform matching for authentication, using\r\ndata from a short range depth sensor. We present the results of two\r\ninitial user studies. A first study was conducted to crowd source a\r\nsimple gesture set for use in further evaluations. The results of our\r\nsecond study indicate that AirAuth achieves a very high Equal Error Rate\r\n(EER-)based accuracy of 96.6 % for simple gesture set and 100 % for\r\nuser-specific gestures. Future work will encompass the evaluation of\r\npossible attack scenarios and obtaining qualitative user feedback on\r\nusability advantages of gesture-based authentication."
    },
    {
        "Projects": [
            "cemint"
        ],
        "keywords": [],
        "AcceptDate": "02/26/2014",
        "palwebID": "PR-14-707",
        "Venue": "ACM interactions",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-707/FXPAL-PR-14-707.docx",
            "http://palweb/files/PR/2014/PR-14-707/FXPAL-PR-14-707.pdf"
        ],
        "PublicationDate": "07/01/2014",
        "ID": "707",
        "Authors": [
            "Scott Carter",
            "Matthew Cooper",
            "Laurent Denoue",
            "John Doherty",
            "Vikash Rugoobur"
        ],
        "Title": "Supporting media bricoleurs",
        "Abstract": "Online video is incredibly rich. A 15-minute home improvement YouTube tutorial might include 1500 words of narration, 100 or more significant keyframes showing a visual change from multiple perspectives, several animated objects, references to other examples, a tool list, comments from viewers and a host of other metadata. Furthermore, video accounts for 90% of worldwide Internet traffic. However, it is our observation that video is not widely seen as a full-fledged document;  dismissed as a media that, at worst, gilds over substance and, at best, simply augments text-based communications. In this piece, we suggest that negative attitudes toward multimedia documents that include audio and video are largely unfounded and arise mostly because we lack the necessary tools to treat video content as first-order media or to support seamlessly mixing media."
    },
    {
        "Projects": [
            "MiningSocialMedia"
        ],
        "keywords": [
            "sentiment",
            "polarity",
            "Twitter",
            "microblogs"
        ],
        "AcceptDate": "03/10/2014",
        "palwebID": "PR-14-708",
        "Venue": "ICWSM (The 8th International AAAI Conference on Weblogs and Social Media)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-708/FXPAL-PR-14-708.pdf"
        ],
        "PublicationDate": "06/01/2014",
        "ID": "708",
        "Authors": [
            "Francine Chen",
            "Hamid Mirisaee"
        ],
        "Title": "Do Topic-Dependent Models Improve Microblog Sentiment Estimation?",
        "Abstract": "A topic-independent sentiment model is commonly used to estimate sentiment \r\nin microblogs. But for movie and product reviews, domain adaptation has been shown to improve sentiment estimation performance.\r\nWe investigated the utility of topic-dependent polarity estimation models for microblogs. We examined both a model trained on Twitter tweets containing a target keyword and a model trained on an enlarged set of tweets containing terms related to a topic.  Comparing the performance of the topic-dependent models to a topic-independent model trained on a general sample of  tweets, we noted that for some topics,\r\ntopic-dependent models performed better. We then propose a method for predicting which topics\r\nare likely to have better sentiment estimation performance when a topic-dependent sentiment model is used."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/10/2014",
        "palwebID": "PR-14-709",
        "Venue": "International Journal of Multimedia Information Retrieval Special Issue on Cross-Media Analysis",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-709/FXPAL-PR-14-709.pdf"
        ],
        "PublicationDate": "09/04/2014",
        "ID": "709",
        "Authors": [
            "Qiong Liu",
            "Andreas Girgensohn",
            "Lynn Wilcox",
            "Frank Shipman",
            "Tony Dunnigan"
        ],
        "Title": "MET: Media Embedded Target\r\nfor Connecting Paper to Digital Media",
        "Abstract": "Media Embedded Target, or MET, is an iconic mark printed in a blank margin of a page that indicates a media link is associated with a nearby region of the page. It guides the user to capture the region and thus retrieve the associated link through visual search within indexed content. The target also serves to separate page regions with media links from other regions of the page. The capture application on the cell phone displays a sight having the same shape as the target near the edge of a camera-view display. The user moves the phone to align the sight with the target printed on the page. Once the system detects correct sight-target alignment, the region in the camera view is captured and sent to the recognition engine which identifies the image and causes the associated media to be displayed on the phone. Since target and sight alignment defines a capture region, this approach saves storage by only indexing visual features in the predefined capture region, rather than indexing the entire page. Target-sight alignment assures that the indexed region is fully captured. We compare the use of MET for guiding capture with two standard methods: one that uses a logo to indicate that media content is available and text to define the capture region and another that explicitly indicates the capture region using a visible boundary mark."
    },
    {
        "Projects": [
            "ShowHow"
        ],
        "keywords": [
            "ShowHow"
        ],
        "AcceptDate": "02/03/2014",
        "palwebID": "PR-14-710",
        "Venue": "Fuji Xerox Technical Report",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-710/FXPAL-PR-14-710.pdf"
        ],
        "PublicationDate": "02/20/2014",
        "ID": "710",
        "Authors": [
            "Scott Carter",
            "Matthew Cooper",
            "John Adcock"
        ],
        "Title": "ShowHow: Supporting Expository Video Capture and Access",
        "Abstract": "Video content creators invest enormous effort \r\ncreating work that is in turn typically viewed passively. \r\nHowever, learning tasks using video requires users \r\nnot only to consume the content but also to engage, \r\ninteract with, and repurpose it. Furthermore, to \r\npromote learning with video in domains where content \r\ncreators are not necessarily videographers, it is \r\nimportant that capture tools facilitate creation of \r\ninteractive content. In this paper, we describe some \r\nearly experiments toward this goal. A literature review \r\ncoupled with formative field studies led to a system \r\ndesign that can incorporate a broad set of \r\nvideo-creation and interaction styles. \r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/18/2014",
        "palwebID": "PR-14-711",
        "Venue": "SIGIR 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-711/FXPAL-PR-14-711.pdf"
        ],
        "PublicationDate": "07/06/2014",
        "ID": "711",
        "Authors": [
            "Pernilla Qvarfordt",
            "Simon Tretter",
            "Gene Golovchinsky",
            "Tony Dunnigan"
        ],
        "Title": "SearchPanel: Framing Complex Search Needs",
        "Abstract": "People often use more than one query when searching for information. They revisit search results to re-find information and build an understanding of their search need through iterative explorations of query formulation. These tasks are not well-supported by search interfaces and web browsers. We designed and built SearchPanel, a Chrome browser extension that helps people manage their ongoing information seeking. This extension combines document and process metadata into an interactive representation of the retrieved documents that can be used for sense-making, navigation, and re-finding documents. In a real-world deployment spanning over two months, results show that SearchPanel appears to have been primarily used for complex information needs, in search sessions with long durations and high numbers of queries. The process metadata features in SearchPanel seem to be of particular importance when working on complex information needs."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/23/2014",
        "palwebID": "PR-14-712",
        "Venue": "ICME 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-712/PR-14-712.pdf"
        ],
        "PublicationDate": "07/14/2014",
        "ID": "712",
        "Authors": [
            "Henry Tang",
            "Patrick Chiu",
            "Qiong Liu"
        ],
        "Title": "<img src=\"/images/best.png\" title=\"Best Demo Award\" border=\"0\" />GESTURE VIEWPORT: INTERACTING WITH MEDIA CONTENT USING FINGER GESTURES ON ANY SURFACE",
        "Abstract": "In this paper, we describe Gesture Viewport, a projector-camera system that enables finger gesture interactions with media content on any surface. We propose a novel and computationally very efficient finger localization method based on the detection of occlusion patterns inside a virtual sensor grid rendered in a layer on top of a viewport widget. We develop several robust interaction techniques to prevent unintentional gestures to occur, to provide visual feedback to a user, and to minimize the interference of the sensor grid with the media content. We show the effectiveness of the system through three scenarios: viewing photos, navigating Google Maps, and controlling Google Street View."
    },
    {
        "Projects": [],
        "keywords": [
            "In-air gestures",
            "authentication",
            "shoulder surfing",
            "user experience",
            "acceptabilty",
            "template update mechanism",
            "mobile devices"
        ],
        "AcceptDate": "05/09/2014",
        "palwebID": "PR-14-713",
        "Venue": "MobileHCI 2014 (Full Paper)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-713/FXPAL-PR-14-713.pdf"
        ],
        "PublicationDate": "09/23/2014",
        "ID": "713",
        "Authors": [
            "Sven Kratz",
            "Tanvir Aumi"
        ],
        "Title": "AirAuth: Evaluating In-Air Hand Gestures for Authentication",
        "Abstract": "Secure authentication with devices or services that store sensitive and personal information is highly important. However, traditional password and pin-based authentication methods compromise between the level of security and user experience. AirAuth is a biometric authentication technique that uses in-air gesture input to authenticate users. We evaluated our technique on a predefined (simple) gesture set and our classifier achieved an average accuracy of 96.6% in an equal error rate (EER-)based study. We obtained an accuracy of 100% when exclusively using personal (complex) user gestures. In a further user study, we found that AirAuth is highly resilient to video-based shoulder surfing attacks, with a mea- sured false acceptance rate of just 2.2%. Furthermore, a longitudinal study demonstrates AirAuth\u00e2\u20ac\u2122s repeatability and accuracy over time. AirAuth is relatively simple, robust and requires only a low amount of computational power and is hence deployable on embedded or mobile hardware. Un- like traditional authentication methods, our system\u00e2\u20ac\u2122s security is positively aligned with user-rated pleasure and excitement levels. In addition, AirAuth attained acceptability ratings in personal, office, and public spaces that are comparable to an existing stroke-based on-screen authentication technique. Based on the results presented in this paper, we believe that AirAuth shows great promise as a novel, secure, ubiquitous, and highly usable authentication method."
    },
    {
        "Projects": [
            "Polly"
        ],
        "keywords": [
            "telepresence",
            "remote guiding",
            "wearable",
            "gimbal",
            "user feedback"
        ],
        "AcceptDate": "05/23/2014",
        "palwebID": "PR-14-716",
        "Venue": "MobileHCI 2014 (Industrial Case Study)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-716/FXPAL-PR-14-716.pdf"
        ],
        "PublicationDate": "09/23/2014",
        "ID": "716",
        "Authors": [
            "weiqing su",
            "Sven Kratz",
            "Don Kimber"
        ],
        "Title": "Polly: \"Being There\" through the Parrot and a Guide",
        "Abstract": "Telepresence systems usually lack mobility. Polly, a wearable telepresence device, allows users to explore remote locations or experience events remotely by means of a person that serves as a mobile \"guide\". We built a series of hardware prototypes and our current, most promising embodiment consists of a smartphone mounted on a stabilized gimbal that is wearable. The gimbal enables remote control of the viewing angle as well as providing active image stabilization while the guide is walking. We present qualitative findings from a series of 8 field tests using either Polly or only a mobile phone. We found that guides felt more physical comfort when using Polly vs. a phone and that Polly was accepted by other persons at the remote location. Remote participants appreciated the stabilized video and ability to control camera view. Connection and bandwidth issues appear to be the most challenging issues for Polly-like systems."
    },
    {
        "Projects": [
            "MiningSocialMedia"
        ],
        "keywords": [],
        "AcceptDate": "05/14/2014",
        "palwebID": "PR-14-717",
        "Venue": "ACM SIGIR International Workshop on Social Media Retrieval and Analysis",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-717/FXPAL-PR-14-717.pdf"
        ],
        "PublicationDate": "07/11/2014",
        "ID": "717",
        "Authors": [
            "Dhiraj Joshi",
            "Francine Chen",
            "Lynn Wilcox"
        ],
        "Title": "Finding Selfies of Users in Microblogged Photos",
        "Abstract": "We examine the use of clustering to identify selfies in a social media user\u00e2\u20ac\u2122s photos for use in estimating demographic information such as age, gender, and race. Faces are first detected within a user\u00e2\u20ac\u2122s photos followed by clustering using visual similarity. We define a cluster scoring scheme that uses a combination of within-cluster visual similarity and average face size in a cluster to rank potential selfie-clusters. Finally, we evaluate this ranking approach over a collection of Twitter users and discuss methods that can be used for improving performance in the future."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/01/2014",
        "palwebID": "PR-14-729",
        "Venue": "ACM International Conference on Interactive Experiences for Television and Online Video (ACM TVX)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-729/FXPAL-PR-14-729.docx",
            "http://palweb/files/PR/2014/PR-14-729/FXPAL-PR-14-729.pdf"
        ],
        "PublicationDate": "06/25/2014",
        "ID": "729",
        "Authors": [
            "Dick Bulterman"
        ],
        "Title": "Interacting with Third-Party Content:\r\nIs a Second Screen Enough?",
        "Abstract": "Creating compelling multimedia content is a difficult task. It involves not only the creative process of developing a compelling media-based story, but it also requires significant technical support for content editing, management and distribution. This has been true for printed, audio and visual presentations for centuries. It is certainly true for broadcast media such as radio and television.\r\nThe talk will survey several approaches to describe and\r\nmanage media interactions. We will focus on the temporal modeling of context-sensitive personalized interactions of complex collections of independent media objects. Using the concepts of \u00c3\u00a2\u00e2\u0082\u00ac\u00cb\u009ctogetherness\u00c3\u00a2\u00e2\u0082\u00ac\u00e2\u0084\u00a2 being employed in the EU\u00c3\u00a2\u00e2\u0082\u00ac\u00e2\u0084\u00a2s FP-7 project TA2: Together Anywhere, Together Anytime, we will follow the process of media capture, profiling, composition, sharing and end-user manipulation. We will\r\nconsider the promise of using automated tools and contrast this with the reality of letting real users manipulation presentation semantics in real time.\r\n\r\nThe talk will not present a closed form solution, but will present a series of topics and problems that can stimulate the development of a new generation of systems to stimulate social media interaction."
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [
            "Loco",
            "indoor location",
            "boosting"
        ],
        "AcceptDate": "06/16/2014",
        "palwebID": "PR-14-744",
        "Venue": "Proceedings of the 2014 ACM international joint conference on Pervasive and ubiquitous computing (UbiComp '14)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-744/FXPAL-PR-14-744.pdf"
        ],
        "PublicationDate": "09/09/2014",
        "ID": "744",
        "Authors": [
            "Jacob Biehl",
            "Matthew Cooper",
            "Gerry Filby",
            "Sven Kratz"
        ],
        "Title": "LoCo: A Ready-to-Deploy Framework for Efficient Room\r\n Localization using Wi-Fi",
        "Abstract": "In recent years, there has been an explosion of social and collaborative applications that leverage location to provide users novel and engaging experiences. Current location technologies work well outdoors but fare poorly indoors. In this paper we present LoCo, a new framework that can provide highly accurate room-level location using a supervised classification scheme. We provide experiments that show this technique is orders of magnitude more efficient than current state-of-the-art WiFi localization techniques. Low classification overhead and computational footprint make classification practical and efficient even on mobile devices. Our framework has also been designed to be easily deployed and leveraged by developers to help create a new wave of location driven applications and services."
    },
    {
        "Projects": [
            "cemint"
        ],
        "keywords": [
            "cemint"
        ],
        "AcceptDate": "07/01/2014",
        "palwebID": "PR-14-745",
        "Venue": "DocEng 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-745/FXPAL-PR-14-745.pdf"
        ],
        "PublicationDate": "09/16/2014",
        "ID": "745",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Andreas Girgensohn",
            "Matthew Cooper"
        ],
        "Title": "Building digital project rooms for web meetings",
        "Abstract": "Distributed teams must co-ordinate a variety of tasks. To do so they need to be able to create, share, and annotate documents as well as discuss plans and goals. Many workflow tools support document sharing, while other tools support videoconferencing, however there exists little support for connecting the two. In this work we describe a system that allows users to share and markup content during web meetings. This shared content can provide important conversational props within the context of a meeting; it can also help users review archived meetings. Users can also extract shared content from meetings directly into other workflow tools."
    },
    {
        "Projects": [
            "cemint",
            "TalkMiner"
        ],
        "keywords": [
            "cemint",
            "TalkMiner"
        ],
        "AcceptDate": "07/07/2014",
        "palwebID": "PR-14-750",
        "Venue": "ACM Multimedia 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-750/FXPAL-PR-14-750.pdf"
        ],
        "PublicationDate": "11/03/2014",
        "ID": "750",
        "Authors": [
            "Huizhong Chen",
            "Matthew Cooper",
            "Dhiraj Joshi"
        ],
        "Title": "Multi-modal Language Models for Lecture Video Retrieval",
        "Abstract": "We propose Multi-modal Language Models (MLMs), which adapt latent variable  models for text document analysis to modeling co-occurrence relationships in multi-modal data. In this paper, we focus on the \r\napplication of MLMs to indexing slide and spoken text associated with lecture videos, and subsequently employ a multi-modal probabilistic ranking function for lecture video retrieval. The MLM achieves highly competitive results against well established retrieval methods such as the Vector Space Model and Probabilistic Latent Semantic Analysis. Retrieval performance with MLMs is also shown to improve with the quality of the available extracted spoken text."
    },
    {
        "Projects": [
            "Polly"
        ],
        "keywords": [
            "Polly"
        ],
        "AcceptDate": "07/13/2014",
        "palwebID": "PR-14-751",
        "Venue": "Assistive Computer Vision and Robotics Workshop of ECCV",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-751/PR-14-751.pdf"
        ],
        "PublicationDate": "09/12/2014",
        "ID": "751",
        "Authors": [
            "Don Kimber",
            "Patrick Proppe",
            "Sven Kratz",
            "Jim Vaughan",
            "Bee-Yian Liew"
        ],
        "Title": "Polly: Telepresence from a Guide's Shoulder",
        "Abstract": "Polly is an inexpensive, portable telepresence device based\r\non the metaphor of a parrot riding a guide's shoulder and acting as proxy\r\nfor remote participants. Although remote users may be anyone with a\r\ndesire for `tele-visits', we focus on limited mobility users. We present a\r\nseries of prototypes and field tests that informed design iterations. Our\r\ncurrent implementations utilize a smartphone on a stabilized, remotely\r\ncontrolled gimbal that can be hand held, placed on perches or carried by\r\nwearable frame. We describe findings from trials at campus, museum and\r\nfaire tours with remote users, including quadriplegics. We found guides\r\nwere more comfortable using Polly than a phone and that Polly was\r\naccepted by other people. Remote participants appreciated stabilized\r\nvideo and having control of the camera. One challenge is negotiation\r\nof movement and view control. Our tests suggests Polly is an effective\r\nalternative to telepresence robots, phones or fixed cameras."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/01/2014",
        "palwebID": "PR-14-752",
        "Venue": "UIST 2014",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-752/FXPAL-PR-14-752.pdf"
        ],
        "PublicationDate": "10/05/2014",
        "ID": "752",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Matthew Cooper"
        ],
        "Title": "Video Text Retouch: Retouching Text in Videos with Direct Manipulation",
        "Abstract": "Video Text Retouch is a technique for retouching textual content found in many online videos such as screencasts, recorded presentations and many online e-learning videos. Viewed through our special, HTML5-based player, users can edit in real-time the textual content of the video frames, such as correcting \r\ntypos or inserting new words between existing characters. Edits are overlaid and tracked at the desired position for as long as the original video content remains similar. We describe the interaction techniques, image processing algorithms and give implementation details of the system."
    },
    {
        "Projects": [
            "MiningSocialMedia"
        ],
        "keywords": [
            "MiningSocialMedia"
        ],
        "AcceptDate": "08/01/2014",
        "palwebID": "PR-14-753",
        "Venue": "ACM Multimedia Workshop on Geotagging and Its Applications in Multimedia",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-753/FXPAL-PR-14-753.pdf"
        ],
        "PublicationDate": "11/03/2014",
        "ID": "753",
        "Authors": [
            "Francine Chen",
            "Dhiraj Joshi",
            "Yasuhide Miura",
            "Tomoko Ohkuma"
        ],
        "Title": "Social Media-based Profiling of Store Locations",
        "Abstract": "We present a method for profiling businesses at specific locations that is based on mining information from social media. The method matches geo-tagged tweets from Twitter against venues from Foursquare to identify the specific business mentioned in a tweet. By linking geo-coordinates to places, the tweets associated with a business, such as a store, can then be used to profile that business. We used a sentiment estimator developed for tweets to create sentiment profiles of the stores in a chain, computing the average sentiment of tweets associated with each store. We present the results as heatmaps which show how sentiment differs across stores in the same chain and how some chains have more positive sentiment than other chains. We also created profiles of social group size for businesses and show sample heatmaps illustrating how the size of a social group can vary."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/15/2014",
        "palwebID": "PR-14-754",
        "Venue": "Book Chapter in Scene Vision, MIT Press, (Editors Kestas Kveraga and Moshe Bar).",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-754/FXPAL-PR-14-754.pdf"
        ],
        "PublicationDate": "11/01/2014",
        "ID": "754",
        "Authors": [
            "Dhiraj Joshi",
            "Ritendra Datta",
            "Elena Fedorovskaya",
            "Xin Lu",
            "Quang-Tuan Luong",
            "James Wang",
            "Jia Li",
            "Jiebo Luo"
        ],
        "Title": "On Aesthetics and Emotions in Scene Images: \r\nA Computational Perspective.\r\n",
        "Abstract": "In this chapter, we discuss the problem of computational inference of aesthetics and emotions from images. We draw inspiration from diverse disciplines such as philosophy, photography, art, and psychology to define and understand the key concepts of aesthetics and emotions. We introduce the primary computational problems that the research community has been striving to solve and the computational framework required for solving them. We also describe datasets available for performing assessment and outline several real-world applications where research in this domain can be employed. This chapter discusses the contributions of a significant number of research articles that have attempted to solve problems in aesthetics and emotion inference in the last several years. We conclude the chapter with directions for future research."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/27/2014",
        "palwebID": "PR-15-755",
        "Venue": "CSCW 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-755/FXPAL-PR-15-755.pdf"
        ],
        "PublicationDate": "03/14/2015",
        "ID": "755",
        "Authors": [
            "Jacob Biehl",
            "Daniel Avrahami",
            "Tony Dunnigan"
        ],
        "Title": "Not Really There: Understanding Embodied Communication Affordances in Team Perception and Participation\r\n",
        "Abstract": "In this paper, we report findings from a study that compared basic video-conferencing, emergent kinetic video-conferencing techniques, and face-to-face meetings. In our study, remote and co-located participants worked together in groups of three. We show, in agreement with prior literature, the strong adverse impact of being remote on participation-levels. We also show that local and remote participants perceived differently their own contributions and others.  Extending prior work, we also show that local participants exhibited significantly more overlapping speech with remote participants who used an embodied proxy, than with remote participants in basic-video conferencing (and at a rate similar to overlapping speech for co-located groups). We also describe differences in how the technologies were used to follow conversation. We discuss how these findings extend our understanding of the promise and potential limitations of embodied video-conferencing solutions."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/01/2014",
        "palwebID": "PR-14-756",
        "Venue": "2nd ACM Symposium on Spatial User Interaction (SUI)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-756/FXPAL-PR-14-756.pdf"
        ],
        "PublicationDate": "10/04/2014",
        "ID": "756",
        "Authors": [
            "Barry Kollee",
            "Sven Kratz",
            "Tony Dunnigan"
        ],
        "Title": "Exploring Gestural Interaction in Smart Spaces using Head Mounted Devices with Ego-Centric Sensing",
        "Abstract": "It is now possible to develop head-mounted devices (HMDs) that allow for ego-centric sensing of mid-air gestural input. Therefore, we explore the use of HMD-based gestural input techniques in smart space environments. We developed a usage scenario to evaluate HMD-based gestural interactions and conducted a user study to elicit qualitative feedback on several HMD-based gestural input techniques. Our results show that for the proposed scenario, mid-air hand gestures are preferred to head gestures for input and rated more favorably compared to non-gestural input techniques available on existing HMDs. Informed by these study results, we developed a prototype HMD system that supports gestural interactions as proposed in our scenario. We conducted a second user study to quantitatively evaluate our prototype comparing several gestural and non-gestural input techniques. The results of this study show no clear advantage or disadvantage of gestural inputs vs.~non-gestural input techniques on HMDs. We did find that voice control as (sole) input modality performed worst  compared to the other input techniques we evaluated. Lastly, we present two further applications implemented with our system, demonstrating 3D scene viewing and ambient light control. We conclude by briefly discussing the implications of ego-centric vs.~exo-centric tracking for interaction in smart spaces."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/08/2014",
        "palwebID": "PR-15-757",
        "Venue": "The Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI-15)",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-757/FXPAL-PR-15-757.pdf"
        ],
        "PublicationDate": "01/25/2015",
        "ID": "757",
        "Authors": [
            "Yan-Ying Chen",
            "Yin-Hsi Kuo",
            "Chun-Che Wu",
            "Winston H. Hsu"
        ],
        "Title": "Visually Interpreting Names as Demographic Attributes by Exploiting Click-Through Data",
        "Abstract": "Name of an identity is strongly influenced by his/her cultural background such as gender and ethnicity, both vital attributes for user profiling, attribute-based retrieval, etc. Typically, the associations between names and attributes (e.g., people named are mostly females) are annotated manually or provided by the census data of governments. We propose to associate a name and its likely demographic attributes by exploiting click-throughs between name queries and images with automatically detected facial attributes. This is the first work attempting to translate an abstract name to demographic attributes in visual-data-driven manner, and it is adaptive to incremental data, more countries and even unseen names (the names out of click-through data) without additional manual labels. In the experiments, the automatic name-attribute associations can help gender inference with competitive accuracy by using manual labeling. It also benefits profiling social media users and keyword-based face image retrieval, especially for contributing 12% relative improvement of accuracy in adapting to unseen names."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/15/2014",
        "palwebID": "PR-15-758",
        "Venue": "CSCW 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-758/FXPAL-PR-15-758.pdf"
        ],
        "PublicationDate": "03/14/2015",
        "ID": "758",
        "Authors": [
            "Seongtaek Lim",
            "Patrick Chiu"
        ],
        "Title": "Collaboration Map: Visualizing Temporal Dynamics of Small Group Collaboration",
        "Abstract": "Collaboration Map (CoMap) is an interactive visualization tool showing temporal changes of small group collaborations. As dynamic entities, collaboration groups have flexible features such as people involved, areas of work, and timings. CoMap shows a graph of collaborations during user-adjustable periods, providing overviews of collaborations' dynamic features. We demonstrate CoMap with a co-authorship dataset extracted from DBLP to visualize 587 publications by 29 researchers at a research organization."
    },
    {
        "Projects": [
            "BeThere"
        ],
        "keywords": [
            "BeThere"
        ],
        "AcceptDate": "12/23/2014",
        "palwebID": "PR-15-759",
        "Venue": "Human-Robot Interaction (HRI) 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-759/FXPAL-PR-15-759.pdf"
        ],
        "PublicationDate": "03/02/2015",
        "ID": "759",
        "Authors": [
            "Sven Kratz",
            "Jim Vaughan",
            "Don Kimber"
        ],
        "Title": "Evaluating Stereoscopic Video with Head Tracking for Immersive Teleoperation of Mobile Telepresence Robots",
        "Abstract": "Our research focuses on improving the effectiveness and usability of driving mobile telepresence robots by increasing the user's sense of immersion during the navigation task. To this end we developed a robot platform that allows immersive navigation using head-tracked stereoscopic video and a HMD. We present the result of an initial user study that compares System Usability Scale (SUS) ratings of a robot teleoperation task using head-tracked stereo vision with a baseline fixed video feed and the effect of a low or high placement of the camera(s). Our results show significantly higher ratings for the fixed video condition and no effect of the camera placement. Future work will focus on examining the reasons for the lower ratings of stereo video and and also exploring further visual navigation interfaces."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/15/2014",
        "palwebID": "PR-15-760",
        "Venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (CHI 2015)",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-760/PC-14-279.pdf"
        ],
        "PublicationDate": "04/18/2015",
        "ID": "760",
        "Authors": [
            "Daniel Avrahami"
        ],
        "Title": "The Effect of Edge Targets on Touch Performance",
        "Abstract": "Edge targets, such as buttons or menus along the edge of a screen, are known to afford fast acquisition performance in desktop mousing environments. As the popularity of touch based devices continues to grow, understanding the affordances of edge targets on touchscreen is needed. This paper describes results from two controlled experiments that examine in detail the effect of edge targets on performance in touch devices. Our results shows that on touch devices, a target's proximity to the edge has a significant negative effect on reaction time. We examine the effect in detail and explore mitigating factors. We discuss potential explanations for the effect and propose implications for the design of efficient interfaces for touch devices."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/01/2015",
        "palwebID": "PR-15-761",
        "Venue": "CHI 2015 (Extended Abstracts)",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-761/PC-15-289.pdf"
        ],
        "PublicationDate": "04/18/2015",
        "ID": "761",
        "Authors": [
            "Sven Kratz",
            "Maribeth Back"
        ],
        "Title": "Towards Accurate Automatic Segmentation of IMU-Tracked\r\nMotion Gestures",
        "Abstract": "We present our ongoing research on automatic segmentation of motion gestures tracked by IMUs. We postulate that by recognizing gesture execution phases from motion data that we may be able to auto-delimit user gesture entries. We demonstrate that machine learning classifiers can be trained to recognize three distinct phases of gesture entry: the start, middle and end of a gesture motion. We further demonstrate that this type of classification can be done at the level of individual gestures. Furthermore, we describe how we captured a new data set for data exploration and discuss a tool we developed to allow manual annotations of gesture phase information. Initial results we obtained using the new data set annotated with our tool show a precision of 0.95 for recognition of the gesture phase and a precision of 0.93 for simultaneous recognition of the gesture phase and the gesture type."
    },
    {
        "Projects": [
            "ShowHow"
        ],
        "keywords": [],
        "AcceptDate": "03/01/2015",
        "palwebID": "PR-15-762",
        "Venue": "IEEE Pervasive Computing",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-762/PC-14-281.pdf"
        ],
        "PublicationDate": "07/01/2015",
        "ID": "762",
        "Authors": [
            "Scott Carter",
            "Matthew Cooper",
            "Pernilla Qvarfordt",
            "Ville Makela"
        ],
        "Title": "Creating expository documents with web-based authoring and heads-up capture",
        "Abstract": "Tutorials are one of the most fundamental means of conveying\r\nknowledge. In this paper, we present a suite of applications that allow\r\nusers to combine different types of media captured from handheld,\r\nstandalone, or wearable devices to create multimedia tutorials.\r\nWe conducted a study comparing standalone (camera on tripod)\r\nversus wearable capture (Google Glass). The results show\r\nthat tutorial authors have a slight preference for wearable capture\r\ndevices, especially when recording activities involving larger objects."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/12/2015",
        "palwebID": "PR-15-763",
        "Venue": "\"Everyday Telepresence\" workshop at CHI 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-763/PC-15-291.pdf"
        ],
        "PublicationDate": "04/18/2015",
        "ID": "763",
        "Authors": [
            "Jennifer Marlow",
            "Daniel Avrahami",
            "Jacob Biehl",
            "Scott Carter",
            "Matthew Cooper",
            "Don Kimber",
            "Sven Kratz"
        ],
        "Title": "'Good Enough' is not Good Enough: Challenges of Social Interaction in Video-Mediated Telepresence ",
        "Abstract": "As video-mediated communication reaches broad adoption, improving immersion and social interaction are important areas of focus in the design of tools for exploration and work-based communication.  Here we present three threads of research focused on developing new ways of enabling exploration of a remote environment and interacting with the people and artifacts therein. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/12/2014",
        "palwebID": "PR-15-764",
        "Venue": "IEEE Transactions on Affective Computing",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-764/PC-15-288.pdf"
        ],
        "PublicationDate": "08/31/2015",
        "ID": "764",
        "Authors": [
            "Yan-Ying Chen",
            "Tao Chen",
            "Taikun Liu",
            "Hong-Yuan Mark Liao",
            "Shih-Fu Chang"
        ],
        "Title": "Assistive Image Comment Robot - A Novel Mid-Level Concept-Based Representation",
        "Abstract": "We present a general framework and working system for predicting likely affective responses of the viewers in the social media environment after an image is posted online. Our approach emphasizes a mid-level concept representation, in which intended affects of the image publisher is characterized by a large pool of visual concepts (termed PACs) detected from image content directly instead of textual metadata, evoked viewer affects are represented by concepts (termed VACs) mined from online comments, and statistical methods are used to model the correlations among these two types of concepts. We demonstrate the utilities of such approaches by developing an end-to-end Assistive Comment Robot application, which further includes components for multi-sentence comment generation, interactive interfaces, and relevance feedback functions. Through user studies, we showed machine suggested\r\ncomments were accepted by users for online posting in 90% of completed user sessions, while very favorable results were also\r\nobserved in various dimensions (plausibility, preference, and realism) when assessing the quality of the generated image comments."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/14/2014",
        "palwebID": "PR-15-769",
        "Venue": "CHI 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-769/PC-15-296.pdf"
        ],
        "PublicationDate": "04/18/2015",
        "ID": "769",
        "Authors": [
            "Jennifer Marlow",
            "Laura Dabbish",
            "Jodi Forlizzi"
        ],
        "Title": "Exploring the Role of Activity Trace Design on Evaluations of Online Worker Quality",
        "Abstract": "Websites can record individual users' activities and display them in a variety of ways. There is a tradeoff between detail and abstraction in visualization, especially when the amount of content increases and becomes more difficult to process. We conducted an experiment on Mechanical Turk varying the quality, detail, and visual presentation of information about an individual's past work to see how these design features affected perceptions of the worker. We found that providing detail in the display through text increased processing time and led to less positive evaluations. Visually abstract displays required less processing time but decreased confidence in evaluation. This suggests that different design parameters may engender differing psychological processes that influence reactions towards an unknown person."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/20/2014",
        "palwebID": "PR-15-771",
        "Venue": "CSCW 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-771/PC-15-295.pdf"
        ],
        "PublicationDate": "03/14/2015",
        "ID": "771",
        "Authors": [
            "Jennifer Marlow",
            "Laura Dabbish"
        ],
        "Title": "The effects of visualizing activity history on attitudes and behaviors in a peer production context",
        "Abstract": "In a variety of peer production settings, from Wikipedia to open source software development to crowdsourcing, individuals may encounter, edit, or review the work of unknown others. Typically this is done without much context to the person's past behavior or performance. To understand how exposure to an unknown individual's activity history influences attitudes and behaviors, we conducted an online experiment on Mechanical Turk varying the content, quality, and presentation of information about another Turker's work history. Surprisingly, negative work history did not lead to negative outcomes, but in contrast, a positive work history led to positive initial impressions that persisted in the face of contrary information. This work provides insight into the impact of activity history design factors on psychological and behavioral outcomes that can be of use in other related settings."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-774",
        "Venue": "International Workshop on Quality of Multimedia Experience (QoMEX)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-774/PC-15-300.pdf"
        ],
        "PublicationDate": "09/18/2014",
        "ID": "774",
        "Authors": [
            "M.R. Schmitt",
            "S. Gunkel",
            "Pablo Cesar",
            "Dick Bulterman"
        ],
        "Title": "Asymmetric Delay in Video-Mediated Group Discussions",
        "Abstract": "Delay has been found as one of the most crucial factors\r\ndetermining the Quality of Experience (QoE) in synchronous\r\nvideo-mediated communication. The effect has been extensively\r\nstudied for dyadic conversations and recently the study of small\r\ngroup communications has become the focus of the research\r\ncommunity. Contrary to dyads, in which the delay is symmetrically perceived, this is not the case for groups. Due to the heterogeneous structure of the internet asymmetric delays between participants are likely to occur."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-776",
        "Venue": "ACM Brazilian Symposium on Multimedia and the Web",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-776/PC-15-303.pdf"
        ],
        "PublicationDate": "11/18/2014",
        "ID": "776",
        "Authors": [
            "Rodrigo Laiola Guimaraes",
            "Dick Bulterman",
            "Pablo Cesar",
            "Jack Jansen"
        ],
        "Title": "Synchronizing Web Documents with Style",
        "Abstract": "In this paper we report on our efforts to define a set of document extensions to Cascading Style Sheets (CSS) that allow for structured timing and synchronization of elements within a Web page. Our work considers the scenario in which the temporal structure can be decoupled from the content of the Web page in a similar way that CSS does with the layout, colors and fonts. Based on the SMIL (Synchronized Multimedia Integration Language) temporal model we propose CSS document extensions and discuss the design and implementation of a proof of concept that realizes our contributions. As HTML5 seems to move away from technologies like Flash and XML (eXtensible Markup Language), we believe our approach provides a flexible declarative solution to specify rich media experiences that is more aligned with current Web practices."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-777",
        "Venue": "International Journal on Multimedia Tools and Applications",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-777/PC-15-302.pdf"
        ],
        "PublicationDate": "03/01/2014",
        "ID": "777",
        "Authors": [
            "Dick Bulterman",
            "Pablo Cesar",
            "E. Munson",
            "M.G.C. Pimentel"
        ],
        "Title": "Multimedia Authoring and Annotation",
        "Abstract": "With the massive amount of captured multimedia, authoring is more relevant than ever. Multimedia content is available in many settings including the web, mobile devices, desktop applications, as well as games and interactive TV. The authoring and production of multimedia documents demands attention to many issues related to the structure and to the synchronization of the media components, to the specification of the document and of the interaction, to the roles of authors and end users, as well as issues concerning reuse and digital rights management. Several complementary approaches to support the authoring of multimedia documents have been reported in the literature, and in many cases they have been studied via authoring tools and applications. One aim of this special issue is to assess current approaches, tools and applications, discussing how they tackle the main issues relative to the process of authoring, as well as their limitations."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-779",
        "Venue": "SPIE optics + photonics (SPIE)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-779/PC-15-299.pdf"
        ],
        "PublicationDate": "08/17/2014",
        "ID": "779",
        "Authors": [
            "R.N. Mekuria",
            "Pablo Cesar",
            "Dick Bulterman"
        ],
        "Title": "Source coding for transmission of reconstructed dynamic geometry: a rate-distortion-complexity analysis of different approaches",
        "Abstract": "Live 3D reconstruction of a human as a 3D mesh with commodity electronics is becoming a reality. Immersive applications (i.e. cloud gaming, tele-presence) benefit from effective transmission of such content over a bandwidth limited link. In this paper we outline different approaches for compressing live reconstructed mesh geometry based on distributing mesh reconstruction functions between sender and receiver. We evaluate rate-performance-complexity of different configurations. First, we investigate 3D mesh compression methods (i.e. dynamic/static) from MPEG-4. Second, we evaluate the option of using octree based point cloud compression and receiver side surface reconstruction."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-780",
        "Venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)",
        "palwebURL": [],
        "PublicationDate": "05/04/2014",
        "ID": "780",
        "Authors": [
            "R.N. Mekuria",
            "Dick Bulterman",
            "Pablo Cesar"
        ],
        "Title": "Low Complexity Connectivity Driven Dynamic Geometry Compression for 3D Tele-Immersion",
        "Abstract": "Geometry based 3D Tele-Immersion is a novel emerging media application that involves on the fly reconstructed 3D mesh geometry. To enable real-time communication of such live reconstructed mesh geometry over a bandwidth limited link, fast dynamic geometry compression is needed. However, most tools and methods have been developed for compressing synthetically generated graphics content. These methods achieve good compression rates by exploiting topological and geometric properties that typically do not hold for reconstructed mesh geometry. The live reconstructed dynamic geometry is causal and often non-manifold, open, non-oriented and time-inconsistent. Based on our experience developing a prototype for 3D Teleimmersion based on live reconstructed geometry, we discuss currently available tools. We then present our approach for dynamic compression that better exploits the fact that the 3D geometry is reconstructed and achieve a state of art rate-distortion under stringent real-time constraints."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/18/2014",
        "palwebID": "PR-14-781",
        "Venue": "IEEE Transactions on Multimedia",
        "palwebURL": [],
        "PublicationDate": "06/18/2014",
        "ID": "781",
        "Authors": [
            "R.N. Mekuria",
            "M. Sanna",
            "E. Izquierdo",
            "Dick Bulterman",
            "Pablo Cesar"
        ],
        "Title": "Enabling 3D Tele-Immersion with Live Reconstructed Mesh Geometry with Fast Mesh Compression and Linear Rateless Coding",
        "Abstract": "3D Tele-immersion enables participants in remote locations to share, in real-time, an activity. It offers users interactive and immersive experiences, but it challenges current media streaming solutions. Work in the past has mainly focused on the efficient delivery of image-based 3D videos and on realistic rendering and reconstruction of geometry-based 3D objects. The contribution of this paper is a real-time streaming component for 3D Tele-Immersion with dynamic reconstructed geometry. This component includes both a novel fast compression method and a rateless packet protection scheme specifically designed towards the requirements imposed by real time transmission of live-reconstructed mesh geometry. Tests on a large dataset show an encoding speed-up upto 10 times at comparable compression ratio and quality, when compared to the high-end MPEG-4 SC3DMC mesh encoders. The implemented rateless code ensures complete packet loss protection of the triangle mesh object and a delivery delay within interactive bounds. Contrary to most linear fountain codes, the designed codec enables real time progressive decoding allowing partial decoding each time a packet is received. This approach is compared to transmission over TCP in packet loss rates and latencies, typical in managed WAN and MAN networks, and heavily outperforms it in terms of end-to-end delay. The streaming component has been integrated into a larger 3D Tele-Immersive environment that includes state of the art 3D reconstruction and rendering modules. This resulted in a prototype that can capture, compress transmit and render triangle mesh geometry in real-time in realistic internet conditions as shown in experiments. Compared to alternative methods, lower interactive end-to-end delay and frame rates over 3 times higher are achieved."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-782",
        "Venue": "ACM International Workshop on Understanding and Modeling Multiparty, Multimodal Interactions (UMMMI)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-782/PC-15-305.pdf"
        ],
        "PublicationDate": "11/16/2014",
        "ID": "782",
        "Authors": [
            "M.R. Schmitt",
            "S. Gunkel",
            "Pablo Cesar",
            "Dick Bulterman"
        ],
        "Title": "Mitigating problems in video-mediated group discussions: Towards conversation aware video-conferencing systems",
        "Abstract": "In this paper we discuss communication problems in video-mediated small group discussions. We present results from a study in which ad-hoc groups of five people, with moderator, solved a quiz question-select answer style task over a video-conferencing system. The task was performed under different delay conditions, of up to 2000ms additional one-way delay. Even with a delay up to 2000ms, we could not observe any effect on the achieved quiz scores. In contrast, the subjective satisfaction was severely negatively affected. While we would have suspected a clear conversational breakdown with such a high delay, groups adapted their communication style and thus still managed to solve the task. This is, most groups decided to switch to a more explicit turn-taking scheme.\r\nWe argue that future video-conferencing systems can provide a\r\nbetter experience if they are aware of the current conversational\r\nsituation and can provide compensation mechanisms. Thus we\r\nprovide an overview of what cues are relevant and how they are\r\naffected by the video-conferencing system and how recent\r\nadvancements in computational social science can be leveraged.  Further, we provide an analysis of the suitability of normal webcam data for such cue recognition. Based on our observations, we suggest strategies that can be implemented to alleviate the problems."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-784",
        "Venue": "ACM Workshop on Mobile Video (ACM MoVid)",
        "palwebURL": [],
        "PublicationDate": "03/19/2014",
        "ID": "784",
        "Authors": [
            "S. Gunkel",
            "Jack Jansen",
            "I. Kegel",
            "Dick Bulterman",
            "Pablo Cesar"
        ],
        "Title": "The Optimiser: monitoring and improving switching delays in video conferencing",
        "Abstract": "With the growing popularity of video communication systems, more people are using group video chat, rather than only one-to-one video calls. In such multi-party sessions, remote participants compete for the available screen space and bandwidth. A common solution is showing the current speaker prominently. Bandwidth limitations may not allow all streams to be sent at a high resolution at all times, especially with many participants in a call. This can be mitigated by only switching on higher resolutions when they are required. This switching encounters delays due to latency and the properties of encoded video streams. In this paper, we analyse and improve the switching delay of our video conferencing system. Our server-centric system offers a next-generation video chat solution, providing end-to-end video encoding. To evaluate our system we use a testbed that allows us to emulate different network conditions. We measure the video switching delay between three clients, each connected via different network profiles. Our results show that missing Intra-Frames in the transmission has a strong influence on the switching delay. Based on this, we provide an optimization mechanism that improves those delays by resending Intra-Frames."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-14-785",
        "Venue": "ACM International Workshop on Socially-aware Multimedia (SAM)",
        "palwebURL": [
            "http://palweb/files/PR/2014/PR-14-785/PC-15-306.pdf"
        ],
        "PublicationDate": "11/07/2014",
        "ID": "785",
        "Authors": [
            "M.R. Schmitt",
            "S. Gunkel",
            "Pablo Cesar",
            "Dick Bulterman"
        ],
        "Title": "The influence of interactivity patterns on the Quality of Experience in multi-party video-mediated conversations under symmetric delay conditions",
        "Abstract": "As commercial, off-the-shelf, services enable people to easily connect with friends and relatives, video-mediated communication is filtering into our daily activities. With the proliferation of broadband and powerful devices, multi-party gatherings are becoming a reality in home environments. With the technical infrastructure in place and has been accepted by a large user base, researchers and system designers are concentrating on understanding and optimizing the Quality of Experience (QoE) for participants. Theoretical foundations for QoE have identified three crucial factors for understanding the impact on the individual\u00c3\u0083\u00c2\u00a2\u00c3\u0082\u00c2\u0080\u00c3\u0082\u00c2\u0099s perception: system, context, and user. While most of the current research tends to focus on the system factors (delay, bandwidth, resolution), in this paper we offer a more complete analysis that takes into consideration context and user factors. In particular, we investigate the influence of delay (constant system factor) in the QoE of multi-party conversations. Regarding the context, we extend the typical one-to-one condition to explore conversations between small groups (up to five people). In terms of user factors,\r\nwe take into account conversation analysis, turn-taking and role-theory, for better understanding the impact of different user\r\nprofiles. Our investigation allows us to report a detailed analysis on how delay influences the QoE, concluding that the actual\r\ninteractivity pattern of each participant in the conversation results on different noticeability thresholds of delays. Such results have a direct impact on how we should design and construct video-communication services for multi-party conversations, where user activity should be considered as a prime adaptation and optimization parameter."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/30/2015",
        "palwebID": "PR-15-786",
        "Venue": "ICME 2015 Mobile Multimedia Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-786/PC-15-308.pdf"
        ],
        "PublicationDate": "06/29/2015",
        "ID": "786",
        "Authors": [
            "Mingming Fan",
            "Qiong Liu",
            "Henry Tang",
            "Khai Truong"
        ],
        "Title": "POLI: MOBILE AR BY HEARING POSITION FROM LIGHT",
        "Abstract": "Connecting digital information to physical objects can enrich their content and make them more vivid. Traditional augmented reality techniques reach this goal by augmenting physical objects or their surroundings with various markers and typically require end users to wear additional devices to explore the augmented content. In this paper, we propose POLI, which allows a system administrator to author digital content with his/her mobile device while allows end-users to explore the authored content with their mobile devices. POLI provides three novel interactive approaches for authoring digital content. It does not change the nature appearances of physical objects and does not require users to wear any additional hardware on their bodies."
    },
    {
        "Projects": [
            "Polly"
        ],
        "keywords": [],
        "AcceptDate": "06/01/2015",
        "palwebID": "PR-15-787",
        "Venue": "MobileHCI 2015 ",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-787/PC-15-322.pdf"
        ],
        "PublicationDate": "08/24/2015",
        "ID": "787",
        "Authors": [
            "Sven Kratz",
            "Daniel Avrahami",
            "Don Kimber",
            "Jim Vaughan",
            "Patrick Proppe"
        ],
        "Title": "Polly Wanna Show You: Examining Viewpoint-Conveyance Techniques for a Shoulder-Worn Telepresence System [Industrial Case Study]",
        "Abstract": "In this paper we report findings from two user studies that explore the problem of establishing common viewpoint in the context of a wearable telepresence system. In our first study, we assessed the ability of a local person (the guide) to identify the view orientation of the remote person by looking at the physical pose of the telepresence device. In the follow-up study, we explored visual feedback methods for communicating the relative viewpoints of the remote user and the guide via a head-mounted display. Our results show that actively observing the pose of the device is useful for viewpoint estimation. However, in the case of telepresence devices without physical directional affordances, a\r\nlive video feed may yield comparable results. Lastly, more abstract visualizations lead to significantly longer recognition times, but may be necessary in more complex environments."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/23/2015",
        "palwebID": "PR-15-788",
        "Venue": "DocEng 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-788/PR-15-788.pdf"
        ],
        "PublicationDate": "09/08/2015",
        "ID": "788",
        "Authors": [
            "Laurent Denoue",
            "Matthew Cooper",
            "Scott Carter"
        ],
        "Title": "Searching Live Meetings: \"Show me the Action\"",
        "Abstract": "Web-based tools for remote collaboration are quickly becoming an established element of the modern workplace. During live meetings, people share web sites, edit presentation slides, and share code editors. It is common for participants to refer to previously spoken or shared content in the course of synchronous distributed collaboration. A simple approach is to index with Optical Character Recognition\r\n(OCR) the video frames, or key-frames, being shared and let user retrieve them with text queries. Here we show that a complementary approach is to look at the actions users\r\ntake inside the live document streams. Based on observations of real meetings, we focus on two important signals: text editing and mouse cursor motion. We describe the detection\r\nof text and cursor motion, their implementation in our WebRTC-based system, and how users are better able to search live documents during a meeting based on these detected and indexed actions."
    },
    {
        "Projects": [
            "PersonalLiteDisplays"
        ],
        "keywords": [],
        "AcceptDate": "06/23/2015",
        "palwebID": "PR-15-789",
        "Venue": "DocEng 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-789/PR-15-789.pdf"
        ],
        "PublicationDate": "09/08/2015",
        "ID": "789",
        "Authors": [
            "Chelhwon Kim",
            "Patrick Chiu",
            "Henry Tang"
        ],
        "Title": "High-Quality Capture of Documents on a Cluttered Tabletop with a 4K Video Camera",
        "Abstract": "We present a novel system for detecting and capturing paper documents on a tabletop using a 4K video camera mounted overhead on pan-tilt servos.  Our automated system first finds paper documents on a cluttered tabletop based on a text probability map, and then takes a sequence of high-resolution frames of the located document to reconstruct a high quality and fronto-parallel document page image. The quality of the resulting images enables OCR processing on the whole page. We performed a preliminary evaluation on a small set of 10 document pages and our proposed system achieved 98% accuracy with the open source Tesseract OCR engine."
    },
    {
        "Projects": [
            "HyperMeeting"
        ],
        "keywords": [],
        "AcceptDate": "07/04/2015",
        "palwebID": "PR-15-791",
        "Venue": "ACM Multimedia",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-791/PR-15-791.pdf"
        ],
        "PublicationDate": "10/26/2015",
        "ID": "791",
        "Authors": [
            "Andreas Girgensohn",
            "Jennifer Marlow",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "HyperMeeting: Supporting Asynchronous Meetings with Hypervideo",
        "Abstract": "While synchronous meetings are an important part of collaboration, it is not always possible for all stakeholders to meet at the same time. We created the concept of hypermeetings to support meetings with asynchronous attendance. Hypermeetings consist of a chain of video-recorded meetings with hyperlinks for navigating through the video content. HyperMeeting supports the synchronized viewing of prior meetings during a videoconference. Natural viewing behavior such as pausing generates hyperlinks between the previously recorded meetings and the current video recording. During playback, automatic link-following guided by playback plans present the relevant content to users. Playback plans take into account the user's meeting attendance and viewing history and match them with features such as speaker segmentation. A user study showed that participants found hyperlinks useful but did not always understand where they would take them. The study results provide a good basis for future system improvements."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/07/2015",
        "palwebID": "PR-15-792",
        "Venue": "ACM MM",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-792/PR-15-792.pdf"
        ],
        "PublicationDate": "10/26/2015",
        "ID": "792",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue",
            "Matthew Cooper"
        ],
        "Title": "Searching and browsing live, web-based meetings",
        "Abstract": "Establishing common ground is one of the key problems for any form of communication. The problem is particularly pronounced in remote meetings, in which participants can easily lose track of the details of dialogue for any number of reasons. In this demo we present a web-based tool, MixMeet, that allows teleconferencing\r\nparticipants to search the contents of live meetings so they can rapidly retrieve previously shared content to get on the same page, correct a misunderstanding, or discuss a new idea."
    },
    {
        "Projects": [
            "EyeTracking"
        ],
        "keywords": [],
        "AcceptDate": "06/29/2015",
        "palwebID": "PR-15-793",
        "Venue": "International Symposium on Wearable Computers (ISWC) ",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-793/PC-15-311.pdf"
        ],
        "PublicationDate": "09/09/2015",
        "ID": "793",
        "Authors": [
            "Pernilla Qvarfordt",
            "Diako Mardanbegi"
        ],
        "Title": "Creating Gaze Annotations in Head Mounted displays",
        "Abstract": "To facilitate distributed communication in mobile settings, we developed a system for creating and sharing gaze anno-tations using head mounted displays, such as Google Glass. Gaze annotations make it possible to point out objects of interest within an image and add a verbal description to it. To create an annotation, the user simply looks at an object of interest in the image and speaks out the information connected to the object. The gaze location is recorded and inserted as a gaze marker and the voice is transcribed using speech recognition. After an annotation has been created, it can be shared with another person. We performed a user study that showed that users experienced that gaze annota-tions add precision and expressiveness compared to an annotation to the whole image."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "05/21/2015",
        "palwebID": "PR-15-794",
        "Venue": "UbiComp 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-794/PC-15-294.pdf"
        ],
        "PublicationDate": "09/07/2015",
        "ID": "794",
        "Authors": [
            "Jacob Biehl",
            "Matthew Cooper",
            "Gerry Filby",
            "Adam J. Lee"
        ],
        "Title": "You're where? Prove it! -- Towards trusted indoor location estimation of mobile devices",
        "Abstract": "Location-enabled applications now permeate the mobile computing landscape.  As technologies like Bluetooth Low Energy (BLE) and Apple's iBeacon protocols begin to see widespread adoption, we will no doubt see a proliferation of indoor location enabled application experiences. While not essential to each of these applications, many will require that the location of the device be true and verifiable.  In this paper, we present LocAssure, a new framework for trusted indoor location estimation.  The system leverages existing technologies like BLE and iBeacons, making the solution practical and compatible with technologies that are already in use today. In this work, we describe our system, situate it within a broad location assurance taxonomy, describe the protocols that enable trusted localization in our system, and provide an analysis of early deployment and use characteristics.  Through developer APIs, LocAssure can provide critical security support for a broad range of indoor location applications. "
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "08/11/2015",
        "palwebID": "PR-15-797",
        "Venue": "MM Commons Workshop co-located with ACM Multimedia 2015.",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-797/PR-15-797.pdf"
        ],
        "PublicationDate": "10/30/2015",
        "ID": "797",
        "Authors": [
            "Dhiraj Joshi",
            "Matthew Cooper",
            "Francine Chen",
            "Yan-Ying Chen"
        ],
        "Title": "Building User Profiles from Shared Photos",
        "Abstract": "In this paper, we analyze the association between a social media user's photo content and their interests. Visual content of photos is analyzed using state-of-the-art deep learning based automatic concept recognition. An aggregate visual concept signature is thereby computed for each user. User tags manually applied to their photos are also used to construct a tf-idf based signature per user. We also obtain social groups that users join to represent their social interests. In an effort to compare the visual-based versus tag-based user profiles with social interests, we compare corresponding similarity matrices with a reference similarity matrix based on users' group memberships. A random baseline is also included that groups users by random sampling while preserving the actual group sizes. A difference metric is proposed and it is shown that the combination of visual and text features better approximates the group-based similarity matrix than either modality individually. We also validate the visual analysis against the reference inter-user similarity using the Spearman rank correlation coefficient. Finally we cluster users by their visual signatures and rank clusters using a cluster uniqueness criteria. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/24/2015",
        "palwebID": "PR-16-799",
        "Venue": "CSCW 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-799/PR-16-799.pdf"
        ],
        "PublicationDate": "02/27/2016",
        "ID": "799",
        "Authors": [
            "Jennifer Marlow",
            "Scott Carter",
            "Nathan Good",
            "Jung-Wei Chen"
        ],
        "Title": "Beyond Talking Heads: Multimedia Artifact Creation, Use, and Sharing in Distributed Meetings",
        "Abstract": "Remote meetings are messy. There are an ever-increasing number of support tools available, and, as past work has shown, people will tend to select a subset of those tools to satisfy their own institutional, social, and personal needs. While video tools make it relatively easy to have conversations at a distance, they are less adapted to sharing and archiving multimedia content.  In this paper we take a deeper look at how sharing multimedia content occurs before, during, and after distributed meetings. Our findings shed light on the decisions and rationales people use to select from the vast set of tools available to them to prepare for, conduct, and reconcile the results of a remote meeting.  "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/24/2015",
        "palwebID": "PR-16-801",
        "Venue": "CSCW 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-801/PR-16-801.pdf"
        ],
        "PublicationDate": "02/27/2016",
        "ID": "801",
        "Authors": [
            "Jennifer Marlow",
            "Eveline van Everdingen",
            "Daniel Avrahami"
        ],
        "Title": "Taking Notes or Playing Games? \r\nUnderstanding Multitasking in Video Communication\r\n",
        "Abstract": "This paper presents a detailed examination of factors that affect perceptions of, and attitudes towards multitasking in dyadic video conferencing. We first report findings from interviews with 15 professional users of videoconferencing. We then report results from a controlled online experiment with 397 participants based in the United States. Our results show that the technology used for multitasking has a significant effect on others' assumptions of what secondary activity the multitasker is likely engaged in, and that this assumed activity in turn affects evaluations of politeness and appropriateness. We also describe how different layouts of the video conferencing UI may lead to better or worse ratings of engagement and in turn ratings of polite or impolite behavior. We then propose a model that captures our results and use the model to discuss implications for behavior and for the design of video communication tools. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/15/2015",
        "palwebID": "PR-15-802",
        "Venue": "International Journal of Semantic Computing",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-802/PC-15-317.pdf"
        ],
        "PublicationDate": "09/15/2015",
        "ID": "802",
        "Authors": [
            "Shang Ma",
            "Qiong Liu",
            "Henry Tang"
        ],
        "Title": "AN OVERVIEW OF LOCATION SEMANTICS TECHNOLOGIES AND\r\nAPPLICATIONS",
        "Abstract": "A localization system is a coordinate system for describing the world, organizing the world, and controlling the world. Without a coordinate system, we cannot specify the world in mathematical forms; we cannot regulate processes that may involve spatial collisions; we cannot even automate a robot for physical actions. This paper provides an overview of indoor localization technologies,\r\npopular models for extracting semantics from location data, approaches for associating semantic information and location data, and applications that may be enabled with location semantics. To make the presentation easy to understand, we will use a museum scenario to explain pros and cons of different technologies and models. More specifically, we will first explore users\u00c3\u0083\u00c2\u00a2\u00c3\u0082\u00c2\u0080\u00c3\u0082\u00c2\u0099 needs in a museum scenario. Based on these needs, we will then discuss advantages and disadvantages of using different\r\nlocalization technologies to meet these needs. From these discussions, we can highlight gaps\r\nbetween real application requirements and existing technologies, and point out promising\r\nlocalization research directions. Similarly, we will also discuss context information required by different applications and explore models and ontologies for connecting users, objects, and environment factors with semantics. By identifying gaps between various models and real application requirements, we can draw a roadmap for future location semantics research."
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "09/04/2015",
        "palwebID": "PR-15-803",
        "Venue": "IEEE BigData 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-803/PR-15-803.pdf"
        ],
        "PublicationDate": "10/29/2015",
        "ID": "803",
        "Authors": [
            "Bokai Cao",
            "Francine Chen",
            "Dhiraj Joshi",
            "Philip Yu"
        ],
        "Title": "Inferring Crowd-Sourced Venues for Tweets",
        "Abstract": "Knowing the geo-located venue of a tweet can facilitate better understanding of a user's geographic context, allowing apps to more precisely present information, recommend services, and target advertisements. However, due to privacy concerns, few users choose to enable geotagging of their tweets resulting in a small percentage of tweets being geotagged; furthermore, even if the geo-coordinates are available, the closest venue to the geo-location may be incorrect.\r\n\r\nIn this paper, we present a method for providing a ranked list of geo-located venues for a non-geotagged tweet, which simultaneously indicates the venue name and the geo-location at a very fine-grained granularity. In our proposed method for Venue Inference for Tweets ({\\VIT}), we construct a heterogeneous social network in order to analyze the embedded social relations, and leverage available but limited geographic data to estimate the geo-located venue of tweets. A single classifier is trained to predict the probability of a tweet and a geo-located venue being linked, rather than training a separate model for each venue. We examine the performance of four types of social relation features and three types of geographic features embedded in a social network when predicting whether a tweet and a venue are linked, with a best accuracy of over 88%. We use the classifier probability estimates to rank the predicted geo-located venues of a non-geotagged tweet from over 19k possibilities, and observed an average top-5 accuracy of 29%."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/18/2015",
        "palwebID": "PR-15-804",
        "Venue": "ISM 2015",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-804/PC-15-334.pdf"
        ],
        "PublicationDate": "12/14/2015",
        "ID": "804",
        "Authors": [
            "Mingming Fan",
            "Qiong Liu",
            "Shang Ma"
        ],
        "Title": "Indoor Toy Car Localization and Navigation using\r\nProjected Light",
        "Abstract": "Indoor localization is challenging in terms of both the\r\naccuracy and possible using scenarios. In this paper, we\r\nintroduce the design and implementation of a toy car\r\nlocalization and navigation system, which demonstrates that a\r\nprojected light based localization technique allows multiple\r\ndevices to know and exchange their fine-grained location\r\ninformation in an indoor environment. The projected light\r\nconsists of a sequence of gray code images which assigns each\r\npixel in the projection area a unique gray code so as to\r\ndistinguish their coordination. The light sensors installed on the\r\ntoy car and the potential \u00e2\u0080\u009cpassenger\u00e2\u0080\u009d receive the light stream\r\nfrom the projected light stream, based on which their locations\r\nare computed. The toy car then utilizes A* algorithm to plan the\r\nroute based on its own location, orientation, the target\u00e2\u0080\u0099s location and the map of available \u00e2\u0080\u009croads\u00e2\u0080\u009d. The fast speed of localization enables the toy car to adjust its own orientation while \u00e2\u0080\u009cdriving\u00e2\u0080\u009d and keep itself on \u00e2\u0080\u009croads\u00e2\u0080\u009d. The toy car system demonstrates that the localization technique can power other applications that require fine-grained location information of multiple objects simultaneously."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/06/2015",
        "palwebID": "PR-15-805",
        "Venue": "ACM Multimedia Conference 2015 (Video)",
        "palwebURL": [
            "http://palweb/files/PR/2015/PR-15-805/PC-15-323.pdf"
        ],
        "PublicationDate": "10/26/2015",
        "ID": "805",
        "Authors": [
            "Tony Dunnigan",
            "John Doherty",
            "Daniel Avrahami",
            "Jacob Biehl",
            "Patrick Chiu",
            "Chelhwon Kim",
            "Qiong Liu",
            "Henry Tang",
            "Lynn Wilcox"
        ],
        "Title": "Evolution of a Tabletop Telepresence System Through Art and Technology",
        "Abstract": "New technology comes about in a number of different ways. It may come from advances in scientific research, through new combinations of existing technology, or by simply from imagining what might be possible in the future. This video describes the evolution of Tabletop Telepresence, a system for remote collaboration through desktop videoconferencing combined with a digital desk. Tabletop Telepresence provides a means to share paper documents between remote desktops, interact with documents and request services (such as translation), and communicate with a remote person through a teleconference. It was made possible by combining advances in camera/projector technology that enable a fully functional digital desk, embodied telepresence in video conferencing and concept art that imagines future workstyles.  "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-12-806",
        "Venue": "ACM MM 2012",
        "palwebURL": [
            "http://palweb/files/PR/2012/PR-12-806/PR-12-806.pdf"
        ],
        "PublicationDate": "10/29/2012",
        "ID": "806",
        "Authors": [
            "Don Kimber",
            "Jun Shingu",
            "Jim Vaughan",
            "Dave Arendash",
            "David Lee",
            "Maribeth Back",
            "Shingo Uchihashi"
        ],
        "Title": "Through the Looking-Glass: Mirror Worlds for Augmented Awareness & Capability",
        "Abstract": "We describe a system for supporting mirror worlds - 3D virtual models of physical spaces that reflect the structure and activities of those spaces to help support context awareness and tasks such as planning and recollection of events.  Through views on web pages, portable devices, or on 'magic window' displays located in the physical space, remote people may 'look in' to the space, while people within the space are provided information not apparent through unaided perception.  For example, by looking at a mirror display, people can learn how long others have been present, or where they have been.  People in one part of a building can get a sense of activities in the rest of the building, know who is present in their office, and look in to presentations in other rooms. The system can be used to bridge across sites and help provide different parts of an organization with a shared awareness of each other's space and activities.  We describe deployments of our mirror world system at several locations."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/14/2015",
        "palwebID": "PR-16-808",
        "Venue": "MMM 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-808/PR-16-808.pdf"
        ],
        "PublicationDate": "01/04/2016",
        "ID": "808",
        "Authors": [
            "Britta Meixner",
            "Matthias Gold"
        ],
        "Title": "Second-layer Navigation in Mobile Hypervideo for Medical Training",
        "Abstract": "Hypervideos yield to different challenges in the area of navigation due to their underlying graph structure. Especially when used on tablets or by older people, a lack of clarity may lead to confusion and rejection of this type of medium. To avoid confusion, the hypervideo can be extended with a well known table of contents, which needs to be created separately by the authors due to an underlying graph structure. In this work, we present an extended presentation of a table of contents for hypervideos on mobile devices. The design was tested in a real world medical training scenario with the target group of people older than 45 which is the main target group of these applications. This user group is a particular challenge since they sometimes have limited experience in the use of mobile devices and physical deficiencies with growing age. Our user interface was designed in three steps. The findings of an expert group and a survey were used to create two different prototypical versions of the display, which were then tested against each other in a user test. This test revealed that a divided view is desired. The table of contents in an easy-to-touch version should be on the left side and previews of scenes should be on the right side of the view. These findings were implemented in the existing SIVA HTML5 open source player and tested with a second group of users. This test only lead to minor changes in the GUI."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/12/2015",
        "palwebID": "PR-16-811",
        "Venue": "AAAI",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-811/PC-15-330.pdf"
        ],
        "PublicationDate": "02/12/2016",
        "ID": "811",
        "Authors": [
            "Sirius Chen",
            "Yan-Ying Chen",
            "Francine Chen",
            "Dhiraj Joshi"
        ],
        "Title": "Business-Aware Visual Concept Discovery from Social Media for Multimodal Business Venue Recognition",
        "Abstract": "Image localization is important for marketing and recommendation of local business; however, the level of granularity is still a critical issue. Given a consumer photo and its rough GPS information, we are interested in extracting the fine-grained location information (i.e. business venues) of the image. To this end, we propose a novel framework for business venue recognition. The framework mainly contains three parts. First, business aware visual concept discovery: we mine a set of concepts that are useful for business venue recognition based on three guidelines including business-awareness, visually detectable, and discriminative power. Second, business-aware concept detection by convolutional neural networks (BA-CNN): we pro- pose a new network architecture that can extract semantic concept features from input image. Third, multimodal business venue recognition: we extend visually detected concepts to multimodal feature representations that allow a test image to be associated with business reviews and images from social media for business venue recognition. The experiments results show the visual concepts detected by BA-CNN can achieve up to 22.5% relative improvement for business venue recognition compared to the state-of-the-art convolutional neural network features. Experiments also show that by leveraging multimodal information from social media we can further boost the performance, especially in the case when the database images belonging to each business venue are scarce.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/15/2015",
        "palwebID": "PR-16-812",
        "Venue": "CSCW",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-812/PR-16-812.pdf"
        ],
        "PublicationDate": "02/27/2016",
        "ID": "812",
        "Authors": [
            "Ville Makela",
            "Scott Carter",
            "Jennifer Marlow"
        ],
        "Title": "MixMeetWear: Live Meetings At-a-glance ",
        "Abstract": "We present MixMeetWear, a smartwatch application that allows users to maintain awareness of the audio and visual content of a meeting while completing other tasks. Users of the system can listen to the audio of a meeting and also view, zoom, and pan webcam and shared content keyframes of other meeting participants' live streams in real time. Users can also provide input to the meeting via speech-to-text or predefined responses. A study showed that the system is useful for peripheral awareness of some meetings."
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "12/08/2015",
        "palwebID": "PR-16-813",
        "Venue": "IUI 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-813/PC-15-351.pdf"
        ],
        "PublicationDate": "03/07/2016",
        "ID": "813",
        "Authors": [
            "Francine Chen",
            "Patrick Chiu",
            "Seongtaek Lim"
        ],
        "Title": "Topic Modeling of Document Metadata for Visualizing Collaborations over Time\r\n",
        "Abstract": "We describe methods for analyzing and visualizing document metadata to provide insights about collaborations over time. We investigate the use of Latent Dirichlet Allocation (LDA) based topic modeling to compute areas of interest on which people collaborate. The topics are represented in a node-link force directed graph by persistent fixed nodes laid out with multidimensional scaling (MDS), and the people by transient movable nodes. The topics are also analyzed to detect bursts to highlight \"hot\" topics during a time interval.  As the user manipulates a time interval slider, the people nodes and links are dynamically updated. We evaluate the results of LDA topic modeling for the visualization by comparing topic keywords against the submitted keywords from the InfoVis 2004 Contest, and we found that the additional terms provided by LDA-based keyword sets result in improved similarity between a topic keyword set and the documents in a corpus.  We extended the InfoVis dataset from 8 to 20 years and collected publication metadata from our lab over a period of 21 years, and created interactive visualizations for exploring these larger datasets."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/08/2015",
        "palwebID": "PR-16-814",
        "Venue": "IUI 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-814/PC-15-348.pdf"
        ],
        "PublicationDate": "03/07/2016",
        "ID": "814",
        "Authors": [
            "Daniel Avrahami",
            "Eveline van Everdingen",
            "Jennifer Marlow"
        ],
        "Title": "Supporting Multitasking in Video Conferencing using Gaze Tracking and On-Screen Activity Detection",
        "Abstract": "The use of videoconferencing in the workplace has been steadily growing. While multitasking during video conferencing is often necessary, it is also viewed as impolite and sometimes unacceptable. One potential contributor to negative attitudes towards such multitasking is the disrupted sense of eye contact that occurs when an individual shifts their gaze away to another screen, for example, in a dual-monitor setup, common in office settings. We present a system to improve a sense of eye contact over videoconferencing in dual-monitor setups. Our system uses computer vision and desktop activity detection to dynamically choose the camera with the best view of a user\u00c3\u0083\u00c2\u0083\u00c3\u0082\u00c2\u00a2\u00c3\u0083\u00c2\u0082\u00c3\u0082\u00c2\u0080\u00c3\u0083\u00c2\u0082\u00c3\u0082\u00c2\u0099s face. We describe two alternative implementations of our system (RGB-only, and a combination of RGB and RGB-D cameras). We then describe results from an online experiment that shows the potential of our approach to significantly improve perceptions of a person\u00c3\u0083\u00c2\u0083\u00c3\u0082\u00c2\u00a2\u00c3\u0083\u00c2\u0082\u00c3\u0082\u00c2\u0080\u00c3\u0083\u00c2\u0082\u00c3\u0082\u00c2\u0099s politeness and engagement in the meeting."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/13/2015",
        "palwebID": "PR-16-815",
        "Venue": "CHI 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-815/PC-15-344.pdf"
        ],
        "PublicationDate": "05/07/2016",
        "ID": "815",
        "Authors": [
            "Daniel Epstein",
            "Daniel Avrahami",
            "Jacob Biehl"
        ],
        "Title": "Taking 5: Work-Breaks, Productivity, and Opportunities for Personal Informatics for Knowledge Workers",
        "Abstract": "Taking breaks from work is an essential and universal practice. In this paper, we extend current research on productivity in the workplace to consider the break habits of knowledge workers and explore opportunities of break logging for personal informatics. We report on three studies. Through a survey of 147 U.S.-based knowledge workers, we investigate what activities respondents consider to be breaks from work, and offer an understanding of the benefit workers desire when they take breaks. We then present results from a two-week in-situ diary study with 28 participants in the U.S. who logged 800 breaks, offering insights into the effect of work breaks on productivity. We finally explore the space of information visualization of work breaks and productivity in a third study. We conclude with a discussion of implications for break recommendation systems, availability and interuptibility research, and the quantified workplace."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/13/2015",
        "palwebID": "PR-16-816",
        "Venue": "CHI 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-816/PC-15-338.pdf"
        ],
        "PublicationDate": "05/07/2016",
        "ID": "816",
        "Authors": [
            "Elena Agapie",
            "Daniel Avrahami",
            "Jennifer Marlow"
        ],
        "Title": "<img src=\"/images/honorable.png\" title=\"Honorable Mention Award\" border=\"0\"/>Staying the Course: System-Driven Lapse Management for Supporting Behavior Change",
        "Abstract": "The negative effect of lapses during a behavior-change program has been shown to increase the risk of repeated lapses and, ultimately, program abandonment. In this paper, we examine the potential of system-driven lapse management - supporting users through lapses as part of a behavior-change tool. We first review lessons from domains such as dieting and addiction research and discuss the design space of lapse management. We then explore the value of one approach to lapse management - the use of \"cheat points\" as a way to encourage sustained participation. In an online study, we first examine interpretations of progress that was reached through using cheat points. We then present findings from a deployment of lapse management in a two-week field study with 30 participants. Our results demonstrate the potential of this approach to motivate and change users' behavior. We discuss important open questions for the design of future technology-mediated behavior change programs."
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [],
        "AcceptDate": "01/12/2016",
        "palwebID": "PR-16-819",
        "Venue": "Personal and Ubiquitous Computing (Springer)",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-819/PR-16-819.pdf"
        ],
        "PublicationDate": "02/18/2016",
        "ID": "819",
        "Authors": [
            "Matthew Cooper",
            "Jacob Biehl",
            "Gerry Filby",
            "Sven Kratz"
        ],
        "Title": "LoCo: Boosting for indoor location classification combining Wi-Fi and BLE",
        "Abstract": "In recent years, there has been an explosion of services that lever- age location to provide users novel and engaging experiences. However, many applications fail to realize their full potential because of limitations in current location technologies. Current frameworks work well outdoors but fare poorly indoors. In this paper we present LoCo, a new framework that can provide highly accurate room-level indoor location. LoCo does not require users to carry specialized location hardware, it uses radios that are present in most contemporary devices and, combined with a boosting classification technique, provides a significant runtime performance improvement. We provide experiments that show the combined radio technique can achieve accuracy that improves on current state-of-the-art Wi-Fi only techniques. LoCo is designed to be easily deployed within an environment and readily leveraged by application developers. We believe LoCo's high accuracy and accessibility can drive a new wave of location-driven applications and services."
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "01/26/2016",
        "palwebID": "PR-16-820",
        "Venue": "LREC 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-820/PR-16-820.pdf"
        ],
        "PublicationDate": "05/23/2016",
        "ID": "820",
        "Authors": [
            "Shigeyuki Sakaki",
            "Francine Chen",
            "Mandy Korpusik",
            "Yan-Ying Chen"
        ],
        "Title": "Corpus for Customer Purchase Behavior Prediction in Social Media",
        "Abstract": "Many people post about their daily life on social media. These posts may include information about the purchase activity of people, and insights useful to companies can be derived from them: e.g. profile information of a user who mentioned something about their product. As a further advanced analysis, we consider extracting users who are likely to buy a product from the set of users who mentioned that the product is attractive.\r\n\r\n\r\nIn this paper, we report our methodology for building a corpus for Twitter user purchase behavior prediction. First, we collected Twitter users who posted a want phrase + product name: e.g. \"want a Xperia\" as candidate want users, and also candidate bought users in the same way. Then, we asked an annotator to judge whether a candidate user actually bought a product. We also annotated whether tweets randomly sampled from want/bought user timelines are relevant or not to purchase. In this annotation, 58% of want user tweets and 35% of bought user tweets were annotated as relevant. Our data indicate that information embedded in timeline tweets can be used to predict purchase behavior of tweeted products."
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "03/11/2016",
        "palwebID": "PR-16-822",
        "Venue": "ICME 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-822/PR-16-822.pdf"
        ],
        "PublicationDate": "07/11/2016",
        "ID": "822",
        "Authors": [
            "Yan-Ying Chen",
            "Francine Chen",
            "Matthew Cooper",
            "Dhiraj Joshi"
        ],
        "Title": "Using Business-Aware Latent Topics For Image Captioning In Social Media",
        "Abstract": "Captions are a central component in image posts that communicate the background story behind photos. Captions can enhance the engagement with audiences and are therefore critical to campaigns or advertisement. Previous studies in image captioning either rely solely on image content or summarize multiple web documents related to image's location; both neglect users' activities. We propose business-aware latent topics as a new contextual cue for image captioning that represent user activities. The idea is to learn the typical activities of people who posted images from business venues with similar categories (e.g., fast food restaurants) to provide appropriate context for similar topics (e.g., burger) in new posts. User activities are modeled via a latent topic representation. In turn, the image captioning model can generate sentences that better reflect user activities at business venues. In our experiments, the business-aware latent topics are effective for adapting to captions to images captured in various businesses than the existing baselines. Moreover, they complement other contextual cues (image, time) in a multi-modal framework.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/14/2016",
        "palwebID": "PR-16-823",
        "Venue": "Multimedia Systems Journal",
        "palwebURL": [],
        "PublicationDate": "04/13/2016",
        "ID": "823",
        "Authors": [
            "Britta Meixner"
        ],
        "Title": "A Pattern-based Evaluation of Download and Cache Management Algorithms for Annotated Interactive Non-linear Videos",
        "Abstract": "With modern technologies, it is possible to create annotated interactive non-linear videos (a form of hypervideo) for the Web. These videos have a non-linear structure of linked scenes to which additional information (other media like images, text, audio, or additional videos) can be added. A variety of user interactions - like in- and between-scene navigation or zooming into additional information - are possible in players for this type of video. Like linear video, quality of experience (QoE) with annotated hypervideo experiences is tied to the temporal consistency of the video stream at the client end - its flow. Despite its interactive complexity, users expect this type of video experience to flow as seamlessly as simple linear video. However, the added hypermedia elements bog playback engines down.\r\n\r\nDownload and cache management systems address the flow issue, but their effectiveness is tied to numerous questions respecting user requirements, computational strategy, and evaluative metrics. In this work, we a) define QoE metrics, b) examine structural and behavioral patterns of interactive annotated non-linear video, c) propose download and cache management algorithms and strategies, d) describe the implementation of an evaluative simulation framework, and e) present the algorithm test results."
    },
    {
        "Projects": [
            "MiningSocialMultimedia",
            "MiningSocialMedia"
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-16-824",
        "Venue": "Fuji Xerox Technical Report",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-824/PC-16-384.pdf"
        ],
        "PublicationDate": "03/17/2016",
        "ID": "824",
        "Authors": [
            "Francine Chen",
            "Dhiraj Joshi",
            "Yasuhide Miura",
            "Tomoko Ohkuma"
        ],
        "Title": "Social Media-Based Profiling of Business Locations",
        "Abstract": "We present a method for profiling businesses at specific locations that is based on mining information from social media. The method matches geo-tagged tweets from Twitter against venues from Foursquare to identify the specific business mentioned in a tweet. By linking geo-coordinates to places, the tweets associated with a business, such as a store, can then be used to profile that business. From these venue-located tweets, we create sentiment profiles for each of the stores in a chain. We present the results as heat maps showing how sentiment differs across stores in the same chain and how some chains have more positive sentiment than other chains. We also estimate social group size from photos and create profiles of social group size for businesses. Sample heat maps of these results illustrate how the average social group size can vary across businesses."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/11/2016",
        "palwebID": "PR-16-826",
        "Venue": "ACM TVX 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-826/PR-16-826.pdf"
        ],
        "PublicationDate": "06/22/2016",
        "ID": "826",
        "Authors": [
            "Britta Meixner",
            "Werner Bailer",
            "Maarten Wijnants",
            "Rene Kaiser",
            "Joscha J\u00e4ger",
            "Rik Bauwens",
            "Frank Bentley"
        ],
        "Title": "4th International Workshop on Interactive Content Consumption (WSICC'16)",
        "Abstract": "WSICC has established itself as a truly interactive workshop at EuroITV'13, TVX'14, and TVX'15 with three successful editions. The fourth edition of the WSICC workshop aims to bring together researchers and practitioners working on novel approaches for interactive multimedia content consumption. New technologies, devices, media formats, and consumption paradigms are emerging that allow for new types of interactivity. Examples include multi-panoramic video and object-based audio, increasingly available in live scenarios with content feeds from a multitude of sources. \r\nAll these recent advances have an impact on different aspects related to interactive content consumption, which the workshop categorizes into Enabling Technologies, Content, User Experience, and User Interaction. The resources from past editions of the workshop are available on the http://wsicc.net website."
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "03/31/2016",
        "palwebID": "PR-16-827",
        "Venue": "SIGIR 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-827/PR-16-827.pdf"
        ],
        "PublicationDate": "07/18/2016",
        "ID": "827",
        "Authors": [
            "Bastiaan Sijtsma",
            "Pernilla Qvarfordt",
            "Francine Chen"
        ],
        "Title": "Tweetviz: Visualizing Tweets for Business Intelligence",
        "Abstract": "Social media offers potential opportunities for businesses to\r\nextract business intelligence. This paper presents Tweetviz,\r\nan interactive tool to help businesses extract actionable information from a large set of noisy Twitter messages. Tweetviz visualizes tweet sentiment of business locations, identifies other business venues that Twitter users visit, and estimates some simple demographics of the Twitter users frequenting a business. A user study to evaluate the system's ability indicates that Tweetviz can provide an overview of a business's issues and sentiment as well as information aiding users in creating customer profiles."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/30/2016",
        "palwebID": "PR-16-828",
        "Venue": "EICS 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-828/PR-16-828.pdf"
        ],
        "PublicationDate": "06/21/2016",
        "ID": "828",
        "Authors": [
            "Sven Kratz",
            "Jason Wiese"
        ],
        "Title": "GestureSeg: Developing a Gesture Segmentation System using Gesture Execution Phase Labeling by Crowd Workers",
        "Abstract": "Most current mobile and wearable devices are equipped with inertial measurement units (IMU) that allow the detection of motion gestures, which can be used for interactive applications. A difficult problem to solve, however, is how to separate ambient motion from an actual motion gesture input. In this work, we explore the use of motion gesture data labeled with gesture execution phases for training supervised learning classifiers for gesture segmentation. We believe that using gesture execution phase data can significantly improve the accuracy of gesture segmentation algorithms. We define gesture execution phases as the start, middle and end of each gesture. Since labeling motion gesture data with gesture execution phase information is work intensive, we used crowd workers to perform the labeling. Using this labeled data set, we trained SVM-based classifiers to segment motion gestures from ambient movement of the device t. We describe initial results that indicate that gesture execution phase can be accurately recognized by SVM classifiers. Our main results show that training gesture segmentation classifiers with phase-labeled data substantially increases the accuracy of gesture segmentation: we achieved a gesture segmentation accuracy of 0.89 for simulated online segmentation using a sliding window approach."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/25/2016",
        "palwebID": "PR-16-829",
        "Venue": "ACM International Conference on Multimedia Retrieval (ICMR)",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-829/PR-16-829.pdf"
        ],
        "PublicationDate": "06/06/2016",
        "ID": "829",
        "Authors": [
            "Chidansh Bhatt",
            "Andrei Popescu-Belis",
            "Matthew Cooper"
        ],
        "Title": "Audiovisual Summarization of Lectures and Meetings Using a Segment Similarity Graph",
        "Abstract": "We propose a method for extractive summarization of audiovisual recordings focusing on topic-level segments. We first build a content similarity graph between all segments of all documents in the collection, using word vectors from the transcripts, and then select the most central segments for the summaries. We evaluate the method quantitatively on the AMI Meeting Corpus using gold standard reference summaries and the Rouge metric, and qualitatively on lecture recordings using a novel two-tiered approach with human judges. The results show that our method compares favorably with others in terms of Rouge, and outperforms the baselines for human scores, thus also validating our evaluation protocol."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "02/08/2016",
        "palwebID": "PR-16-830",
        "Venue": "CHI 2016 (Late Breaking Work)",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-830/PC-16-368.pdf"
        ],
        "PublicationDate": "05/07/2016",
        "ID": "830",
        "Authors": [
            "Sven Kratz",
            "Tony Dunnigan"
        ],
        "Title": "ThermoTouch: Design of a High Dynamic (Temperature) Range Thermal Haptic Display",
        "Abstract": "We describe a novel thermal haptic output device, ThermoTouch, that provides a grid of thermal pixels. Unlike previous devices which mainly use Peltier elements for thermal output, ThermoTouch uses liquid cooling and electro-resistive heating to output thermal feedback at arbitrary grid locations. We describe the design of the prototype, highlight advantages and disadvantages of the technique and briefly discuss future improvements and research applications. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/22/2016",
        "palwebID": "PR-16-831",
        "Venue": "3rd IEEE International Workshop on Mobile Multimedia Computing (MMC)",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-831/PC-16-385.pdf"
        ],
        "PublicationDate": "07/11/2016",
        "ID": "831",
        "Authors": [
            "Shang Ma",
            "Qiong Liu"
        ],
        "Title": "ON HEARING YOUR POSITION THROUGH LIGHT FOR MOBILE ROBOT INDOOR NAVIGATION",
        "Abstract": "Mobile Audio Commander (MAC) is a mobile phone-based multimedia sensing system that facilitates the introduction of extra sensors to existing mobile robots for advanced capabilities. In this paper, we use MAC to introduce an accurate indoor positioning sensor to a robot to facilitate its indoor navigation. More specifically, we use a projector to send out position ID through light signal, use a light sensor and the audio channel on a mobile phone to decode the position ID, and send navigation commands to a target robot through audio output. With this setup, our system can simplify user's robot navigation. Users can define a robot navigation path on a phone, and our system will compare the navigation path with its accurate location sensor inputs and generate analog line-following signal, collision avoidance signal, and analog angular signal to adjust the robot's straight movements and turns. This paper describes two examples of using MAC and a positioning system to enable complicated robot navigation with proper user interface design, external circuit design and real sensor installations on existing robots."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/18/2016",
        "palwebID": "PR-16-832",
        "Venue": "IEEE Multimedia Magzine",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-832/PC-16-386.pdf"
        ],
        "PublicationDate": "05/02/2016",
        "ID": "832",
        "Authors": [
            "Qiong Liu"
        ],
        "Title": "The BAMMF Series in the Silicon Valley",
        "Abstract": "Silicon Valley is home to many of the world's largest technology corporations, as well as thousands of small startups. Despite the development of other high-tech economic centers throughout the US and around the world, Silicon Valley continues to be a leading hub for high-tech innovation and development, in part because most of its companies and universities are within 20 miles of each other. Given the high concentration of multimedia researchers in Silicon Valley, and the high demand for information exchange, I was able to work with a team of researchers from various companies and organizations to start the Bay Area Multimedia Forum (BAMMF) series back in November 2013."
    },
    {
        "Projects": [
            "MultimediaCaptureAndAccess"
        ],
        "keywords": [],
        "AcceptDate": "04/25/2016",
        "palwebID": "PR-16-833",
        "Venue": "Mobile HCI 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-833/PR-16-833.pdf"
        ],
        "PublicationDate": "09/06/2016",
        "ID": "833",
        "Authors": [
            "Scott Carter",
            "Jennifer Marlow",
            "Aki Komori",
            "Ville Makela"
        ],
        "Title": "Bringing mobile into meetings: Enhancing distributed meeting participation on smartwatches and mobile phones",
        "Abstract": "Most teleconferencing tools treat users in distributed meetings monolithically: all participants are meant to be connected to one another in the more-or-less the same manner. In reality, though, people connect to meetings in all manner of different contexts, sometimes sitting in front of a laptop or tablet giving their full attention, but at other times mobile and involved in other tasks or as a liminal participant in a larger group meeting. In this paper we present the design and evaluation of two applications, MixMeetWear and MeetingMate, designed to help users in non-standard contexts participate in meetings."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "05/06/2016",
        "palwebID": "PR-16-834",
        "Venue": "Ro-Man 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-834/PR-16-834.pdf"
        ],
        "PublicationDate": "08/26/2016",
        "ID": "834",
        "Authors": [
            "Jim Vaughan",
            "Sven Kratz",
            "Don Kimber"
        ],
        "Title": "<img src=\"/images/best.png\" title=\"Best Paper Award\" border=\"0\" /> Look Where You're Going: Visual Interfaces for Robot Teleoperation\r\n",
        "Abstract": "Two related challenges with current teleoperated robotic systems are lack of peripheral vision and awareness, and difficulty or tedium of navigating through remote spaces.  We address these challenges by providing an interface with a focus plus context (F+C) view of the robot location, and where the user can navigate simply by looking where they want to go, and clicking or drawing a path on the view to indicate the desired trajectory or destination.  The F+C view provides an undistorted, perspectively correct central region surrounded by a wide field of view peripheral portion, and avoids the need for separate views. The navigation method is direct and intuitive in comparison to keyboard or joystick based navigation, which require the user to be in a control loop as the robot moves.  Both the F+C views and the direct click navigation were evaluated in a preliminary user study."
    },
    {
        "Projects": [
            "RobotAugmentedWorkspace"
        ],
        "keywords": [],
        "AcceptDate": "10/12/2016",
        "palwebID": "PR-16-835",
        "Venue": "Ro-Man 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-835/PR-16-835.pdf"
        ],
        "PublicationDate": "08/26/2016",
        "ID": "835",
        "Authors": [
            "Sven Kratz",
            "Fred Ferreira"
        ],
        "Title": "Immersed Remotely: Evaluating the Use of Head Mounted Devices for Remote Collaboration in Robotic Telepresence",
        "Abstract": "Mobile Telepresence Robots (MTR) are an emerging technology that extend the functionality of telepresence systems by adding mobility. MTRs nowadays, however, rely on stationary imaging systems such as a single narrow-view camera for vision, which can lead to reduced operator performance due to view-related deficiencies in situational awareness. We therefore developed an improved imaging and viewing platform that allows immersive telepresence using a Head Mounted Device (HMD) with head-tracked mono and stereoscopic video. Using a remote collaboration task to ground our research, we examine the effectiveness head-tracked HMD systems in comparison to a baseline monitor-based system.  \r\nWe performed a user study where participants were divided into three groups: fixed camera monitor-based baseline condition (without HMD), HMD with head-tracked 2D camera and HMD with head-tracked stereo camera. Results showed the use of HMD reduces task error rates and improves perceived collaborative success and quality of view, compared to the baseline condition. No major difference was found, however, between stereo and 2D camera conditions for participants wearing an HMD."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/06/2016",
        "palwebID": "PR-16-838",
        "Venue": "WSICC Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-838/PR-16-838.pdf"
        ],
        "PublicationDate": "06/06/2016",
        "ID": "838",
        "Authors": [
            "Britta Meixner",
            "Fabian Kallmeier"
        ],
        "Title": "Speech Control for HTML5 Hypervideo Players",
        "Abstract": "Hypervideo usage scenarios like physiotherapy trainings or instructions for manual tasks make it hard for users to use an input device like a mouse or touch screen on a hand-held device while they are performing an exercise or use both hands to perform a manual task. In this work, we are trying to overcome this issue by providing an alternative input method for hypervideo navigation using speech commands. In a user test, we evaluated two different speech recognition libraries, annyang (in combination with the Web Speech API) and PocketSphinx.js (in combination with the Web Audio API), for their usability to control hypervideo players. Test users spoke 18 words, either in German or English, which were recorded and then processed by both libraries. We found out that annyang shows better recognition results. However, depending on other factors of influence, like the occurrence of background noise (reliability), the availability of an internet connection, or the used browser, PocketSphinx.js may be a better fit. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/01/2016",
        "palwebID": "PR-16-839",
        "Venue": "Hypertext 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-839/PR-16-839.pdf"
        ],
        "PublicationDate": "07/12/2016",
        "ID": "839",
        "Authors": [
            "Britta Meixner",
            "Christoph Einsiedler"
        ],
        "Title": "Pre-fetching Strategies for HTML5 Hypervideo Players",
        "Abstract": "Web videos are becoming more and more popular. Current web technologies make it simpler than ever to both stream videos and create complex constructs of interlinked videos with additional information (video, audio, images, and text); so called hypervideos. When viewers interact with hypervideos by clicking on links, new content has to be loaded. This may lead to excessive waiting times, interrupting the presentation -- especially when videos are loaded into the hypervideo player. In this work, we propose hypervideo pre-fetching strategies, which can be implemented in players to minimize waiting times. We examine the possibilities offered by the HTML5 <video> tag as well as the Media Source Extensions (MSE). Both HTML5 and MSE allow element pre-fetching (video and additional information) up to a certain granularity. Depending on the strategy and technology used, beginning scene waiting times and the overall download volume may increase. The strategies presented in this paper allow the number of delays during playback and the overall waiting time of a video to be reduced significantly from an average of 8.1 breaks to less than one break. The overall waiting times can be reduced by one third, to less than 18 seconds improving the hypervideo watching experience. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/10/2016",
        "palwebID": "PR-16-841",
        "Venue": "WSICC Workshop at TVX",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-841/PC-16-397.pdf"
        ],
        "PublicationDate": "06/22/2016",
        "ID": "841",
        "Authors": [
            "Britta Meixner",
            "Stefan John",
            "Philipp Defner"
        ],
        "Title": "Screen Concepts for Multi-Version Hypervideo Authoring",
        "Abstract": "The creation of hypervideos usually requires a lot of planning and is time consuming with respect to media content creation. However, when structure and media are put together to author a hypervideo, it may only require minor changes to make the hypervideo available in other languages or for another user group (like beginners versus experts). However, to make the translation of media and all navigation elements of a hypervideo efficient and manageable, the authoring tool needs a GUI that provides a good overview of elements that can be translated and of missing translations. In this work, we propose screen concepts that help authors to provide different versions (for example language and/or experience level) of a hypervideo. We analyzed different variants of GUI elements and evaluated them in a survey. We draw guidelines from the results that can help with the creation of similar systems in the future. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/22/2016",
        "palwebID": "PR-16-842",
        "Venue": "WSICC Workshop at TVX",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-842/PC-16-389.pdf"
        ],
        "PublicationDate": "06/22/2016",
        "ID": "842",
        "Authors": [
            "Britta Meixner",
            "Christian Handschigl",
            "Stefan John",
            "Michael Granitzer"
        ],
        "Title": "From Single Screen to Dual Screen - a Design Study for a User-Controlled Hypervideo-Based Physiotherapy Training",
        "Abstract": "Hypervideo based physiotherapy trainings bear an opportunity to support patients in continuing their training after being released from a rehabilitation clinic. Many exercises require the patient to sit on the floor or a gymnastic ball, lie on a gymnastics mat, or do the exercises in other postures. Using a laptop or tablet with a stand to show the exercises is more helpful than for example just having some drawings on a leaflet. However, it may lead to incorrect execution of the exercises while maintaining eye contact with the screen or require the user to get up and select the next exercise if the devices is positioned for a better view. A dual screen application, where contents are shown on a TV screen and the flow of the video can be controlled from a mobile second device, allows patients to keep their correct posture and the same time view and select contents. In this paper we propose first studies for user interface designs for such apps. Initial paper prototypes are discussed and refined in two focus groups. The results are then presented to a broader range of users in a survey. Three prototypes for the mobile app and one prototype for the TV are identified for future user tests."
    },
    {
        "Projects": [
            "HyperMeeting"
        ],
        "keywords": [],
        "AcceptDate": "04/01/2016",
        "palwebID": "PR-16-843",
        "Venue": "Hypertext 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-843/PR-16-843.pdf"
        ],
        "PublicationDate": "07/10/2016",
        "ID": "843",
        "Authors": [
            "Andreas Girgensohn",
            "Jennifer Marlow",
            "Frank Shipman",
            "Lynn Wilcox"
        ],
        "Title": "Guiding Users through Asynchronous Meeting Content with Hypervideo Playback Plans",
        "Abstract": "We previously created the HyperMeeting system to support a chain of geographically and temporally distributed meetings in the form of a hypervideo. This paper focuses on playback plans that guide users through the recorded meeting content by automatically following available hyperlinks. Our system generates playback plans based on users' interests or prior meeting attendance and presents a dialog that lets users select the most appropriate plan. Prior experience with playback plans revealed users' confusion with automatic link following within a sequence of meetings. To address this issue, we designed three timeline visualizations of playback plans. A user study comparing the timeline designs indicated that different visualizations are preferred for different tasks, making switching among them important. The study also provided insights that will guide research of personalized hypervideo, both inside and outside a meeting context."
    },
    {
        "Projects": [
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "07/16/2016",
        "palwebID": "PR-16-844",
        "Venue": "CBRecSys: Workshop on New Trends in Content-Based Recommender Systems at ACM Recommender Systems Conference",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-844/PR-16-844.pdf"
        ],
        "PublicationDate": "09/02/2016",
        "ID": "844",
        "Authors": [
            "Mandy Korpusik",
            "Shigeyuki Sakaki",
            "Francine Chen",
            "Yan-Ying Chen"
        ],
        "Title": "Recurrent Neural Networks for Customer Purchase Prediction on Twitter",
        "Abstract": "The abundance of data posted to Twitter enables companies to extract useful information, such as Twitter users who are dissatisfied with a product. We endeavor to determine which Twitter users are potential customers for companies and would be receptive to product recommendations through the language they use in tweets after mentioning a product of interest. With Twitter's API, we collected tweets from users who tweeted about mobile devices or cameras. An expert annotator determined whether each tweet was relevant to customer purchase behavior and\r\nwhether a user, based on their tweets, eventually bought the product. For the relevance task, among four models, a feed-forward neural network yielded \r\nthe best cross-validation accuracy of over 80% per product. For customer purchase prediction of a product, we observed improved performance with the use of sequential input of tweets to recurrent models, with an LSTM model being best; we also observed the use of relevance predictions in our model to be more effective with less powerful RNNs and on more difficult tasks.\r\n"
    },
    {
        "Projects": [
            "MultimediaCaptureAndAccess"
        ],
        "keywords": [],
        "AcceptDate": "07/08/2016",
        "palwebID": "PR-16-845",
        "Venue": "ACM MM",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-845/PR-16-845.pdf"
        ],
        "PublicationDate": "10/15/2016",
        "ID": "845",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue",
            "Matthew Cooper"
        ],
        "Title": "WorkCache: Salvaging siloed knowledge",
        "Abstract": "The proliferation of workplace multimedia collaboration applications has meant on one hand more opportunities for group work but on the other more data locked away in proprietary interfaces. We are developing new tools to capture and access multimedia content from any source. In this demo, we focus primarily on new methods that allow users to rapidly reconstitute, enhance, and share document-based information."
    },
    {
        "Projects": [
            "MultimediaCaptureAndAccess"
        ],
        "keywords": [],
        "AcceptDate": "06/27/2016",
        "palwebID": "PR-16-846",
        "Venue": "Document Engineering DocEng 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-846/PR-16-846.pdf"
        ],
        "PublicationDate": "09/13/2016",
        "ID": "846",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Matthew Cooper"
        ],
        "Title": "DocuGram: Turning Screen Recordings into Documents",
        "Abstract": "In this paper we describe DocuGram, a novel tool to capture and share documents from any application. As users scroll through pages of their document inside the native application (Word, Google Docs, web browser), the system captures and analyses in real-time the video frames and reconstitutes the original document pages into an easy to view HTML-based representation. In addition to regenerating the document pages, a DocuGram also includes the interactions users had over them, e.g. mouse motions and voice comments. A DocuGram acts as a modern copy machine, allowing users to copy and share any document from any application."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/30/2016",
        "palwebID": "PR-16-852",
        "Venue": "UIST 2016 (Demo)",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-852/PC-16-405.pdf"
        ],
        "PublicationDate": "10/16/2016",
        "ID": "852",
        "Authors": [
            "Jun Shingu",
            "Patrick Chiu",
            "Sven Kratz",
            "Jim Vaughan",
            "Don Kimber"
        ],
        "Title": "Depth Based Shadow Pointing Interface for Public Display",
        "Abstract": "We propose a robust pointing detection with virtual shadow representation for interacting with a public display. Using a depth camera, our shadow is generated by a model with an angled virtual sun light and detects the nearest point as a pointer. Position of the shadow becomes higher when user walks closer, which conveys the notion of correct distance to control the pointer and offers accessibility to the higher area of the display. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/16/2016",
        "palwebID": "PR-16-853",
        "Venue": "Multimedia for personal health and health care \u2013 MMHealth 2016 @ ACM Multimedia 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-853/PC-16-411.pdf"
        ],
        "PublicationDate": "10/15/2016",
        "ID": "853",
        "Authors": [
            "Christian Handschigl",
            "Britta Meixner",
            "Stefan John",
            "Michael Granitzer"
        ],
        "Title": "Second Screen Hypervideo-Based Physiotherapy Training",
        "Abstract": "Adapting to personal needs and supporting correct posture are important in physiotherapy training. In this demo, we show a dual screen application (handheld and TV) that allows patients to view hypervideo training programs. Designed to guide their daily exercises, these programs can be adapted to daily needs. The dual screen concept offers the positional flexibility missing in single screen solutions."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/02/2016",
        "palwebID": "PR-16-854",
        "Venue": "Multimedia for personal health and health care \u2013 MMHealth 2016 @ ACM Multimedia 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-854/PC-16-408.pdf"
        ],
        "PublicationDate": "10/15/2016",
        "ID": "854",
        "Authors": [
            "Britta Meixner",
            "Christian Handschigl",
            "Stefan John",
            "Michael Granitzer"
        ],
        "Title": "A Dual Screen Concept for User-Controlled Hypervideo-Based Physiotherapy Training",
        "Abstract": "Dual screen concepts for hypervideo-based physiotherapy training are important in healthcare settings, but existing applications often cannot be adapted to personal needs and do not support correct posture. In this paper, we describe the design and implementation of a dual screen application (handheld and TV) that allows patients to view hypervideos designed to help them correctly perform their exercises. This approach lets patients adapt their training to their daily needs and their overall training progress. We evaluated this prototypical implementation in a user test with post-operative care prostate cancer patients. From our results, we derived design recommendations for dual screen physical training hypervideo applications."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/08/2016",
        "palwebID": "PR-16-855",
        "Venue": "ACM Multimedia 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-855/PC-16-396.pdf"
        ],
        "PublicationDate": "10/15/2016",
        "ID": "855",
        "Authors": [
            "Stefan John",
            "Christian Handschigl",
            "Britta Meixner",
            "Michael Granitzer"
        ],
        "Title": "Hypervideo Production Using Crowdsourced Youtube Videos",
        "Abstract": "Different systems exist for the creation of hypervideos nowadays. However, the creation of the video scenes which are put together to a hypervideo is a tedious and time consuming job. Then again huge video databases like YouTube exist which already provide rich sources of video materials. Yet it is not allowed to download and re-purpose the videos from there legally, which requires a solution to link whole videos or parts of videos and play them from the platform in an embedded player. This work presents the SIVA Web Producer, a Chrome extension for the creation of hypervideos consisting of scenes from YouTube videos. After creating a project, the Chrome extension allows to import YouTube videos or parts thereof as video clips. These can than be linked to a scene graph. A preview is provided and finalized videos can be published on the SIVA Web Portal."
    },
    {
        "Projects": [
            "CollaborativeExploratorySearch"
        ],
        "keywords": [],
        "AcceptDate": "04/30/2016",
        "palwebID": "PR-16-856",
        "Venue": "Information Processing & Management",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-856/PC-15-325.pdf"
        ],
        "PublicationDate": "06/11/2016",
        "ID": "856",
        "Authors": [
            "Jiyin He",
            "Pernilla Qvarfordt",
            "Martin Halvey",
            "Gene Golovchinsky"
        ],
        "Title": "Beyond Actions: Exploring the Discovery of Tactics from User Logs",
        "Abstract": "Search log analysis has become a common practice to gain insights into user search behaviour, it helps gain an understanding of user needs and preferences, as well as how well a system supports such needs. Currently log analysis is typically focused on the low-level user actions, i.e. logged events such as issued queries and clicked results; and often only a selection of such events are logged and analysed. However, the types of logged events may differ widely from interface to interface, making comparison between systems difficult. Further, analysing a selection of events may lead to conclusions out of context\u00e2\u0080\u0094 e.g. the statistics of observed query reformulations may be influenced by the existence of a relevance feedback component. Alternatively, in lab studies user activities can be analysed at a higher level, such as search tactics and strategies, abstracted away from detailed interface implementation. However, the required manual codings that map logged events to higher level interpretations prevent this type of analysis from going large scale. In this paper, we propose a new method for analysing search logs by (semi-)automatically identifying user search tactics from logged events, allowing large scale analysis that is comparable across search systems. We validate the efficiency and effectiveness of the proposed tactic identification method using logs of two reference search systems of different natures: a product search system and a video search system. With the identified tactics, we perform a series of novel log analyses in terms of entropy rate of user search tactic sequences, demonstrating how this type of analysis allows comparisons of user search behaviours across systems of different nature and design. This analysis provides insights not achievable with traditional log analysis."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "05/09/2016",
        "palwebID": "PR-16-857",
        "Venue": "HCIC Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-857/PC-16-390.pdf"
        ],
        "PublicationDate": "06/19/2016",
        "ID": "857",
        "Authors": [
            "Matthew Lee",
            "Pernilla Qvarfordt",
            "Jennifer Marlow",
            "Daniel Avrahami"
        ],
        "Title": "The Connected [Work]Life",
        "Abstract": "As workstyles change to include more dynamic contexts and denser spaces, connected objects and spaces in the workplace can play a bigger role in helping people get their work done, while also helping them navigate the continually blending boundaries between work- and home lives. In this talk, we argue that the workplace is particularly well-suited for realizing the \"connected life\" by including both company-initiated sensing in the workplace and personal tracking devices introduced by individual workers. We describe some examples of ubiquitous sensing in the workplace, and future opportunities as well as open technical and ethical issues for designing for the connected [work]life. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "05/01/2016",
        "palwebID": "PR-16-858",
        "Venue": "International Workshop on  Interactive Content Consumption ",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-858/PC-16-414.pdf"
        ],
        "PublicationDate": "06/22/2016",
        "ID": "858",
        "Authors": [
            "Don Kimber",
            "Enock Glidden",
            "Jennifer Marlow"
        ],
        "Title": "WorldViews: Connecting the world through easy sharing of views",
        "Abstract": "The confluence of technologies such as telepresence, immersive imaging, model based virtual mirror worlds, mobile live streaming, etc. give rise to a capability for people anywhere to view and connect with present or past\r\nevents nearly anywhere on earth. This capability properly belongs to a public commons, available as a birthright of all humans, and can been seen as part of an evolutionary transition supporting a global collective mind. We describe examples and elements of this capability, and suggest how they can be better integrated through a tool we\r\ncall TeleViewer and a framework called WorldViews,\r\nwhich supports easy sharing of views as well as connecting of providers and consumers of views all around the world."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/26/2016",
        "palwebID": "PR-16-859",
        "Venue": "ENCYCLOPEDIA WITH SEMANTIC COMPUTING",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-859/PC-16-416.pdf"
        ],
        "PublicationDate": "10/31/2016",
        "ID": "859",
        "Authors": [
            "Shang Ma",
            "Qiong Liu"
        ],
        "Title": "Semantic localization",
        "Abstract": "Improvements in sensor and wireless network enable accurate, automated, instant determination and dissemination of a user's or\r\nobjects position. The new enabler of location-based services (LBSs) apart from the current ubiquitous networking infrastructure is\r\nthe enrichment of the different systems with semantics information, such as time, location, individual capability, preference and\r\nmore. Such semantically enriched system-modeling aims at developing applications with enhanced functionality and advanced\r\nreasoning capabilities. These systems are able to deliver more personalized services to users by domain knowledge with advanced\r\nreasoning mechanisms, and provide solutions to problems that were otherwise infeasible. This approach also takes user's preference\r\nand place property into consideration that can be utilized to achieve a comprehensive range of personalized services, such as\r\nadvertising, recommendations, or polling. This paper provides an overview of indoor localization technologies, popular models for\r\nextracting semantics from location data, approaches for associating semantic information and location data, and applications that\r\nmay be enabled with location semantics. To make the presentation easy to understand, we will use a museum scenario to explain\r\npros and cons of different technologies and models. More specifically, we will first explore users' needs in a museum scenario.\r\nBased on these needs, we will then discuss advantages and disadvantages of using different localization technologies to meet these\r\nneeds. From these discussions, we can highlight gaps between real application requirements and existing technologies, and point\r\nout promising localization research directions. By identifying gaps between various models and real application requirements,\r\nwe can draw a road map for future location semantics research."
    },
    {
        "Projects": [
            "MultimediaCaptureAndAccess"
        ],
        "keywords": [],
        "AcceptDate": "11/03/2016",
        "palwebID": "PR-17-860",
        "Venue": "TRECVID Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-860/PC-16-428.pdf"
        ],
        "PublicationDate": "03/01/2017",
        "ID": "860",
        "Authors": [
            "Chidansh Bhatt",
            "Matthew Cooper"
        ],
        "Title": "FXPAL Experiments for TRECVID 2016 Video Hyperlinking",
        "Abstract": "This is a summary of our participation in the TRECVID 2016 video hyperlinking task (LNK). We submitted four runs in total. A baseline system combined on established vectorspace text indexing and cosine similarity. Our other runs explored the use of distributed word representations in combination with fine-grained inter-segment text similarity measures.\r\n"
    },
    {
        "Projects": [
            "ElasticWorkstyle"
        ],
        "keywords": [],
        "AcceptDate": "02/15/2016",
        "palwebID": "PR-16-861",
        "Venue": "Springer Multimedia Tools and Applications: SPECIAL ISSUE ON ",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-861/PC-16-366.pdf"
        ],
        "PublicationDate": "07/01/2016",
        "ID": "861",
        "Authors": [
            "Sven Kratz",
            "Wyko Rijnsburger"
        ],
        "Title": "Personalized Presentation Annotations Using Optical HMDs",
        "Abstract": "It is difficult to adjust the content of traditional slide presentations to the knowledge level, interest and role of individuals. This might force presenters to include content that is irrelevant for part of the audience, which negatively affects the knowledge transfer of the presentation. In this work, we present a prototype that is able to eliminate non-pertinent information from slides by presenting annotations for individual attendees on optical head-mounted displays. We first create guidelines for creating optimal annotations by evaluating several types of annotations alongside different types of slides. Then we evaluate the knowledge acquisition of presentation attendees using the prototype versus traditional presentations. Our results show that annotations with a limited amount of information, such as text up to 5 words, can significantly increase the amount of knowledge gained from attending a group presentation. Additionally, presentations where part of the information is moved to annotations are judged more positively on attributes such as clarity and enjoyment."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/03/2016",
        "palwebID": "PR-16-862",
        "Venue": "ACM SIGSPATIAL GIS 2016",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-862/PR-16-862.pdf"
        ],
        "PublicationDate": "11/02/2016",
        "ID": "862",
        "Authors": [
            "Yifang Yin",
            "Guanfeng Wang",
            "Roger Zimmermann"
        ],
        "Title": "Automatic Geographic Metadata Correction for Sensor-Rich Video Sequences.",
        "Abstract": "Videos recorded with current mobile devices are increasingly geotagged at fine granularity and used in various location based applications and services. However, raw sensor data collected is often noisy, resulting in subsequent inaccurate geospatial analysis. In this study, we focus on the challenging correction of compass readings and present an automatic approach to reduce these metadata errors. Given the small geo-distance between consecutive video frames, image-based localization does not work due to the high ambiguity in the depth reconstruction of the scene. As an alternative, we collect geographic context from OpenStreetMap and estimate the absolute viewing direction by comparing the image scene to world projections obtained with different external camera parameters. To design a comprehensive model, we further incorporate smooth approximation and feature-based rotation estimation when formulating the error terms. Experimental results show that our proposed pyramid-based method outperforms its competitors and reduces orientation errors by an average of 58.8%. Hence, for downstream applications, improved results can be obtained with these more accurate geo-metadata. To illustrate, we present the performance gain in landmark retrieval and tag suggestion by utilizing the accuracy-enhanced geo-metadata."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/26/2016",
        "palwebID": "PR-16-863",
        "Venue": "7th ACM SIGSPATIAL International Workshop on GeoStreaming (IWGS 2016)",
        "palwebURL": [
            "http://palweb/files/PR/2016/PR-16-863/PR-16-863.pdf"
        ],
        "PublicationDate": "10/31/2016",
        "ID": "863",
        "Authors": [
            "Yifang Yin",
            "Rajiv Ratn Shah",
            "Roger Zimmermann"
        ],
        "Title": "A General Feature-based Map Matching Framework with Trajectory Simplications.",
        "Abstract": "Accurate map matching has been a fundamental but challenging problem that has drawn great research attention in recent years. It aims to reduce the uncertainty in a trajectory by matching the GPS points to the road network on a digital map. Most existing work has focused on estimating the likelihood of a candidate path based on the GPS observations, while neglecting to model the probability of a route choice from the perspective of drivers. Here we propose a novel feature-based map matching algorithm that estimates the cost of a candidate path based on both GPS observations and human factors. To take human factors into consideration is very important especially when dealing with low sampling rate data where most of the movement details are lost. Additionally, we simultaneously analyze a subsequence of coherent GPS points by utilizing a new segment-based probabilistic map matching strategy, which is less susceptible to the noisiness of the positioning data. We have evaluated the proposed approach on a public large-scale GPS dataset, which consists of 100 trajectories distributed all over the world. The experimental results show that our method is robust to sparse data with large sampling intervals (e.g., 60 s to 300 s) and challenging track features (e.g., u-turns and loops). Compared with two state-of-the-art map matching algorithms, our method substantially reduces the route mismatch error by 6.4% to 32.3% and obtains the best map matching results in all the different combinations of sampling rates and challenging features."
    },
    {
        "Projects": [
            "BreakSense"
        ],
        "keywords": [],
        "AcceptDate": "12/14/2016",
        "palwebID": "PR-17-864",
        "Venue": "CHI 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-864/PR-17-864.pdf"
        ],
        "PublicationDate": "04/22/2017",
        "ID": "864",
        "Authors": [
            "Scott Cambo",
            "Daniel Avrahami",
            "Matthew Lee"
        ],
        "Title": "BreakSense: Combining Physiological and Location Sensing to Promote Mobility during Work-Breaks",
        "Abstract": "Work breaks can play an important role in the mental and physical well-being of workers and contribute positively to productivity. In this paper we explore the use of activity-, physiological-, and indoor-location sensing to promote mobility during work-breaks. While the popularity of devices and applications to promote physical activity is growing, prior research highlights important constraints when designing for the workplace. With these constraints in mind, we developed BreakSense, a mobile application that uses a Bluetooth beacon infrastructure, a smartphone and a smartwatch to encourage mobility during breaks with a game-like design. We discuss constraints imposed by design for work and the workplace, and highlight challenges associated with the use of noisy sensors and methods to overcome them. We then describe a short deployment of BreakSense within our lab that examined bound vs. unbound augmented breaks and how they affect users\u2019 sense of completion and readiness to work."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/12/2016",
        "palwebID": "PR-17-865",
        "Venue": "IEEE PerCom 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-865/PR-17-865.pdf"
        ],
        "PublicationDate": "03/13/2017",
        "ID": "865",
        "Authors": [
            "Shang Ma",
            "Qiong Liu",
            "Chelhwon Kim"
        ],
        "Title": "Lift: Using Projected Coded Light for Finger Tracking and Device Augmentation",
        "Abstract": "We present Lift, a visible light-enabled finger tracking and object localization technique that allows users to perform freestyle multi-touch gestures on any object\u2019s surface in an everyday environment. By projecting encoded visible patterns onto an object\u2019s surface (e.g. paper, display, or table), and localizing the user\u2019s fingers with light sensors, Lift offers users a richer interactive space than the device\u2019s existing interfaces. Additionally, everyday objects can be augmented by attaching sensor units onto their surface to accept multi-touch gesture input. We also present two applications as proof of concept. Finally, results from our experiments indicate that Lift can localize ten fingers simultaneously with an average accuracy of 1.7 millimeter and an average refresh rate of 84 Hz with 31 milliseconds delay on WiFi and 23 milliseconds delay on serial communication, making gesture recognition on non-instrumented objects possible."
    },
    {
        "Projects": [
            "CustomerBehaviorModeling"
        ],
        "keywords": [],
        "AcceptDate": "02/01/2017",
        "palwebID": "PR-17-866",
        "Venue": "EACL 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-866/PC-16-431.pdf"
        ],
        "PublicationDate": "04/03/2017",
        "ID": "866",
        "Authors": [
            "Heike Adel",
            "Francine Chen",
            "Yan-Ying Chen"
        ],
        "Title": "Ranking Convolutional Recurrent Neural Networks for\r\nPurchase Stage Identification on Imbalanced Twitter Data",
        "Abstract": "Users often use social media to share their interest in products. We propose to identify purchase stages from Twitter data following the AIDA model (Awareness, Interest, Desire, Action). In particular, we define a task of classifying the purchase stage of each tweet in a user's tweet sequence. We introduce RCRNN, a Ranking Convolutional Recurrent Neural Network which computes tweet representations using convolution over word embeddings and models a tweet sequence with gated recurrent units. Also, we consider various methods to cope with the imbalanced label distribution in our data and show that a ranking layer outperforms class weights."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-17-867",
        "Venue": "International Conference on Robotics and Automation",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-867/PC-17-437.pdf"
        ],
        "PublicationDate": "05/29/2017",
        "ID": "867",
        "Authors": [
            "Maani Ghaffari Jadidi",
            "Mitesh Patel",
            "Jaime  Valls Miro"
        ],
        "Title": "Gaussian Processes Online Observation Classification for RSSI-based Low-cost Indoor Positioning Systems",
        "Abstract": "In this paper, we propose a real-time classification scheme to cope with noisy Radio Signal Strength Indicator (RSSI) measurements utilized in indoor positioning systems. RSSI values are often converted to distances for position estimation. However due to multipathing and shadowing effects, finding a unique sensor model using both parametric and nonparametric methods is highly challenging. We learn decision regions using the Gaussian Processes classification to accept measurements that are consistent with the operating sensor model. The proposed approach can perform online, does not rely on a particular sensor model or parameters, and is robust to sensor failures. The experimental results achieved using hardware show that available positioning algorithms can benefit from incorporating the classifier into their measurement model as a meta-sensor modeling technique."
    },
    {
        "Projects": [
            "CustomerBehaviorModeling"
        ],
        "keywords": [],
        "AcceptDate": "02/24/2017",
        "palwebID": "PR-17-868",
        "Venue": "IEEE ICME 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-868/PR-17-868.pdf"
        ],
        "PublicationDate": "07/10/2017",
        "ID": "868",
        "Authors": [
            "Ryosuke Shigenaka",
            "Yan-Ying Chen",
            "Francine Chen",
            "Dhiraj Joshi",
            "Yukihiro Tsuboshita"
        ],
        "Title": "<img src=\"/images/honorable.png\" title=\"Honorable Mention Award\" border=\"0\"/>Image-Based User Profiling of Frequent and Regular Venue Categories",
        "Abstract": "The availability of mobile access has shifted social media use. With that phenomenon, what users shared on social media and where they visited is naturally an excellent resource to learn their visiting behavior. Knowing visit behaviors would help market survey and customer relationship management, e.g., sending customers coupons of the businesses that they visit frequently. Most prior studies leverage meta-data e.g., check- in locations to profile visiting behavior but neglect important information from user-contributed content, e.g., images. This work addresses a novel use of image content for predicting the user visit behavior, i.e., the frequent and regular business venue categories that the content owner would visit. To collect training data, we propose a strategy to use geo-metadata associated with images for deriving the labels of an image owner\u2019s visit behavior. Moreover, we model a user\u2019s sequential images by using an end-to-end learning framework to reduce the optimization loss. That helps improve the prediction accuracy against the baseline as demonstrated in our experiments. The prediction is completely based on image content that is more available in social media than geo-metadata, and thus allows coverage in profiling a wider set of users."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/01/2017",
        "palwebID": "PR-17-869",
        "Venue": "Communities & Technologies 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-869/PR-17-869.pdf"
        ],
        "PublicationDate": "06/26/2017",
        "ID": "869",
        "Authors": [
            "Jennifer Marlow",
            "Jason  Wiese",
            "Daniel Avrahami"
        ],
        "Title": "Exploring the Effects of Audience Visibility on Presenters\r\nand Attendees in Online Educational Presentations",
        "Abstract": "Video conferencing is widely used to help deliver\r\neducational presentations, such as lectures or informational\r\nwebinars, to a distributed audience. While individuals in a\r\ndyadic conversation may be able to use webcam streams to assess the engagement level of their interlocutor with some ease, as the size of the audience in a video conference setting increases, it becomes increasingly difficult to interpret how engaged the overall group may be. In this work, we use a mixed-methods approach to understand how presenters and attendees of online presentations use available cues to perceive and interpret audience behavior (such as how engaged the group is). Our results suggest that while webcams are seen as useful by presenters to increase audience visibility and encourage attention, audience members do not uniformly benefit from seeing others\u2019 webcams; other interface cues such as chat may be more useful and informative engagement indicators for both parties. We conclude with design recommendations for future systems to improve what is sensed and presented."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-17-870",
        "Venue": "The Handbook of Multimodal-Multisensor Interfaces",
        "palwebURL": [],
        "PublicationDate": "05/10/2017",
        "ID": "870",
        "Authors": [
            "Pernilla Qvarfordt"
        ],
        "Title": "Gaze-informed multimodal interaction",
        "Abstract": "Observe at a person pointing out and describing something. Where is that person looking? Chances are good that this person also looks at what she is talking about and pointing at. Gaze is naturally coordinated with our speech and hand movements. By utilizing this tendency, we can create a natural interaction with computing devices and environments. In this chapter, we will first briefly discuss some basic properties of the gaze signal we can get from eye trackers, followed by a review of a multimodal system utilizing the gaze signal as one input modality. In Multimodal Gaze Interaction, data from eye trackers is used as an active input mode where for instance gaze is used as an alternative, or complimentary, pointing modality along with other input modalities. Using gaze as an active or explicit input method is challenging for several reasons. One of them being that eyes are primarily used for perceiving our environment, so knowing when a person selects an item with gaze versus just looking around is an issue. Researchers have tried to solve this by combining gaze with various input methods, such as manual pointing, speech, touch, etc. However, gaze information can also be used in interactive systems, for other purposes than explicit pointing since a user's gaze is a good indication of the user's attention. In passive gaze interaction, the gaze is not used as the primary input method, but as a supporting input method. In these kinds of systems, gaze is mainly used for inferring and reasoning about the user's cognitive state or activities in a way that can support the interaction.  These kinds of multimodal systems often combine gaze with a multitude of input modalities.\r\n\r\nIn this chapter we focus on interactive systems, exploring the design space for gaze-informed multimodal interaction spanning from gaze as active input mode to passive and if the usage scenario is stationary (at e.g. a desk) or mobile. There are a number of studies aimed at describing, detecting or modeling specific behaviors or cognitive states. We will touch on some of these works since they can guide us in how to build gaze-informed multimodal interaction."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "06/12/2017",
        "palwebID": "PR-17-871",
        "Venue": "Recsys 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-871/PR-17-871.pdf"
        ],
        "PublicationDate": "08/26/2017",
        "ID": "871",
        "Authors": [
            "Jennifer Marlow",
            "Jason Wiese"
        ],
        "Title": "Surveying User Reactions to Recommendations Based on Inferences Made by Face Detection Technology\r\n",
        "Abstract": "It is increasingly possible to use cameras and sensors to detect and analyze human appearance for the purposes of personalizing user experiences. Such systems are already deployed in some public places to personalize advertisements and recommend items. However, since these technologies are not yet widespread, we do not have a good sense of the perceived benefits and drawbacks of public display systems that use face detection as an input for personalized recommendations. We conducted a user study with a system that inferred a user\u2019s gender and age from a facial detection and analysis algorithm and used this to present recommendations in two scenarios (finding stores to visit in a mall and finding a pair of sunglasses to buy).\u00a0 This work provides an initial step towards understanding user reactions to a new and emerging form of implicit recommendation based on physical appearance.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/01/2017",
        "palwebID": "PR-17-872",
        "Venue": "ICDAR 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-872/PR-17-872.pdf"
        ],
        "PublicationDate": "11/10/2017",
        "ID": "872",
        "Authors": [
            "Chelhwon Kim",
            "Patrick Chiu",
            "Hideto Oda"
        ],
        "Title": "Capturing Handwritten Ink Strokes with a Fast Video Camera",
        "Abstract": "We present a system for capturing ink strokes written with ordinary pen and paper using a fast camera with a frame rate comparable to a stylus digitizer. From the video frames, ink strokes are extracted and used as input to an online handwriting recognition engine. A key component in our system is a pen up/down detection model for detecting the contact of the pen-tip with the paper in the video frames. The proposed model consists of feature representation with convolutional neural networks and classification with a recurrent neural network. We also use a high speed tracker with kernelized correlation filters to track the pen-tip. For training and evaluation, we collected labeled video data of users writing English and Japanese phrases from public datasets, and we report on character accuracy scores for different frame rates in the two languages."
    },
    {
        "Projects": [
            "TourismKiosk"
        ],
        "keywords": [],
        "AcceptDate": "06/30/2017",
        "palwebID": "PR-17-873",
        "Venue": "Ubicomp",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-873/PC-17-455.pdf"
        ],
        "PublicationDate": "09/11/2017",
        "ID": "873",
        "Authors": [
            "Scott Carter",
            "Jennifer Marlow",
            "Matthew Cooper"
        ],
        "Title": "No app needed: Enabling mobile phone communication\r\nwith a tourist kiosk using cameras and screens",
        "Abstract": "For tourists, interactions with digital public displays often depend on specific technologies that users may not be familiar with (QR codes, NFC, Bluetooth); may not have access to because of networking issues (SMS), may lack a required app (QR codes), or device technology (NFC); may not want to use because of time constraints (WiFi, Bluetooth); or may not want to use because they are worried about sharing their data with a third-party service (text, WiFi). In this demonstration, we introduce ItineraryScanner, a system that allows users to\r\nseamlessly share content with a public travel kiosk system."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/13/2017",
        "palwebID": "PR-17-874",
        "Venue": "IEEE Transactions on Visualization and Computer Graphics (Proceedings of VAST 2017)",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-874/PC-17-449.pdf"
        ],
        "PublicationDate": "10/01/2017",
        "ID": "874",
        "Authors": [
            "Siwei Fu",
            "Hao Dong",
            "Weiwei Cui",
            "Jian Zhao",
            "Huamin Qu"
        ],
        "Title": "How Do Ancestral Traits Shape Family Trees over Generations?",
        "Abstract": "Whether and how does the structure of family trees differ by ancestral traits over generations? This is a fundamental question regarding the structural heterogeneity of family trees for the multi-generational transmission research. However, previous work mostly focuses on parent-child scenarios due to the lack of proper tools to handle the complexity of extending the research to multi-generational processes. Through an iterative design study with social scientists and historians, we develop TreeEvo that assists users to generate and test empirical hypotheses for multi-generational research. TreeEvo summarizes and organizes family trees by structural features in a dynamic manner based on a traditional Sankey diagram. A pixel-based technique is further proposed to compactly encode trees with complex structures in each Sankey Node. Detailed information of trees is accessible through a space-efficient visualization with semantic zooming. Moreover, TreeEvo embeds Multinomial Logit Model (MLM) to examine statistical associations between tree structure and ancestral traits. We demonstrate the effectiveness and usefulness of TreeEvo through an in-depth case-study with domain experts using a real-world dataset (containing 54,128 family trees of 126,196 individuals)."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/13/2017",
        "palwebID": "PR-17-875",
        "Venue": "IEEE Transactions on Visualization and Computer Graphics (Proceedings of VAST 2017)",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-875/PC-17-447.pdf"
        ],
        "PublicationDate": "10/01/2017",
        "ID": "875",
        "Authors": [
            "Jian Zhao",
            "Michael Glueck",
            "Petra Isenberg",
            "Fanny Chevalier",
            "Azam Khan"
        ],
        "Title": "<img src=\"/images/honorable.png\" title=\"Honorable Mention Award\" border=\"0\"/>Supporting Handoff in Asynchronous Collaborative Sensemaking Using Knowledge-Transfer Graphs",
        "Abstract": "During asynchronous collaborative analysis, handoff of partial findings is challenging because externalizations produced by analysts may not adequately communicate their investigative process. To address this challenge, we developed techniques to automatically capture and help encode tacit aspects of the investigative process based on an analyst\u2019s interactions, and streamline explicit authoring of handoff annotations. We designed our techniques to mediate awareness of analysis coverage, support explicit communication of progress and uncertainty with annotation, and implicit communication through playback of investigation histories. To evaluate our techniques, we developed an interactive visual analysis system, KTGraph, that supports an asynchronous investigative document analysis task. We conducted a two-phase user study to characterize a set of handoff strategies and to compare investigative performance with and without our techniques. The results suggest that our techniques promote the use of more effective handoff strategies, help increase an awareness of prior investigative process and insights, as well as improve final investigative outcomes."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/13/2017",
        "palwebID": "PR-17-876",
        "Venue": "IEEE Transactions on Visualization and Computer Graphics (Proceedings of VAST 2017)",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-876/PC-17-446.pdf"
        ],
        "PublicationDate": "10/01/2017",
        "ID": "876",
        "Authors": [
            "Jian Zhao",
            "Maoyuan Sun",
            "Francine Chen",
            "Patrick Chiu"
        ],
        "Title": "BiDots: Visual Exploration of Weighted Biclusters",
        "Abstract": "Discovering and analyzing biclusters, i.e., two sets of related entities with close relationships, is a critical task in many real-world applications, such as exploring entity co-occurrences in intelligence analysis, and studying gene expression in bio-informatics. While the output of biclustering techniques can offer some initial low-level insights, visual approaches are required on top of that due to the algorithmic output complexity.This paper proposes a visualization technique, called BiDots, that allows analysts to interactively explore biclusters over multiple domains. BiDots overcomes several limitations of existing bicluster visualizations by encoding biclusters in a more compact and cluster-driven manner. A set of handy interactions is incorporated to support flexible analysis of biclustering results. More importantly, BiDots addresses the cases of weighted biclusters, which has been underexploited in the literature. The design of BiDots is grounded by a set of analytical tasks derived from previous work. We demonstrate its usefulness and effectiveness for exploring computed biclusters with an investigative document analysis task, in which suspicious people and activities are identified from a text corpus."
    },
    {
        "Projects": [
            "VisionAndLanguageAnalysis"
        ],
        "keywords": [],
        "AcceptDate": "07/03/2017",
        "palwebID": "PR-17-877",
        "Venue": "British Machine Vision Conference (BMVC) 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-877/PR-17-877.pdf"
        ],
        "PublicationDate": "09/04/2017",
        "ID": "877",
        "Authors": [
            "Sirius Chen",
            "Yan-Ying Chen",
            "Francine Chen"
        ],
        "Title": "Video to Text Summary: Joint Video Summarization and Captioning with Recurrent Neural Networks",
        "Abstract": "Video summarization and video captioning are considered two separate tasks in existing studies. For longer videos, automatically identifying the important parts of video content and annotating them with captions will enable a richer and more concise condensation of the video. We propose a general neural network architecture that jointly considers two supervisory signals (i.e., an image-based video summary and text-based video captions) in the training phase and generates both a video summary and corresponding captions for a given video in the test phase. Our main idea is that the summary signals can help a video captioning model learn to focus on important frames. On the other hand, caption signals can help a video summarization model to learn better semantic representations. Jointly modeling both the video summarization and the video captioning tasks offers a novel end-to-end solution that generates a captioned video summary enabling users to index and navigate through the highlights in a video. Moreover, our experiments show the joint model can achieve better performance than state-of- the-art approaches in both individual tasks."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/01/2017",
        "palwebID": "PR-17-878",
        "Venue": "ACM Document Engineering 2017",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-878/PC-17-454.pdf"
        ],
        "PublicationDate": "09/04/2017",
        "ID": "878",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Jennifer Marlow",
            "Matthew Cooper"
        ],
        "Title": "DocHandles: linking document fragments in messaging apps",
        "Abstract": "In this paper, we describe DocHandles, a novel system that allows users to link to specific document parts in their chat applications. As users type a message, they can invoke the tool by referring to a specific part of a document, e.g., \u201c@fig1 needs revision\u201d. By combining text parsing and document layout analysis, DocHandles can find and present all the figures \u201c1\u201d inside previously shared documents, allowing users to explicitly link to the relevant \u201cdocument handle\u201d. Documents become first-class citizens inside the conversation stream where users can seamlessly integrate documents in their text-centric messaging application."
    },
    {
        "Projects": [
            "ReflectLive"
        ],
        "keywords": [],
        "AcceptDate": "08/08/2017",
        "palwebID": "PR-17-879",
        "Venue": "Computer-Supported Cooperative Work and Social Computing",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-879/PR-17-879.pdf"
        ],
        "PublicationDate": "11/01/2017",
        "ID": "879",
        "Authors": [
            "Matthew Lee",
            "Scott Carter",
            "Heather Faucett"
        ],
        "Title": "I Should Listen More: Real-time Sensing and Feedback of Non-Verbal Communication in Video Telehealth",
        "Abstract": "Video telehealth is growing to allow more clinicians to see patients from afar. As a result, clinicians, typically trained for in-person visits, must learn to communicate both health information and non-verbal affective signals to patients through a digital medium. We introduce a system called ReflectLive that senses and provides real-time feedback about non-verbal communication behaviors to clinicians so they can improve their communication behaviors. A user evaluation with 10 clinicians showed that the real-time feedback helped clinicians maintain better eye contact with patients and was not overly distracting. Clinicians reported being more aware of their non-verbal communication behaviors and reacted positively to summaries of their conversational metrics, motivating them to want to improve. Using ReflectLive as a probe, we also discuss the benefits and concerns around automatically quantifying the \u201csoft skills\u201d and complexities of clinician-patient communication, the controllability of behaviors, and the design considerations for how to present real-time and summative feedback to clinicians."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/01/2017",
        "palwebID": "PR-17-880",
        "Venue": "ACM MM Workshop",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-880/PC-17-466.pdf"
        ],
        "PublicationDate": "10/23/2017",
        "ID": "880",
        "Authors": [
            "Saeideh Bakhshi",
            "David Shamma"
        ],
        "Title": "Mixed Methods and the Future of Multi-modal Media",
        "Abstract": "Humans are complex and their behaviors follow complex multimodal patterns, however to solve many social computing problems one often looks at complexity in large-scale yet single point data sources or methodologies. While single data/single method techniques, fueled by large scale data, enjoyed some success, it is not without fault. Often with one type of data and method, all the other aspects of human behavior are overlooked, discarded, or, worse, misrepresented. We identify this as two succinct problems. First, social computing problems that cannot be solved using a single data source and need intelligence from multiple modals and, second, social behavior that cannot be fully understood using only one form of methodology. Throughout this talk, we discuss these problems and their implications, illustrate examples, and propose new directives to properly approach in the social computing research in today\u2019s age."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/01/2017",
        "palwebID": "PR-17-881",
        "Venue": "Fuji Xerox Technical Report",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-881/PR-17-881.pdf"
        ],
        "PublicationDate": "09/01/2017",
        "ID": "881",
        "Authors": [
            "Daniel Avrahami",
            "Jennifer Marlow",
            "Jacob Biehl"
        ],
        "Title": "Opportunities for Productivity and Wellbeing: Human Sensing in the Workplace",
        "Abstract": "\u30e2\u30d0\u30a4\u30eb\u6280\u8853\u306e\u767a\u5c55\u3068\u65e5\u5e38\u751f\u6d3b\u306b\u304a\u3051\u308b\u7d99\u7d9a\u7684\u306a\u3064\u306a\u304c\u308a\u306f\u3001\u4ed5\u4e8b\u306e\u9032\u3081\u65b9\u306b\u5927\u304d\u304f\u5f71\u97ff\u3092\u4e0e\u3048\u3066\u3044\u308b\u3002\u30bb\u30f3\u30b7\u30f3\u30b0\u6280\u8853\u306e\u6d3b\u7528\u306f\u500b\u4eba\u306b\u3088\u308b\u4f7f\u7528\u4e8b\u4f8b\u304c\u591a\u304f\u3092\u5360\u3081\u3066\u3044\u308b\u304c\u3001\u30ef\u30fc\u30af\u30d7\u30ec\u30a4\u30b9\u306f\u30bb\u30f3\u30b7\u30f3\u30b0\u6280\u8853\u3092\u6d3b\u7528\u3059\u308b\u306e\u306b\u91cd\u8981\u304b\u3064\u9069\u5207\u306a\u74b0\u5883\u3067\u3042\u308b\u3002\u3064\u307e\u308a\u3001\u5f93\u696d\u54e1\u304c\u81ea\u5206\u306e\u8ffd\u8de1\u53ef\u80fd\u306a\u7aef\u672b\u3092\u4f7f\u3063\u3066\u30bb\u30f3\u30b7\u30f3\u30b0\u6280\u8853\u3092\u9023\u643a\u3055\u305b\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b\u3002\u672c\u7a3f\u3067\u306f\u3001\u30ef\u30fc\u30af\u30d7\u30ec\u30a4\u30b9\u306b\u304a\u3051\u308b\u8eab\u4f53\u7684\u3001\u7cbe\u795e\u7684\u3001\u304a\u3088\u3073\u793e\u4f1a\u7684\u306b\u826f\u597d\u306a\u72b6\u614b\u3068\u751f\u7523\u6027\u3092\u5411\u4e0a\u3055\u305b\u308b\u6280\u8853\u306b\u3064\u3044\u3066\u30012\u3064\u306e\u6700\u65b0\u306e\u8abf\u67fb\u7d50\u679c\u3068\u3001\u884c\u52d5\u3092\u5909\u3048\u308b\u59ff\u52e2\u3092\u7dad\u6301\r\n\u308b\u305f\u3081\u306e\u4ed5\u7d44\u307f\u3092\u5831\u544a\u3059\u308b\u3002\u6b21\u306b\u3001\u65b0\u3057\u3044\u4f5c\u696d\u306e\u9818\u57df\u306b\u3064\u3044\u3066\u7c21\u5358\u306b\u8b70\u8ad6\u3059\u308b\u3002"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/03/2017",
        "palwebID": "PR-18-882",
        "Venue": "Multimedia Modeling",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-882/PC-17-464.pdf"
        ],
        "PublicationDate": "02/05/2018",
        "ID": "882",
        "Authors": [
            "Stevan Rudinac",
            "Tat-Seng Chua",
            "Nicolas Diaz-Ferreyra",
            "Gerald Friedland",
            "Tatjana Gornostaja",
            "Benoit Huet",
            "Rainne Kaptein",
            "Krister Lind",
            "Marie-Francine Moens",
            "Jaakko Peltonen",
            "Miriam Redi",
            "Markus Schedl",
            "David Shamma",
            "Alan Smeaton",
            "Lexing Xie"
        ],
        "Title": "Rethinking Summarization and Storytelling for Modern Social Multimedia",
        "Abstract": "Traditional summarization initiatives have been focused on specific types of documents such as articles, reviews, videos, image feeds, or tweets, a practice which may result in pigeonholing the summarization task in the surrounding of modern, content-rich multimedia collections. Consequently, much of the research to date has revolved around mostly toy problems in narrow domains and working on single-source media types. We argue that summarization and story generation systems need to refocus the problem space in order to meet the information needs in the age of user-generated content in different formats and languages. Here we create a framework for flexible multimedia storytelling. Narratives, stories, and summaries carry a set of challenges in big data and dynamic multi-source media that give rise to new research in spatial-temporal representation, viewpoint generation, and explanation."
    },
    {
        "Projects": [
            "VideoRec"
        ],
        "keywords": [],
        "AcceptDate": "11/03/2017",
        "palwebID": "PR-18-883",
        "Venue": "Multimedia Modeling 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-883/PC-17-463.pdf"
        ],
        "PublicationDate": "02/05/2018",
        "ID": "883",
        "Authors": [
            "Chidansh Bhatt",
            "Matthew Cooper",
            "Jian Zhao"
        ],
        "Title": "SeqSense: video recommendation using topic sequence mining",
        "Abstract": "This paper examines content-based recommendation in domains exhibiting sequential topical structure. An example is educational video, including Massive Open Online Courses (MOOCs) in which knowledge builds within and across courses. Conventional content-based or collaborative filtering recommendation methods do not exploit courses' sequential nature. We describe a system for video recommendation that combines topic-based video representation with sequential pattern mining of inter-topic relationships. Unsupervised topic modeling provides a scalable and domain-independent representation. We mine inter-topic relationships from manually constructed syllabi that instructors provide to guide students through their courses.  This approach also allows the inclusion of multi-video sequences among the recommendation results.\r\nIntegrating the resulting sequential information with content-level similarity provides relevant as well as diversified recommendations. Quantitative evaluation indicates that the proposed system, \\textit{SeqSense}, recommends fewer redundant videos than baseline methods, and instead emphasizes results consistent with mined topic transitions."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/10/2017",
        "palwebID": "PR-18-885",
        "Venue": "CHI 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-885/PC-17-475.pdf"
        ],
        "PublicationDate": "04/21/2018",
        "ID": "885",
        "Authors": [
            "Sergio Cabrero",
            "Thomas R\u00f6ggla",
            "Jack Jansen",
            "David Shamma",
            "Pablo Cesar"
        ],
        "Title": "Designing the Club of the Future with Data: A Case Study on Collaboration of Creative Industries",
        "Abstract": " This paper describes the development of a multi-sensory clubbing experience which was deployed during two a two-day event within the context of the Amsterdam Dance Event in October 2016 in Amsterdam. We present how the entire experience was developed end-to-end and deployed at the event through the collaboration of several project partners from industries such as art and design, music, food, technology and research. Central to the system are smart textiles, namely wristbands equipped with Bluetooth LE sensors which were used to sense people attending the dance event.  We describe the components of the system, the development process,  collaboration between the involved entities and the event itself. To conclude  the paper, we highlight insights gained from conducting a real world research  deployment across many collaborators and stakeholders. "
    },
    {
        "Projects": [
            "Work Reflection"
        ],
        "keywords": [],
        "AcceptDate": "12/11/2017",
        "palwebID": "PR-18-886",
        "Venue": "CHI 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-886/PR-18-886.pdf"
        ],
        "PublicationDate": "04/21/2018",
        "ID": "886",
        "Authors": [
            "Di Lu",
            "Jennifer Marlow",
            "Rafal Kocielnik",
            "Daniel Avrahami"
        ],
        "Title": "Challenges and Opportunities for Technology-Supported Activity Reporting in the Workplace\r\n",
        "Abstract": "Effective communication of activities and progress in the workplace is crucial for the success of many modern organizations. In this paper, we extend current research on workplace communication and uncover opportunities for technology to support effective work activity reporting. We report on three studies: With a survey of 68 knowledge workers followed by 14 in-depth interviews, we investigated the perceived benefits of different types of progress reports and an array of challenges at three stages: Collection, Composition, and Delivery. We show an important interplay between written and face-to-face reporting, and highlight the importance of tailoring a report to its audience. We then present results from an analysis of 722 reports composed by 361 U.S.-based knowledge workers, looking at the influence of the audience on a report\u2019s language. We conclude by discussing opportunities for future technologies to assist both employees and managers in collecting, interpreting, and reporting progress in the workplace.\r\n\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/11/2017",
        "palwebID": "PR-18-887",
        "Venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-887/PR-18-887.pdf"
        ],
        "PublicationDate": "04/21/2018",
        "ID": "887",
        "Authors": [
            "Siwei Fu",
            "Jian Zhao",
            "Hao Fei Cheng",
            "Haiyi Zhu",
            "Jennifer Marlow"
        ],
        "Title": "T-Cal: Understanding Team Conversation Data with Calendar-based Visualization",
        "Abstract": "Understanding team communication and collaboration patterns is critical for improving work efficiency in organizations. This paper presents an interactive visualization system, T-Cal, that supports the analysis of conversation data from modern team messaging platforms (e.g., Slack). T-Cal employs a user-familiar visual interface, a calendar, to enable seamless multi-scale browsing of data from different perspectives. T-Cal also incorporates a number of analytical techniques for disentangling interleaving conversations, extracting keywords, and estimating sentiment. The design of T-Cal is based on an iterative user-centered design process including field studies, requirements gathering, initial prototypes demonstration, and evaluation with domain users. The resulting two case studies indicate the effectiveness and usefulness of T-Cal in real-world applications, including student group chats during a MOOC and daily conversations within an industry research lab."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/11/2017",
        "palwebID": "PR-18-888",
        "Venue": "Proceedings of the SIGCHI Conference on Human Factors in Computing Systems",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-888/PR-18-888.pdf"
        ],
        "PublicationDate": "04/21/2018",
        "ID": "888",
        "Authors": [
            "Jian Zhao",
            "Chidansh Bhatt",
            "Matthew Cooper",
            "David Shamma"
        ],
        "Title": "Flexible Learning with Semantic Visual Exploration and Sequence-Based Recommendation of MOOC Videos",
        "Abstract": "Massive Open Online Course (MOOC) platforms have scaled online education to unprecedented enrollments, but remain limited by their rigid, predetermined curricula. This paper presents MOOCex, a technique that can offer a more flexible learning experience for MOOCs. MOOCex can recommend lecture videos across different courses with multiple perspectives, and considers both the video content and also sequential inter-topic relationships mined from course syllabi. MOOCex is also equipped with interactive visualization allowing learners to explore the semantic space of recommendations within their current learning context. The results of comparisons to traditional methods, including content-based recommendation and ranked list representation, indicate the effectiveness of MOOCex. Further, feedback from MOOC learners and instructors suggests that MOOCex enhances both MOOC-based learning and teaching."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/17/2017",
        "palwebID": "PR-17-889",
        "Venue": "IEEE Internet of Things Journal",
        "palwebURL": [
            "http://palweb/files/PR/2017/PR-17-889/PC-16-430.pdf"
        ],
        "PublicationDate": "11/23/2017",
        "ID": "889",
        "Authors": [
            "Shang Ma",
            "Qiong Liu",
            "Phillip Sheu"
        ],
        "Title": "Foglight: Visible Light-enabled Indoor Localization System for Low-power IoT Devices",
        "Abstract": "Advances in small and low power electronics have created new opportunities for the Internet of Things (IoT), leading to an explosion of physical objects being connected to the Internet. However, there still lacks an indoor localization solution that can answer the needs of various location-based IoT applications with desired simplicity, robustness, accuracy, and responsiveness. We introduce Foglight, a visible light enabled indoor localization system for IoT devices that relies on unique spatial encoding produced when mechanical mirrors inside a projector are flipped based on gray-coded binary images. Foglight employs simple off-the-shelf light sensors that can be easily coupled with existing IoT devices - such as thermometers, gas meters, or light switches - making their location discoverable. Our sensor unit is computation efficient; it can perform high-accuracy localization with minimum signal processing overhead, allowing any low-power IoT device on which it rests to be able to locate itself. Additionally, results from our evaluation reveal that Foglight can locate a target device with an average accuracy of 1.7 millimeters and average refresh rate of 84 Hz with minimal latency, 31.46 milliseconds on WiFi and 23.2 milliseconds on serial communication. Two example applications are developed to demonstrate possible scenarios as proof of concept. We also discuss limitations, how they could be overcome, and propose next steps."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/07/2017",
        "palwebID": "PR-18-890",
        "Venue": "IUI 2018",
        "palwebURL": [],
        "PublicationDate": "03/01/2018",
        "ID": "890",
        "Authors": [
            "Daniel Avrahami",
            "Mitesh Patel",
            "Yusuke Yamaura",
            "Sven Kratz"
        ],
        "Title": "Below the Surface: Unobtrusive Activity Recognition for Work Surfaces using RF-radar sensing",
        "Abstract": "Activity recognition is a core component of many intelligent and context-aware systems. In this paper, we present a solution for discreetly and unobtrusively recognizing common work activities above a work surface without using cameras. We demonstrate our approach, which utilizes an RF-radar sensor mounted under the work surface, in two work domains; recognizing work activities at a convenience-store counter (useful for post-hoc analytics) and recognizing common office deskwork activities (useful for real-time applications). We classify seven clerk activities with 94.9% accuracy using data collected in a lab environment, and recognize six common deskwork activities collected in real offices with 95.3% accuracy. We show that using multiple projections of RF signal leads to improved recognition accuracy. Finally, we show how smartwatches worn by users can be used to attribute an activity, recognized with the RF sensor, to a particular user in multi-user scenarios. We believe our solution can mitigate some of users\u2019 privacy concerns associated with cameras and is useful for a wide range of intelligent systems."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "01/25/2018",
        "palwebID": "PR-18-891",
        "Venue": " arXiv",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-891/PC-18-480.pdf"
        ],
        "PublicationDate": "01/25/2018",
        "ID": "891",
        "Authors": [
            "Scott Carter",
            "Pernilla Qvarfordt",
            "Matthew Cooper",
            "Aki Komori"
        ],
        "Title": "Tools for online tutorials: comparing capture devices, tutorial representations, and access devices",
        "Abstract": "Tutorials are one of the most fundamental means of conveying knowledge. Ideally when the task involves physical or digital objects, tutorials not only describe each step with text or via audio narration but show it as well using photos or animation. In most cases, online tutorial authors capture media from handheld mobile devices to compose these documents, but increasingly they use wearable devices as well. In this work, we explore the full life-cycle of online tutorial creation and viewing using head-mounted capture and displays. We developed a media-capture tool for Google Glass that requires minimal attention to the capture device and instead allows the author to focus on creating the tutorial's content rather than its capture. The capture tool is coupled with web-based authoring tools for creating annotatable videos and multimedia documents. In a study comparing standalone (camera on tripod) versus wearable capture (Google Glass) as well as two types of multimedia representation for authoring tutorials (video-based or document-based), we show that tutorial authors have a preference for wearable capture devices, especially when recording activities involving larger objects in non-desktop environments. Authors preferred document-based multimedia tutorials because they are more straightforward to compose and the step-based structure translates more directly to explaining a procedure. In addition, we explored using head-mounted displays (Google Glass) for accessing tutorials in comparison to lightweight computing devices such as tablets. Our study included tutorials recorded with the same capture methods as in our access study. We found that although authors preferred head-mounted capture, tutorial consumers preferred video recorded by a camera on tripod that provides a more stable image of the workspace. Head-mounted displays are good for glanceable information, however video demands more attention and our participants made more errors using Glass than when using a tablet, which was easier to ignore. Our findings point out several design implications for online tutorial authoring and access methods."
    },
    {
        "Projects": [
            "Enterprise Messaging Summarization and Visualization"
        ],
        "keywords": [],
        "AcceptDate": "02/14/2018",
        "palwebID": "PR-18-892",
        "Venue": "NAACL 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-892/PR-18-892.pdf"
        ],
        "PublicationDate": "06/01/2018",
        "ID": "892",
        "Authors": [
            "Jyun-Yu Jiang",
            "Francine Chen",
            "Yan-Ying Chen",
            "Wei Wang"
        ],
        "Title": "Learning to Disentangle Interleaved Conversational Threads with a Siamese Hierarchical Network and Similarity Ranking",
        "Abstract": "An enormous amount of conversation occurs online every day, including on chat platforms where multiple conversations may take place concurrently.\r\nInterleaved conversations lead to difficulties in not only following discussions but also retrieving relevant information from simultaneous messages.\r\nConversation disentanglement aims to separate overlapping messages into detached conversations.\r\n\r\nIn this paper, we propose to leverage representation learning for conversation disentanglement. A Siamese Hierarchical Convolutional Neural Network (SHCNN), which integrates local and more global representations of a message, is first presented to estimate the conversation-level similarity between closely posted messages. With the estimated similarity scores, our algorithm for Conversation Identification by SImilarity Ranking (CISIR) then derives conversations based on high-confidence message pairs and pairwise redundancy.\r\nExperiments were conducted with four publicly available datasets of conversations from Reddit and IRC channels. The experimental results show that our approach significantly outperforms comparative baselines in both pairwise similarity estimation and conversation disentanglement."
    },
    {
        "Projects": [
            "Robotic Platform"
        ],
        "keywords": [],
        "AcceptDate": "01/08/2018",
        "palwebID": "PR-18-893",
        "Venue": "International Conference on Robotics and Automation",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-893/PR-18-893.pdf"
        ],
        "PublicationDate": "05/21/2018",
        "ID": "893",
        "Authors": [
            "Mitesh Patel",
            "Brendan Emery",
            "Yan-Ying Chen"
        ],
        "Title": "ContextualNet: Exploiting Contextual Information using LSTMs to Improve Image-based Localization",
        "Abstract": "Convolutional Neural Networks (CNN) have successfully been utilized for localization using a single monocular image [1]. Most of the work to date has either focused on reducing the dimensionality of data for better learning of parameters during training or on developing different variations of CNN models to improve pose estimation. Many of the best performing works solely consider the content in a single image, while the context from historical images is ignored. In this paper, we propose a combined CNN-LSTM which is capable of incorporating contextual information from historical images to better estimate the current pose. Experimental results achieved using a dataset collected in an indoor office space improved the overall system results to 0.8 m & 2.5\u00b0 at the third quartile of the cumulative distribution as compared with 1.5 m & 3.0\u00b0 achieved by PoseNet [1]. Furthermore, we demonstrate how the temporal information exploited by the CNN-LSTM model assists in localizing the robot in situations where image content does not have sufficient features."
    },
    {
        "Projects": [
            "Work Reflection"
        ],
        "keywords": [],
        "AcceptDate": "12/07/2017",
        "palwebID": "PR-18-894",
        "Venue": "DIS 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-894/PC-17-474.pdf"
        ],
        "PublicationDate": "06/01/2018",
        "ID": "894",
        "Authors": [
            "Rafal Kocielnik",
            "Daniel Avrahami",
            "Jennifer Marlow",
            "Di Lu",
            "Gary Hsieh"
        ],
        "Title": "Designing for Workplace Reflection: A Chat and Voice-Based Conversational Agent",
        "Abstract": "Conversational agents stand to play an important role in supporting behavior change and well-being in many domains. With users able to interact with conversational agents through both text and voice, understanding how designing for these channels supports behavior change is important. To begin answering this question, we designed a conversational agent for the workplace that supports workers\u2019 activity-journaling and self-learning through reflection. Our agent, named Robota, combines chat-based communication as a Slack Bot and voice interaction through a personal device using a custom Amazon Alexa Skill. Through a 3-week controlled deployment, we examine how voice-based and chat-based interaction affect workers\u2019 reflection and support self-learning. We demonstrate that, while many current technical limitations exist, adding dedicated mobile voice interaction separate from the already busy chat modality may further enable users to step back and reflect on their work. We conclude with discussion of the implications of our findings to design of workplace self-tracking systems specifically and to behavior-change systems in general."
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [],
        "AcceptDate": "12/01/2017",
        "palwebID": "PR-18-895",
        "Venue": "International Conference on Robotics and Automation",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-895/PC-17-462.pdf"
        ],
        "PublicationDate": "05/21/2018",
        "ID": "895",
        "Authors": [
            "Raphael Falque",
            "Mitesh Patel",
            "Jacob Biehl"
        ],
        "Title": "CovBSM: An Optimization Approach to RF Beacon Deployment for Indoor Localization",
        "Abstract": "In this paper, we propose a novel solution to optimize the deployment of (RF) beacons for the purpose of indoor localization. We propose a system that optimizes both the number of beacons and their placement in a given environment. We propose a novel cost-function, called CovBSM, that allows to simultaneously optimize the 3-coverage while maximizing the beacon spreading. Using this cost function, we propose a framework that maximize both the number of beacons and their placement in a given environment. The proposed solution accounts for the indoor infrastructure and its influence on the (RF) signal propagation by embedding a realistic simulator into the optimization process."
    },
    {
        "Projects": [
            "CopyrightDetection"
        ],
        "keywords": [],
        "AcceptDate": "03/20/2018",
        "palwebID": "PR-18-896",
        "Venue": "Document Engineering",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-896/PR-18-896.pdf"
        ],
        "PublicationDate": "08/28/2018",
        "ID": "896",
        "Authors": [
            "Andreas Girgensohn",
            "Lynn Wilcox",
            "Qiong Liu"
        ],
        "Title": "Automatic Rights Management for Photocopiers",
        "Abstract": "We introduce a system to automatically manage photocopies made from copyrighted printed materials. The system monitors photocopiers to detect the copying of pages from copyrighted publications. Such activity is tallied for billing purposes. Access rights to the materials can be checked to prevent printing. Digital images of the copied pages are checked against a database of copyrighted pages. To preserve the privacy of the copying of non-copyright materials, only digital fingerprints are submitted to the image matching service. A problem with such systems is creation of the database of copyright pages. To facilitate this, our system maintains statistics of clusters of similar unknown page images along with copy sequence. Once such a cluster has grown to a sufficient size, a human inspector can determine whether those page sequences are copyrighted. The system has been tested with 100,000s of pages from conference proceedings and with millions of randomly generated pages. Retrieval accuracy has been around 99% even with copies of copies or double-page copies."
    },
    {
        "Projects": [
            "Educational Video",
            "EnterpriseCommunication"
        ],
        "keywords": [],
        "AcceptDate": "03/30/2018",
        "palwebID": "PR-18-898",
        "Venue": "ACM Intl. Conf. on Multimedia Retrieval (ICMR)",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-898/PC-18-484.pdf"
        ],
        "PublicationDate": "06/11/2018",
        "ID": "898",
        "Authors": [
            "Matthew Cooper",
            "Jian Zhao",
            "Chidansh Bhatt",
            "David Shamma"
        ],
        "Title": "Using Recommendation to Explore Educational Video",
        "Abstract": "Massive Open Online Course (MOOC) platforms have scaled online education to unprecedented enrollments, but remain limited by their rigid, predetermined curricula.  Increasingly, professionals consume this content to augment or update specific skills rather than complete degree or certification programs.  To better address the needs of this emergent user population, we describe a visual recommender system called MOOCex.  The system recommends lecture videos {\\em across} multiple courses and content platforms to provide a choice of perspectives on topics. The recommendation engine considers both video content and sequential inter-topic relationships mined from course syllabi. Furthermore, it allows for interactive visual exploration of the semantic space of recommendations within a learner's current context. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/08/2018",
        "palwebID": "PR-18-899",
        "Venue": "UbiComp 2018 (IMWUT)",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-899/PC-17-472.pdf"
        ],
        "PublicationDate": "10/01/2018",
        "ID": "899",
        "Authors": [
            "Rafal Kocielnik",
            "Lily Xiao",
            "Daniel Avrahami",
            "Gary Hsieh"
        ],
        "Title": "Reflection Companion: A Conversational System for Engaging Users in Reflection on Physical Activity",
        "Abstract": "Despite reflection being identified as a key component of behavior change, most existing tools do not explicitly design for it, carrying an implicit assumption that providing access to self-tracking data is enough to trigger reflection. In this work we design a system for reflection around physical activity. Through a set of workshops, we generated a corpus of 275 reflective questions. We then combine these questions into a set of 25 reflective mini-dialogues. We deliver our mini-dialogues through MMS. 33 active users of fitness trackers used our system in a 2-week field deployment. Results suggest that the mini-dialogues were successful in triggering reflection and that this reflection led to increases in motivation, empowerment, and adoption of new behaviors. Encouragingly, 16 participants elected to use the system for two additional weeks without compensation. We present implications for the design of technology-supported dialog system for reflection."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/17/2018",
        "palwebID": "PR-18-900",
        "Venue": "The 23rd ACM Symposium on Access Control Models & Technologies (SACMAT)",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-900/PC-18-495.pdf"
        ],
        "PublicationDate": "06/13/2018",
        "ID": "900",
        "Authors": [
            "Jacob Biehl",
            "Adam J. Lee"
        ],
        "Title": "Sensing or Watching? Balancing Utility and Privacy in Sensing Systems via Collection and Enforcement Mechanisms",
        "Abstract": "Devices with embedded sensors are permeating the computing landscape, allowing the collection and analysis of rich data about individuals, smart spaces, and their interactions. This class of de- vices enables a useful array of home automation and connected workplace functionality to individuals within instrumented spaces. Unfortunately, the increasing pervasiveness of sensors can lead to perceptions of privacy loss by their occupants. Given that many instrumented spaces exist as platforms outside of a user\u2019s control\u2014e.g., IoT sensors in the home that rely on cloud infrastructure or connected workplaces managed by one\u2019s employer\u2014enforcing access controls via a trusted reference monitor may do little to assuage individuals\u2019 privacy concerns. This calls for novel enforcement mechanisms for controlling access to sensed data.\r\nIn this paper, we investigate the interplay between sensor fidelity and individual comfort, with the goal of understanding the design space for effective, yet palatable, sensors for the workplace. In the context of a common space contextualization task, we survey and interview individuals about their comfort with three common sensing modalities: video, audio, and passive infrared. This allows us to explore the extent to which discomfort with sensor platforms is a function of detected states or sensed data. Our findings uncover interesting interplays between content, context, fidelity, history, and privacy. This, in turn, leads to design recommendations regarding how to increase comfort with sensing technologies by revisiting the mechanisms by which user preferences and policies are enforced in situations where the infrastructure itself is not trusted."
    },
    {
        "Projects": [
            "Conversational Documents"
        ],
        "keywords": [],
        "AcceptDate": "05/08/2018",
        "palwebID": "PR-18-901",
        "Venue": "DocEng 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-901/PC-18-488.pdf"
        ],
        "PublicationDate": "08/28/2018",
        "ID": "901",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue",
            "Matthew Cooper",
            "Jennifer Marlow"
        ],
        "Title": "FormYak: Converting forms to conversations",
        "Abstract": "Historically, people have interacted with companies and institutions through telephone-based dialogue systems and paper-based forms. Now, these interactions are rapidly moving to web- and phone-based chat systems. While converting traditional telephone dialogues to chat is relatively straightforward, converting forms to conversational interfaces can be challenging. In this work, we introduce methods and interfaces to enable the conversion of PDF and web-based documents that solicit user input into chat-based dialogues. Document data is first extracted to associate fields and their textual descriptions using meta-data and lightweight visual analysis. The field labels, their spatial layout, and associated text are further analyzed to group related fields into natural conversational units. These correspond to questions presented to users in chat interfaces to solicit information needed to complete the original documents and downstream processes they support. This user supplied data can be inserted into the source documents and/or in downstream databases. User studies of our tool show that it streamlines form-to-chat conversion and produces conversational dialogues of at least the same quality as a purely manual approach."
    },
    {
        "Projects": [
            "Conversational Documents"
        ],
        "keywords": [],
        "AcceptDate": "05/08/2018",
        "palwebID": "PR-18-902",
        "Venue": "DocEng 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-902/PC-18-489.pdf"
        ],
        "PublicationDate": "08/28/2018",
        "ID": "902",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Matthew Cooper"
        ],
        "Title": "SlideDiff: Animating Textual and Media Changes in Slides",
        "Abstract": "SlideDiff is a system that automatically creates an animated rendering of textual and media differences between two versions of a slide. While previous work focuses either on textual or image data, SlideDiff integrates text and media changes, as well as their interactions, e.g. adding an image forces nearby text boxes to shrink. Provided with two versions of a slide (not the full history of edits), SlideDiff detects the textual and image differences, and then animates the changes by mimicking what a user would have done, such as moving the cursor, typing text, resizing image boxes, adding images. This editing metaphor is well known to most users, helping them better understand what has changed, and fosters a sense of connection between remote workers, making them feel as if we edited together. After detection of text and image differences, the animations are rendered in HTML and CSS, including mouse cursor motion, text and image box selection and resizing, text deletion and insertion with its cursor. We discuss strategies for animating changes, in particular the importance of starting with large changes and finishing with smaller edits, and provide evidence of the utility of SlideDiff in a workplace setting."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/03/2018",
        "palwebID": "PR-18-903",
        "Venue": "UbiComp 2018 (IMWUT)",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-903/PR-18-903.pdf"
        ],
        "PublicationDate": "10/01/2018",
        "ID": "903",
        "Authors": [
            "Yanxia Zhang",
            "Jeffrey  Olenick",
            "Chu-Hsiang Chang",
            "Steve W. J.  Kozlowski",
            "Hayley  Hung"
        ],
        "Title": "TeamSense: Assessing Personal Affect and Group Cohesion in Small Teams Through Dyadic Interaction and Behavior Analysis with Wearable Sensors",
        "Abstract": "Continuous monitoring with unobtrusive wearable social sensors is becoming a popular method to assess individual affect states and team effectiveness in human research. A large number of applications have demonstrated the effectiveness of applying wearable sensing in corporate settings; for example, in short periodic social events or in a university campus. However, little is known of how we can automatically detect individual affect and group cohesion for long duration missions. Predicting negative affect states and low cohesiveness is vital for team missions. Knowing team members\u2019 negative states allows timely interventions to enhance their effectiveness. This work investigates whether sensing social interactions and individual behaviors with wearable sensors can provide insights into assessing individual affect states and group cohesion. We analyzed wearable sensor data from a team of six crew members who were deployed on a four-month simulation of a space exploration mission at a remote location. Our work proposes to recognize team members\u2019 affect states and group cohesion as a binary classification problem using novel behavior features that represent dyadic interaction and individual activities. Our method aggregates features from individual members into group levels to predict team cohesion. Our results show that the behavior features extracted from the wearable social sensors provide useful information in assessing personal affect and team cohesion. Group task cohesion can be predicted with a high performance of over 0.8 AUC. Our work demonstrates that we can extract social interactions from sensor data to predict group cohesion in longitudinal missions. We found that quantifying behavior patterns including dyadic interactions and face-to-face communications are important in assessing team process."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/11/2018",
        "palwebID": "PR-18-904",
        "Venue": "IEEE Transactions on Visualization and Computer Graphics (Proceedings of VAST 2018)",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-904/PR-18-904.pdf"
        ],
        "PublicationDate": "10/21/2018",
        "ID": "904",
        "Authors": [
            "Zhicong Lu",
            "Mingming Fan",
            "Yun Wang",
            "Jian Zhao",
            "Michelle Annett",
            "Daniel Wigdor"
        ],
        "Title": "InkPlanner: Supporting Prewriting via Intelligent Visual Diagramming",
        "Abstract": "Prewriting is the process of generating and organizing ideas before drafting a document. Although often overlooked by novice writers and writing tool developers, prewriting is a critical process that improves the quality of a final document. To better understand current prewriting practices, we first conducted interviews with writing learners and experts. Based on the learners\u2019 needs and experts\u2019 recommendations, we then designed and developed InkPlanner, a novel pen and touch visualization tool that allows writers to utilize visual diagramming for ideation during prewriting. InkPlanner further allows writers to sort their ideas into a logical and sequential narrative by using a novel widget\u2014 NarrativeLine. Using a NarrativeLine, InkPlanner can automatically generate a document outline to guide later drafting exercises. Inkplanner is powered by machine-generated semantic and structural suggestions that are curated from various texts. To qualitatively review the tool and understand how writers use InkPlanner for prewriting, two writing experts were interviewed and a user study was conducted with university students. The results demonstrated that InkPlanner encouraged writers to generate more diverse ideas and also enabled them to think more strategically about how to organize their ideas for later drafting."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/26/2018",
        "palwebID": "PR-18-905",
        "Venue": "IEEE Transactions on Visualization and Computer Graphics",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-905/PC-18-478.pdf"
        ],
        "PublicationDate": "07/31/2018",
        "ID": "905",
        "Authors": [
            "Maoyuan Sun",
            "Jian Zhao",
            "Hao Wu",
            "Kurt Luther",
            "Chris North",
            "Naren Ramakrishnan"
        ],
        "Title": "The Effect of Edge Bundling and Seriation on Sensemaking of Biclusters in Bipartite Graphs",
        "Abstract": "Exploring coordinated relationships (e.g., shared relationships between two sets of entities) is an important analytics task in a variety of real-world applications, such as discovering similarly behaved genes in bioinformatics, detecting malware collusions in cyber security, and identifying products bundles in marketing analysis. Coordinated relationships can be formalized as biclusters. In order to support visual exploration of biclusters, bipartite graphs based visualizations have been proposed, and edge bundling is used to show biclusters. However, it suffers from edge crossings due to possible overlaps of biclusters, and lacks in-depth understanding of its impact on user exploring biclusters in bipartite graphs. To address these, we propose a novel bicluster-based seriation technique that can reduce edge crossings in bipartite graphs drawing and conducted a user experiment to study the effect of edge bundling and this proposed technique on visualizing biclusters in bipartite graphs. We found that they both had impact on reducing entity visits for users exploring biclusters, and edge bundles helped them find more justified answers. Moreover, we identified four key trade-offs that inform the design of future bicluster visualizations. The study results suggest that edge bundling is critical for exploring biclusters in bipartite graphs, which helps to reduce low-level perceptual problems and support high-level inferences."
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [],
        "AcceptDate": "06/21/2018",
        "palwebID": "PR-18-906",
        "Venue": "9th International Conference on Indoor Positioning and Indoor Navigation",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-906/PC-18-506.pdf"
        ],
        "PublicationDate": "09/24/2018",
        "ID": "906",
        "Authors": [
            "Maani Ghaffari Jadidi",
            "Mitesh Patel",
            "Jaime Valls  Miro",
            "Gamini  Dissanayake",
            "Jacob Biehl",
            "Andreas Girgensohn"
        ],
        "Title": "A Radio-Inertial Localization and Tracking System with BLE\r\nBeacons Prior Maps",
        "Abstract": "In this paper, we develop a system for the lowcost indoor localization and tracking problem using radio signal strength indicator, Inertial Measurement Unit (IMU), and magnetometer sensors. We develop a novel and simplified probabilistic IMU motion model as the proposal distribution of the sequential Monte-Carlo technique to track the robot trajectory. Our algorithm can globally localize and track a robot with a priori unknown location, given an informative prior map of the Bluetooth Low Energy (BLE) beacons. Also, we formulate the problem as an optimization problem that serves as the Backend of the algorithm mentioned above (Front-end). Thus, by simultaneously solving for the robot trajectory and the map of BLE beacons, we recover a continuous and smooth trajectory of the robot, corrected locations of the BLE beacons, and the time varying IMU bias. The evaluations achieved using hardware show that through the proposed closed-loop system the localization performance can be improved; furthermore, the system becomes robust to the error in the map of beacons by feeding back the optimized map to the Front-end."
    },
    {
        "Projects": [
            "TeamSense"
        ],
        "keywords": [],
        "AcceptDate": "08/24/2018",
        "palwebID": "PR-18-907",
        "Venue": "The 8th International Conference on the Internet of Things (IoT 2018)",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-907/PR-18-907.pdf"
        ],
        "PublicationDate": "10/15/2018",
        "ID": "907",
        "Authors": [
            "Yanxia Zhang",
            "Hayley  Hung"
        ],
        "Title": "Using Topic Models to Mine Everyday Object Usage Routines through Connected IoT Sensors",
        "Abstract": "With the tremendous progress in sensing and IoT infrastructure, it is foreseeable that IoT systems will soon be available for commercial markets, such as in people's homes. In this paper, we present a deployment study using sensors attached to household objects to capture the resourcefulness of three individuals. The concept of resourcefulness \r\nhighlights the ability of humans to repurpose objects spontaneously for a different use case than was initially intended. It is a crucial element for human health and wellbeing, which is of great interest for various aspects of HCI and design research. Traditionally, resourcefulness is captured through ethnographic practice. Ethnography can only provide sparse and often short duration observations of human experience, often relying on participants being aware of and remembering behaviours or thoughts they need to report on. Our hypothesis is that resourcefulness can also be captured through continuously monitoring objects being used in everyday life. We developed a system that can record object movement continuously and deployed them in homes of three elderly people for over two weeks. We explored the use of probabilistic topic models to analyze the collected data and identify common patterns."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/23/2018",
        "palwebID": "PR-18-908",
        "Venue": "ACM ISS 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-908/PR-18-908.pdf"
        ],
        "PublicationDate": "11/25/2018",
        "ID": "908",
        "Authors": [
            "Patrick Chiu",
            "Chelhwon Kim",
            "Hideto Oda"
        ],
        "Title": "Recognizing Gestures on Projected Button Widgets with an RGB-D Camera Using a CNN ",
        "Abstract": "Projector-camera systems can turn any surface such as tabletops and walls into an interactive display.  A basic problem is to recognize the gesture actions on the projected UI widgets.  Previous approaches using finger template matching or occlusion patterns have issues with environmental lighting conditions, artifacts and noise in the video images of a projection, and inaccuracies of depth cameras. In this work, we propose a new recognizer that employs a deep neural net with an RGB-D camera; specifically, we use a CNN (Convolutional Neural Network) with optical flow computed from the color and depth channels.  We evaluated our method on a new dataset of RGB-D videos of 12 users interacting with buttons projected on a tabletop surface."
    },
    {
        "Projects": [
            "TourismKiosk"
        ],
        "keywords": [],
        "AcceptDate": "08/15/2018",
        "palwebID": "PR-18-909",
        "Venue": "CSCW2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-909/PC-18-501.pdf"
        ],
        "PublicationDate": "11/03/2018",
        "ID": "909",
        "Authors": [
            "Nami Tokunaga",
            "Jennifer Marlow",
            "Scott Carter"
        ],
        "Title": "CollaboPlanner: Integrating Mobile Phones and Public Displays for Collaborative Travel Planning",
        "Abstract": "Searching collaboratively for places of interest is a common activity that frequently occurs on individual mobile phones, or on large tourist-information displays in public places such as visitor centers or train stations. We\r\ncreated a public display system for collaborative travel planning, as well as a mobile app that can augment the display. We tested them against third-party mobile apps in a simulated travel-search task to understand how the unique features of mobile phones and large displays might be leveraged together to improve collaborative travel planning experience."
    },
    {
        "Projects": [
            "Enterprise Messaging Summarization and Visualization"
        ],
        "keywords": [],
        "AcceptDate": "08/10/2018",
        "palwebID": "PR-18-910",
        "Venue": "EMNLP 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-910/PR-18-910.pdf"
        ],
        "PublicationDate": "10/31/2018",
        "ID": "910",
        "Authors": [
            "Ryuji Kano",
            "Yasuhide Miura",
            "Motoki Taniguchi",
            "Yan-Ying Chen",
            "Francine Chen",
            "Tomoko Ohkuma"
        ],
        "Title": "Harnessing Popularity in Social Media for Extractive Summarization of Online Conversations",
        "Abstract": "We leverage a popularity measure in social media as a distant label for extractive summarization of online conversations. In social media, users can vote, share, or bookmark a post they prefer. The number of these actions is regarded as a measure of popularity. However, popularity is not solely determined by content of a post, e.g., a text or an image in a post, but is highly contaminated by its contexts, e.g., timing, and authority. We propose a disjunctive model, which computes the contribution of content and context separately. For evaluation, we build a dataset where the informativeness of a comment is annotated. We evaluate the results with ranking metrics, and show that our model outperforms the baseline model, which directly uses popularity as a measure of informativeness."
    },
    {
        "Projects": [
            "Work Reflection"
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-18-911",
        "Venue": "Studies in Conversational UX Design",
        "palwebURL": [],
        "PublicationDate": "09/04/2018",
        "ID": "911",
        "Authors": [
            "Rafal Kocielnik",
            "Gary Hsieh",
            "Daniel Avrahami"
        ],
        "Title": "Helping Users Reflect on Their Own Health-Related Behaviors",
        "Abstract": "In this chapter we discuss the use of external sources of data in designing conversational dialogues. We focus on applications in behavior change around physical activity involving dialogues that help users better understand their self-tracking data and motivate healthy behaviors. We start by introducing the areas of behavior change and personal informatics and discussing the importance of self-tracking data in these areas. We then introduce the role of reflective dialogue-based counseling systems in this domain, discuss specific value that self-tracking data can bring, and how it can be used in creating the dialogues. The core of the chapter focuses on six practical examples of design of dialogues involving self-tracking data that we either tested in our research or propose as future directions based on our experiences. We end the chapter by discussing how the design principles for involving external data in conversations can be applied to broader domains. Our goal for this chapter is to share our experiences, outline design principles, highlight several design opportunities in external data-driven computer-based conversations, and encourage the reader to explore creative ways of involving external sources of data in shaping dialogues-based interactions."
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [],
        "AcceptDate": "06/21/2018",
        "palwebID": "PR-18-912",
        "Venue": "International Conference on Indoor Positioning and Indoor Navigation",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-912/PC-18-494.pdf"
        ],
        "PublicationDate": "09/24/2018",
        "ID": "912",
        "Authors": [
            "Mitesh Patel",
            "Andreas Girgensohn",
            "Jacob Biehl"
        ],
        "Title": "Fusing Map Information with a Probabilistic Sensor\r\nModel for Indoor Localization using RF Beacons",
        "Abstract": "Accurate localization is a fundamental requirement for a variety of applications, ranging from industrial robot operations to location-powered applications on mobile devices. A key technical challenge in achieving this goal is providing a clean and reliable estimation of location from a variety of low-cost, uncalibrated sesnors. Many current techniques rely on Particle Filter (PF) based algorithms. They have proven successful at effectively fusing various sensors inputs to create meaningful location predictions. In this paper we build upon this large corpous of work. Like prior work, our technique fuses Received Signal Strength Indicator (RSSI) measurements from Bluetooth Low Energy (BLE) beacons with map information. A key contribution of our work is a new sensor model for BLE beacons that does not require the mapping from RSSI to distance. We further contribute a novel method of utilizing map information during the initialization of the system and during the resampling phase when new particles are generated. Using our proposed sensor model and map prior information the performance of the overall localization is improved by 1.20 m on comparing the 75th percentile of the cumulative distribution with traditional localization techniques."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/30/2018",
        "palwebID": "PR-18-913",
        "Venue": "IEEE AIVR 18",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-913/PC-18-510.pdf"
        ],
        "PublicationDate": "12/10/2018",
        "ID": "913",
        "Authors": [
            "Jing Qian",
            "Laurent Denoue",
            "Jacob Biehl",
            "David Shamma"
        ],
        "Title": "AI for Toggling the Linearity of Interactions in AR",
        "Abstract": "  Interaction in Augmented Reality or Mixed Reality environments is\r\n  generally classified into two modalities: linear (relative to\r\n  object) or non-linear (relative to camera). Switching between these\r\n  modes can be arduous in cases where someone's interaction with the\r\n  device is limited or restricted as is often the case in medical or\r\n  industrial applications where one's hands might be sterile or\r\n  soiled. To solve this, we present Sound-to-Experience where the\r\n  modality can be effectively toggled by a noise or sound which is\r\n  detected using a modern Artificial Intelligence deep-network\r\n  classifier.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "10/01/2018",
        "palwebID": "PR-18-914",
        "Venue": "SIGGRAPH Asia 2018",
        "palwebURL": [
            "http://palweb/files/PR/2018/PR-18-914/PC-18-505.pdf"
        ],
        "PublicationDate": "12/04/2018",
        "ID": "914",
        "Authors": [
            "Jian Zhao",
            "Francine Chen",
            "Patrick Chiu"
        ],
        "Title": "A Generic Visualization Framework for Understanding Missing Links in Bipartite Networks",
        "Abstract": "The analysis of bipartite networks is critical in many application domains, such as studying gene expression in bio-informatics. One important task is missing link prediction, which infers the exis- tence of new links based on currently observed ones. However, in practice, analysts need to utilize their domain knowledge based on the algorithm outputs in order to make sense of the results. We pro- pose a novel visual analysis framework, MissBi, which allows for examining and understanding missing links in bipartite networks. Some initial feedback from a management school professor has demonstrated the effectiveness of the tool."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "10/30/2018",
        "palwebID": "PR-19-915",
        "Venue": "ACM Transactions on Interactive Intelligent System",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-915/PC-18-496.pdf"
        ],
        "PublicationDate": "02/01/2019",
        "ID": "915",
        "Authors": [
            "Daniel Avrahami",
            "Mitesh Patel",
            "Yusuke Yamaura",
            "Sven Kratz",
            "Matthew Cooper"
        ],
        "Title": "Unobtrusive Activity Recognition and Position Estimation for Work Surfaces using RF-radar Sensing",
        "Abstract": "Activity recognition is a core component of many intelligent and context-aware systems. We present a solution for discreetly and unobtrusively recognizing common work activities above a work surface without using cameras.We demonstrate our approach, which utilizes an RF-radar sensor mounted under the work surface, in three domains; recognizing work activities at a convenience-store counter, recognizing common office deskwork activities, and estimating the position of customers in a showroom environment. Our examples illustrate potential benefits for both post-hoc business analytics and for real-time applications. Our solution was able to classify seven clerk activities with 94.9% accuracy using data collected in a lab environment and able to recognize six common deskwork activities collected in real offices with 95.3% accuracy. Using two sensors simultaneously, we demonstrate coarse position estimation around a large surface with 95.4% accuracy. We show that using multiple projections of RF signal leads to improved recognition accuracy. Finally, we show how smartwatches worn by users can be used to attribute an activity, recognized with the RF sensor, to a particular user in multi-user scenarios. We believe our solution can mitigate some of users\u2019 privacy concerns associated with cameras and is useful for a wide range of intelligent systems."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/03/2018",
        "palwebID": "PR-19-916",
        "Venue": "HCI  International 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-916/PC-18-519.pdf"
        ],
        "PublicationDate": "07/26/2019",
        "ID": "916",
        "Authors": [
            "Ryuya Sato",
            "Don Kimber",
            "Yanxia Zhang"
        ],
        "Title": "Investigating the Relationship between Connection, Agency and Autonomy for Controlling a Robot Arm for Remote Social Physical Interaction",
        "Abstract": "An open challenge in current telecommunication systems including Skype and other existing research systems is a lack of physical interaction, and consequently a restricted feeling of connection for users.  For example, those telecommunication systems cannot allow remote users to move pieces of a board game while playing with a local user. We propose that installing a robot arm and teleoperating it can address the problem by enabling remote physical interaction. We compare three methods for remote control to study the relationship between connection, and how it relates to agency and autonomy for each control scheme.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "12/07/2018",
        "palwebID": "PR-19-917",
        "Venue": "CHI 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-917/PC-18-511.pdf"
        ],
        "PublicationDate": "04/27/2019",
        "ID": "917",
        "Authors": [
            "Vincent Tseng",
            "Matthew Lee",
            "Laurent Denoue",
            "Daniel Avrahami"
        ],
        "Title": "Overcoming Distractions during Transitions from Break to Work using a Conversational Website-Blocking System",
        "Abstract": "Work breaks -- both physical and digital -- play an important role in productivity and workplace wellbeing. Yet, the growing availability of digital distractions from online content can turn breaks into prolonged \"cyberloafing\". In this paper, we present UpTime, a system that aims to support workers' transitions from breaks back to work--moments susceptible to digital distractions. Combining a browser extension and chatbot, users interact with UpTime through proactive and reactive chat prompts. By sensing transitions from inactivity, UpTime helps workers avoid distractions by automatically blocking distracting websites temporarily, while still giving them control to take necessary digital breaks. We report findings from a 3-week comparative field study with 15 workers. Our results show that automatic, temporary blocking at transition points can significantly reduce digital distractions and stress without sacrificing workers' sense of control. Our findings, however, also emphasize that overloading users' existing communication channels for chatbot interaction should be done thoughtfully."
    },
    {
        "Projects": [
            "EnterpriseCommunication",
            "MiningSocialMultimedia"
        ],
        "keywords": [],
        "AcceptDate": "01/21/2019",
        "palwebID": "PR-19-918",
        "Venue": "The Web Conference 2019 (formerly WWW)",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-918/PR-19-918.pdf"
        ],
        "PublicationDate": "04/29/2019",
        "ID": "918",
        "Authors": [
            "Koki Nagatani",
            "Qian Zhang",
            "Masahiro Sato",
            "Yan-Ying Chen",
            "Francine Chen",
            "Tomoko Ohkuma"
        ],
        "Title": "Augmenting Knowledge Tracing by Considering Forgetting Behavior",
        "Abstract": "We describe a corpus analysis method to extract terminology from a collection of technical specifications book in the field of construction. Using statistics and word n-grams analyzes, we extract the terminology of the domain and then perform pruning steps with linguistic patterns and internet queries to improve the quality of the final terminology. In this paper we specifically focus on the improvements got by applying Internet queries and patterns. These improvements are evaluated by using a manual evaluation carried out by 6 experts in the field in the case of technical specification books."
    },
    {
        "Projects": [
            "ReflectLive"
        ],
        "keywords": [],
        "AcceptDate": "12/31/2018",
        "palwebID": "PR-19-919",
        "Venue": "IEEE 2nd International Conference on Multimedia Information Processing and Retrieval",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-919/PR-19-919.pdf"
        ],
        "PublicationDate": "03/14/2019",
        "ID": "919",
        "Authors": [
            "Moritz Einfalt",
            "Matthew Lee",
            "Lyndon Kennedy",
            "Rainer Lienhart"
        ],
        "Title": "Detecting Speech Impairments from Temporal Visual Facial Features of Aphasia Patients",
        "Abstract": "We present an approach to detect speech impairments from video of people with aphasia, a neurological condition that affects the ability to comprehend and produce speech. To counter inherent privacy issues, we propose a cross-media approach using only visual facial features to detect speech properties without listening to the audio content of speech. Our method uses facial landmark detections to measure facial motion over time. We show how to detect speech and pause instances based on temporal mouth shape analysis and identify repeating mouth patterns using a dynamic warping mechanism. We relate our developed features for pause frequency, mouth pattern repetitions, and pattern variety to actual symptoms of people with aphasia in the AphasiaBank dataset. Our evaluation shows that our developed features are able to reliably differentiate dysfluent speech production of people with aphasia from those without aphasia with an accuracy of 0.86. A combination of these handcrafted features and further statistical measures on talking and repetition improves classification performance to an accuracy of 0.88."
    },
    {
        "Projects": [
            "CodedLight"
        ],
        "keywords": [],
        "AcceptDate": "02/25/2019",
        "palwebID": "PR-19-920",
        "Venue": "Internet of Things Journal",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-920/PR-19-920.pdf"
        ],
        "PublicationDate": "03/15/2019",
        "ID": "920",
        "Authors": [
            "Qiong Liu"
        ],
        "Title": "Projected Visible Light for 3D Finger Tracking and Device Augmentation on Everyday Objects",
        "Abstract": "Recent advances on the Internet of Things (IoT) lead to an explosion of physical objects being connected to the Internet. These objects sense, compute, interpret what is occurring within themselves and the world, and preferably interact with users. In this work, we present a visible light-enabled finger tracking technique allowing users to perform freestyle multi-touch gestures on everyday object\u2019s surface. By projecting encoded patterns onto an object\u2019s surface (e.g. paper, display, or table) through a projector, and localizing the user\u2019s fingers with light sensors, the proposed system offers users a richer interactive space than the device\u2019s existing interfaces. More importantly, results from our experiments indicate that this system can localize ten fingers simultaneously with an accuracy of 1.7 millimeters and an refresh rate of 84 Hz with only 31 milliseconds delay on WiFi or 23 milliseconds delay on serial communication, easily supporting multi-finger gesture interaction on everyday ob-jects. We also develop two example applications to demonstrate possible scenarios. Finally, we conduct a pre-liminary exploration of 3D depth inference using the same setup and achieve 2.43 cm depth estimation accuracy."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/11/2019",
        "palwebID": "PR-19-921",
        "Venue": "ACM TVX",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-921/PC-19-528.pdf"
        ],
        "PublicationDate": "06/05/2019",
        "ID": "921",
        "Authors": [
            "David Shamma",
            "Jennifer Marlow",
            "Laurent Denoue"
        ],
        "Title": "Interacting with Smart Consumer Cameras: Exploring Gesture, Voice, and AI Control in Video Streaming",
        "Abstract": "  Livestreaming and video calls have grown in popularity due to the\r\n  increased connectivity and advancements in mobile devices. Our  \r\n  interactions with these cameras are limited as the cameras are\r\n  either fixed or manually remote controlled.  Here we present a\r\n  Wizard-of-Oz elicitation study to inform the design of interactions\r\n  with smart 360\\textdegree\\ cameras or robotic mobile desk cameras\r\n  for use in video-conferences and live-streaming situations. \r\n  There was an overall preference\r\n  for devices that can minimize distraction as well as preferences for\r\n  devices that can show they demonstrate an understanding of\r\n  video-meeting context.   We find\r\n  participants dynamically grow with regards to the complexity of \r\n  interactions which illustrate the need for deeper event semantics \r\n  within the Camera AI. Finally, we detail interaction techniques and\r\n  design insights to inform the next generation of personal video\r\n  cameras for streaming and collaboration.\r\n"
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/15/2018",
        "palwebID": "PR-19-922",
        "Venue": "ICWSM 19",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-922/PC-18-509.pdf"
        ],
        "PublicationDate": "06/12/2019",
        "ID": "922",
        "Authors": [
            "Saeideh Bakhshi",
            "Lyndon Kennedy",
            "Eric Gilbert",
            "David Shamma"
        ],
        "Title": "Filtered Food and Nofilter Landscapes: Role of Content and Visual Effects in Photo Engagement",
        "Abstract": "  Millions of images are shared through social media every day. Yet,\r\n  we know little about how the activities and preferences of users are\r\n  dependent on the content of these images. In this paper, we seek to\r\n  understand viewers engagement with photos.  We design a quantitative\r\n  study to expand previous research on in-app visual effects (also\r\n  known as filters) through the examination of visual content\r\n  identified through computer vision. This study is based on analysis\r\n  of 4.9M Flickr images and is organized around three important\r\n  engagement factors, likes, comments and favorites.  We find that\r\n  filtered photos are not equally engaging across different categories\r\n  of content. Photos of food and people attract more engagement when\r\n  filters are used, while photos of natural scenes and photos taken at\r\n  night are more engaging when left unfiltered.  In addition to\r\n  contributing to the research around social media engagement and\r\n  photography practices, our findings offer several design\r\n  implications for mobile photo sharing platforms."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "03/21/2019",
        "palwebID": "PR-19-923",
        "Venue": "DIS",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-923/PR-19-923.pdf"
        ],
        "PublicationDate": "06/23/2019",
        "ID": "923",
        "Authors": [
            "Christine Dierk",
            "Scott Carter",
            "Patrick Chiu",
            "Tony Dunnigan",
            "Don Kimber"
        ],
        "Title": "Use Your Head! Exploring Interaction Modalities for Hat Technologies",
        "Abstract": "As our landscape of wearable technologies proliferates, we find more devices situated on our heads. However, many challenges hinder them from widespread adoption---from their awkward, bulky form factor (today's AR and VR goggles) to their socially stigmatized designs (Google Glass) and a lack of a well-developed head-based interaction design language. In this paper, we explore a socially acceptable, large, head-worn interactive wearable---a hat. We report results from a gesture elicitation study with 17 participants, extract a taxonomy of gestures, and define a set of design concerns for interactive hats. Through this lens, we detail the design and fabrication of three hat prototypes capable of sensing touch, head movements, and gestures, and including ambient displays of several types. Finally, we report an evaluation of our hat prototype and insights to inform the design of future hat technologies. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/16/2019",
        "palwebID": "PR-19-924",
        "Venue": "ACM TVX 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-924/PC-19-538.pdf"
        ],
        "PublicationDate": "06/05/2019",
        "ID": "924",
        "Authors": [
            "David Shamma",
            "Tony Dunnigan",
            "Yulius Tjahjadi",
            "John Doherty"
        ],
        "Title": "Visualizing Gaze Presence for 360\u00b0 Cameras",
        "Abstract": "Advancements in 360\u00b0 cameras have increased their related livestreams. In the case of video conferencing, 360\u00b0 cameras provide almost unrestricted visibility into a conference room for a remote viewer without the need for an articulating camera. However, local participants are left wondering if someone is connected and where remote participants might be looking. To address this, we fabricated a prototype device that shows the gaze and presence of remote 360\u00b0 viewers using a ring of LEDs that match the remote viewports. We discuss the long term use of one of the prototypes in a lecture hall and present future directions for visualizing gaze presence in 360\u00b0 video streams."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/03/2019",
        "palwebID": "PR-19-925",
        "Venue": "Personal and Ubiquitous Computing",
        "palwebURL": [],
        "PublicationDate": "05/08/2019",
        "ID": "925",
        "Authors": [
            "Jacob Biehl",
            "Adam J. Lee",
            "Gerry Filby"
        ],
        "Title": "Anchor of trust: towards collusion-resistant trusted indoor location for enterprise and industrial use",
        "Abstract": "Reliable location estimation has been a key enabler of many applications in the UbiComp space. Much progress has been made on the development of accurate of indoor location systems, which form the foundation of many interesting applications, particularly in consumer scenarios. However, many location-based applications in enterprise settings also require addressing another facet of reliability: assurance. Without having strong guarantees of a location estimate\u2019s legitimacy, stakeholders must explicitly balance the advantages offered with the risks of falsification. In this space, there are two key threats: replay attacks, where signal and sensor information is collected in one location and replayed in another to falsify a location estimation later in time; and wormhole attacks, where signal and sensor information is forwarded to a remote location by a colluding device to falsify location estimation in real-time. In this work, we improve upon the state of the art in wormhole-resistant location estimation techniques. Specifically, we present the Location Anchor, which leverages a combination of technical solutions and social contracts to provide high-assurance proofs of device location that are resistant to wormhole attacks. Unlike existing work, the Location Anchor has minimal hardware costs, supports a rich tapestry of applications, and is compatible with commodity smartphone and tablet platforms. We show that the Location Anchor can extend existing replay-resistant location systems into wormhole-resistant location systems, even in the face of very aggressive attacker assumptions. We describe the protocols underlying the Location Anchor, as well as report on the efficacy of a prototype implementation."
    },
    {
        "Projects": [
            "Enterprise Messaging Summarization and Visualization"
        ],
        "keywords": [],
        "AcceptDate": "05/13/2019",
        "palwebID": "PR-19-926",
        "Venue": "ACL",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-926/PR-19-926.pdf"
        ],
        "PublicationDate": "07/28/2019",
        "ID": "926",
        "Authors": [
            "Francine Chen",
            "Yan-Ying Chen"
        ],
        "Title": "Adversarial Domain Adaptation Using Artificial Titles for Abstractive Title Generation",
        "Abstract": "A common issue in training a deep learning, abstractive summarization model is lack of a large set of training summaries. This paper examines techniques for adapting from a labeled source domain to an unlabeled target domain in the context of an encoder-decoder model for text generation. In addition to adversarial domain adaptation (ADA), we introduce the use of artificial titles and sequential training to capture the grammatical style of the unlabeled target domain. Evaluation on adapting to/from news articles and Stack Exchange posts indicates that the use of these techniques can boost performance for both unsupervised adaptation as well as fine-tuning with limited target data."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "04/13/2019",
        "palwebID": "PR-19-927",
        "Venue": "ACM SIGMOD/PODS workshop on Human-In-the-Loop Data Analytics (HILDA)",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-927/PC-19-544.pdf"
        ],
        "PublicationDate": "06/30/2019",
        "ID": "927",
        "Authors": [
            "Chidansh Bhatt",
            "Jian Zhao",
            "Hideto Oda",
            "Francine Chen",
            "Matthew Lee"
        ],
        "Title": "OPaPi: Optimized Parts Pick-up routing for efficient manufacturing",
        "Abstract": "Manufacturing environments require changes in work procedures and settings based on changes in product demand affecting the types of products for production. Resource re-organization and time needed for worker adaptation to such frequent changes can be expensive. For example, for each change, managers in a factory may be required to manually create a list of inventory items to be picked up by workers. Uncertainty in predicting the appropriate pick-up time due to differences in worker-determined routes may make it difficult for managers to generate a fixed schedule for delivery to the assembly line. To address these problems, we propose OPaPi, a human-centric system that improves the efficiency of manufacturing by optimizing parts pick-up routes and schedules. OPaPi leverages frequent pattern mining and the traveling salesman problem solver to suggest rack placement for more efficient routes. The system further employs interactive visualization to incorporate an expert\u2019s domain knowledge and\r\ndifferent manufacturing constraints for real-time adaptive decision making."
    },
    {
        "Projects": [
            "Human Action Prediction"
        ],
        "keywords": [],
        "AcceptDate": "05/15/2019",
        "palwebID": "PR-19-928",
        "Venue": "The 17th IEEE International Conference on Embedded and Ubiquitous Computing (IEEE EUC 2019)",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-928/PR-19-928.pdf"
        ],
        "PublicationDate": "08/02/2019",
        "ID": "928",
        "Authors": [
            "Yanxia Zhang",
            "Andreas Girgensohn",
            "Yulius Tjahjadi"
        ],
        "Title": "Activity Forecasting in Routine Tasks by Combining Local Motion Trajectories and High-level Temporal Models",
        "Abstract": "Human activity forecasting from videos in routine-based tasks is an open research problem that has numerous applications in robotics, visual monitoring and skill  assessment. Currently,  many challenges  exist in activity forecasting because human actions are not fully observable from continuous recording. Additionally, a large number of human activities involve fine-grained articulated human motions that are  hard to capture using frame-level representations. To overcome thesechallenges, we propose a method that  forecasts human actions by learning the dynamics of local motion patterns extracted  from dense trajectories using longshort-term memory (LSTM). The experiments on a pub-lic dataset validated the effectiveness of our proposed method in activity forecasting and demonstrate large improvements over the baseline two stream end-to-endmodel. We also learnt that human activity forecasting benefits from learning both the short-range motion pat-terns and long-term dependencies between actions."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/08/2019",
        "palwebID": "PR-19-929",
        "Venue": "IEEE InfoVis 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-929/PC-19-541.pdf"
        ],
        "PublicationDate": "10/20/2019",
        "ID": "929",
        "Authors": [
            "Mingming Fan",
            "Ke Wu",
            "Jian Zhao",
            "Yue Li",
            "Winter Wei",
            "Khai Truong"
        ],
        "Title": "VisTA: Integrating Machine Intelligence with Visualization to Support the Investigation of Think-Aloud Sessions",
        "Abstract": "Think-aloud protocols are widely used by user experience (UX) practitioners in usability testing to uncover issues in user interface design. It is often arduous to analyze large amounts of recorded think-aloud sessions and few UX practitioners have an opportunity to get a second perspective during their analysis due to time and resource constraints. Inspired by the recent research that shows subtle verbalization and speech patterns tend to occur when users encounter usability problems, we take the first step to design and evaluate an intelligent visual analytics tool that leverages such patterns to identify usability problem encounters and present them to UX practitioners to assist their analysis. We first conducted and recorded think-aloud sessions, and then extracted textual and acoustic features from the recordings and trained machine learning (ML) models to detect problem encounters. Next, we iteratively designed and developed a visual analytics tool, VisTA, which enables dynamic investigation of think-aloud sessions with a timeline visualization of ML predictions and input features. We conducted a between-subjects laboratory study to compare three conditions, i.e., VisTA, VisTASimple (no visualization of the ML\u2019s input features), and Baseline (no ML information at all), with 30 UX professionals. The findings show that UX professionals identified more problem encounters when using VisTA than Baseline by leveraging the problem visualization as an overview, anticipations, and anchors as well as the feature visualization as a means to understand what ML considers and omits. Our findings also provide insights into how they treated ML, dealt with (dis)agreement with ML, and reviewed the videos (i.e., play, pause, and rewind)."
    },
    {
        "Projects": [
            "MultimodalLearning"
        ],
        "keywords": [],
        "AcceptDate": "06/24/2019",
        "palwebID": "PR-19-930",
        "Venue": "British Machine Vision Conference",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-930/PR-19-930.csv",
            "http://palweb/files/PR/2019/PR-19-930/PR-19-930.pdf"
        ],
        "PublicationDate": "09/01/2019",
        "ID": "930",
        "Authors": [
            "Philipp Harzig",
            "Yan-Ying Chen",
            "Francine Chen",
            "Rainer Lienhart"
        ],
        "Title": "Addressing Data Bias Problems for Chest X-ray Image Report Generation",
        "Abstract": "Automatic medical report generation from chest X-ray images is one possibility for assisting doctors to reduce their workload. However, the different patterns and data distribution of normal and abnormal cases can bias machine learning models. Previous attempts did not focus on isolating the generation of the abnormal and normal sentences in order to increase the variability of generated paragraphs. To address this, we propose to separate abnormal and normal sentence generation by using a dual word LSTM in a hierarchical LSTM model.\r\nIn addition, we conduct an analysis on the distinctiveness of generated sentences compared to the BLEU score, which increases when less distinct reports are generated. Together with this analysis, we propose a way of selecting a model that generates more distinctive sentences. We hope our findings will help to encourage the development of new metrics to better verify methods of automatic medical report generation."
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [],
        "AcceptDate": "06/30/2019",
        "palwebID": "PR-19-931",
        "Venue": "Indoor Positioning and Indoor Navigation",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-931/PR-19-931.pdf"
        ],
        "PublicationDate": "09/30/2019",
        "ID": "931",
        "Authors": [
            "Chelhwon Kim",
            "Chidansh Bhatt",
            "Mitesh Patel",
            "Don Kimber",
            "Yulius Tjahjadi"
        ],
        "Title": "InFo: Indoor localization using Fusion of Visual Information from Static and Dynamic Cameras",
        "Abstract": "Localization in an indoor and/or Global Positioning System (GPS)-denied environment is paramount to drive various applications that require locating humans and/or robots in an unknown environment. Various localization systems using different ubiquitous sensors such as camera, radio frequency, inertial measurement unit have been developed. Most of these systems cannot accommodate for scenarios which have substan- tial changes in the environment such as a large number of people (unpredictable) and sudden change in the environment floor plan (unstructured). In this paper, we propose a system, InFo that can leverage real-time visual information captured by surveillance cameras and augment that with images captured by the smart device user to deliver accurate discretized location information. Through our experiments, we demonstrate that our deep learning based InFo system provides an improvement of 10% as compared to a system that does not utilize this real-time information."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/22/2019",
        "palwebID": "PR-19-932",
        "Venue": "International Conference on the Internet of Things (IoT 2019)",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-932/PC-19-557.pdf"
        ],
        "PublicationDate": "10/22/2019",
        "ID": "932",
        "Authors": [
            "Jacob Biehl",
            "Andreas Girgensohn",
            "Mitesh Patel"
        ],
        "Title": "Achieving Accurate Room-Level Indoor Location Estimation with Emerging IoT Networks",
        "Abstract": "A motivating, core capability of most smart, Internet of Things enabled spaces (e.g., home, office, hospital, factory) is the ability to leverage context of use.  Location is a key context element; particularly indoor location. Recent advances in radio ranging technologies, such as 802.11-2016 FTM, promise the availability of low-cost, near-ubiquitous time-of-flight-based ranging estimates. In this paper, we build on prior work to enhance the technology's ability to provide useful location estimates. We demonstrate meaningful improvements in coordinate-based estimation accuracy and substantial increases in room-level estimation accuracy. Furthermore, insights gained in our real-world deployment provides important implications for future Internet of Things context applications and their supporting technology deployments such as workflow management, inventory control, or healthcare information tools."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/18/2019",
        "palwebID": "PR-19-933",
        "Venue": "IEEE VIS 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-933/PC-19-558.pdf"
        ],
        "PublicationDate": "10/20/2019",
        "ID": "933",
        "Authors": [
            "Jian Zhao",
            "Maoyuan Sun",
            "Francine Chen",
            "Patrick Chiu"
        ],
        "Title": "MissBiN: Visual Analysis of Missing Links in Bipartite Networks",
        "Abstract": "The analysis of bipartite networks is critical in a variety of application domains, such as exploring entity co-occurrences in intelligence analysis and investigating gene expression in bio-informatics. One important task is missing link prediction, which infers the existence of unseen links based on currently observed ones. In this paper, we propose MissBiN that involves analysts in the loop for making sense of link prediction results. MissBiN combines a novel method for link prediction and an interactive visualization for examining and understanding the algorithm outputs. Further, we conducted quantitative experiments to assess the performance of the proposed link prediction algorithm, and a case study to evaluate the overall effectiveness of MissBiN."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/18/2019",
        "palwebID": "PR-19-934",
        "Venue": "IEEE VIS 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-934/PC-19-562.pdf"
        ],
        "PublicationDate": "10/20/2019",
        "ID": "934",
        "Authors": [
            "Maoyuan Sun",
            "David Koop",
            "Jian Zhao",
            "Chris North",
            "Naren Ramakrishnan"
        ],
        "Title": "Interactive Bicluster Aggregation in Bipartite Graphs",
        "Abstract": "Exploring coordinated relationships is important for sensemaking of data in various fields, such as intelligence analysis. To support such investigations, visual analysis tools use biclustering to mine relationships in bipartite graphs and visualize the resulting biclusters with standard graph visualization techniques. Due to overlaps among biclusters, such visualizations can be cluttered (e.g., with many edge crossings), when there are a large number of biclusters. Prior work attempted to resolve this problem by automatically ordering nodes in a bipartite graph. However, visual clutter is still a serious problem, since the number of displayed biclusters remains unchanged. We propose bicluster aggregation as an alternative approach, and have developed two methods of interactively merging biclusters. These interactive bicluster aggregations help organize similar biclusters and reduce the number of displayed biclusters. Initial expert feedback indicates potential usefulness of these techniques in practice."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-19-935",
        "Venue": "arXiv",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-935/PC-19-564.pdf"
        ],
        "PublicationDate": "08/02/2019",
        "ID": "935",
        "Authors": [
            "Philipp Harzig",
            "Yan-Ying Chen",
            "Francine Chen",
            "Rainer Lienhart"
        ],
        "Title": "Addressing Data Bias Problems for Chest X-ray Image Report Generation",
        "Abstract": "Automatic medical report generation from chest X-ray images is one possibility for assisting doctors to reduce their workload. However, the different patterns and data distribution of normal and abnormal cases can bias machine learning models. Previous attempts did not focus on isolating the generation of the abnormal and normal sentences in order to increase the variability of generated paragraphs. To address this, we propose to separate abnormal and normal sentence generation by using a dual word LSTM in a hierarchical LSTM model. In addition, we conduct an analysis on the distinctiveness of generated sentences compared to the BLEU score, which increases when less distinct reports are generated. Together with this analysis, we propose a way of selecting a model that generates more distinctive sentences. We hope our findings will help to encourage the development of new metrics to better verify methods of automatic medical report generation."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/08/2019",
        "palwebID": "PR-19-936",
        "Venue": "ACM MM",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-936/PC-19-548.pdf"
        ],
        "PublicationDate": "10/21/2019",
        "ID": "936",
        "Authors": [
            "Scott Carter",
            "Laurent Denoue",
            "Daniel Avrahami"
        ],
        "Title": "Documenting physical objects with live video and object\r\ndetection",
        "Abstract": "Responding to requests for information from an application, a remote person, or an organization that involve documenting the presence and/or state of physical objects can lead to incomplete or inaccurate documentation. We propose a system that couples information requests with a live object recognition tool to semi-automatically catalog requested items and collect evidence of their current state."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/08/2019",
        "palwebID": "PR-19-937",
        "Venue": "ACM MM",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-937/PC-19-549.pdf"
        ],
        "PublicationDate": "10/21/2019",
        "ID": "937",
        "Authors": [
            "Laurent Denoue",
            "Scott Carter",
            "Chelhwon Kim"
        ],
        "Title": "CamaLeon: Smart Camera for Conferencing in the Wild",
        "Abstract": "Despite work on smart spaces, nowadays a lot of knowledge work happens in the wild: at home,\r\nin coffee places, trains, buses, planes, and of course in crowded open office cubicles. Conducting\r\nweb conferences in these settings creates privacy issues, and can also distract participants, leading to a perceived lack of professionalism from the remote peer(s).\r\nTo solve this common problem, we implemented CamaLeon, a browser-based tool that uses real-time machine vision powered by deep learning to change the webcam stream sent by the remote peer: specifically, CamaLeon dynamically changes the \"wild\" background into one that resembles that of the office workers.\r\nIn order to detect the background in wild settings, we designed and trained a fast UNet model on head and shoulder images. CamaLeon also uses a face detector to determine whether it should stream the person's face, depending on its location (or lack of presence). It uses face recognition to make sure it streams only a face that belongs to the user who connected to the meeting.\r\nThe system was tested during a few real video conferencing calls at our company where 2 workers are remote. Both parties felt a sense of enhanced co-presence, and the remote participants felt more professional with their background replaced."
    },
    {
        "Projects": [
            "CustomerBehaviorModeling"
        ],
        "keywords": [],
        "AcceptDate": "07/18/2019",
        "palwebID": "PR-20-938",
        "Venue": "Natural Language Engineering",
        "palwebURL": [],
        "PublicationDate": "05/15/2020",
        "ID": "938",
        "Authors": [
            "Heike Adel",
            "Francine Chen",
            "Yan-Ying Chen"
        ],
        "Title": "Tackling Challenges of Neural Purchase Stage Identification from Imbalanced Twitter Data",
        "Abstract": "Twitter and other social media platforms are often used for sharing interest in products. The identification of purchase decision stages, such as in the AIDA model (Awareness, Interest, Desire, Action),  can enable more personalized e-commerce services and a finer-grained targeting of ads than predicting purchase intent only.\r\nIn this paper, we propose and analyze neural models for identifying the purchase stage of single tweets in a user's tweet sequence. In particular, we identify three challenges of purchase stage identification: imbalanced label distribution with a high number of negative instances, limited amount of training data, and domain adaptation with no or only little target domain data.\r\n\r\nOur experiments reveal that the imbalanced label distribution is the main challenge for our models. We address it with ranking loss and perform detailed investigations of the performance of our models on the different output classes. In order to improve the generalization of the models and augment the limited  amount of training data, we examine the use of sentiment analysis as a complementary, secondary task in a multitask framework. For applying our models to tweets from another product domain, we consider two scenarios: For the first scenario without any labeled data in the target product domain, we show that learning domain-invariant representations with adversarial training is most promising while for the second scenario with a small number of labeled target examples, finetuning the source model weights performs best.\r\n\r\nFinally, we conduct several analyses, including extracting attention weights and representative phrases for the different purchase stages. The results suggest that the model is learning features indicative of purchase stages and that the confusion errors are sensible."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "",
        "palwebID": "PR-19-939",
        "Venue": "arxiv",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-939/PC-19-556.pdf"
        ],
        "PublicationDate": "06/05/2019",
        "ID": "939",
        "Authors": [
            "Sanjeev Karn",
            "Francine Chen",
            "Yan-Ying Chen",
            "Ulli Waltinger",
            "Hinrich Schuetze"
        ],
        "Title": "Generating Multi-Sentence Abstractive Summaries of Interleaved Texts",
        "Abstract": "In multi-participant postings, as in online chat conversations, several conversations or topic threads may take place concurrently. This leads to difficulties for readers reviewing the postings in not only following discussions but also in quickly identifying their essence. A two-step process, disentanglement of interleaved posts followed by summarization of each thread, addresses the issue, but disentanglement errors are propagated to the summarization step, degrading the overall performance. To address this, we propose an end-to-end trainable encoder-decoder network for summarizing interleaved posts. The interleaved posts are encoded hierarchically, i.e., word-to-word (words in a post) followed by post-to-post (posts in a channel). The decoder also generates summaries hierarchically, thread-to-thread (generate thread representations) followed by word-to-word (i.e., generate summary words). Additionally, we propose a hierarchical attention mechanism for interleaved text. Overall, our end-to-end trainable hierarchical framework enhances performance over a sequence to sequence framework by 8\\% on a synthetic interleaved texts dataset."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/23/2019",
        "palwebID": "PR-19-940",
        "Venue": "ACM ISS 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-940/PC-19-566.pdf"
        ],
        "PublicationDate": "11/10/2019",
        "ID": "940",
        "Authors": [
            "Chelhwon Kim",
            "Patrick Chiu",
            "Joseph de la Pena",
            "Laurent Denoue",
            "Jun Shingu",
            "Yulius Tjahjadi"
        ],
        "Title": "<i class=\"fa fa-trophy fa-2x\" title=\"Best Poster Award\" > </i>Toward Long Distance Tabletop Hand-Document Telepresence",
        "Abstract": "In a telepresence scenario with remote users discussing a document, it can be difficult to follow which parts are being discussed.  One way to address this is by showing the user's hand position on the document, which also enables expressive gestural communication. An important practical problem is how to capture and transmit the hand movements efficiently with high resolution document images. We propose a tabletop system with two channels that integrates document capture with a 4K video camera and hand tracking with a webcam, in which the document image and hand skeleton data are transmitted at different rates and handled by a lightweight Web browser client at remote sites. To enhance the rendering, we employ velocity based smoothing and ephemeral motion traces. We tested our prototype over long distances from USA to Japan and to Italy, and report on latency and jitter performance. Our system achieves relatively low latency over a long distance in comparison with a tele-immersive system that transmits mesh data over much shorter distances."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/23/2019",
        "palwebID": "PR-19-941",
        "Venue": "ACM ISS 2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-941/PC-19-565.pdf"
        ],
        "PublicationDate": "11/10/2019",
        "ID": "941",
        "Authors": [
            "Chelhwon Kim",
            "Patrick Chiu",
            "Yulius Tjahjadi"
        ],
        "Title": "A Web-Based Remote Assistance System with Gravity-Aware 3D Hand Gesture Visualization",
        "Abstract": "We present a remote assistance system that enables a remotely located expert to provide guidance using hand gestures to a customer who performs a physical task in a different location. The system is built on top of a web-based real-time media communication framework which allows the customer to use a commodity smartphone to send a live video feed to the expert, from which the expert can see the view of the customer's workspace and can show his/her hand gestures over the video in real-time. The expert's hand gesture is captured with a hand tracking device and visualized with a rigged 3D hand model on the live video feed. The system can be accessed via a web browser, and it does not require any app software to be installed on the customer's device. Our system supports various types of devices including smartphone, tablet, desktop PC, and smart glass. To improve the collaboration experience, the system provides a novel gravity-aware hand visualization technique. "
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "07/08/2019",
        "palwebID": "PR-19-942",
        "Venue": "ACM MM",
        "palwebURL": [],
        "PublicationDate": "10/21/2019",
        "ID": "942",
        "Authors": [
            "Susanne Boll",
            "David Shamma",
            "Tat-Seng Chua"
        ],
        "Title": "Legal and Ethical Challenges in Multimedia Research",
        "Abstract": "Multimedia research has now moved beyond laboratory experiments and is rapidly being deployed in real-life applications including advertisements, social interaction, search, security, automated driving, and healthcare. Hence, the developed algorithms now have a direct impact on the individuals using the abovementioned services and the society as a whole. While there is a huge potential to benefit the society using such technologies, there is also an urgent need to identify the checks and balances to ensure that the impact of such technologies is ethical and positive. This panel will bring together an array of experts who have experience collecting large-scale datasets, building multimedia algorithms, and deploying them in practical applications, as well as, a lawyer whose eyes have been on the fundamental rights at stake. They will lead a discussion on the ethics and lawfulness of dataset creation, licensing, privacy of individuals represented in the datasets, algorithmic transparency, algorithmic bias, explainability, and the implications of application deployment. Through an interactive process engaging the audience, the panel hopes to: increase the awareness of such concepts in the multimedia research community; initiate a discussion on community guidelines all for setting the future direction of conducting multimedia research in a lawful and ethical manner."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "08/23/2019",
        "palwebID": "PR-19-943",
        "Venue": "VDS'19",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-943/PR-19-943.pdf"
        ],
        "PublicationDate": "10/20/2019",
        "ID": "943",
        "Authors": [
            "John Wenskovitch",
            "Jian Zhao",
            "Scott Carter",
            "Matthew Cooper",
            "Chris North"
        ],
        "Title": "Albireo: An Interactive Tool for Visually Summarizing Computational Notebook Structure",
        "Abstract": "Computational notebooks have become a major medium for data exploration and insight communication in data science. Although expressive, dynamic, and flexible, in practice they are loose collections of scripts, charts, and tables that rarely tell a story or clearly represent the analysis process. This leads to a number of usability issues, particularly in the comprehension and exploration of notebooks. In this work, we design, implement, and evaluate Albireo, a visualization approach to summarize the structure of notebooks, with the goal of supporting more effective exploration and communication by displaying the dependencies and relationships between the cells of a notebook using a dynamic graph structure. We evaluate the system via a case study and expert interviews, with our results indicating that such a visualization is useful for an analyst\u2019s self-reflection during exploratory programming, and also effective for communication of narratives and collaboration between analysts."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "09/28/2019",
        "palwebID": "PR-19-944",
        "Venue": "IEEE ISM2019",
        "palwebURL": [
            "http://palweb/files/PR/2019/PR-19-944/PR-19-944.pdf"
        ],
        "PublicationDate": "12/09/2019",
        "ID": "944",
        "Authors": [
            "Qiong Liu",
            "Hao Hu",
            "Ray Yuan",
            "Yanxia Zhang",
            "Yan-Ying Chen"
        ],
        "Title": "Sensory Media Association through Reciprocating Training",
        "Abstract": "This paper reports our explorations on learning Sensory Media Association through Reciprocating Training (SMART). The proposed learning system contains two deep autoencoders, one for learning speech representations and another for learning image representations. Two deep networks are trained to bridge the latent spaces of two autoencoders, yielding representation mappings for both speech-to-image and image-to-speech. To improve feature clustering in both latent spaces, the system alternately uses one modality to guide the learning of another modality. Different from traditional technology that uses a fixed modality for supervision (e.g. using text labels for image classification), the proposed approach facilitates a machine to learn from sensory data of two or more modalities through alternating guidance among these modalities. We evaluate the proposed model with MNIST digit images and corresponding digit speeches in the Google Command Digit Dataset (GCDD). We also evaluate the model with a dataset based on COIL-100 and corresponding Watson synthesized speech. The results demonstrate the model's promising viability for sensory media association."
    },
    {
        "Projects": [
            "Work Reflection"
        ],
        "keywords": [],
        "AcceptDate": "12/09/2019",
        "palwebID": "PR-20-945",
        "Venue": "CHI 2020",
        "palwebURL": [
            "http://palweb/files/PR/2020/PR-20-945/PC-19-570.pdf"
        ],
        "PublicationDate": "04/18/2020",
        "ID": "945",
        "Authors": [
            "Daniel Avrahami",
            "Kristin Williams",
            "Matthew Lee",
            "Nami Tokunaga",
            "Yulius Tjahjadi",
            "Jennifer Marlow"
        ],
        "Title": "Celebrating Everyday Success: Improving Engagement and Motivation using a System for Recording Daily Highlights",
        "Abstract": "The demands of daily work offer few opportunities for workers to take stock of their own progress, big or small, which can lead to lower motivation, engagement, and higher risk of burnout. We present Highlight Matome, a personal online tool that encourages workers to quickly record and rank a single work highlight each day, helping them gain awareness of their own successes. We describe results from a field experiment investigating our tool's effectiveness for improving workers' engagement, perceptions, and affect. Thirty-three knowledge workers in Japan and the U.S. used Highlight Matome for six weeks. Our results show that using our tool for less than one minute each day significantly increased measures of work engagement, dedication, and positivity. A qualitative analysis of the highlights offers a window into participants' emotions and perceptions. We discuss implications for theories of inner work life and worker well-being."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "01/13/2020",
        "palwebID": "PR-20-946",
        "Venue": "IsraHCI 2020",
        "palwebURL": [
            "http://palweb/files/PR/2020/PR-20-946/PC-20-583.pdf"
        ],
        "PublicationDate": "02/27/2020",
        "ID": "946",
        "Authors": [
            "Daniel Avrahami",
            "Kristin Williams",
            "Matthew Lee",
            "Nami Tokunaga",
            "Yulius Tjahjadi",
            "Jennifer Marlow"
        ],
        "Title": "Celebrating Everyday Success: Improving Engagement and Motivation using a System for Recording Daily Highlights",
        "Abstract": "\tThe demands of daily work offer few opportunities for workers to take stock of their own progress, big or small, which can lead to lower motivation, engagement, and higher risk of burnout. We present Highlight Matome, a personal online tool that encourages workers to quickly record and rank a single work highlight each day, helping them gain awareness of their own successes. We describe results from a field experiment investigating our tool's effectiveness for improving workers' engagement, perceptions, and affect. Thirty-three knowledge workers in Japan and the U.S. used Highlight Matome for six weeks. Our results show that using our tool for less than one minute each day significantly increased measures of work engagement, dedication, and positivity. A qualitative analysis of the highlights offers a window into participants' emotions and perceptions. We discuss implications for theories of inner work life and worker well-being."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "11/27/2019",
        "palwebID": "PR-20-947",
        "Venue": "CHI 2020",
        "palwebURL": [
            "http://palweb/files/PR/2020/PR-20-947/PC-20-586.pdf"
        ],
        "PublicationDate": "04/25/2020",
        "ID": "947",
        "Authors": [
            "Jie Li",
            "Vinoba Vinayagamoorthy",
            "Raz Schwartz",
            "Pablo Cesar",
            "David Shamma",
            "Wijnand IJsselsteijn"
        ],
        "Title": "Social VR: A New Medium for Remote\r\nCommunication and Collaboration",
        "Abstract": "There is a growing need for effective remote communication,\r\nwhich has many positive societal impacts, such as reducing\r\nenvironmental pollution and travel costs, supporting\r\nrich collaboration by remotely connecting talented people.\r\nSocial Virtual Reality (VR) invites multiple users to join a\r\ncollaborative virtual environment, which creates new opportunities\r\nfor remote communication. The goal of social VR\r\nis not to completely replicate reality, but to facilitate and extend\r\nthe existing communication channels of the physical\r\nworld. Apart from the benefits provided by social VR, privacy\r\nconcerns and ethical risks are raised when the boundary\r\nbetween the real and the virtual world is blurred. This\r\nworkshop is intended to spur discussions regarding technology,\r\nevaluation protocols, application areas, research\r\nethics and legal regulations for social VR as an emerging\r\nimmersive remote communication tool."
    },
    {
        "Projects": [
            ""
        ],
        "keywords": [],
        "AcceptDate": "01/31/2020",
        "palwebID": "PR-20-948",
        "Venue": "arXiv",
        "palwebURL": [
            "http://palweb/files/PR/2020/PR-20-948/PC-18-516.pdf"
        ],
        "PublicationDate": "01/31/2020",
        "ID": "948",
        "Authors": [
            "Daniel Avrahami",
            "Scott Carter",
            "Nami Tokunaga"
        ],
        "Title": "Using Inaudible Audio to Improve Indoor-Localization- and Proximity-Aware Intelligent Applications",
        "Abstract": "While it is often critical for indoor-location- and proximity-aware applications to know whether a user is in a space or not (e.g., a specific room or office), a key challenge is that the difference between standing on one side or another of a doorway or wall is well within the error range of most RF-based approaches. In this work, we address this challenge by augmenting RF-based localization and proximity detection with active ultrasonic sensing, taking advantage of the limited propagation of sound waves. This simple and cost-effective approach can allow, for example, a Bluetooth smart-lock to discern whether a user is inside or outside their home. We describe a configurable architecture for our solution and present experiments that validate this approach but also demonstrate that different user behavior and application needs can impact system configuration decisions. Finally, we describe applications that could benefit from our solution and address privacy concerns."
    },
    {
        "Projects": [],
        "keywords": [],
        "AcceptDate": "04/17/2020",
        "palwebID": "PR-20-949",
        "Venue": "Americas Conference on Information Systems (AMCIS) ",
        "palwebURL": [
            "http://palweb/files/PR/2020/PR-20-949/PC-20-594.pdf"
        ],
        "PublicationDate": "08/12/2020",
        "ID": "949",
        "Authors": [
            "Yanxia Zhang"
        ],
        "Title": "Artificially Intelligent (AI) Drones for First Responders",
        "Abstract": ""
    },
    {
        "Projects": [
            "LoCo"
        ],
        "keywords": [],
        "AcceptDate": "05/06/2020",
        "palwebID": "PR-20-950",
        "Venue": "Personal and Ubiquitous Computing",
        "palwebURL": [
            "http://palweb/files/PR/2020/PR-20-950/PC-19-578.pdf"
        ],
        "PublicationDate": "05/31/2020",
        "ID": "950",
        "Authors": [
            "Andreas Girgensohn",
            "Mitesh Patel",
            "Jacob Biehl"
        ],
        "Title": "Indoor Localization Techniques for Enhancing IoT Applications in Social Contexts and Processes",
        "Abstract": "An important capability of most smart, Internet-of-Things-enabled spaces (e.g., office, home, hospital, factory) is the ability to leverage context of use. This can support social awareness, allowing people to interact more effectively which each other. Location is a key context element; particularly indoor location. Recent advances in radio ranging technologies, such as 802.11-2016 FTM, promise the availability of low-cost, near-ubiquitous time-of-flight-based ranging estimates. In this paper, we build on prior work to enhance this ranging technology's ability to provide useful location estimates. For further improvements, we model user-motion behavior to estimate the user motion state by taking the temporal measurements available from time-of-flight ranging. We select the velocity parameter of a particle-filter-based on this motion state. We demonstrate meaningful improvements in coordinate-based estimation accuracy and substantial increases in room-level estimation accuracy. Furthermore, insights gained in our real-world deployment provides important implications for future Internet of Things context applications and their supporting technology deployments such as social interaction, workflow management, inventory control, or healthcare information tools."
    }
]
